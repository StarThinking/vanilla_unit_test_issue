2020-12-03 07:23:56,700 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=11
Formatting using clusterid: testClusterID
2020-12-03 07:23:57,940 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:57,961 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:57,963 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:57,964 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:57,999 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:58,000 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:58,000 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:58,017 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:58,097 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:58,104 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:58,105 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:58,106 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:58,114 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:58,115 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:58
2020-12-03 07:23:58,118 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:58,120 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,124 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:58,124 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:58,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:58,151 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = true
2020-12-03 07:23:58,151 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(617)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-12-03 07:23:58,182 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:58,183 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:58,184 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:58,184 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:58,186 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:58,187 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:58,187 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:58,188 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:23:58,188 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:58,189 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:58,190 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:58,235 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:58,236 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:58,237 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:58,238 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:58,264 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:58,265 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,265 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:58,266 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:58,273 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:58,274 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:58,274 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:58,275 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:58,283 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:58,287 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:58,296 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:58,296 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:58,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:58,309 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:58,309 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:58,310 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:58,318 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:58,319 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:58,323 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:58,324 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:58,325 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:58,326 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:58,385 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:23:58,527 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:58,724 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:58,774 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:58,774 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:58,932 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:58,932 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:59,032 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:59,037 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:59,541 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:59,652 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:59,653 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:59,689 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:59,746 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@437da279] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:59,767 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:59,774 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:59,794 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4683ms
2020-12-03 07:23:59,937 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:59,941 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:59,941 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:59,953 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:59,957 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:59,958 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:59,958 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:00,001 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:00,001 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:00,014 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37041
2020-12-03 07:24:00,016 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:00,076 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e0e1046{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:00,077 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dc19a70{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:00,132 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1c852c0f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:00,146 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3b79fd76{HTTP/1.1,[http/1.1]}{localhost:37041}
2020-12-03 07:24:00,147 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5037ms
2020-12-03 07:24:00,165 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:00,166 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:00,166 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:00,167 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:00,167 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:00,167 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:00,168 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:00,168 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:00,169 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:00,170 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:00,171 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:00,171 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:00,172 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:00
2020-12-03 07:24:00,173 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:00,173 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:00,174 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:00,179 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:00,184 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:00,184 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = true
2020-12-03 07:24:00,185 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(617)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-12-03 07:24:00,186 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:00,189 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:00,190 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:00,190 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:00,191 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:00,191 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:00,191 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:00,191 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:24:00,192 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:00,192 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:00,192 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:00,193 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:00,193 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:00,194 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:00,194 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:00,196 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:00,199 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:00,200 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:00,200 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:00,200 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:00,201 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:00,201 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:00,201 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:00,202 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:00,202 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:00,203 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:00,203 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:00,204 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:00,204 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:00,204 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:00,204 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:00,205 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:00,205 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:00,206 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:00,276 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:00,405 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:00,409 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:00,409 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:00,410 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:24:00,411 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:00,448 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:00,457 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:00,457 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:00,462 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:00,463 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:24:00,682 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:00,682 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 474 msecs
2020-12-03 07:24:00,900 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:00,940 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:00,957 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:01,291 [Listener at localhost/36993] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36993 to access this namenode/service.
2020-12-03 07:24:01,296 [Listener at localhost/36993] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:01,331 [Listener at localhost/36993] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:01,364 [Listener at localhost/36993] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:01,365 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@79c97cb] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(263)) - Updating block keys
2020-12-03 07:24:01,365 [Listener at localhost/36993] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:01,386 [Listener at localhost/36993] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:24:01,386 [Listener at localhost/36993] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:01,391 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:24:01,392 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:01,392 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:01,392 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:01,392 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:01,393 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 27 msec
2020-12-03 07:24:01,452 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:01,453 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:01,458 [Listener at localhost/36993] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36993
2020-12-03 07:24:01,462 [Listener at localhost/36993] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:01,463 [Listener at localhost/36993] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:01,473 [Listener at localhost/36993] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 9 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:01,481 [CacheReplicationMonitor(272845039)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:01,484 [Listener at localhost/36993] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:01,575 [Listener at localhost/36993] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:01,620 [Listener at localhost/36993] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:01,661 [Listener at localhost/36993] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:01,668 [Listener at localhost/36993] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:01,673 [Listener at localhost/36993] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:01,679 [Listener at localhost/36993] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:01,681 [Listener at localhost/36993] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:01,687 [Listener at localhost/36993] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:01,694 [Listener at localhost/36993] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33790
2020-12-03 07:24:01,697 [Listener at localhost/36993] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:01,697 [Listener at localhost/36993] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:01,729 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:01,731 [Listener at localhost/36993] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:01,733 [Listener at localhost/36993] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:01,744 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:01,748 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:01,749 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:01,749 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:01,749 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:01,754 [Listener at localhost/36993] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42448
2020-12-03 07:24:01,754 [Listener at localhost/36993] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:01,757 [Listener at localhost/36993] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@569bf9eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:01,757 [Listener at localhost/36993] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@274872f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:01,766 [Listener at localhost/36993] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fcbe147{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:01,767 [Listener at localhost/36993] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@235f4c10{HTTP/1.1,[http/1.1]}{localhost:42448}
2020-12-03 07:24:01,768 [Listener at localhost/36993] INFO  server.Server (Server.java:doStart(419)) - Started @6658ms
2020-12-03 07:24:02,216 [Listener at localhost/36993] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40698
2020-12-03 07:24:02,218 [Listener at localhost/36993] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:02,218 [Listener at localhost/36993] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:02,217 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56b78e55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:02,492 [Listener at localhost/36993] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:02,493 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:02,500 [Listener at localhost/37687] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37687
2020-12-03 07:24:02,528 [Listener at localhost/37687] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:02,531 [Listener at localhost/37687] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:02,569 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:02,585 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:02,586 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:02,631 [Listener at localhost/37687] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:02,634 [Listener at localhost/37687] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:02,645 [Listener at localhost/37687] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:02,647 [Listener at localhost/37687] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:02,650 [Listener at localhost/37687] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:02,650 [Listener at localhost/37687] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:02,651 [Listener at localhost/37687] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:02,651 [Listener at localhost/37687] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:02,652 [Listener at localhost/37687] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:02,653 [Listener at localhost/37687] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33065
2020-12-03 07:24:02,654 [Listener at localhost/37687] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:02,654 [Listener at localhost/37687] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:02,660 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:02,662 [Listener at localhost/37687] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:02,681 [Listener at localhost/37687] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:02,682 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:02,686 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:02,687 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:02,688 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:02,688 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:02,689 [Listener at localhost/37687] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40243
2020-12-03 07:24:02,690 [Listener at localhost/37687] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:02,693 [Listener at localhost/37687] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71e9a896{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:02,694 [Listener at localhost/37687] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@408b35bf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:02,705 [Listener at localhost/37687] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@615f972{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:02,707 [Listener at localhost/37687] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@285f09de{HTTP/1.1,[http/1.1]}{localhost:40243}
2020-12-03 07:24:02,707 [Listener at localhost/37687] INFO  server.Server (Server.java:doStart(419)) - Started @7597ms
2020-12-03 07:24:02,842 [Listener at localhost/37687] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33798
2020-12-03 07:24:02,842 [Listener at localhost/37687] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:02,842 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31500940] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:02,843 [Listener at localhost/37687] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:02,847 [Listener at localhost/37687] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:02,860 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:02,864 [Listener at localhost/44980] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44980
2020-12-03 07:24:02,870 [Listener at localhost/44980] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:02,871 [Listener at localhost/44980] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:02,872 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:02,874 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:02,874 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:02,879 [Listener at localhost/44980] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:02,881 [Listener at localhost/44980] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:02,882 [Listener at localhost/44980] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:02,884 [Listener at localhost/44980] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:02,885 [Listener at localhost/44980] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:02,886 [Listener at localhost/44980] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:02,886 [Listener at localhost/44980] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:02,887 [Listener at localhost/44980] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:02,887 [Listener at localhost/44980] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:02,888 [Listener at localhost/44980] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42513
2020-12-03 07:24:02,889 [Listener at localhost/44980] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:02,889 [Listener at localhost/44980] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:02,891 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:02,893 [Listener at localhost/44980] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:02,894 [Listener at localhost/44980] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:02,894 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:02,898 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:02,899 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:02,899 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:02,899 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:02,901 [Listener at localhost/44980] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35234
2020-12-03 07:24:02,901 [Listener at localhost/44980] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:02,905 [Listener at localhost/44980] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@425357dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:02,906 [Listener at localhost/44980] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@210386e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:02,912 [Listener at localhost/44980] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5528a42c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:02,913 [Listener at localhost/44980] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a551a63{HTTP/1.1,[http/1.1]}{localhost:35234}
2020-12-03 07:24:02,914 [Listener at localhost/44980] INFO  server.Server (Server.java:doStart(419)) - Started @7804ms
2020-12-03 07:24:03,050 [Listener at localhost/44980] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37071
2020-12-03 07:24:03,052 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edb61b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,052 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,052 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,052 [Listener at localhost/44980] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,052 [Listener at localhost/44980] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,053 [Listener at localhost/44980] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,054 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,054 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,054 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,061 [Listener at localhost/35625] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35625
2020-12-03 07:24:03,069 [Listener at localhost/35625] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,070 [Listener at localhost/35625] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,071 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:03,072 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,072 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,078 [Listener at localhost/35625] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:03,080 [Listener at localhost/35625] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:03,080 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,081 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,083 [Listener at localhost/35625] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:03,085 [Listener at localhost/35625] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,086 [Listener at localhost/35625] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,086 [Listener at localhost/35625] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:03,087 [Listener at localhost/35625] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,087 [Listener at localhost/35625] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,087 [Listener at localhost/35625] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,088 [Listener at localhost/35625] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39759
2020-12-03 07:24:03,088 [Listener at localhost/35625] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,089 [Listener at localhost/35625] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,091 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,093 [Listener at localhost/35625] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,094 [Listener at localhost/35625] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:03,094 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,099 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,100 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:03,100 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,100 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,101 [Listener at localhost/35625] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45182
2020-12-03 07:24:03,101 [Listener at localhost/35625] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,103 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,103 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,103 [Listener at localhost/35625] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ecf9fb3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,104 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,104 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,105 [Listener at localhost/35625] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27f9e982{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,106 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:24:03,106 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:24:03,113 [Listener at localhost/35625] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@588ab592{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:03,115 [Listener at localhost/35625] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c8b96ec{HTTP/1.1,[http/1.1]}{localhost:45182}
2020-12-03 07:24:03,115 [Listener at localhost/35625] INFO  server.Server (Server.java:doStart(419)) - Started @8005ms
2020-12-03 07:24:03,184 [Listener at localhost/35625] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37352
2020-12-03 07:24:03,185 [Listener at localhost/35625] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,185 [Listener at localhost/35625] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,185 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d8f2f3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,186 [Listener at localhost/35625] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,187 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,191 [Listener at localhost/35952] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35952
2020-12-03 07:24:03,195 [Listener at localhost/35952] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,196 [Listener at localhost/35952] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,197 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:03,198 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,199 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,202 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,202 [Listener at localhost/35952] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:03,202 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,204 [Listener at localhost/35952] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:03,204 [Listener at localhost/35952] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:03,205 [Listener at localhost/35952] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,207 [Listener at localhost/35952] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,207 [Listener at localhost/35952] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:03,208 [Listener at localhost/35952] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,208 [Listener at localhost/35952] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,208 [Listener at localhost/35952] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,210 [Listener at localhost/35952] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37878
2020-12-03 07:24:03,210 [Listener at localhost/35952] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,210 [Listener at localhost/35952] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,212 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,214 [Listener at localhost/35952] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,214 [Listener at localhost/35952] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:03,215 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,217 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,217 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:03,218 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,218 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,219 [Listener at localhost/35952] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46661
2020-12-03 07:24:03,219 [Listener at localhost/35952] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,221 [Listener at localhost/35952] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58783f6c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,222 [Listener at localhost/35952] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@512d92b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,232 [Listener at localhost/35952] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dfd5f51{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:03,233 [Listener at localhost/35952] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:46661}
2020-12-03 07:24:03,234 [Listener at localhost/35952] INFO  server.Server (Server.java:doStart(419)) - Started @8123ms
2020-12-03 07:24:03,252 [Listener at localhost/35952] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42356
2020-12-03 07:24:03,252 [Listener at localhost/35952] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,253 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3abd581e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,253 [Listener at localhost/35952] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,254 [Listener at localhost/35952] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,255 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,259 [Listener at localhost/42066] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42066
2020-12-03 07:24:03,264 [Listener at localhost/42066] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,264 [Listener at localhost/42066] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,265 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:03,267 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,268 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,273 [Listener at localhost/42066] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:03,276 [Listener at localhost/42066] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:03,277 [Listener at localhost/42066] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:03,277 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,278 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,280 [Listener at localhost/42066] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,281 [Listener at localhost/42066] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,281 [Listener at localhost/42066] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:03,282 [Listener at localhost/42066] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,282 [Listener at localhost/42066] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,283 [Listener at localhost/42066] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,284 [Listener at localhost/42066] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37501
2020-12-03 07:24:03,284 [Listener at localhost/42066] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,284 [Listener at localhost/42066] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,286 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,289 [Listener at localhost/42066] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,290 [Listener at localhost/42066] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:03,291 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,294 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,296 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:03,296 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,296 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,298 [Listener at localhost/42066] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45924
2020-12-03 07:24:03,298 [Listener at localhost/42066] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,301 [Listener at localhost/42066] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e53135d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,302 [Listener at localhost/42066] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a7704c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,304 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,305 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,305 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:24:03,314 [Listener at localhost/42066] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@26d10f2e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:03,316 [Listener at localhost/42066] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@10ad20cb{HTTP/1.1,[http/1.1]}{localhost:45924}
2020-12-03 07:24:03,316 [Listener at localhost/42066] INFO  server.Server (Server.java:doStart(419)) - Started @8206ms
2020-12-03 07:24:03,345 [Listener at localhost/42066] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41528
2020-12-03 07:24:03,346 [Listener at localhost/42066] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,346 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c282004] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,346 [Listener at localhost/42066] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,346 [Listener at localhost/42066] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,349 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,354 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38374
2020-12-03 07:24:03,360 [Listener at localhost/38374] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,361 [Listener at localhost/38374] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,362 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:03,363 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,363 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,367 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,367 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,370 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,370 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-06c4601f-c029-49a4-9490-379500980798 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:24:03,371 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,371 [Listener at localhost/38374] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:03,372 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,372 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:24:03,373 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,376 [Listener at localhost/38374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:03,376 [Listener at localhost/38374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:03,378 [Listener at localhost/38374] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,379 [Listener at localhost/38374] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,379 [Listener at localhost/38374] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:03,380 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,380 [Listener at localhost/38374] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,380 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,381 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44498
2020-12-03 07:24:03,382 [Listener at localhost/38374] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,382 [Listener at localhost/38374] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,383 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,386 [Listener at localhost/38374] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,386 [Listener at localhost/38374] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:03,387 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,390 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,391 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:03,391 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,391 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,392 [Listener at localhost/38374] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 32840
2020-12-03 07:24:03,393 [Listener at localhost/38374] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,395 [Listener at localhost/38374] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f325091{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,396 [Listener at localhost/38374] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77b325b3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,405 [Listener at localhost/38374] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a34b7b8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:03,406 [Listener at localhost/38374] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58cd06cb{HTTP/1.1,[http/1.1]}{localhost:32840}
2020-12-03 07:24:03,407 [Listener at localhost/38374] INFO  server.Server (Server.java:doStart(419)) - Started @8297ms
2020-12-03 07:24:03,431 [Listener at localhost/38374] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36504
2020-12-03 07:24:03,432 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,432 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64b31700] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,432 [Listener at localhost/38374] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,433 [Listener at localhost/38374] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,434 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,439 [Listener at localhost/38794] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38794
2020-12-03 07:24:03,445 [Listener at localhost/38794] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,445 [Listener at localhost/38794] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,446 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:03,448 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,449 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,457 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,456 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,449 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,462 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,462 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:24:03,476 [Listener at localhost/38794] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:03,479 [Listener at localhost/38794] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:03,479 [Listener at localhost/38794] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:03,480 [Listener at localhost/38794] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,481 [Listener at localhost/38794] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,481 [Listener at localhost/38794] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:03,482 [Listener at localhost/38794] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,482 [Listener at localhost/38794] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,482 [Listener at localhost/38794] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,483 [Listener at localhost/38794] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40921
2020-12-03 07:24:03,483 [Listener at localhost/38794] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,483 [Listener at localhost/38794] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,484 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,487 [Listener at localhost/38794] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:03,488 [Listener at localhost/38794] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:03,489 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:03,492 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:03,493 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:03,493 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:03,493 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:03,495 [Listener at localhost/38794] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36477
2020-12-03 07:24:03,495 [Listener at localhost/38794] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:03,500 [Listener at localhost/38794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fb68ec6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:03,501 [Listener at localhost/38794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3add81c4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:03,510 [Listener at localhost/38794] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7ee55e70{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:03,510 [Listener at localhost/38794] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3fcdcf{HTTP/1.1,[http/1.1]}{localhost:36477}
2020-12-03 07:24:03,511 [Listener at localhost/38794] INFO  server.Server (Server.java:doStart(419)) - Started @8401ms
2020-12-03 07:24:03,518 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,519 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,518 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,519 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,520 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0ea987f6-e383-4d5a-a033-5af60ff63c64 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:24:03,520 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,520 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:24:03,521 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,521 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2a69a8b0-47db-4b19-946d-a1505cf0911a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:24:03,567 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,568 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,570 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6897f411-d91f-4418-a84f-f8abaa165629 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:24:03,676 [Listener at localhost/38794] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38290
2020-12-03 07:24:03,676 [Listener at localhost/38794] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:03,676 [Listener at localhost/38794] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:03,676 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46292372] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:03,677 [Listener at localhost/38794] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:03,678 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:03,681 [Listener at localhost/37529] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37529
2020-12-03 07:24:03,686 [Listener at localhost/37529] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:03,687 [Listener at localhost/37529] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:03,688 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:03,693 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:03,693 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:03,706 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,706 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:03,706 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,707 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:03,712 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:03,713 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:03,790 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:24:03,790 [Listener at localhost/37529] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:03,792 [Listener at localhost/37529] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:03,793 [Listener at localhost/37529] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:03,794 [Listener at localhost/37529] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:03,798 [Listener at localhost/37529] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,798 [Listener at localhost/37529] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:03,799 [Listener at localhost/37529] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:03,799 [Listener at localhost/37529] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:03,799 [Listener at localhost/37529] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:03,800 [Listener at localhost/37529] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38540
2020-12-03 07:24:03,801 [Listener at localhost/37529] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:03,801 [Listener at localhost/37529] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:03,801 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-893e3d81-c846-44ce-8672-82a1201e27e5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:24:04,026 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,038 [Listener at localhost/37529] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:04,039 [Listener at localhost/37529] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:04,039 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,088 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:04,088 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:04,088 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:04,089 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:04,149 [Listener at localhost/37529] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35880
2020-12-03 07:24:04,149 [Listener at localhost/37529] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:04,156 [Listener at localhost/37529] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17f9344b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:04,158 [Listener at localhost/37529] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54e81b21{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:04,167 [Listener at localhost/37529] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@199e4c2b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:04,169 [Listener at localhost/37529] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6e0d4a8{HTTP/1.1,[http/1.1]}{localhost:35880}
2020-12-03 07:24:04,169 [Listener at localhost/37529] INFO  server.Server (Server.java:doStart(419)) - Started @9059ms
2020-12-03 07:24:04,192 [Listener at localhost/37529] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37704
2020-12-03 07:24:04,193 [Listener at localhost/37529] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:04,193 [Listener at localhost/37529] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:04,193 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@30272916] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:04,194 [Listener at localhost/37529] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:04,196 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:04,200 [Listener at localhost/34574] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34574
2020-12-03 07:24:04,211 [Listener at localhost/34574] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:04,211 [Listener at localhost/34574] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:04,214 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:04,216 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:04,217 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:04,225 [Listener at localhost/34574] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:24:04,225 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:04,226 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:04,228 [Listener at localhost/34574] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:24:04,228 [Listener at localhost/34574] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:24:04,230 [Listener at localhost/34574] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:04,237 [Listener at localhost/34574] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:04,237 [Listener at localhost/34574] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:04,238 [Listener at localhost/34574] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:04,238 [Listener at localhost/34574] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:04,239 [Listener at localhost/34574] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:04,239 [Listener at localhost/34574] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34475
2020-12-03 07:24:04,240 [Listener at localhost/34574] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:04,240 [Listener at localhost/34574] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:04,255 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,257 [Listener at localhost/34574] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:04,258 [Listener at localhost/34574] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:04,258 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,260 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:04,262 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:04,262 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:04,263 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:04,264 [Listener at localhost/34574] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41513
2020-12-03 07:24:04,266 [Listener at localhost/34574] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:04,270 [Listener at localhost/34574] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22175d4f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:04,272 [Listener at localhost/34574] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b809711{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:04,280 [Listener at localhost/34574] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@405325cf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:04,280 [Listener at localhost/34574] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3e1162e7{HTTP/1.1,[http/1.1]}{localhost:41513}
2020-12-03 07:24:04,282 [Listener at localhost/34574] INFO  server.Server (Server.java:doStart(419)) - Started @9172ms
2020-12-03 07:24:04,283 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:04,283 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:04,283 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:04,284 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:04,303 [Listener at localhost/34574] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34450
2020-12-03 07:24:04,304 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c2f1700] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:04,304 [Listener at localhost/34574] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:04,304 [Listener at localhost/34574] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:04,305 [Listener at localhost/34574] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:04,305 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:04,309 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36510
2020-12-03 07:24:04,314 [Listener at localhost/36510] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:04,315 [Listener at localhost/36510] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:04,315 [Thread-259] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:04,319 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:04,319 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:04,322 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5be1416f-8d13-41e4-a78b-2782ae34ff50 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:24:04,322 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:24:04,323 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,323 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,324 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,324 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,324 [Thread-259] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:04,325 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:04,325 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:04,325 [Thread-259] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:04,325 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:04,325 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:04,328 [Listener at localhost/36510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:24:04,329 [Listener at localhost/36510] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:24:04,330 [Listener at localhost/36510] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:24:04,331 [Listener at localhost/36510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:04,332 [Listener at localhost/36510] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:04,332 [Listener at localhost/36510] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:04,333 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:04,333 [Listener at localhost/36510] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:04,333 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:04,334 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45861
2020-12-03 07:24:04,334 [Listener at localhost/36510] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:04,334 [Listener at localhost/36510] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:04,335 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,337 [Listener at localhost/36510] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:04,338 [Listener at localhost/36510] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:04,338 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:04,340 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:04,340 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:04,340 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:04,341 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:04,341 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39717
2020-12-03 07:24:04,342 [Listener at localhost/36510] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:04,343 [Listener at localhost/36510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4163f1cd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:04,343 [Listener at localhost/36510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e681bc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:04,349 [Listener at localhost/36510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@60297f36{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:04,351 [Listener at localhost/36510] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1bf0f6f6{HTTP/1.1,[http/1.1]}{localhost:39717}
2020-12-03 07:24:04,351 [Listener at localhost/36510] INFO  server.Server (Server.java:doStart(419)) - Started @9241ms
2020-12-03 07:24:04,372 [Listener at localhost/36510] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38820
2020-12-03 07:24:04,373 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@df4b72] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:04,373 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:04,373 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:04,374 [Listener at localhost/36510] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:04,375 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:04,380 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42769
2020-12-03 07:24:04,390 [Listener at localhost/42769] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:04,390 [Listener at localhost/42769] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:04,391 [Thread-281] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993 starting to offer service
2020-12-03 07:24:04,393 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:04,394 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:04,399 [Thread-281] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36993
2020-12-03 07:24:04,403 [Thread-281] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:04,492 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:04,493 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:04,535 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9b21bacd-350f-4982-b7a8-2cc941879e51 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:24:04,535 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,535 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,535 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:04,535 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:04,651 [Thread-281] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:04,651 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:04,651 [Thread-259] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:04,652 [Thread-281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:04,652 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:04,652 [Thread-259] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:04,654 [Thread-281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 
2020-12-03 07:24:04,655 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a050ede7-f836-4855-a01b-8ee70d50f317 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:24:04,655 [Thread-259] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-555897bc-5fa7-4dd3-8790-b724d53839c8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:24:04,665 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,665 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,665 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,665 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:04,665 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:04,665 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:04,665 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:04,665 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:05,181 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,182 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,182 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:05,182 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:05,916 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,967 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:05,916 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,916 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,981 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:05,981 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,981 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,981 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:05,982 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:05,982 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:05,982 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:05,982 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-31c6b034-09fb-4323-bb55-99fcee17da60 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:24:05,982 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:05,982 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:05,982 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:06,151 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,151 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,151 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:06,152 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:06,152 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,152 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,152 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:06,152 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:06,310 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:06,415 [Thread-259] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:06,416 [Thread-259] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:06,416 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:06,416 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:06,417 [Thread-281] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 17012@87d415f0d30c
2020-12-03 07:24:06,417 [Thread-281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 is not formatted for namespace 1443257071. Formatting...
2020-12-03 07:24:06,453 [Thread-259] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:24:06,453 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,453 [Thread-281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6ed95eab-bbcb-4e63-9776-276535f797bd for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 
2020-12-03 07:24:06,453 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,454 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:06,454 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:06,454 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:24:06,680 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:06,680 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:06,690 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,690 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,690 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,690 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,691 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:06,691 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:06,691 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:06,691 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:06,838 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:06,955 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,955 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:06,956 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:06,956 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:07,132 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b4c365af-82dd-413b-b8c8-0985174a0d5a
2020-12-03 07:24:07,286 [IPC Server handler 9 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,295 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,295 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:07,361 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:07,398 [IPC Server handler 4 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,399 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,400 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:07,441 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,441 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,441 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,441 [Thread-259] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,441 [Thread-281] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,441 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,442 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:07,442 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:07,442 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:07,441 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:07,442 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:07,442 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:07,502 [IPC Server handler 8 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,503 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,503 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:07,580 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e7524eb2-d776-49a1-9c40-f1cb575f4069
2020-12-03 07:24:07,580 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:07,580 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4b9cbc85-1163-4e5a-b3f3-54dab64913c8
2020-12-03 07:24:07,605 [IPC Server handler 6 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,606 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,606 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:07,709 [IPC Server handler 5 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,710 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,711 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:07,779 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,780 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:07,780 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:07,780 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:07,852 [IPC Server handler 3 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,854 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,854 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:07,857 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc
2020-12-03 07:24:07,857 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:24:07,858 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a
2020-12-03 07:24:07,858 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127
2020-12-03 07:24:07,860 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:24:07,861 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:24:07,862 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f
2020-12-03 07:24:07,863 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:24:07,867 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0ea987f6-e383-4d5a-a033-5af60ff63c64
2020-12-03 07:24:07,868 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:24:07,870 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6897f411-d91f-4418-a84f-f8abaa165629
2020-12-03 07:24:07,871 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:24:07,900 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 77b52241-cc52-4fd8-a2fc-0aaeec6f3607
2020-12-03 07:24:07,900 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:07,903 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-06c4601f-c029-49a4-9490-379500980798
2020-12-03 07:24:07,903 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:24:07,905 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f
2020-12-03 07:24:07,905 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:24:07,957 [IPC Server handler 9 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:07,958 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:07,958 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,045 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,045 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,045 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,045 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,052 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:08,055 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:08,056 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:08,057 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:08,060 [IPC Server handler 0 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,061 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,061 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,066 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:08,066 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:08,066 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:08,066 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:08,068 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:08,068 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:08,068 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:08,068 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:08,070 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:08,070 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:08,069 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:08,069 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:08,071 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,071 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,071 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,071 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,072 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:08,072 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:08,072 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:08,073 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:08,073 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:08,073 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:08,073 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:08,073 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:08,168 [IPC Server handler 4 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,169 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,169 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,239 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 166ms
2020-12-03 07:24:08,241 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 167ms
2020-12-03 07:24:08,245 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 172ms
2020-12-03 07:24:08,245 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 172ms
2020-12-03 07:24:08,246 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 174ms
2020-12-03 07:24:08,246 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 173ms
2020-12-03 07:24:08,249 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:08,249 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:08,249 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,249 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,252 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:24:08,252 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:24:08,252 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 4ms
2020-12-03 07:24:08,253 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 179ms
2020-12-03 07:24:08,253 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 180ms
2020-12-03 07:24:08,253 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 182ms
2020-12-03 07:24:08,253 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 182ms
2020-12-03 07:24:08,253 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:08,253 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:08,254 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,254 [Thread-323] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,254 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:08,253 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:08,254 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,254 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,254 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 182ms
2020-12-03 07:24:08,256 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:24:08,256 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 184ms
2020-12-03 07:24:08,254 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-12-03 07:24:08,254 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:08,256 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:24:08,258 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:08,254 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:08,255 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 2ms
2020-12-03 07:24:08,259 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:08,259 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,259 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 5ms
2020-12-03 07:24:08,259 [Thread-326] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,259 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:24:08,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:08,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-6897f411-d91f-4418-a84f-f8abaa165629): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,259 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 6ms
2020-12-03 07:24:08,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,260 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:24:08,260 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:08,260 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 3ms
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-06c4601f-c029-49a4-9490-379500980798): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,263 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0ea987f6-e383-4d5a-a033-5af60ff63c64): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,272 [IPC Server handler 2 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,273 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,273 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,352 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6
2020-12-03 07:24:08,355 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821
2020-12-03 07:24:08,355 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:24:08,358 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-893e3d81-c846-44ce-8672-82a1201e27e5
2020-12-03 07:24:08,359 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:24:08,360 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,361 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:08,361 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:08,361 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:08,362 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:08,363 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,493 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:08,509 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:08,510 [IPC Server handler 6 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,514 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,515 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,531 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 78587f8e-70ad-4e7b-8442-08f4c20524fa
2020-12-03 07:24:08,531 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:08,531 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,531 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,531 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,532 [Thread-259] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,532 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,532 [Thread-281] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,532 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:08,532 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:08,532 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1172035344-172.17.0.2-1606980238362 is not formatted. Formatting ...
2020-12-03 07:24:08,533 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:08,532 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:08,533 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1172035344-172.17.0.2-1606980238362 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1172035344-172.17.0.2-1606980238362/current
2020-12-03 07:24:08,535 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d
2020-12-03 07:24:08,536 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:24:08,538 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5be1416f-8d13-41e4-a78b-2782ae34ff50
2020-12-03 07:24:08,538 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:24:08,540 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,541 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:08,542 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:08,542 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:08,542 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:08,543 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,544 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:08,544 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:08,618 [IPC Server handler 5 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,618 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,619 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,716 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d4151987-ce5a-49a4-8bb1-a5a8fd05932f
2020-12-03 07:24:08,721 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2a69a8b0-47db-4b19-946d-a1505cf0911a
2020-12-03 07:24:08,721 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:24:08,722 [IPC Server handler 3 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,726 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,726 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,726 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a050ede7-f836-4855-a01b-8ee70d50f317
2020-12-03 07:24:08,727 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:24:08,728 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:08,729 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:08,730 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:08,730 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:08,730 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:08,731 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,731 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:08,731 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:08,783 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 290ms
2020-12-03 07:24:08,786 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 277ms
2020-12-03 07:24:08,787 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 424ms
2020-12-03 07:24:08,789 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:08,789 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:08,789 [Thread-352] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,790 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:24:08,789 [Thread-351] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,789 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 245ms
2020-12-03 07:24:08,789 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 245ms
2020-12-03 07:24:08,836 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 293ms
2020-12-03 07:24:08,836 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 47ms
2020-12-03 07:24:08,836 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 48ms
2020-12-03 07:24:08,837 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:08,837 [IPC Server handler 9 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,837 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:08,837 [Thread-353] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,837 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:08,837 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:08,837 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,838 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,837 [Thread-354] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,837 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:24:08,837 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,838 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:24:08,838 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-893e3d81-c846-44ce-8672-82a1201e27e5): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,838 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 2ms
2020-12-03 07:24:08,839 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:08,839 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:08,840 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5be1416f-8d13-41e4-a78b-2782ae34ff50): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,840 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,950 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 219ms
2020-12-03 07:24:08,957 [IPC Server handler 0 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:08,959 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:08,959 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:08,970 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 239ms
2020-12-03 07:24:08,970 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 239ms
2020-12-03 07:24:08,971 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:08,971 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:08,971 [Thread-361] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,971 [Thread-362] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:08,971 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-12-03 07:24:08,971 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:24:08,972 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 2ms
2020-12-03 07:24:08,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:08,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:08,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-2a69a8b0-47db-4b19-946d-a1505cf0911a): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:08,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-a050ede7-f836-4855-a01b-8ee70d50f317): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,062 [IPC Server handler 4 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,063 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,063 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f): no suitable block pools found to scan.  Waiting 1814399149 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-06c4601f-c029-49a4-9490-379500980798): no suitable block pools found to scan.  Waiting 1814399149 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f): no suitable block pools found to scan.  Waiting 1814399149 ms.
2020-12-03 07:24:09,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0ea987f6-e383-4d5a-a033-5af60ff63c64): no suitable block pools found to scan.  Waiting 1814399150 ms.
2020-12-03 07:24:09,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-893e3d81-c846-44ce-8672-82a1201e27e5): no suitable block pools found to scan.  Waiting 1814399725 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-6897f411-d91f-4418-a84f-f8abaa165629): no suitable block pools found to scan.  Waiting 1814399143 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5be1416f-8d13-41e4-a78b-2782ae34ff50): no suitable block pools found to scan.  Waiting 1814399728 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc): no suitable block pools found to scan.  Waiting 1814399148 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821): no suitable block pools found to scan.  Waiting 1814399726 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d): no suitable block pools found to scan.  Waiting 1814399728 ms.
2020-12-03 07:24:09,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127): no suitable block pools found to scan.  Waiting 1814399143 ms.
2020-12-03 07:24:09,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a): no suitable block pools found to scan.  Waiting 1814399150 ms.
2020-12-03 07:24:09,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-2a69a8b0-47db-4b19-946d-a1505cf0911a): no suitable block pools found to scan.  Waiting 1814399860 ms.
2020-12-03 07:24:09,112 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-a050ede7-f836-4855-a01b-8ee70d50f317): no suitable block pools found to scan.  Waiting 1814399860 ms.
2020-12-03 07:24:09,166 [IPC Server handler 2 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,167 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,167 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,171 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b375db5b-90a2-43b2-8010-a0a075e864b6
2020-12-03 07:24:09,171 [Thread-281] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:09,171 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:09,171 [Thread-259] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1443257071;bpid=BP-1172035344-172.17.0.2-1606980238362;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1443257071;c=1606980238362;bpid=BP-1172035344-172.17.0.2-1606980238362;dnuuid=null
2020-12-03 07:24:09,173 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989
2020-12-03 07:24:09,173 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:24:09,176 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-31c6b034-09fb-4323-bb55-99fcee17da60
2020-12-03 07:24:09,176 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:24:09,178 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:09,179 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:09,180 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:09,180 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:09,181 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:09,181 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,181 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:09,181 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:09,207 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:52 AM with interval of 21600000ms
2020-12-03 07:24:09,207 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:51 AM with interval of 21600000ms
2020-12-03 07:24:09,207 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:51 AM with interval of 21600000ms
2020-12-03 07:24:09,207 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:17 PM with interval of 21600000ms
2020-12-03 07:24:09,207 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:25 AM with interval of 21600000ms
2020-12-03 07:24:09,207 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:54 AM with interval of 21600000ms
2020-12-03 07:24:09,209 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:04 PM with interval of 21600000ms
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b4c365af-82dd-413b-b8c8-0985174a0d5a) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid e7524eb2-d776-49a1-9c40-f1cb575f4069) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 77b52241-cc52-4fd8-a2fc-0aaeec6f3607) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d4151987-ce5a-49a4-8bb1-a5a8fd05932f) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 78587f8e-70ad-4e7b-8442-08f4c20524fa) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 4b9cbc85-1163-4e5a-b3f3-54dab64913c8) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,233 [IPC Server handler 6 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39759, datanodeUuid=3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, infoPort=37352, infoSecurePort=0, ipcPort=35952, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6
2020-12-03 07:24:09,235 [IPC Server handler 6 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39759
2020-12-03 07:24:09,236 [IPC Server handler 6 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6 (127.0.0.1:39759).
2020-12-03 07:24:09,240 [IPC Server handler 8 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage 78587f8e-70ad-4e7b-8442-08f4c20524fa
2020-12-03 07:24:09,240 [IPC Server handler 8 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37501
2020-12-03 07:24:09,245 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,245 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,253 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,254 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,257 [IPC Server handler 8 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 78587f8e-70ad-4e7b-8442-08f4c20524fa (127.0.0.1:37501).
2020-12-03 07:24:09,257 [IPC Server handler 5 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage b4c365af-82dd-413b-b8c8-0985174a0d5a
2020-12-03 07:24:09,257 [IPC Server handler 5 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33790
2020-12-03 07:24:09,258 [IPC Server handler 5 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b4c365af-82dd-413b-b8c8-0985174a0d5a (127.0.0.1:33790).
2020-12-03 07:24:09,259 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 78587f8e-70ad-4e7b-8442-08f4c20524fa) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,260 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b4c365af-82dd-413b-b8c8-0985174a0d5a) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,260 [IPC Server handler 7 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage 4b9cbc85-1163-4e5a-b3f3-54dab64913c8
2020-12-03 07:24:09,260 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,261 [IPC Server handler 7 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33065
2020-12-03 07:24:09,261 [IPC Server handler 7 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4b9cbc85-1163-4e5a-b3f3-54dab64913c8 (127.0.0.1:33065).
2020-12-03 07:24:09,261 [IPC Server handler 1 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37878, datanodeUuid=77b52241-cc52-4fd8-a2fc-0aaeec6f3607, infoPort=42356, infoSecurePort=0, ipcPort=42066, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage 77b52241-cc52-4fd8-a2fc-0aaeec6f3607
2020-12-03 07:24:09,261 [IPC Server handler 1 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37878
2020-12-03 07:24:09,262 [IPC Server handler 1 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 77b52241-cc52-4fd8-a2fc-0aaeec6f3607 (127.0.0.1:37878).
2020-12-03 07:24:09,262 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 4b9cbc85-1163-4e5a-b3f3-54dab64913c8) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,262 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,263 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,263 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,260 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,285 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,286 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,273 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 77b52241-cc52-4fd8-a2fc-0aaeec6f3607) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,288 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,288 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,288 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,273 [IPC Server handler 3 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage e7524eb2-d776-49a1-9c40-f1cb575f4069
2020-12-03 07:24:09,261 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,289 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,289 [IPC Server handler 3 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42513
2020-12-03 07:24:09,290 [IPC Server handler 3 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e7524eb2-d776-49a1-9c40-f1cb575f4069 (127.0.0.1:42513).
2020-12-03 07:24:09,293 [IPC Server handler 9 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage d4151987-ce5a-49a4-8bb1-a5a8fd05932f
2020-12-03 07:24:09,294 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid e7524eb2-d776-49a1-9c40-f1cb575f4069) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,294 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,294 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,294 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,295 [IPC Server handler 9 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44498
2020-12-03 07:24:09,296 [IPC Server handler 9 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d4151987-ce5a-49a4-8bb1-a5a8fd05932f (127.0.0.1:44498).
2020-12-03 07:24:09,297 [IPC Server handler 4 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-06c4601f-c029-49a4-9490-379500980798 for DN 127.0.0.1:37878
2020-12-03 07:24:09,297 [IPC Server handler 4 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f for DN 127.0.0.1:37878
2020-12-03 07:24:09,305 [IPC Server handler 0 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,306 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d4151987-ce5a-49a4-8bb1-a5a8fd05932f) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,306 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,307 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,307 [IPC Server handler 2 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d for DN 127.0.0.1:37501
2020-12-03 07:24:09,311 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,312 [IPC Server handler 2 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5be1416f-8d13-41e4-a78b-2782ae34ff50 for DN 127.0.0.1:37501
2020-12-03 07:24:09,314 [IPC Server handler 6 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc for DN 127.0.0.1:33065
2020-12-03 07:24:09,314 [IPC Server handler 6 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f for DN 127.0.0.1:33065
2020-12-03 07:24:09,314 [IPC Server handler 5 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a for DN 127.0.0.1:33790
2020-12-03 07:24:09,314 [IPC Server handler 5 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0ea987f6-e383-4d5a-a033-5af60ff63c64 for DN 127.0.0.1:33790
2020-12-03 07:24:09,314 [IPC Server handler 8 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127 for DN 127.0.0.1:42513
2020-12-03 07:24:09,315 [IPC Server handler 8 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6897f411-d91f-4418-a84f-f8abaa165629 for DN 127.0.0.1:42513
2020-12-03 07:24:09,315 [IPC Server handler 1 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2a69a8b0-47db-4b19-946d-a1505cf0911a for DN 127.0.0.1:44498
2020-12-03 07:24:09,315 [IPC Server handler 1 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a050ede7-f836-4855-a01b-8ee70d50f317 for DN 127.0.0.1:44498
2020-12-03 07:24:09,315 [IPC Server handler 7 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821 for DN 127.0.0.1:39759
2020-12-03 07:24:09,315 [IPC Server handler 7 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-893e3d81-c846-44ce-8672-82a1201e27e5 for DN 127.0.0.1:39759
2020-12-03 07:24:09,317 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,317 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,348 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaad4fcfe9d5b97c7: Processing first storage report for DS-5be1416f-8d13-41e4-a78b-2782ae34ff50 from datanode 78587f8e-70ad-4e7b-8442-08f4c20524fa
2020-12-03 07:24:09,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaad4fcfe9d5b97c7: from storage DS-5be1416f-8d13-41e4-a78b-2782ae34ff50 node DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfb7aa7dfd346dac5: Processing first storage report for DS-06c4601f-c029-49a4-9490-379500980798 from datanode 77b52241-cc52-4fd8-a2fc-0aaeec6f3607
2020-12-03 07:24:09,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfb7aa7dfd346dac5: from storage DS-06c4601f-c029-49a4-9490-379500980798 node DatanodeRegistration(127.0.0.1:37878, datanodeUuid=77b52241-cc52-4fd8-a2fc-0aaeec6f3607, infoPort=42356, infoSecurePort=0, ipcPort=42066, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5c53208ff969ba47: Processing first storage report for DS-2a69a8b0-47db-4b19-946d-a1505cf0911a from datanode d4151987-ce5a-49a4-8bb1-a5a8fd05932f
2020-12-03 07:24:09,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5c53208ff969ba47: from storage DS-2a69a8b0-47db-4b19-946d-a1505cf0911a node DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbf39291c470a59ef: Processing first storage report for DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f from datanode 4b9cbc85-1163-4e5a-b3f3-54dab64913c8
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbf39291c470a59ef: from storage DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f node DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaad4fcfe9d5b97c7: Processing first storage report for DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d from datanode 78587f8e-70ad-4e7b-8442-08f4c20524fa
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaad4fcfe9d5b97c7: from storage DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d node DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9712c7bb405abb2d: Processing first storage report for DS-6897f411-d91f-4418-a84f-f8abaa165629 from datanode e7524eb2-d776-49a1-9c40-f1cb575f4069
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9712c7bb405abb2d: from storage DS-6897f411-d91f-4418-a84f-f8abaa165629 node DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,361 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x53bb69dc82f3c842: Processing first storage report for DS-0ea987f6-e383-4d5a-a033-5af60ff63c64 from datanode b4c365af-82dd-413b-b8c8-0985174a0d5a
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x53bb69dc82f3c842: from storage DS-0ea987f6-e383-4d5a-a033-5af60ff63c64 node DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfb7aa7dfd346dac5: Processing first storage report for DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f from datanode 77b52241-cc52-4fd8-a2fc-0aaeec6f3607
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfb7aa7dfd346dac5: from storage DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f node DatanodeRegistration(127.0.0.1:37878, datanodeUuid=77b52241-cc52-4fd8-a2fc-0aaeec6f3607, infoPort=42356, infoSecurePort=0, ipcPort=42066, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5c53208ff969ba47: Processing first storage report for DS-a050ede7-f836-4855-a01b-8ee70d50f317 from datanode d4151987-ce5a-49a4-8bb1-a5a8fd05932f
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5c53208ff969ba47: from storage DS-a050ede7-f836-4855-a01b-8ee70d50f317 node DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9712c7bb405abb2d: Processing first storage report for DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127 from datanode e7524eb2-d776-49a1-9c40-f1cb575f4069
2020-12-03 07:24:09,362 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9712c7bb405abb2d: from storage DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127 node DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,363 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbf39291c470a59ef: Processing first storage report for DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc from datanode 4b9cbc85-1163-4e5a-b3f3-54dab64913c8
2020-12-03 07:24:09,363 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbf39291c470a59ef: from storage DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc node DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,377 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x53bb69dc82f3c842: Processing first storage report for DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a from datanode b4c365af-82dd-413b-b8c8-0985174a0d5a
2020-12-03 07:24:09,377 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x53bb69dc82f3c842: from storage DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a node DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,391 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 209ms
2020-12-03 07:24:09,391 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 210ms
2020-12-03 07:24:09,392 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 211ms
2020-12-03 07:24:09,393 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:09,393 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:09,393 [Thread-378] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,393 [Thread-379] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,397 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 4ms
2020-12-03 07:24:09,397 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 4ms
2020-12-03 07:24:09,397 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 4ms
2020-12-03 07:24:09,398 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:09,398 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:09,398 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-31c6b034-09fb-4323-bb55-99fcee17da60): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,398 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,399 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:49 AM with interval of 21600000ms
2020-12-03 07:24:09,399 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:09,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-31c6b034-09fb-4323-bb55-99fcee17da60): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:09,400 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b375db5b-90a2-43b2-8010-a0a075e864b6) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,402 [IPC Server handler 8 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40921, datanodeUuid=b375db5b-90a2-43b2-8010-a0a075e864b6, infoPort=38290, infoSecurePort=0, ipcPort=37529, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage b375db5b-90a2-43b2-8010-a0a075e864b6
2020-12-03 07:24:09,402 [IPC Server handler 8 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40921
2020-12-03 07:24:09,402 [IPC Server handler 8 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b375db5b-90a2-43b2-8010-a0a075e864b6 (127.0.0.1:40921).
2020-12-03 07:24:09,403 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b375db5b-90a2-43b2-8010-a0a075e864b6) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,403 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,403 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,404 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,409 [IPC Server handler 7 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989 for DN 127.0.0.1:40921
2020-12-03 07:24:09,409 [IPC Server handler 7 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-31c6b034-09fb-4323-bb55-99fcee17da60 for DN 127.0.0.1:40921
2020-12-03 07:24:09,416 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb653c78f66d3b54: Processing first storage report for DS-31c6b034-09fb-4323-bb55-99fcee17da60 from datanode b375db5b-90a2-43b2-8010-a0a075e864b6
2020-12-03 07:24:09,416 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xaad4fcfe9d5b97c7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,416 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5c53208ff969ba47,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,416 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9712c7bb405abb2d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,416 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbf39291c470a59ef,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,416 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x53bb69dc82f3c842,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,416 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfb7aa7dfd346dac5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,417 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,417 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,417 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,417 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,417 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,417 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb653c78f66d3b54: from storage DS-31c6b034-09fb-4323-bb55-99fcee17da60 node DatanodeRegistration(127.0.0.1:40921, datanodeUuid=b375db5b-90a2-43b2-8010-a0a075e864b6, infoPort=38290, infoSecurePort=0, ipcPort=37529, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,417 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,418 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb653c78f66d3b54: Processing first storage report for DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989 from datanode b375db5b-90a2-43b2-8010-a0a075e864b6
2020-12-03 07:24:09,418 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb653c78f66d3b54: from storage DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989 node DatanodeRegistration(127.0.0.1:40921, datanodeUuid=b375db5b-90a2-43b2-8010-a0a075e864b6, infoPort=38290, infoSecurePort=0, ipcPort=37529, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,419 [IPC Server handler 6 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,420 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb653c78f66d3b54,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,420 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,420 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,421 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,522 [IPC Server handler 8 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,524 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,524 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,598 [Thread-281] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 69786233-6756-487d-b8a1-e118dfcb0c82
2020-12-03 07:24:09,598 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d2294dd4-a969-4050-b47d-abaa1b0e42a4
2020-12-03 07:24:09,598 [Thread-259] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b0f71a78-c835-4888-a4d9-a24629dc63da
2020-12-03 07:24:09,600 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c
2020-12-03 07:24:09,601 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:24:09,603 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-555897bc-5fa7-4dd3-8790-b724d53839c8
2020-12-03 07:24:09,603 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:24:09,604 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9b21bacd-350f-4982-b7a8-2cc941879e51
2020-12-03 07:24:09,604 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:24:09,605 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6ed95eab-bbcb-4e63-9776-276535f797bd
2020-12-03 07:24:09,605 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:24:09,609 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7
2020-12-03 07:24:09,609 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:09,609 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:24:09,610 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:09,610 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf
2020-12-03 07:24:09,610 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:24:09,611 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:09,612 [Thread-281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:24:09,612 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:24:09,612 [Thread-281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:24:09,613 [Thread-281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:24:09,613 [Thread-281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:24:09,614 [Thread-259] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:24:09,614 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,614 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:24:09,615 [Thread-259] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:24:09,615 [Thread-389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:24:09,615 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,618 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:24:09,618 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:09,618 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:24:09,618 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:24:09,619 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:09,619 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:09,619 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:09,620 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,620 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:09,620 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:09,626 [IPC Server handler 7 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,627 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:09,627 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:09,687 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 69ms
2020-12-03 07:24:09,694 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 74ms
2020-12-03 07:24:09,695 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 77ms
2020-12-03 07:24:09,695 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 77ms
2020-12-03 07:24:09,695 [Thread-389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 80ms
2020-12-03 07:24:09,696 [Thread-401] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:24:09,696 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:24:09,696 [Thread-401] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,696 [Thread-402] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,696 [Thread-401] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 0ms
2020-12-03 07:24:09,696 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-12-03 07:24:09,696 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 1ms
2020-12-03 07:24:09,697 [Thread-390] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 79ms
2020-12-03 07:24:09,697 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:24:09,697 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 83ms
2020-12-03 07:24:09,697 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:24:09,697 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1172035344-172.17.0.2-1606980238362 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 77ms
2020-12-03 07:24:09,697 [Thread-259] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:13 AM with interval of 21600000ms
2020-12-03 07:24:09,697 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-555897bc-5fa7-4dd3-8790-b724d53839c8): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,697 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:24:09,697 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1172035344-172.17.0.2-1606980238362: 77ms
2020-12-03 07:24:09,697 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,699 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b0f71a78-c835-4888-a4d9-a24629dc63da) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,698 [Thread-405] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,698 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:24:09,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-555897bc-5fa7-4dd3-8790-b724d53839c8): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:09,702 [Thread-406] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,699 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:09,706 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-12-03 07:24:09,706 [Thread-408] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,706 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 8ms
2020-12-03 07:24:09,702 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:09,707 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 5ms
2020-12-03 07:24:09,707 [Thread-409] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1172035344-172.17.0.2-1606980238362/current/replicas doesn't exist 
2020-12-03 07:24:09,707 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:24:09,708 [IPC Server handler 0 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34475, datanodeUuid=b0f71a78-c835-4888-a4d9-a24629dc63da, infoPort=34450, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage b0f71a78-c835-4888-a4d9-a24629dc63da
2020-12-03 07:24:09,708 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 11ms
2020-12-03 07:24:09,709 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 2ms
2020-12-03 07:24:09,709 [IPC Server handler 0 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34475
2020-12-03 07:24:09,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:24:09,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:24:09,709 [IPC Server handler 0 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b0f71a78-c835-4888-a4d9-a24629dc63da (127.0.0.1:34475).
2020-12-03 07:24:09,709 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1172035344-172.17.0.2-1606980238362: 11ms
2020-12-03 07:24:09,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,709 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-6ed95eab-bbcb-4e63-9776-276535f797bd): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,710 [Thread-281] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:13 PM with interval of 21600000ms
2020-12-03 07:24:09,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:09,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1172035344-172.17.0.2-1606980238362 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:09,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-6ed95eab-bbcb-4e63-9776-276535f797bd): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:09,710 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:24 AM with interval of 21600000ms
2020-12-03 07:24:09,710 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:09,712 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-9b21bacd-350f-4982-b7a8-2cc941879e51): finished scanning block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,712 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b0f71a78-c835-4888-a4d9-a24629dc63da) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,712 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,711 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 69786233-6756-487d-b8a1-e118dfcb0c82) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,713 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d2294dd4-a969-4050-b47d-abaa1b0e42a4) service to localhost/127.0.0.1:36993 beginning handshake with NN
2020-12-03 07:24:09,712 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:09,713 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,713 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,713 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-9b21bacd-350f-4982-b7a8-2cc941879e51): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:24:09,715 [IPC Server handler 3 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38540, datanodeUuid=d2294dd4-a969-4050-b47d-abaa1b0e42a4, infoPort=37704, infoSecurePort=0, ipcPort=34574, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage d2294dd4-a969-4050-b47d-abaa1b0e42a4
2020-12-03 07:24:09,716 [IPC Server handler 3 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38540
2020-12-03 07:24:09,716 [IPC Server handler 3 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d2294dd4-a969-4050-b47d-abaa1b0e42a4 (127.0.0.1:38540).
2020-12-03 07:24:09,716 [IPC Server handler 2 on default port 36993] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362) storage 69786233-6756-487d-b8a1-e118dfcb0c82
2020-12-03 07:24:09,716 [IPC Server handler 2 on default port 36993] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45861
2020-12-03 07:24:09,716 [IPC Server handler 2 on default port 36993] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 69786233-6756-487d-b8a1-e118dfcb0c82 (127.0.0.1:45861).
2020-12-03 07:24:09,718 [IPC Server handler 1 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-555897bc-5fa7-4dd3-8790-b724d53839c8 for DN 127.0.0.1:34475
2020-12-03 07:24:09,718 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d2294dd4-a969-4050-b47d-abaa1b0e42a4) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,718 [IPC Server handler 1 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf for DN 127.0.0.1:34475
2020-12-03 07:24:09,718 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,718 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 69786233-6756-487d-b8a1-e118dfcb0c82) service to localhost/127.0.0.1:36993 successfully registered with NN
2020-12-03 07:24:09,718 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,718 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1172035344-172.17.0.2-1606980238362 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:24:09,719 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:24:09,719 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,719 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36993 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:09,724 [IPC Server handler 5 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c for DN 127.0.0.1:45861
2020-12-03 07:24:09,724 [IPC Server handler 5 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6ed95eab-bbcb-4e63-9776-276535f797bd for DN 127.0.0.1:45861
2020-12-03 07:24:09,725 [IPC Server handler 9 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b21bacd-350f-4982-b7a8-2cc941879e51 for DN 127.0.0.1:38540
2020-12-03 07:24:09,725 [IPC Server handler 9 on default port 36993] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7 for DN 127.0.0.1:38540
2020-12-03 07:24:09,725 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfbe096263254a690: Processing first storage report for DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf from datanode b0f71a78-c835-4888-a4d9-a24629dc63da
2020-12-03 07:24:09,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfbe096263254a690: from storage DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf node DatanodeRegistration(127.0.0.1:34475, datanodeUuid=b0f71a78-c835-4888-a4d9-a24629dc63da, infoPort=34450, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfbe096263254a690: Processing first storage report for DS-555897bc-5fa7-4dd3-8790-b724d53839c8 from datanode b0f71a78-c835-4888-a4d9-a24629dc63da
2020-12-03 07:24:09,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfbe096263254a690: from storage DS-555897bc-5fa7-4dd3-8790-b724d53839c8 node DatanodeRegistration(127.0.0.1:34475, datanodeUuid=b0f71a78-c835-4888-a4d9-a24629dc63da, infoPort=34450, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,727 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfbe096263254a690,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,727 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xeb66c9e31aff9830: Processing first storage report for DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c from datanode 69786233-6756-487d-b8a1-e118dfcb0c82
2020-12-03 07:24:09,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xeb66c9e31aff9830: from storage DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c node DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7985cd08eff6c33f: Processing first storage report for DS-9b21bacd-350f-4982-b7a8-2cc941879e51 from datanode d2294dd4-a969-4050-b47d-abaa1b0e42a4
2020-12-03 07:24:09,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7985cd08eff6c33f: from storage DS-9b21bacd-350f-4982-b7a8-2cc941879e51 node DatanodeRegistration(127.0.0.1:38540, datanodeUuid=d2294dd4-a969-4050-b47d-abaa1b0e42a4, infoPort=37704, infoSecurePort=0, ipcPort=34574, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xeb66c9e31aff9830: Processing first storage report for DS-6ed95eab-bbcb-4e63-9776-276535f797bd from datanode 69786233-6756-487d-b8a1-e118dfcb0c82
2020-12-03 07:24:09,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xeb66c9e31aff9830: from storage DS-6ed95eab-bbcb-4e63-9776-276535f797bd node DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7985cd08eff6c33f: Processing first storage report for DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7 from datanode d2294dd4-a969-4050-b47d-abaa1b0e42a4
2020-12-03 07:24:09,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7985cd08eff6c33f: from storage DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7 node DatanodeRegistration(127.0.0.1:38540, datanodeUuid=d2294dd4-a969-4050-b47d-abaa1b0e42a4, infoPort=37704, infoSecurePort=0, ipcPort=34574, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:09,728 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xeb66c9e31aff9830,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,728 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7985cd08eff6c33f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:09,729 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,728 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:09,729 [IPC Server handler 7 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,732 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:09,764 [IPC Server handler 0 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/striped	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:09,807 [IPC Server handler 3 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/striped	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:09,814 [IPC Server handler 2 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:09,858 [Thread-416] INFO  hdfs.TestFileChecksum (TestFileChecksum.java:testStripedFileChecksumWithMissedDataBlocksRangeQuery(290)) - Checksum file:/striped/stripedFileChecksum1, requested length:188743680
2020-12-03 07:24:11,001 [IPC Server handler 1 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:24:11,180 [IPC Server handler 5 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/striped/stripedFileChecksum1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:11,683 [IPC Server handler 9 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:34475, 127.0.0.1:39759, 127.0.0.1:33065, 127.0.0.1:42513, 127.0.0.1:44498, 127.0.0.1:33790, 127.0.0.1:40921, 127.0.0.1:37501, 127.0.0.1:45861 for /striped/stripedFileChecksum1
2020-12-03 07:24:11,791 [Thread-417] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,803 [Thread-418] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,813 [Thread-419] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,824 [Thread-420] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,835 [Thread-421] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,844 [Thread-422] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,901 [Thread-423] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38196 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775788_1001 src: /127.0.0.1:38196 dest: /127.0.0.1:44498
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:55950 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775790_1001 src: /127.0.0.1:55950 dest: /127.0.0.1:33065
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38418 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775789_1001 src: /127.0.0.1:38418 dest: /127.0.0.1:42513
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60272 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775791_1001 src: /127.0.0.1:60272 dest: /127.0.0.1:39759
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39608 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001 src: /127.0.0.1:39608 dest: /127.0.0.1:34475
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:59804 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775787_1001 src: /127.0.0.1:59804 dest: /127.0.0.1:33790
2020-12-03 07:24:11,926 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40072 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775786_1001 src: /127.0.0.1:40072 dest: /127.0.0.1:40921
2020-12-03 07:24:12,807 [Thread-424] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:12,829 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:52864 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775785_1001 src: /127.0.0.1:52864 dest: /127.0.0.1:37501
2020-12-03 07:24:12,844 [Thread-425] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:12,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41248 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775784_1001 src: /127.0.0.1:41248 dest: /127.0.0.1:45861
2020-12-03 07:24:12,873 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd7cb0cca8d9304ab: Processing first storage report for DS-893e3d81-c846-44ce-8672-82a1201e27e5 from datanode 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6
2020-12-03 07:24:12,874 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd7cb0cca8d9304ab: from storage DS-893e3d81-c846-44ce-8672-82a1201e27e5 node DatanodeRegistration(127.0.0.1:39759, datanodeUuid=3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, infoPort=37352, infoSecurePort=0, ipcPort=35952, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:12,874 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd7cb0cca8d9304ab: Processing first storage report for DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821 from datanode 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6
2020-12-03 07:24:12,875 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd7cb0cca8d9304ab: from storage DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821 node DatanodeRegistration(127.0.0.1:39759, datanodeUuid=3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, infoPort=37352, infoSecurePort=0, ipcPort=35952, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:12,876 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd7cb0cca8d9304ab,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 27 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:12,876 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39608, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001, duration(ns): 187012266
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41248, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775784_1001, duration(ns): 185984348
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55950, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775790_1001, duration(ns): 187160384
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38196, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775788_1001, duration(ns): 186768791
2020-12-03 07:24:13,084 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,084 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60272, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775791_1001, duration(ns): 186532179
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40072, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775786_1001, duration(ns): 187414772
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38418, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775789_1001, duration(ns): 185537178
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52864, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775785_1001, duration(ns): 185370465
2020-12-03 07:24:13,080 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59804, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775787_1001, duration(ns): 186515565
2020-12-03 07:24:13,085 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,085 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,085 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,085 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,085 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,084 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,084 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,093 [IPC Server handler 8 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:42513, 127.0.0.1:45861, 127.0.0.1:40921, 127.0.0.1:44498, 127.0.0.1:33065, 127.0.0.1:37501, 127.0.0.1:33790, 127.0.0.1:34475, 127.0.0.1:37878 for /striped/stripedFileChecksum1
2020-12-03 07:24:13,097 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,100 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38508 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 src: /127.0.0.1:38508 dest: /127.0.0.1:42513
2020-12-03 07:24:13,103 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,107 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41252 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 src: /127.0.0.1:41252 dest: /127.0.0.1:45861
2020-12-03 07:24:13,110 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,113 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40160 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775774_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775774_1002 src: /127.0.0.1:40160 dest: /127.0.0.1:40921
2020-12-03 07:24:13,114 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,122 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38291 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 src: /127.0.0.1:38291 dest: /127.0.0.1:44498
2020-12-03 07:24:13,123 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,132 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:56050 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 src: /127.0.0.1:56050 dest: /127.0.0.1:33065
2020-12-03 07:24:13,135 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,151 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:52940 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 src: /127.0.0.1:52940 dest: /127.0.0.1:37501
2020-12-03 07:24:13,153 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,157 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:59904 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 src: /127.0.0.1:59904 dest: /127.0.0.1:33790
2020-12-03 07:24:13,159 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,161 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39720 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775769_1002 src: /127.0.0.1:39720 dest: /127.0.0.1:34475
2020-12-03 07:24:13,163 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,167 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35376 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775768_1002 src: /127.0.0.1:35376 dest: /127.0.0.1:37878
2020-12-03 07:24:13,301 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40160, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775774_1002, duration(ns): 182171816
2020-12-03 07:24:13,301 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38291, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002, duration(ns): 173845797
2020-12-03 07:24:13,301 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38508, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002, duration(ns): 195092145
2020-12-03 07:24:13,301 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41252, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002, duration(ns): 187520721
2020-12-03 07:24:13,303 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,303 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,303 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59904, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002, duration(ns): 62691195
2020-12-03 07:24:13,302 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52940, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002, duration(ns): 144965055
2020-12-03 07:24:13,302 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56050, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002, duration(ns): 161721100
2020-12-03 07:24:13,302 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35376, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775768_1002, duration(ns): 68587940
2020-12-03 07:24:13,306 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,306 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,302 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39720, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775769_1002, duration(ns): 58176323
2020-12-03 07:24:13,302 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,307 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,305 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,305 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,303 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,316 [IPC Server handler 8 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775760_1003, replicas=127.0.0.1:33790, 127.0.0.1:44498, 127.0.0.1:45861, 127.0.0.1:33065, 127.0.0.1:40921, 127.0.0.1:42513, 127.0.0.1:39759, 127.0.0.1:38540, 127.0.0.1:34475 for /striped/stripedFileChecksum1
2020-12-03 07:24:13,320 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,322 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,322 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:59912 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003 src: /127.0.0.1:59912 dest: /127.0.0.1:33790
2020-12-03 07:24:13,324 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,324 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38308 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775759_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775759_1003 src: /127.0.0.1:38308 dest: /127.0.0.1:44498
2020-12-03 07:24:13,330 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,333 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41276 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775758_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775758_1003 src: /127.0.0.1:41276 dest: /127.0.0.1:45861
2020-12-03 07:24:13,338 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:56070 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775757_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775757_1003 src: /127.0.0.1:56070 dest: /127.0.0.1:33065
2020-12-03 07:24:13,338 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,342 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40186 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775756_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775756_1003 src: /127.0.0.1:40186 dest: /127.0.0.1:40921
2020-12-03 07:24:13,343 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,346 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38541 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775755_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775755_1003 src: /127.0.0.1:38541 dest: /127.0.0.1:42513
2020-12-03 07:24:13,349 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,350 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60400 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775754_1003 src: /127.0.0.1:60400 dest: /127.0.0.1:39759
2020-12-03 07:24:13,352 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,355 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:42926 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775753_1003 src: /127.0.0.1:42926 dest: /127.0.0.1:38540
2020-12-03 07:24:13,357 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,358 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39742 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775752_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775752_1003 src: /127.0.0.1:39742 dest: /127.0.0.1:34475
2020-12-03 07:24:13,661 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40186, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775756_1003, duration(ns): 123767743
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59912, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003, duration(ns): 143217352
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60400, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775754_1003, duration(ns): 116050572
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,661 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56070, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775757_1003, duration(ns): 128111960
2020-12-03 07:24:13,661 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38541, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775755_1003, duration(ns): 120517701
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,661 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38308, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775759_1003, duration(ns): 136591284
2020-12-03 07:24:13,663 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41276, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775758_1003, duration(ns): 126388324
2020-12-03 07:24:13,663 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42926, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775753_1003, duration(ns): 111063149
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,662 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39742, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775752_1003, duration(ns): 107823941
2020-12-03 07:24:13,664 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,663 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,663 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,664 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,669 [IPC Server handler 8 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775744_1004, replicas=127.0.0.1:37501, 127.0.0.1:39759, 127.0.0.1:37878, 127.0.0.1:38540, 127.0.0.1:34475, 127.0.0.1:33065, 127.0.0.1:42513, 127.0.0.1:45861, 127.0.0.1:40921 for /striped/stripedFileChecksum1
2020-12-03 07:24:13,673 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,674 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:52970 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004 src: /127.0.0.1:52970 dest: /127.0.0.1:37501
2020-12-03 07:24:13,675 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,677 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60408 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775743_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775743_1004 src: /127.0.0.1:60408 dest: /127.0.0.1:39759
2020-12-03 07:24:13,678 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,683 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35402 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775742_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775742_1004 src: /127.0.0.1:35402 dest: /127.0.0.1:37878
2020-12-03 07:24:13,683 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,684 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:42936 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775741_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775741_1004 src: /127.0.0.1:42936 dest: /127.0.0.1:38540
2020-12-03 07:24:13,685 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,685 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39752 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775740_1004 src: /127.0.0.1:39752 dest: /127.0.0.1:34475
2020-12-03 07:24:13,690 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,692 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:56092 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775739_1004 src: /127.0.0.1:56092 dest: /127.0.0.1:33065
2020-12-03 07:24:13,701 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,702 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38560 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775738_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775738_1004 src: /127.0.0.1:38560 dest: /127.0.0.1:42513
2020-12-03 07:24:13,706 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,707 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41304 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775737_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775737_1004 src: /127.0.0.1:41304 dest: /127.0.0.1:45861
2020-12-03 07:24:13,711 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,711 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40212 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775736_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775736_1004 src: /127.0.0.1:40212 dest: /127.0.0.1:40921
2020-12-03 07:24:13,812 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56092, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775739_1004, duration(ns): 112833917
2020-12-03 07:24:13,812 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35402, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775742_1004, duration(ns): 122066995
2020-12-03 07:24:13,812 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60408, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775743_1004, duration(ns): 127146631
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40212, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775736_1004, duration(ns): 93715151
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38560, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775738_1004, duration(ns): 102957568
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39752, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775740_1004, duration(ns): 117606228
2020-12-03 07:24:13,814 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41304, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775737_1004, duration(ns): 98266703
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42936, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775741_1004, duration(ns): 120448182
2020-12-03 07:24:13,813 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52970, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004, duration(ns): 130686341
2020-12-03 07:24:13,814 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,814 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,814 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:13,818 [IPC Server handler 8 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775728_1005, replicas=127.0.0.1:34475, 127.0.0.1:37878, 127.0.0.1:37501, 127.0.0.1:45861, 127.0.0.1:38540, 127.0.0.1:42513, 127.0.0.1:33790, 127.0.0.1:44498, 127.0.0.1:40921 for /striped/stripedFileChecksum1
2020-12-03 07:24:13,822 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,823 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39762 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005 src: /127.0.0.1:39762 dest: /127.0.0.1:34475
2020-12-03 07:24:13,824 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,826 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35418 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775727_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775727_1005 src: /127.0.0.1:35418 dest: /127.0.0.1:37878
2020-12-03 07:24:13,827 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,831 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:52992 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775726_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775726_1005 src: /127.0.0.1:52992 dest: /127.0.0.1:37501
2020-12-03 07:24:13,833 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,837 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41314 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775725_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775725_1005 src: /127.0.0.1:41314 dest: /127.0.0.1:45861
2020-12-03 07:24:13,838 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,842 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:42956 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775724_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775724_1005 src: /127.0.0.1:42956 dest: /127.0.0.1:38540
2020-12-03 07:24:13,842 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38576 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775723_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775723_1005 src: /127.0.0.1:38576 dest: /127.0.0.1:42513
2020-12-03 07:24:13,847 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,848 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:59960 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775722_1005 src: /127.0.0.1:59960 dest: /127.0.0.1:33790
2020-12-03 07:24:13,849 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,849 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38356 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775721_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775721_1005 src: /127.0.0.1:38356 dest: /127.0.0.1:44498
2020-12-03 07:24:13,851 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:13,852 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40230 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775720_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775720_1005 src: /127.0.0.1:40230 dest: /127.0.0.1:40921
2020-12-03 07:24:14,014 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42956, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775724_1005, duration(ns): 167229298
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38356, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775721_1005, duration(ns): 159766095
2020-12-03 07:24:14,014 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40230, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775720_1005, duration(ns): 157712715
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59960, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775722_1005, duration(ns): 161133174
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41314, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775725_1005, duration(ns): 171955252
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52992, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775726_1005, duration(ns): 177451977
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39762, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005, duration(ns): 185805044
2020-12-03 07:24:14,016 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,016 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,016 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38576, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775723_1005, duration(ns): 165814644
2020-12-03 07:24:14,015 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35418, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775727_1005, duration(ns): 182901550
2020-12-03 07:24:14,016 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,016 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,020 [IPC Server handler 4 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775712_1006, replicas=127.0.0.1:34475, 127.0.0.1:37878, 127.0.0.1:33065, 127.0.0.1:42513, 127.0.0.1:44498, 127.0.0.1:45861, 127.0.0.1:39759, 127.0.0.1:40921, 127.0.0.1:38540 for /striped/stripedFileChecksum1
2020-12-03 07:24:14,024 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,025 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39780 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775712_1006 src: /127.0.0.1:39780 dest: /127.0.0.1:34475
2020-12-03 07:24:14,025 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,026 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35436 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775711_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775711_1006 src: /127.0.0.1:35436 dest: /127.0.0.1:37878
2020-12-03 07:24:14,026 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,027 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:56122 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775710_1006 src: /127.0.0.1:56122 dest: /127.0.0.1:33065
2020-12-03 07:24:14,027 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,029 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,029 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38590 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775709_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775709_1006 src: /127.0.0.1:38590 dest: /127.0.0.1:42513
2020-12-03 07:24:14,029 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38368 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775708_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775708_1006 src: /127.0.0.1:38368 dest: /127.0.0.1:44498
2020-12-03 07:24:14,030 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,031 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41336 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775707_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775707_1006 src: /127.0.0.1:41336 dest: /127.0.0.1:45861
2020-12-03 07:24:14,034 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,035 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60454 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775706_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775706_1006 src: /127.0.0.1:60454 dest: /127.0.0.1:39759
2020-12-03 07:24:14,036 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,037 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40246 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775705_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775705_1006 src: /127.0.0.1:40246 dest: /127.0.0.1:40921
2020-12-03 07:24:14,039 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,040 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:42982 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775704_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775704_1006 src: /127.0.0.1:42982 dest: /127.0.0.1:38540
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38368, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775708_1006, duration(ns): 97606772
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35436, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775711_1006, duration(ns): 101617129
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42982, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775704_1006, duration(ns): 87518758
2020-12-03 07:24:14,139 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60454, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775706_1006, duration(ns): 92477203
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41336, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775707_1006, duration(ns): 96346924
2020-12-03 07:24:14,139 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40246, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775705_1006, duration(ns): 90374039
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38590, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775709_1006, duration(ns): 97960363
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56122, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775710_1006, duration(ns): 100399342
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,140 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,138 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39780, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775712_1006, duration(ns): 102629338
2020-12-03 07:24:14,140 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,140 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,140 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,139 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,139 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,143 [IPC Server handler 4 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775696_1007, replicas=127.0.0.1:33065, 127.0.0.1:38540, 127.0.0.1:40921, 127.0.0.1:42513, 127.0.0.1:39759, 127.0.0.1:34475, 127.0.0.1:37501, 127.0.0.1:37878, 127.0.0.1:45861 for /striped/stripedFileChecksum1
2020-12-03 07:24:14,146 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,147 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:56136 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775696_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775696_1007 src: /127.0.0.1:56136 dest: /127.0.0.1:33065
2020-12-03 07:24:14,147 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,148 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:42986 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775695_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775695_1007 src: /127.0.0.1:42986 dest: /127.0.0.1:38540
2020-12-03 07:24:14,149 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,149 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40254 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775694_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775694_1007 src: /127.0.0.1:40254 dest: /127.0.0.1:40921
2020-12-03 07:24:14,150 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,151 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38608 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775693_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775693_1007 src: /127.0.0.1:38608 dest: /127.0.0.1:42513
2020-12-03 07:24:14,151 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,152 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60468 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775692_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775692_1007 src: /127.0.0.1:60468 dest: /127.0.0.1:39759
2020-12-03 07:24:14,153 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,154 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39808 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775691_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775691_1007 src: /127.0.0.1:39808 dest: /127.0.0.1:34475
2020-12-03 07:24:14,157 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,158 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:53036 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775690_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775690_1007 src: /127.0.0.1:53036 dest: /127.0.0.1:37501
2020-12-03 07:24:14,159 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,160 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35466 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775689_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775689_1007 src: /127.0.0.1:35466 dest: /127.0.0.1:37878
2020-12-03 07:24:14,161 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,162 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41360 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775688_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775688_1007 src: /127.0.0.1:41360 dest: /127.0.0.1:45861
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41360, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775688_1007, duration(ns): 97350474
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42986, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775695_1007, duration(ns): 111580043
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56136, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775696_1007, duration(ns): 112674891
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38608, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775693_1007, duration(ns): 108747457
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39808, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775691_1007, duration(ns): 105920043
2020-12-03 07:24:14,263 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40254, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775694_1007, duration(ns): 110314061
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60468, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775692_1007, duration(ns): 107440453
2020-12-03 07:24:14,263 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,263 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35466, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775689_1007, duration(ns): 100331975
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53036, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775690_1007, duration(ns): 102268735
2020-12-03 07:24:14,263 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,263 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,262 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,264 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,266 [IPC Server handler 4 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775680_1008, replicas=127.0.0.1:44498, 127.0.0.1:42513, 127.0.0.1:39759, 127.0.0.1:38540, 127.0.0.1:33065, 127.0.0.1:33790, 127.0.0.1:37878, 127.0.0.1:34475, 127.0.0.1:37501 for /striped/stripedFileChecksum1
2020-12-03 07:24:14,270 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,271 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,271 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38396 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775680_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775680_1008 src: /127.0.0.1:38396 dest: /127.0.0.1:44498
2020-12-03 07:24:14,272 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38622 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775679_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775679_1008 src: /127.0.0.1:38622 dest: /127.0.0.1:42513
2020-12-03 07:24:14,272 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,273 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60482 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775678_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775678_1008 src: /127.0.0.1:60482 dest: /127.0.0.1:39759
2020-12-03 07:24:14,274 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,275 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:43008 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775677_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775677_1008 src: /127.0.0.1:43008 dest: /127.0.0.1:38540
2020-12-03 07:24:14,385 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,387 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:56162 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775676_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775676_1008 src: /127.0.0.1:56162 dest: /127.0.0.1:33065
2020-12-03 07:24:14,387 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,388 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60012 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775675_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775675_1008 src: /127.0.0.1:60012 dest: /127.0.0.1:33790
2020-12-03 07:24:14,391 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,392 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35482 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775674_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775674_1008 src: /127.0.0.1:35482 dest: /127.0.0.1:37878
2020-12-03 07:24:14,394 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,395 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39830 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775673_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775673_1008 src: /127.0.0.1:39830 dest: /127.0.0.1:34475
2020-12-03 07:24:14,396 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,397 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:53058 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775672_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775672_1008 src: /127.0.0.1:53058 dest: /127.0.0.1:37501
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60482, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775678_1008, duration(ns): 251021608
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43008, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775677_1008, duration(ns): 138697344
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56162, dest: /127.0.0.1:33065, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 4b9cbc85-1163-4e5a-b3f3-54dab64913c8, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775676_1008, duration(ns): 137050601
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39830, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775673_1008, duration(ns): 129607659
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53058, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775672_1008, duration(ns): 126862564
2020-12-03 07:24:14,527 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60012, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775675_1008, duration(ns): 134289120
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38622, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775679_1008, duration(ns): 252115150
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38396, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775680_1008, duration(ns): 253027746
2020-12-03 07:24:14,526 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35482, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775674_1008, duration(ns): 131950411
2020-12-03 07:24:14,528 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,528 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,527 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,527 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,527 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,527 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,527 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,531 [IPC Server handler 4 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775664_1009, replicas=127.0.0.1:34475, 127.0.0.1:38540, 127.0.0.1:37878, 127.0.0.1:44498, 127.0.0.1:45861, 127.0.0.1:40921, 127.0.0.1:42513, 127.0.0.1:39759, 127.0.0.1:33790 for /striped/stripedFileChecksum1
2020-12-03 07:24:14,534 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,535 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,537 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,539 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,540 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,542 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,546 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,548 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,551 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41388 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775660_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775660_1009 src: /127.0.0.1:41388 dest: /127.0.0.1:45861
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38420 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775661_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775661_1009 src: /127.0.0.1:38420 dest: /127.0.0.1:44498
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38650 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775658_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775658_1009 src: /127.0.0.1:38650 dest: /127.0.0.1:42513
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60036 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775656_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775656_1009 src: /127.0.0.1:60036 dest: /127.0.0.1:33790
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39834 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775664_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775664_1009 src: /127.0.0.1:39834 dest: /127.0.0.1:34475
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:43022 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775663_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775663_1009 src: /127.0.0.1:43022 dest: /127.0.0.1:38540
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40296 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775659_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775659_1009 src: /127.0.0.1:40296 dest: /127.0.0.1:40921
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35492 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775662_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775662_1009 src: /127.0.0.1:35492 dest: /127.0.0.1:37878
2020-12-03 07:24:14,564 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60510 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775657_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775657_1009 src: /127.0.0.1:60510 dest: /127.0.0.1:39759
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40296, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775659_1009, duration(ns): 99862325
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35492, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775662_1009, duration(ns): 100890602
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41388, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775660_1009, duration(ns): 102077249
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38420, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775661_1009, duration(ns): 101647652
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38650, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775658_1009, duration(ns): 101337471
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60510, dest: /127.0.0.1:39759, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775657_1009, duration(ns): 98946515
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39834, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775664_1009, duration(ns): 99504556
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60036, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775656_1009, duration(ns): 101831958
2020-12-03 07:24:14,669 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,669 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,669 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,669 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,669 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43022, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775663_1009, duration(ns): 99784286
2020-12-03 07:24:14,668 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,670 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,669 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,673 [IPC Server handler 4 on default port 36993] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775648_1010, replicas=127.0.0.1:37501, 127.0.0.1:40921, 127.0.0.1:33790, 127.0.0.1:42513, 127.0.0.1:44498, 127.0.0.1:38540, 127.0.0.1:45861, 127.0.0.1:37878, 127.0.0.1:34475 for /striped/stripedFileChecksum1
2020-12-03 07:24:14,677 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,678 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:53078 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775648_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775648_1010 src: /127.0.0.1:53078 dest: /127.0.0.1:37501
2020-12-03 07:24:14,679 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,680 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:40306 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775647_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775647_1010 src: /127.0.0.1:40306 dest: /127.0.0.1:40921
2020-12-03 07:24:14,680 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,681 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:60042 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775646_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775646_1010 src: /127.0.0.1:60042 dest: /127.0.0.1:33790
2020-12-03 07:24:14,682 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,683 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38662 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775645_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775645_1010 src: /127.0.0.1:38662 dest: /127.0.0.1:42513
2020-12-03 07:24:14,683 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,684 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:38440 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775644_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775644_1010 src: /127.0.0.1:38440 dest: /127.0.0.1:44498
2020-12-03 07:24:14,685 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,686 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:43048 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775643_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775643_1010 src: /127.0.0.1:43048 dest: /127.0.0.1:38540
2020-12-03 07:24:14,689 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,690 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:41410 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775642_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775642_1010 src: /127.0.0.1:41410 dest: /127.0.0.1:45861
2020-12-03 07:24:14,691 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,692 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:35520 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775641_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775641_1010 src: /127.0.0.1:35520 dest: /127.0.0.1:37878
2020-12-03 07:24:14,694 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:14,695 [DataXceiver for client DFSClient_NONMAPREDUCE_-1439432710_1 at /127.0.0.1:39868 [Receiving block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775640_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775640_1010 src: /127.0.0.1:39868 dest: /127.0.0.1:34475
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40306, dest: /127.0.0.1:40921, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b375db5b-90a2-43b2-8010-a0a075e864b6, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775647_1010, duration(ns): 114675905
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60042, dest: /127.0.0.1:33790, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b4c365af-82dd-413b-b8c8-0985174a0d5a, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775646_1010, duration(ns): 112721265
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39868, dest: /127.0.0.1:34475, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: b0f71a78-c835-4888-a4d9-a24629dc63da, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775640_1010, duration(ns): 99112059
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38662, dest: /127.0.0.1:42513, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: e7524eb2-d776-49a1-9c40-f1cb575f4069, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775645_1010, duration(ns): 111646258
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35520, dest: /127.0.0.1:37878, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 77b52241-cc52-4fd8-a2fc-0aaeec6f3607, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775641_1010, duration(ns): 92305520
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41410, dest: /127.0.0.1:45861, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 69786233-6756-487d-b8a1-e118dfcb0c82, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775642_1010, duration(ns): 104152310
2020-12-03 07:24:14,797 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,797 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43048, dest: /127.0.0.1:38540, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d2294dd4-a969-4050-b47d-abaa1b0e42a4, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775643_1010, duration(ns): 108697308
2020-12-03 07:24:14,797 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38440, dest: /127.0.0.1:44498, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: d4151987-ce5a-49a4-8bb1-a5a8fd05932f, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775644_1010, duration(ns): 109737980
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,796 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53078, dest: /127.0.0.1:37501, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1439432710_1, offset: 0, srvID: 78587f8e-70ad-4e7b-8442-08f4c20524fa, blockid: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775648_1010, duration(ns): 115911013
2020-12-03 07:24:14,798 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,798 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,798 [PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:14,806 [IPC Server handler 4 on default port 36993] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /striped/stripedFileChecksum1 is closed by DFSClient_NONMAPREDUCE_-1439432710_1
2020-12-03 07:24:14,817 [IPC Server handler 1 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:24:14,832 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-2a69a8b0-47db-4b19-946d-a1505cf0911a,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:14,888 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:extractChecksumProperties(430)) - set bytesPerCRC=512, crcPerBlock=12288
2020-12-03 07:24:14,889 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]: blockChecksum=0xb82cfa69, blockChecksumType=COMPOSITE_CRC
2020-12-03 07:24:14,889 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-31c6b034-09fb-4323-bb55-99fcee17da60,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:14,914 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK]: blockChecksum=0x9693fb79, blockChecksumType=COMPOSITE_CRC
2020-12-03 07:24:14,915 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:33790,DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-2a69a8b0-47db-4b19-946d-a1505cf0911a,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-893e3d81-c846-44ce-8672-82a1201e27e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-9b21bacd-350f-4982-b7a8-2cc941879e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:14,934 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:33790,DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a,DISK]: blockChecksum=0xfbf3413d, blockChecksumType=COMPOSITE_CRC
2020-12-03 07:24:14,935 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:37501,DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775744_1004; getBlockSize()=37748736; corrupt=false; offset=113246208; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-31c6b034-09fb-4323-bb55-99fcee17da60,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:14,954 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:37501,DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d,DISK]: blockChecksum=0x0c7ef6ff, blockChecksumType=COMPOSITE_CRC
2020-12-03 07:24:14,954 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775728_1005; getBlockSize()=37748736; corrupt=false; offset=150994944; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-9b21bacd-350f-4982-b7a8-2cc941879e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:14,975 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]: blockChecksum=0x462cc45a, blockChecksumType=COMPOSITE_CRC
2020-12-03 07:24:14,975 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:makeCompositeCrcResult(315)) - Added blockCrc 0x-47d30597 for block index 0 of size 37748736
2020-12-03 07:24:14,976 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:makeCompositeCrcResult(315)) - Added blockCrc 0x-696c0487 for block index 1 of size 37748736
2020-12-03 07:24:14,976 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:makeCompositeCrcResult(315)) - Added blockCrc 0x-40cbec3 for block index 2 of size 37748736
2020-12-03 07:24:14,976 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:makeCompositeCrcResult(315)) - Added blockCrc 0xc7ef6ff for block index 3 of size 37748736
2020-12-03 07:24:14,976 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:makeCompositeCrcResult(337)) - Added lastBlockCrc 0x462cc45a for block index 4 of size 37748736
2020-12-03 07:24:14,979 [IPC Server handler 0 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:24:14,984 [Thread-416] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:14,984 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6e5bfdfc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:14,985 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-31c6b034-09fb-4323-bb55-99fcee17da60) exiting.
2020-12-03 07:24:14,985 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-923f3a24-830a-4d6e-a1eb-3890fa6b7989) exiting.
2020-12-03 07:24:15,079 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7ee55e70{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,085 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3fcdcf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,086 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3add81c4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,087 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fb68ec6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,093 [Thread-416] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37529
2020-12-03 07:24:15,101 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,102 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,103 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:15,104 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b375db5b-90a2-43b2-8010-a0a075e864b6) service to localhost/127.0.0.1:36993
2020-12-03 07:24:15,104 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b375db5b-90a2-43b2-8010-a0a075e864b6)
2020-12-03 07:24:15,105 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:15,106 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,106 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,111 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:15,111 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:15,112 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:15,112 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:15,119 [Thread-416] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,122 [Thread-416] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:40921, removeBlocksFromBlockMap true
2020-12-03 07:24:15,125 [Thread-416] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:40921
2020-12-03 07:24:15,129 [IPC Server handler 7 on default port 36993] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:24:15,133 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-2a69a8b0-47db-4b19-946d-a1505cf0911a,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c,DISK]]; indices=[0, 1, 2, 3, 4, 5, 7, 8]}
2020-12-03 07:24:15,153 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:extractChecksumProperties(430)) - set bytesPerCRC=512, crcPerBlock=12288
2020-12-03 07:24:15,154 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:34475,DS-555897bc-5fa7-4dd3-8790-b724d53839c8,DISK]: blockChecksum=0xb82cfa69, blockChecksumType=COMPOSITE_CRC
2020-12-03 07:24:15,155 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,306 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,327 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,329 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,330 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,331 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,332 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,340 [DataXceiver for client /127.0.0.1:38758 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:38758 dst: /127.0.0.1:42513
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,340 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[0]=DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,344 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,352 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,354 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,355 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,357 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,358 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,360 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,362 [DataXceiver for client /127.0.0.1:41518 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:41518 dst: /127.0.0.1:45861
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,362 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[1]=DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,365 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,372 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,373 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,375 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,376 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,377 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,378 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,391 [DataXceiver for client /127.0.0.1:38570 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:38570 dst: /127.0.0.1:44498
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,391 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[2]=DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,394 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,411 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,412 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,417 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,421 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,426 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,431 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,437 [DataXceiver for client /127.0.0.1:56346 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:56346 dst: /127.0.0.1:33065
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,437 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[3]=DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,441 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,448 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,459 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,463 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,467 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,471 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,474 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,480 [DataXceiver for client /127.0.0.1:53252 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:53252 dst: /127.0.0.1:37501
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,480 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[4]=DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,482 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,489 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,495 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,496 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,499 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,503 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,506 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,516 [DataXceiver for client /127.0.0.1:60230 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:60230 dst: /127.0.0.1:33790
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,516 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[5]=DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,518 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,525 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,533 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,535 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,542 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,544 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,545 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,547 [DataXceiver for client /127.0.0.1:40062 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34475:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:40062 dst: /127.0.0.1:34475
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,547 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[6]=DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,550 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-6897f411-d91f-4418-a84f-f8abaa165629,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-6ed95eab-bbcb-4e63-9776-276535f797bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-a050ede7-f836-4855-a01b-8ee70d50f317,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-5be1416f-8d13-41e4-a78b-2782ae34ff50,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-0ea987f6-e383-4d5a-a033-5af60ff63c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:24:15,557 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,558 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,559 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,561 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,562 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,563 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:15,565 [DataXceiver for client /127.0.0.1:35734 [Getting checksum for block groupBP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37878:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:35734 dst: /127.0.0.1:37878
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,565 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[7]=DatanodeInfoWithStorage[127.0.0.1:37878,DS-06c4601f-c029-49a4-9490-379500980798,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:24:15,568 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:15,569 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:24:15,571 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:15,571 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2c0f7678] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:15,572 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-dafe115a-4ca9-4f5f-bfcc-87f9dd86d06c) exiting.
2020-12-03 07:24:15,572 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-6ed95eab-bbcb-4e63-9776-276535f797bd) exiting.
2020-12-03 07:24:15,637 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@60297f36{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,640 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1bf0f6f6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,642 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e681bc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,642 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4163f1cd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,643 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42769
2020-12-03 07:24:15,644 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,644 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,653 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:15,654 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 69786233-6756-487d-b8a1-e118dfcb0c82) service to localhost/127.0.0.1:36993
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41526 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41508 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 69786233-6756-487d-b8a1-e118dfcb0c82)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,654 [DataXceiver for client  at /127.0.0.1:41634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,655 [DataXceiver for client  at /127.0.0.1:41580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,657 [DataXceiver for client  at /127.0.0.1:41634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,658 [DataXceiver for client  at /127.0.0.1:41580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41580
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,658 [DataXceiver for client  at /127.0.0.1:41634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41634
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,658 [DataXceiver for client  at /127.0.0.1:41544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,660 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:15,661 [DataXceiver for client  at /127.0.0.1:41508 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,661 [DataXceiver for client  at /127.0.0.1:41544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41544
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,661 [DataXceiver for client  at /127.0.0.1:41508 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41508
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,661 [DataXceiver for client  at /127.0.0.1:41616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,663 [DataXceiver for client  at /127.0.0.1:41562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,663 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,663 [DataXceiver for client  at /127.0.0.1:41616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41616
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,664 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,664 [DataXceiver for client  at /127.0.0.1:41562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41562
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,664 [DataXceiver for client  at /127.0.0.1:41598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,670 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:15,673 [DataXceiver for client  at /127.0.0.1:41598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41598
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,672 [DataXceiver for client  at /127.0.0.1:41526 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 on DS-6ed95eab-bbcb-4e63-9776-276535f797bd, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,673 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:15,674 [DataXceiver for client  at /127.0.0.1:41526 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45861, datanodeUuid=69786233-6756-487d-b8a1-e118dfcb0c82, infoPort=38820, infoSecurePort=0, ipcPort=42769, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002 to /127.0.0.1:41526
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,675 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:15,677 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:15,678 [DataXceiver for client  at /127.0.0.1:41526 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41526 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,677 [DataXceiver for client  at /127.0.0.1:41580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41580 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,683 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,683 [DataXceiver for client  at /127.0.0.1:41508 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41508 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,680 [DataXceiver for client  at /127.0.0.1:41616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41616 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,680 [DataXceiver for client  at /127.0.0.1:41562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41562 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,679 [DataXceiver for client  at /127.0.0.1:41598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41598 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,686 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:24:15,683 [DataXceiver for client  at /127.0.0.1:41634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41634 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,696 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:15,683 [DataXceiver for client  at /127.0.0.1:41544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775775_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45861:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:41544 dst: /127.0.0.1:45861
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,700 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2451c7d-c08f-4ac0-ae5c-b356860e6dcf) exiting.
2020-12-03 07:24:15,696 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6134ac4a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:15,700 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-555897bc-5fa7-4dd3-8790-b724d53839c8) exiting.
2020-12-03 07:24:15,722 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@405325cf{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,723 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3e1162e7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,723 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b809711{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,723 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22175d4f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,724 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36510
2020-12-03 07:24:15,725 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,725 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,725 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:15,727 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b0f71a78-c835-4888-a4d9-a24629dc63da) service to localhost/127.0.0.1:36993
2020-12-03 07:24:15,727 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b0f71a78-c835-4888-a4d9-a24629dc63da)
2020-12-03 07:24:15,727 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:15,728 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,730 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,735 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:15,735 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:15,736 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:15,736 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:15,739 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,739 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:24:15,739 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:15,739 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4fdf8f12] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:15,741 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4b1a76ca-7d95-455c-bf72-41a05a6c96d7) exiting.
2020-12-03 07:24:15,741 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-9b21bacd-350f-4982-b7a8-2cc941879e51) exiting.
2020-12-03 07:24:15,763 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@199e4c2b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,764 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6e0d4a8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,764 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54e81b21{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,765 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17f9344b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,766 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34574
2020-12-03 07:24:15,769 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,769 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,769 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:15,770 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d2294dd4-a969-4050-b47d-abaa1b0e42a4) service to localhost/127.0.0.1:36993
2020-12-03 07:24:15,770 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d2294dd4-a969-4050-b47d-abaa1b0e42a4)
2020-12-03 07:24:15,770 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:15,773 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,774 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,790 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:15,790 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:15,792 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:15,792 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:15,795 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,795 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:24:15,796 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:24:15,796 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37529
2020-12-03 07:24:15,796 [Listener at localhost/42769] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-b375db5b-90a2-43b2-8010-a0a075e864b6
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-b375db5b-90a2-43b2-8010-a0a075e864b6
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.TestFileChecksum.tearDown(TestFileChecksum.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:24:15,798 [Listener at localhost/42769] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:24:15,798 [Listener at localhost/42769] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:24:15,800 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,800 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:24:15,800 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:15,800 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@11963225] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:15,802 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-2a69a8b0-47db-4b19-946d-a1505cf0911a) exiting.
2020-12-03 07:24:15,802 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-a050ede7-f836-4855-a01b-8ee70d50f317) exiting.
2020-12-03 07:24:15,851 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a34b7b8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,852 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58cd06cb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,852 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77b325b3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,853 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f325091{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,854 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38794
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38652 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38670 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,854 [DataXceiver for client  at /127.0.0.1:38634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,855 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:15,855 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,855 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,855 [DataXceiver for client  at /127.0.0.1:38562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,857 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d4151987-ce5a-49a4-8bb1-a5a8fd05932f) service to localhost/127.0.0.1:36993
2020-12-03 07:24:15,860 [DataXceiver for client  at /127.0.0.1:38562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38562
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,860 [DataXceiver for client  at /127.0.0.1:38634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,860 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid d4151987-ce5a-49a4-8bb1-a5a8fd05932f)
2020-12-03 07:24:15,863 [DataXceiver for client  at /127.0.0.1:38562 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38562 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,863 [DataXceiver for client  at /127.0.0.1:38634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38634
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,861 [DataXceiver for client  at /127.0.0.1:38670 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,869 [DataXceiver for client  at /127.0.0.1:38634 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38634 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,869 [DataXceiver for client  at /127.0.0.1:38652 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,885 [DataXceiver for client  at /127.0.0.1:38598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,885 [DataXceiver for client  at /127.0.0.1:38598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38598
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,883 [DataXceiver for client  at /127.0.0.1:38670 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38670
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,886 [DataXceiver for client  at /127.0.0.1:38598 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38598 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,885 [DataXceiver for client  at /127.0.0.1:38544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,885 [DataXceiver for client  at /127.0.0.1:38652 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38652
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,892 [DataXceiver for client  at /127.0.0.1:38544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38544
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,892 [DataXceiver for client  at /127.0.0.1:38616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,888 [DataXceiver for client  at /127.0.0.1:38670 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38670 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,895 [DataXceiver for client  at /127.0.0.1:38616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38616
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,895 [DataXceiver for client  at /127.0.0.1:38580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 on DS-a050ede7-f836-4855-a01b-8ee70d50f317, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,894 [DataXceiver for client  at /127.0.0.1:38544 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38544 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,893 [DataXceiver for client  at /127.0.0.1:38652 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38652 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,902 [DataXceiver for client  at /127.0.0.1:38580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44498, datanodeUuid=d4151987-ce5a-49a4-8bb1-a5a8fd05932f, infoPort=36504, infoSecurePort=0, ipcPort=38794, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002 to /127.0.0.1:38580
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,901 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:15,900 [DataXceiver for client  at /127.0.0.1:38616 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38616 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,909 [DataXceiver for client  at /127.0.0.1:38580 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775773_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44498:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38580 dst: /127.0.0.1:44498
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,916 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,915 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:15,924 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:15,924 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:15,926 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:15,927 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:15,931 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:15,932 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:24:15,932 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1cefc4b3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:15,933 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:15,936 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5be1416f-8d13-41e4-a78b-2782ae34ff50) exiting.
2020-12-03 07:24:15,936 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-ef8e0528-cce9-46d8-96cc-9f02fa721a6d) exiting.
2020-12-03 07:24:15,954 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@26d10f2e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:15,955 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@10ad20cb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:15,955 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a7704c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:15,956 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e53135d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:15,957 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38374
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53266 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53194 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53320 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53284 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53230 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53302 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53248 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53212 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,958 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:15,958 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:15,958 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:15,957 [DataXceiver for client  at /127.0.0.1:53266 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,973 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 78587f8e-70ad-4e7b-8442-08f4c20524fa) service to localhost/127.0.0.1:36993
2020-12-03 07:24:15,976 [DataXceiver for client  at /127.0.0.1:53212 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,976 [DataXceiver for client  at /127.0.0.1:53266 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53266
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,977 [DataXceiver for client  at /127.0.0.1:53212 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53212
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,977 [DataXceiver for client  at /127.0.0.1:53248 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,979 [DataXceiver for client  at /127.0.0.1:53212 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53212 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,977 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 78587f8e-70ad-4e7b-8442-08f4c20524fa)
2020-12-03 07:24:15,981 [DataXceiver for client  at /127.0.0.1:53302 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,981 [DataXceiver for client  at /127.0.0.1:53248 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53248
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,979 [DataXceiver for client  at /127.0.0.1:53266 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53266 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,986 [DataXceiver for client  at /127.0.0.1:53248 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53248 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,985 [DataXceiver for client  at /127.0.0.1:53302 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53302
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,985 [DataXceiver for client  at /127.0.0.1:53230 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:15,995 [DataXceiver for client  at /127.0.0.1:53302 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53302 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,997 [DataXceiver for client  at /127.0.0.1:53230 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53230
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:15,997 [DataXceiver for client  at /127.0.0.1:53284 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,019 [DataXceiver for client  at /127.0.0.1:53230 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53230 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,022 [DataXceiver for client  at /127.0.0.1:53284 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53284
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,022 [DataXceiver for client  at /127.0.0.1:53320 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,023 [DataXceiver for client  at /127.0.0.1:53194 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 on DS-5be1416f-8d13-41e4-a78b-2782ae34ff50, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,025 [DataXceiver for client  at /127.0.0.1:53320 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53320
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,025 [DataXceiver for client  at /127.0.0.1:53284 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53284 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,025 [DataXceiver for client  at /127.0.0.1:53320 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53320 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,025 [DataXceiver for client  at /127.0.0.1:53194 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:37501, datanodeUuid=78587f8e-70ad-4e7b-8442-08f4c20524fa, infoPort=41528, infoSecurePort=0, ipcPort=38374, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002 to /127.0.0.1:53194
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,025 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:16,028 [DataXceiver for client  at /127.0.0.1:53194 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775771_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37501:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:53194 dst: /127.0.0.1:37501
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,031 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,031 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,037 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:16,037 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:16,039 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:16,039 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:16,043 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:16,043 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:24:16,044 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:16,044 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54e7391d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:16,046 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-82cffb7e-c9d5-445e-acd6-34c36a063f8f) exiting.
2020-12-03 07:24:16,046 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-06c4601f-c029-49a4-9490-379500980798) exiting.
2020-12-03 07:24:16,106 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dfd5f51{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:16,107 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:16,107 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@512d92b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:16,108 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58783f6c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:16,109 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42066
2020-12-03 07:24:16,110 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:16,110 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:16,115 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:16,115 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 77b52241-cc52-4fd8-a2fc-0aaeec6f3607) service to localhost/127.0.0.1:36993
2020-12-03 07:24:16,115 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 77b52241-cc52-4fd8-a2fc-0aaeec6f3607)
2020-12-03 07:24:16,115 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:16,116 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,116 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,123 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:16,124 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:16,126 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:16,126 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:16,130 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:16,130 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:24:16,131 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:16,131 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@324dcd31] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:16,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-1b1f0ad5-23c2-43bd-a6cf-fce4bee94821) exiting.
2020-12-03 07:24:16,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-893e3d81-c846-44ce-8672-82a1201e27e5) exiting.
2020-12-03 07:24:16,207 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@588ab592{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:16,208 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c8b96ec{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:16,208 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27f9e982{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:16,209 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ecf9fb3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:16,210 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35952
2020-12-03 07:24:16,211 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:16,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:16,216 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:16,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6) service to localhost/127.0.0.1:36993
2020-12-03 07:24:16,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 3c4fa4e9-3e68-4ead-8d29-084ec9beb8e6)
2020-12-03 07:24:16,216 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:16,217 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,217 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,224 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:16,224 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:16,227 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:16,227 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:16,232 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:16,232 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:24:16,232 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:16,232 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77b7ffa4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:16,235 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-6897f411-d91f-4418-a84f-f8abaa165629) exiting.
2020-12-03 07:24:16,235 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-afeab381-c9ef-41c6-8cd0-5e43e09c1127) exiting.
2020-12-03 07:24:16,261 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5528a42c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:16,262 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a551a63{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:16,262 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@210386e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:16,262 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@425357dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:16,264 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35625
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38890 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38890 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38818 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38800 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38836 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38872 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38854 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38782 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38764 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,265 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:16,265 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:16,265 [DataXceiver for client  at /127.0.0.1:38818 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,264 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:16,264 [DataXceiver for client  at /127.0.0.1:38890 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38890
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,266 [DataXceiver for client  at /127.0.0.1:38818 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38818
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,266 [DataXceiver for client  at /127.0.0.1:38764 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,266 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid e7524eb2-d776-49a1-9c40-f1cb575f4069) service to localhost/127.0.0.1:36993
2020-12-03 07:24:16,278 [DataXceiver for client  at /127.0.0.1:38764 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38764
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,278 [DataXceiver for client  at /127.0.0.1:38782 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,276 [DataXceiver for client  at /127.0.0.1:38818 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38818 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,271 [DataXceiver for client  at /127.0.0.1:38890 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38890 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,279 [DataXceiver for client  at /127.0.0.1:38782 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38782
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,279 [DataXceiver for client  at /127.0.0.1:38854 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,279 [DataXceiver for client  at /127.0.0.1:38764 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38764 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,279 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid e7524eb2-d776-49a1-9c40-f1cb575f4069)
2020-12-03 07:24:16,295 [DataXceiver for client  at /127.0.0.1:38854 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38854
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,293 [DataXceiver for client  at /127.0.0.1:38872 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,293 [DataXceiver for client  at /127.0.0.1:38782 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38782 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,320 [DataXceiver for client  at /127.0.0.1:38872 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38872
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,319 [DataXceiver for client  at /127.0.0.1:38836 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,319 [DataXceiver for client  at /127.0.0.1:38854 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38854 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,327 [DataXceiver for client  at /127.0.0.1:38836 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38836
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,327 [DataXceiver for client  at /127.0.0.1:38800 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 on DS-6897f411-d91f-4418-a84f-f8abaa165629, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,327 [DataXceiver for client  at /127.0.0.1:38872 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38872 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,332 [DataXceiver for client  at /127.0.0.1:38800 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42513, datanodeUuid=e7524eb2-d776-49a1-9c40-f1cb575f4069, infoPort=37071, infoSecurePort=0, ipcPort=35625, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002 to /127.0.0.1:38800
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,332 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:16,338 [DataXceiver for client  at /127.0.0.1:38800 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38800 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,332 [DataXceiver for client  at /127.0.0.1:38836 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775776_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42513:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:38836 dst: /127.0.0.1:42513
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,354 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,354 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,385 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:16,396 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:16,400 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:16,400 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:16,437 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:16,437 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:24:16,437 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:16,437 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2449cff7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:16,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3621fcd2-3ba5-4a4e-bb3a-d132b15949bc) exiting.
2020-12-03 07:24:16,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f) exiting.
2020-12-03 07:24:16,482 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@615f972{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:16,505 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@285f09de{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:16,506 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@408b35bf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:16,507 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71e9a896{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:16,516 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44980
2020-12-03 07:24:16,516 [DataXceiver for client  at /127.0.0.1:56430 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,517 [DataXceiver for client  at /127.0.0.1:56430 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,516 [DataXceiver for client  at /127.0.0.1:56376 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,517 [DataXceiver for client  at /127.0.0.1:56376 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,517 [DataXceiver for client  at /127.0.0.1:56376 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56376
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,518 [DataXceiver for client  at /127.0.0.1:56376 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56376 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,516 [DataXceiver for client  at /127.0.0.1:56358 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,518 [DataXceiver for client  at /127.0.0.1:56358 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,519 [DataXceiver for client  at /127.0.0.1:56358 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56358
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,516 [DataXceiver for client  at /127.0.0.1:56340 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,516 [DataXceiver for client  at /127.0.0.1:56304 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,521 [DataXceiver for client  at /127.0.0.1:56322 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,516 [DataXceiver for client  at /127.0.0.1:56394 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,520 [DataXceiver for client  at /127.0.0.1:56340 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,525 [DataXceiver for client  at /127.0.0.1:56340 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56340
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,526 [DataXceiver for client  at /127.0.0.1:56394 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,526 [DataXceiver for client  at /127.0.0.1:56394 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,526 [DataXceiver for client  at /127.0.0.1:56322 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,526 [DataXceiver for client  at /127.0.0.1:56322 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56322
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,517 [DataXceiver for client  at /127.0.0.1:56430 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56430
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,517 [DataXceiver for client  at /127.0.0.1:56412 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,526 [DataXceiver for client  at /127.0.0.1:56304 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,565 [DataXceiver for client  at /127.0.0.1:56304 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56304
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,565 [DataXceiver for client  at /127.0.0.1:56412 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 on DS-a1c2d627-4d0a-4450-aa93-3252c8fb660f, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,566 [DataXceiver for client  at /127.0.0.1:56412 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33065, datanodeUuid=4b9cbc85-1163-4e5a-b3f3-54dab64913c8, infoPort=33798, infoSecurePort=0, ipcPort=44980, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002 to /127.0.0.1:56412
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,569 [DataXceiver for client  at /127.0.0.1:56358 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56358 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,569 [DataXceiver for client  at /127.0.0.1:56412 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56412 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,569 [DataXceiver for client  at /127.0.0.1:56304 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56304 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,573 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:16,574 [DataXceiver for client  at /127.0.0.1:56340 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56340 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,574 [DataXceiver for client  at /127.0.0.1:56394 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56394 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,574 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:16,575 [DataXceiver for client  at /127.0.0.1:56430 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56430 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,574 [DataXceiver for client  at /127.0.0.1:56322 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775772_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33065:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:56322 dst: /127.0.0.1:33065
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,575 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:16,575 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 4b9cbc85-1163-4e5a-b3f3-54dab64913c8) service to localhost/127.0.0.1:36993
2020-12-03 07:24:16,575 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid 4b9cbc85-1163-4e5a-b3f3-54dab64913c8)
2020-12-03 07:24:16,584 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:16,673 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,674 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:16,688 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:16,720 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:16,727 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:16,728 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:16,729 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:16,729 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:16,729 [Listener at localhost/42769] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:16,740 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4ae33a11] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:16,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0ea987f6-e383-4d5a-a033-5af60ff63c64) exiting.
2020-12-03 07:24:16,745 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-46a68d19-78cf-4e82-8571-5aab8cb57e8a) exiting.
2020-12-03 07:24:16,831 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fcbe147{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:16,832 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@235f4c10{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:16,832 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@274872f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:16,833 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@569bf9eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:16,838 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37687
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60246 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60282 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60210 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60156 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60192 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60174 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,839 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60246 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,881 [DataXceiver for client  at /127.0.0.1:60246 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60246
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,882 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:16,838 [DataXceiver for client  at /127.0.0.1:60264 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,882 [DataXceiver for client  at /127.0.0.1:60174 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,882 [DataXceiver for client  at /127.0.0.1:60174 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60174
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,882 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b4c365af-82dd-413b-b8c8-0985174a0d5a) service to localhost/127.0.0.1:36993
2020-12-03 07:24:16,882 [DataXceiver for client  at /127.0.0.1:60246 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60246 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,881 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:16,883 [DataXceiver for client  at /127.0.0.1:60192 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,886 [DataXceiver for client  at /127.0.0.1:60156 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,886 [DataXceiver for client  at /127.0.0.1:60156 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60156
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,886 [DataXceiver for client  at /127.0.0.1:60192 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60192
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,916 [DataXceiver for client  at /127.0.0.1:60228 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,917 [DataXceiver for client  at /127.0.0.1:60174 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60174 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,935 [DataXceiver for client  at /127.0.0.1:60210 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,936 [DataXceiver for client  at /127.0.0.1:60210 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60210
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,936 [DataXceiver for client  at /127.0.0.1:60282 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,936 [DataXceiver for client  at /127.0.0.1:60228 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,936 [DataXceiver for client  at /127.0.0.1:60282 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60282
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,936 [DataXceiver for client  at /127.0.0.1:60264 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 on DS-0ea987f6-e383-4d5a-a033-5af60ff63c64, because there is no volume scanner for that storageId.
2020-12-03 07:24:16,936 [DataXceiver for client  at /127.0.0.1:60228 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60228
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,937 [DataXceiver for client  at /127.0.0.1:60264 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:33790, datanodeUuid=b4c365af-82dd-413b-b8c8-0985174a0d5a, infoPort=40698, infoSecurePort=0, ipcPort=37687, storageInfo=lv=-57;cid=testClusterID;nsid=1443257071;c=1606980238362):Got exception while serving BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002 to /127.0.0.1:60264
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,951 [DataXceiver for client  at /127.0.0.1:60156 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60156 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,952 [DataXceiver for client  at /127.0.0.1:60192 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60192 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,952 [DataXceiver for client  at /127.0.0.1:60210 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60210 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,951 [DataXceiver for client  at /127.0.0.1:60282 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60282 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,951 [DataXceiver for client  at /127.0.0.1:60228 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60228 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:16,951 [DataXceiver for client  at /127.0.0.1:60264 [Sending block BP-1172035344-172.17.0.2-1606980238362:blk_-9223372036854775770_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33790:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60264 dst: /127.0.0.1:33790
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:17,022 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1172035344-172.17.0.2-1606980238362 (Datanode Uuid b4c365af-82dd-413b-b8c8-0985174a0d5a)
2020-12-03 07:24:17,022 [BP-1172035344-172.17.0.2-1606980238362 heartbeating to localhost/127.0.0.1:36993] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1172035344-172.17.0.2-1606980238362
2020-12-03 07:24:17,023 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:17,024 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1172035344-172.17.0.2-1606980238362] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:17,030 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:17,030 [Listener at localhost/42769] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:17,038 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:17,038 [Listener at localhost/42769] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:17,039 [Listener at localhost/42769] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:17,067 [Listener at localhost/42769] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:17,068 [Listener at localhost/42769] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:17,068 [Listener at localhost/42769] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:17,069 [Listener at localhost/42769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:17,069 [Listener at localhost/42769] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:17,069 [Listener at localhost/42769] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 36
2020-12-03 07:24:17,070 [Listener at localhost/42769] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 37 Total time for transactions(ms): 42 Number of transactions batched in Syncs: 9 Number of syncs: 29 SyncTimes(ms): 7 1 
2020-12-03 07:24:17,071 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3c435123] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:17,071 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@50fe837a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:17,072 [Listener at localhost/42769] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000037
2020-12-03 07:24:17,072 [Listener at localhost/42769] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000037
2020-12-03 07:24:17,073 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:17,089 [CacheReplicationMonitor(272845039)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:17,132 [Listener at localhost/42769] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36993
2020-12-03 07:24:17,148 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:17,155 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:17,166 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:17,163 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:17,303 [Listener at localhost/42769] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:17,316 [Listener at localhost/42769] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:17,336 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1c852c0f{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:17,338 [Listener at localhost/42769] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3b79fd76{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:17,338 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dc19a70{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:17,339 [Listener at localhost/42769] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e0e1046{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
msx-rc 1
