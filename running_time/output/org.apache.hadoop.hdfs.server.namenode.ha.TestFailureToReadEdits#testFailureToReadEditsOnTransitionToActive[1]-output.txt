2020-12-03 07:22:41,394 [main] INFO  qjournal.MiniQJMHACluster (MiniQJMHACluster.java:<init>(113)) - Set MiniQJMHACluster basePort to 13936
2020-12-03 07:22:41,401 [main] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(101)) - Starting MiniJournalCluster with 3 journal nodes
2020-12-03 07:22:41,669 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:41,816 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:41,816 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:22:41,985 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:22:42,006 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,028 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1596ms
2020-12-03 07:22:42,188 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:42,239 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:22:42,239 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,252 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:42,254 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:22:42,255 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:42,255 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:42,286 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37858
2020-12-03 07:22:42,291 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:42,340 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10163d6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:42,342 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15bbf42f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:42,381 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6574a52c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:22:42,390 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@35d44772{HTTP/1.1,[http/1.1]}{localhost:37858}
2020-12-03 07:22:42,390 [main] INFO  server.Server (Server.java:doStart(419)) - Started @1959ms
2020-12-03 07:22:42,392 [main] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:22:42,436 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:42,449 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:42,740 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:42,740 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:42,743 [Listener at localhost/39818] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:22:42,746 [Listener at localhost/39818] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:22:42,746 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,759 [Listener at localhost/39818] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:42,760 [Listener at localhost/39818] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:22:42,761 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,765 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:42,767 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:22:42,768 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:42,769 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:42,771 [Listener at localhost/39818] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36659
2020-12-03 07:22:42,771 [Listener at localhost/39818] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:42,775 [Listener at localhost/39818] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f19ac19{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:42,776 [Listener at localhost/39818] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71329995{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:42,785 [Listener at localhost/39818] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7d9e8ef7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:22:42,892 [Listener at localhost/39818] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6acf18bd{HTTP/1.1,[http/1.1]}{localhost:36659}
2020-12-03 07:22:42,892 [Listener at localhost/39818] INFO  server.Server (Server.java:doStart(419)) - Started @2460ms
2020-12-03 07:22:42,894 [Listener at localhost/39818] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:22:42,895 [Listener at localhost/39818] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:42,896 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:42,902 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:42,902 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:42,906 [Listener at localhost/33559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:22:42,909 [Listener at localhost/33559] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:22:42,909 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,912 [Listener at localhost/33559] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:42,913 [Listener at localhost/33559] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:22:42,914 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,918 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:42,919 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:22:42,919 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:42,920 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:42,921 [Listener at localhost/33559] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37503
2020-12-03 07:22:42,921 [Listener at localhost/33559] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:42,924 [Listener at localhost/33559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@457c9034{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:42,925 [Listener at localhost/33559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50de186c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:42,933 [Listener at localhost/33559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@481ba2cf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:22:42,935 [Listener at localhost/33559] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@46b61c56{HTTP/1.1,[http/1.1]}{localhost:37503}
2020-12-03 07:22:42,936 [Listener at localhost/33559] INFO  server.Server (Server.java:doStart(419)) - Started @2504ms
2020-12-03 07:22:42,937 [Listener at localhost/33559] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:22:42,938 [Listener at localhost/33559] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:42,939 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:42,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:42,944 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:43,534 [IPC Server handler 0 on default port 33559] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive
2020-12-03 07:22:43,534 [IPC Server handler 0 on default port 39818] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive
2020-12-03 07:22:43,534 [IPC Server handler 0 on default port 34146] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive
2020-12-03 07:22:43,549 [IPC Server handler 0 on default port 33559] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive does not exist
2020-12-03 07:22:43,549 [IPC Server handler 0 on default port 39818] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive does not exist
2020-12-03 07:22:43,549 [IPC Server handler 0 on default port 34146] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive does not exist
2020-12-03 07:22:43,576 [IPC Server handler 0 on default port 33559] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:22:43,576 [IPC Server handler 0 on default port 39818] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:22:43,577 [IPC Server handler 0 on default port 39818] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:22:43,577 [IPC Server handler 0 on default port 33559] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:22:43,579 [IPC Server handler 0 on default port 34146] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:22:43,580 [IPC Server handler 0 on default port 34146] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:22:43,929 [Listener at localhost/34146] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=0
Formatting using clusterid: testClusterID
2020-12-03 07:22:44,206 [Listener at localhost/34146] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
2020-12-03 07:22:44,215 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:44,217 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:44,218 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:44,218 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:44,218 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:44,219 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:44,220 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:44,220 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:44,260 [Listener at localhost/34146] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,266 [Listener at localhost/34146] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:44,266 [Listener at localhost/34146] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:44,267 [Listener at localhost/34146] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:44,271 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:44,272 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:44
2020-12-03 07:22:44,275 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:44,275 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,277 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:44,277 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:44,301 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:44,301 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:44,309 [Listener at localhost/34146] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:44,310 [Listener at localhost/34146] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:44,310 [Listener at localhost/34146] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:44,311 [Listener at localhost/34146] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:44,312 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:22:44,313 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:44,313 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:44,313 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:44,314 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:44,314 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:44,314 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:44,354 [Listener at localhost/34146] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:44,354 [Listener at localhost/34146] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:44,355 [Listener at localhost/34146] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:44,355 [Listener at localhost/34146] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:44,370 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:44,370 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,371 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:44,371 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:44,377 [Listener at localhost/34146] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:44,378 [Listener at localhost/34146] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:44,378 [Listener at localhost/34146] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:44,378 [Listener at localhost/34146] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:44,385 [Listener at localhost/34146] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:44,388 [Listener at localhost/34146] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:44,394 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:44,394 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,394 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:44,395 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:44,407 [Listener at localhost/34146] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:44,407 [Listener at localhost/34146] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:44,407 [Listener at localhost/34146] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:44,411 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:44,412 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:44,415 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:44,415 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,416 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:44,416 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:44,441 [IPC Server handler 0 on default port 33559] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1
2020-12-03 07:22:44,441 [IPC Server handler 1 on default port 39818] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:22:44,441 [IPC Server handler 0 on default port 33559] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1 does not exist
2020-12-03 07:22:44,442 [IPC Server handler 1 on default port 39818] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1 does not exist
2020-12-03 07:22:44,441 [IPC Server handler 0 on default port 34146] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1
2020-12-03 07:22:44,442 [IPC Server handler 0 on default port 34146] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1 does not exist
2020-12-03 07:22:44,453 [IPC Server handler 0 on default port 34146] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:22:44,454 [IPC Server handler 1 on default port 39818] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:22:44,454 [IPC Server handler 0 on default port 33559] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:22:44,464 [Listener at localhost/34146] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-2003101440-172.17.0.3-1606980164464
2020-12-03 07:22:44,617 [Listener at localhost/34146] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:44,723 [Listener at localhost/34146] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:44,755 [IPC Server handler 2 on default port 33559] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=687219772;c=1606980164464;bpid=BP-2003101440-172.17.0.3-1606980164464 and force: true
2020-12-03 07:22:44,755 [IPC Server handler 2 on default port 34146] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=687219772;c=1606980164464;bpid=BP-2003101440-172.17.0.3-1606980164464 and force: true
2020-12-03 07:22:44,755 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=687219772;c=1606980164464;bpid=BP-2003101440-172.17.0.3-1606980164464 and force: true
2020-12-03 07:22:44,756 [IPC Server handler 2 on default port 33559] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1 does not exist. Creating ...
2020-12-03 07:22:44,756 [IPC Server handler 2 on default port 39818] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1 does not exist. Creating ...
2020-12-03 07:22:44,756 [IPC Server handler 2 on default port 34146] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1 does not exist. Creating ...
2020-12-03 07:22:44,799 [IPC Server handler 2 on default port 39818] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:44,799 [IPC Server handler 2 on default port 33559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:44,799 [IPC Server handler 2 on default port 34146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:44,800 [IPC Server handler 2 on default port 34146] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null with nsid: 687219772
2020-12-03 07:22:44,800 [IPC Server handler 2 on default port 39818] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null with nsid: 687219772
2020-12-03 07:22:44,800 [IPC Server handler 2 on default port 33559] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null with nsid: 687219772
2020-12-03 07:22:44,850 [IPC Server handler 2 on default port 34146] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos
2020-12-03 07:22:44,850 [IPC Server handler 2 on default port 33559] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos
2020-12-03 07:22:44,850 [IPC Server handler 2 on default port 39818] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos
2020-12-03 07:22:44,909 [IPC Server handler 2 on default port 34146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:44,909 [IPC Server handler 2 on default port 33559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:44,909 [IPC Server handler 2 on default port 39818] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:44,942 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:44,942 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:45,077 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:45,077 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:45,150 [Listener at localhost/34146] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:45,244 [Listener at localhost/34146] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3
2020-12-03 07:22:45,270 [Listener at localhost/34146] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4
2020-12-03 07:22:45,279 [Listener at localhost/34146] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:45,287 [Listener at localhost/34146] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:45,290 [Listener at localhost/34146] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:22:45,291 [Listener at localhost/34146] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:45,331 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64a8c844] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:45,332 [Listener at localhost/34146] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:13937
2020-12-03 07:22:45,332 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:45,334 [Listener at localhost/34146] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:45,335 [Listener at localhost/34146] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:45,335 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:45,338 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:45,339 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:45,339 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:45,339 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:45,347 [Listener at localhost/34146] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:45,348 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:45,353 [Listener at localhost/34146] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 13937
2020-12-03 07:22:45,353 [Listener at localhost/34146] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:45,358 [Listener at localhost/34146] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@485e36bc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:45,359 [Listener at localhost/34146] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a79d4b1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:45,373 [Listener at localhost/34146] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7096b474{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:45,375 [Listener at localhost/34146] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3e14c16d{HTTP/1.1,[http/1.1]}{localhost:13937}
2020-12-03 07:22:45,375 [Listener at localhost/34146] INFO  server.Server (Server.java:doStart(419)) - Started @4944ms
2020-12-03 07:22:45,428 [Listener at localhost/34146] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
2020-12-03 07:22:45,429 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:45,429 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:45,429 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:45,430 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:45,430 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:45,430 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:45,431 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:45,431 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:45,432 [Listener at localhost/34146] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:45,433 [Listener at localhost/34146] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:45,433 [Listener at localhost/34146] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:45,433 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:45,434 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:45
2020-12-03 07:22:45,434 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:45,435 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:45,435 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:45,435 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:45,453 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:45,454 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:45,454 [Listener at localhost/34146] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:45,455 [Listener at localhost/34146] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:45,455 [Listener at localhost/34146] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:45,455 [Listener at localhost/34146] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:45,455 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:22:45,456 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:45,456 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:45,456 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:45,456 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:45,457 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:45,457 [Listener at localhost/34146] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:45,458 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:45,458 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:45,459 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:45,459 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:45,466 [Listener at localhost/34146] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:45,466 [Listener at localhost/34146] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:45,466 [Listener at localhost/34146] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:45,466 [Listener at localhost/34146] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:45,467 [Listener at localhost/34146] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:45,467 [Listener at localhost/34146] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:45,467 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:45,467 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:45,468 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:45,468 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:45,470 [Listener at localhost/34146] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:45,470 [Listener at localhost/34146] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:45,471 [Listener at localhost/34146] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:45,471 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:45,471 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:45,472 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:45,472 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:45,472 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:45,473 [Listener at localhost/34146] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:45,509 [Listener at localhost/34146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:45,552 [Listener at localhost/34146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:45,570 [Listener at localhost/34146] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:45,571 [Listener at localhost/34146] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:45,610 [Listener at localhost/34146] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:45,618 [Listener at localhost/34146] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:45,618 [Listener at localhost/34146] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:45,623 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:45,624 [Listener at localhost/34146] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:45,624 [Listener at localhost/34146] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 149 msecs
2020-12-03 07:22:46,154 [Listener at localhost/34146] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:13936
2020-12-03 07:22:46,201 [Listener at localhost/34146] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:46,219 [Socket Reader #1 for port 13936] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 13936
2020-12-03 07:22:46,255 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:46,306 [Listener at localhost/13936] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:46,339 [Listener at localhost/13936] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:46,340 [Listener at localhost/13936] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:46,340 [Listener at localhost/13936] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:46,373 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:46,373 [IPC Server listener on 13936] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 13936: starting
2020-12-03 07:22:46,376 [Listener at localhost/13936] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:13936
2020-12-03 07:22:46,396 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:46,401 [Listener at localhost/13936] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:22:46,402 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period(1) assuming SECONDS
2020-12-03 07:22:46,402 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:46,402 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:46,406 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.checkpoint.check.period(1) assuming SECONDS
2020-12-03 07:22:46,411 [Listener at localhost/13936] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://127.0.0.1:13939]
Serving checkpoints at http://localhost:13937
2020-12-03 07:22:46,424 [Listener at localhost/13936] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:46,424 [Listener at localhost/13936] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:46,427 [Listener at localhost/13936] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:22:46,427 [Listener at localhost/13936] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:46,446 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f23a3a0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:46,447 [Listener at localhost/13936] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:13939
2020-12-03 07:22:46,449 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:46,452 [Listener at localhost/13936] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:46,460 [Listener at localhost/13936] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:46,461 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:46,465 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:46,466 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:46,466 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:46,467 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:46,470 [Listener at localhost/13936] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:46,470 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:46,471 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 13939
2020-12-03 07:22:46,471 [Listener at localhost/13936] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:46,478 [Listener at localhost/13936] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25bcd0c7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:46,479 [Listener at localhost/13936] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63cd604c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:46,488 [Listener at localhost/13936] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@361c294e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:46,490 [Listener at localhost/13936] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7859e786{HTTP/1.1,[http/1.1]}{localhost:13939}
2020-12-03 07:22:46,491 [Listener at localhost/13936] INFO  server.Server (Server.java:doStart(419)) - Started @6059ms
2020-12-03 07:22:46,494 [Listener at localhost/13936] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
2020-12-03 07:22:46,495 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:46,495 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:46,495 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:46,496 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:46,496 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:46,496 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:46,497 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:46,497 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:46,498 [Listener at localhost/13936] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:46,498 [Listener at localhost/13936] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:46,499 [Listener at localhost/13936] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:46,499 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:46,499 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:46
2020-12-03 07:22:46,500 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:46,500 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:46,500 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:46,500 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:46,513 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:46,513 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:46,513 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:46,514 [Listener at localhost/13936] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:46,514 [Listener at localhost/13936] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:46,514 [Listener at localhost/13936] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:46,514 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:22:46,515 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:46,515 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:46,515 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:46,516 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:46,516 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:46,516 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:46,517 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:46,517 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:46,517 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:46,517 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:46,523 [Listener at localhost/13936] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:46,523 [Listener at localhost/13936] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:46,523 [Listener at localhost/13936] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:46,523 [Listener at localhost/13936] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:46,524 [Listener at localhost/13936] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:46,524 [Listener at localhost/13936] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:46,524 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:46,524 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:46,525 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:46,525 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:46,527 [Listener at localhost/13936] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:46,527 [Listener at localhost/13936] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:46,527 [Listener at localhost/13936] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:46,527 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:46,528 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:46,528 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:46,528 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:46,528 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:46,528 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:46,567 [Listener at localhost/13936] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:46,613 [Listener at localhost/13936] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:46,628 [Listener at localhost/13936] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:46,629 [Listener at localhost/13936] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:46,639 [Listener at localhost/13936] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:46,641 [Listener at localhost/13936] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:46,641 [Listener at localhost/13936] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:22:46,641 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:46,642 [Listener at localhost/13936] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:46,642 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 112 msecs
2020-12-03 07:22:46,643 [Listener at localhost/13936] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:13938
2020-12-03 07:22:46,646 [Listener at localhost/13936] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:46,647 [Socket Reader #1 for port 13938] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 13938
2020-12-03 07:22:46,653 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:46,667 [Listener at localhost/13938] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:46,669 [Listener at localhost/13938] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:46,669 [Listener at localhost/13938] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:46,669 [Listener at localhost/13938] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:46,676 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:46,676 [IPC Server listener on 13938] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 13938: starting
2020-12-03 07:22:46,681 [Listener at localhost/13938] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:13938
2020-12-03 07:22:46,681 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:46,683 [Listener at localhost/13938] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:22:46,683 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period(1) assuming SECONDS
2020-12-03 07:22:46,683 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:46,684 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:46,684 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.checkpoint.check.period(1) assuming SECONDS
2020-12-03 07:22:46,696 [Listener at localhost/13938] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:13937]
Serving checkpoints at http://localhost:13939
2020-12-03 07:22:47,304 [IPC Server handler 0 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,348 [IPC Server handler 0 on default port 13938] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,352 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:47,366 [IPC Server handler 1 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,379 [IPC Server handler 1 on default port 13938] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,380 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:47,381 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:47,381 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:47,383 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:47,387 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 13936
2020-12-03 07:22:47,414 [IPC Server listener on 13936] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 13936
2020-12-03 07:22:47,415 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:47,416 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:47,430 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:47,495 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:47,497 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:47,518 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7096b474{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:47,537 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3e14c16d{HTTP/1.1,[http/1.1]}{localhost:13937}
2020-12-03 07:22:47,538 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a79d4b1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:47,538 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@485e36bc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:47,555 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:47,556 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:47,557 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:47,559 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 13938
2020-12-03 07:22:47,585 [IPC Server listener on 13938] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 13938
2020-12-03 07:22:47,586 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:47,587 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:47,587 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:47,603 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:47,613 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:47,615 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@361c294e{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:47,638 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7859e786{HTTP/1.1,[http/1.1]}{localhost:13939}
2020-12-03 07:22:47,639 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63cd604c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:47,640 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25bcd0c7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:47,665 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
2020-12-03 07:22:47,665 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:47,666 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:47,666 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:47,666 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:47,666 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:47,667 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:47,667 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:47,667 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:47,668 [Listener at localhost/13938] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:47,669 [Listener at localhost/13938] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:47,669 [Listener at localhost/13938] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:47,669 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:47,670 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:47
2020-12-03 07:22:47,670 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:47,670 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:47,671 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:47,671 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:47,675 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:47,676 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:47,676 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:47,676 [Listener at localhost/13938] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:47,677 [Listener at localhost/13938] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:47,677 [Listener at localhost/13938] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:47,677 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:22:47,677 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:47,677 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:47,678 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:47,678 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:47,678 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:47,678 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:47,679 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:47,679 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:47,680 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:47,680 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:47,682 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:47,682 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:47,682 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:47,683 [Listener at localhost/13938] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:47,683 [Listener at localhost/13938] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:47,683 [Listener at localhost/13938] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:47,683 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:47,684 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:47,684 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:47,684 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:47,685 [Listener at localhost/13938] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:47,686 [Listener at localhost/13938] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:47,686 [Listener at localhost/13938] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:47,686 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:47,686 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:47,686 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:47,687 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:47,687 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:47,687 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:47,840 [Listener at localhost/13938] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:47,916 [Listener at localhost/13938] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:47,919 [Listener at localhost/13938] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:47,919 [Listener at localhost/13938] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:47,923 [Listener at localhost/13938] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:47,924 [Listener at localhost/13938] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:47,924 [Listener at localhost/13938] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:47,924 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:47,925 [Listener at localhost/13938] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:47,925 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 235 msecs
2020-12-03 07:22:47,925 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
Data exists in QJM to [127.0.0.1:39818, 127.0.0.1:33559, 127.0.0.1:34146]. Formatting anyway.
2020-12-03 07:22:47,939 [IPC Server handler 0 on default port 33559] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=687219772;c=1606980164464;bpid=BP-2003101440-172.17.0.3-1606980164464 and force: true
2020-12-03 07:22:47,939 [IPC Server handler 1 on default port 39818] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=687219772;c=1606980164464;bpid=BP-2003101440-172.17.0.3-1606980164464 and force: true
2020-12-03 07:22:47,940 [IPC Server handler 0 on default port 34146] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=687219772;c=1606980164464;bpid=BP-2003101440-172.17.0.3-1606980164464 and force: true
2020-12-03 07:22:48,013 [IPC Server handler 1 on default port 39818] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,013 [IPC Server handler 1 on default port 39818] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null with nsid: 687219772
2020-12-03 07:22:48,014 [IPC Server handler 1 on default port 39818] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/committed-txid]
2020-12-03 07:22:48,015 [IPC Server handler 0 on default port 34146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,015 [IPC Server handler 0 on default port 34146] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null with nsid: 687219772
2020-12-03 07:22:48,016 [IPC Server handler 0 on default port 34146] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/committed-txid]
2020-12-03 07:22:48,016 [IPC Server handler 0 on default port 33559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,016 [IPC Server handler 0 on default port 33559] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null with nsid: 687219772
2020-12-03 07:22:48,016 [IPC Server handler 0 on default port 33559] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/committed-txid]
2020-12-03 07:22:48,070 [IPC Server handler 1 on default port 39818] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos
2020-12-03 07:22:48,130 [IPC Server handler 0 on default port 34146] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos
2020-12-03 07:22:48,131 [IPC Server handler 0 on default port 33559] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos
2020-12-03 07:22:48,170 [IPC Server handler 1 on default port 39818] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,223 [IPC Server handler 0 on default port 33559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,225 [IPC Server handler 0 on default port 34146] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,227 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:48,228 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:48,231 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:22:48,250 [IPC Server handler 3 on default port 39818] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:48,251 [IPC Server handler 3 on default port 34146] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:48,252 [IPC Server handler 2 on default port 33559] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:48,296 [IPC Server handler 3 on default port 39818] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:22:48,296 [IPC Server handler 3 on default port 34146] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:22:48,297 [IPC Server handler 3 on default port 39818] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:22:48,297 [IPC Server handler 3 on default port 34146] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:22:48,301 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 1
2020-12-03 07:22:48,305 [Listener at localhost/13938] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:48,306 [Listener at localhost/13938] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:48,307 [Listener at localhost/13938] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:13936
2020-12-03 07:22:48,307 [Listener at localhost/13938] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:48,317 [IPC Server handler 2 on default port 33559] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:22:48,317 [IPC Server handler 2 on default port 33559] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:22:48,350 [Listener at localhost/13938] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:13937
2020-12-03 07:22:48,351 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,353 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5339bbad] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:48,354 [Listener at localhost/13938] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:48,361 [Listener at localhost/13938] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:48,362 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,369 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:48,370 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:48,370 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:48,370 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:48,373 [Listener at localhost/13938] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:48,373 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:48,374 [Listener at localhost/13938] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 13937
2020-12-03 07:22:48,374 [Listener at localhost/13938] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:48,383 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29006752{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:48,384 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66d57c1b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:48,395 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@39ab59f8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:48,396 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@64e92d61{HTTP/1.1,[http/1.1]}{localhost:13937}
2020-12-03 07:22:48,397 [Listener at localhost/13938] INFO  server.Server (Server.java:doStart(419)) - Started @7965ms
2020-12-03 07:22:48,400 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
2020-12-03 07:22:48,401 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:48,401 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:48,401 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:48,401 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:48,401 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:48,401 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:48,402 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:48,402 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:48,402 [Listener at localhost/13938] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,403 [Listener at localhost/13938] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:48,403 [Listener at localhost/13938] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:48,403 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:48,404 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:48
2020-12-03 07:22:48,404 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:48,404 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,404 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:48,404 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:48,411 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:48,411 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:48,411 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:48,412 [Listener at localhost/13938] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:48,412 [Listener at localhost/13938] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:48,412 [Listener at localhost/13938] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:48,412 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:22:48,412 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:48,412 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:48,413 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:48,413 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:48,413 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:48,413 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:48,413 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:48,414 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,414 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:48,414 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:48,419 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:48,419 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:48,419 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:48,419 [Listener at localhost/13938] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:48,419 [Listener at localhost/13938] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:48,420 [Listener at localhost/13938] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:48,420 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:48,420 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,421 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:48,421 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:48,422 [Listener at localhost/13938] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:48,422 [Listener at localhost/13938] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:48,422 [Listener at localhost/13938] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:48,423 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:48,423 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:48,423 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:48,423 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,424 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:48,424 [Listener at localhost/13938] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:48,457 [Listener at localhost/13938] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,491 [Listener at localhost/13938] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,502 [Listener at localhost/13938] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:48,503 [Listener at localhost/13938] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:48,514 [Listener at localhost/13938] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:48,516 [Listener at localhost/13938] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:48,516 [Listener at localhost/13938] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:48,516 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:48,517 [Listener at localhost/13938] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:48,517 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 91 msecs
2020-12-03 07:22:48,517 [Listener at localhost/13938] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:13936
2020-12-03 07:22:48,519 [Listener at localhost/13938] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:48,520 [Socket Reader #1 for port 13936] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 13936
2020-12-03 07:22:48,544 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:48,564 [Listener at localhost/13936] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:48,574 [Listener at localhost/13936] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:48,575 [Listener at localhost/13936] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:48,575 [Listener at localhost/13936] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:48,580 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:48,580 [IPC Server listener on 13936] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 13936: starting
2020-12-03 07:22:48,582 [Listener at localhost/13936] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:13936
2020-12-03 07:22:48,583 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:48,584 [Listener at localhost/13936] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:22:48,592 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period(1) assuming SECONDS
2020-12-03 07:22:48,592 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:48,592 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:48,593 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.checkpoint.check.period(1) assuming SECONDS
2020-12-03 07:22:48,595 [Listener at localhost/13936] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:13939]
Serving checkpoints at http://localhost:13937
2020-12-03 07:22:48,606 [Listener at localhost/13936] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:48,606 [Listener at localhost/13936] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:48,611 [Listener at localhost/13936] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:13938
2020-12-03 07:22:48,614 [Listener at localhost/13936] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:48,624 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@602c4656] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:48,624 [Listener at localhost/13936] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:13939
2020-12-03 07:22:48,624 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,626 [Listener at localhost/13936] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:48,627 [Listener at localhost/13936] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:48,627 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,630 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:48,630 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:48,630 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:48,631 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:48,632 [Listener at localhost/13936] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:48,632 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:48,633 [Listener at localhost/13936] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 13939
2020-12-03 07:22:48,633 [Listener at localhost/13936] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:48,637 [Listener at localhost/13936] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63998bf4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:48,649 [Listener at localhost/13936] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61942c1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:48,665 [Listener at localhost/13936] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@701a32{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:48,669 [Listener at localhost/13936] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39aa45a1{HTTP/1.1,[http/1.1]}{localhost:13939}
2020-12-03 07:22:48,671 [Listener at localhost/13936] INFO  server.Server (Server.java:doStart(419)) - Started @8239ms
2020-12-03 07:22:48,675 [Listener at localhost/13936] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:false
2020-12-03 07:22:48,676 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:48,676 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:48,676 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:48,676 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:48,677 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:48,677 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:48,678 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:48,678 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:48,679 [Listener at localhost/13936] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,679 [Listener at localhost/13936] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:48,680 [Listener at localhost/13936] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:48,687 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:48,688 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:48
2020-12-03 07:22:48,689 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:48,689 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,689 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:48,689 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:48,698 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:48,699 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:48,699 [Listener at localhost/13936] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:48,700 [Listener at localhost/13936] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:48,700 [Listener at localhost/13936] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:48,700 [Listener at localhost/13936] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:48,700 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:22:48,700 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:48,701 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:48,701 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:48,701 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:48,702 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:48,702 [Listener at localhost/13936] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:48,703 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:48,703 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,704 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:48,704 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:48,707 [Listener at localhost/13936] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:48,707 [Listener at localhost/13936] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:48,708 [Listener at localhost/13936] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:48,708 [Listener at localhost/13936] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:48,708 [Listener at localhost/13936] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:48,709 [Listener at localhost/13936] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:48,721 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:48,722 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,723 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:48,724 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:48,725 [Listener at localhost/13936] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:48,725 [Listener at localhost/13936] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:48,726 [Listener at localhost/13936] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:48,726 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:48,726 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:48,727 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:48,727 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,727 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:48,728 [Listener at localhost/13936] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:48,768 [Listener at localhost/13936] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,809 [Listener at localhost/13936] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 8334@267870a45f70
2020-12-03 07:22:48,822 [Listener at localhost/13936] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:48,822 [Listener at localhost/13936] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:48,828 [Listener at localhost/13936] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:48,829 [Listener at localhost/13936] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:48,830 [Listener at localhost/13936] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:22:48,830 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:48,830 [Listener at localhost/13936] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:48,831 [Listener at localhost/13936] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 101 msecs
2020-12-03 07:22:48,831 [Listener at localhost/13936] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:13938
2020-12-03 07:22:48,832 [Listener at localhost/13936] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:48,833 [Socket Reader #1 for port 13938] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 13938
2020-12-03 07:22:48,843 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:48,862 [Listener at localhost/13938] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:48,864 [Listener at localhost/13938] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:48,865 [Listener at localhost/13938] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:48,865 [Listener at localhost/13938] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:48,877 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:48,877 [IPC Server listener on 13938] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 13938: starting
2020-12-03 07:22:48,887 [Listener at localhost/13938] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:13938
2020-12-03 07:22:48,888 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:48,890 [Listener at localhost/13938] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:22:48,890 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period(1) assuming SECONDS
2020-12-03 07:22:48,891 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:48,891 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:48,891 [Listener at localhost/13938] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.checkpoint.check.period(1) assuming SECONDS
2020-12-03 07:22:48,894 [Listener at localhost/13938] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:13937]
Serving checkpoints at http://localhost:13939
2020-12-03 07:22:48,913 [IPC Server handler 0 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:48,929 [IPC Server handler 0 on default port 13938] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:48,931 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:48,933 [IPC Server handler 1 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:48,944 [IPC Server handler 1 on default port 13938] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:48,946 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:48,947 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:48,952 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:48,954 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:48,957 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:22:48,963 [IPC Server handler 4 on default port 33559] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:48,964 [IPC Server handler 4 on default port 34146] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:48,969 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:49,029 [IPC Server handler 4 on default port 33559] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:22:49,029 [IPC Server handler 4 on default port 33559] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:22:49,029 [IPC Server handler 4 on default port 34146] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:22:49,031 [IPC Server handler 4 on default port 34146] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:22:49,037 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 2
2020-12-03 07:22:49,037 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:49,038 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:49,038 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:22:49,054 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:22:49,054 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:22:49,056 [Listener at localhost/13938] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:22:49,060 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:22:49,060 [Listener at localhost/13938] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:49,061 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:22:49,064 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:49,074 [IPC Server handler 4 on default port 39818] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:49,075 [IPC Server handler 1 on default port 34146] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:49,074 [IPC Server handler 1 on default port 33559] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:22:49,173 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:49,185 [Listener at localhost/13938] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 11 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:49,188 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4095)) - NameNode rolling its own edit log because number of edits in open segment exceeds threshold of 0
2020-12-03 07:22:49,192 [CacheReplicationMonitor(1964442851)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:49,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:49,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:49,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:49,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:49,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:49,193 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 132 msec
2020-12-03 07:22:49,205 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:22:49,206 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:22:49,211 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(608)) - logSyncAll toSyncToTxId=2 lastSyncedTxid=1 mostRecentTxid=2
2020-12-03 07:22:49,226 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(613)) - Done logSyncAll lastWrittenTxId=2 lastSyncedTxid=2 mostRecentTxid=2
2020-12-03 07:22:49,227 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 22 2 3 
2020-12-03 07:22:49,235 [IPC Server handler 2 on default port 34146] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:49,235 [IPC Server handler 3 on default port 33559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:49,235 [IPC Server handler 0 on default port 39818] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:49,240 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:49,242 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:49,242 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 3
2020-12-03 07:22:49,373 [IPC Server handler 3 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:49,376 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:22:49,377 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 3, 4
2020-12-03 07:22:49,380 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(608)) - logSyncAll toSyncToTxId=5 lastSyncedTxid=4 mostRecentTxid=5
2020-12-03 07:22:49,389 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(613)) - Done logSyncAll lastWrittenTxId=5 lastSyncedTxid=5 mostRecentTxid=5
2020-12-03 07:22:49,390 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 3 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 18 3 1 
2020-12-03 07:22:49,393 [IPC Server handler 2 on default port 34146] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000003 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000003-0000000000000000005
2020-12-03 07:22:49,394 [IPC Server handler 3 on default port 33559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000003 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000003-0000000000000000005
2020-12-03 07:22:49,407 [IPC Server handler 0 on default port 39818] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000003 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000003-0000000000000000005
2020-12-03 07:22:49,408 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000003 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005
2020-12-03 07:22:49,409 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000003 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000003-0000000000000000005
2020-12-03 07:22:49,409 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 6
2020-12-03 07:22:49,926 [Edit log tailer] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@735fd76d expecting start txid #1
2020-12-03 07:22:49,927 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:36659/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:49,927 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:36659/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-12-03 07:22:49,927 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:36659/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-12-03 07:22:50,128 [qtp873993427-63] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000002, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:50,169 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named http://localhost:36659/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=1&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true) of total size 42.0, total edits 2.0, total load time 214.0 ms
2020-12-03 07:22:50,169 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37503/getJournal?jid=ns1&segmentTxId=3&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=3&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-12-03 07:22:50,169 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37503/getJournal?jid=ns1&segmentTxId=3&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 1
2020-12-03 07:22:50,174 [qtp1611373863-86] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000003-0000000000000000005, fileSize: 114. Sent total: 114 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:50,507 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(507)) - examining name dir with files: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:50,508 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(510)) - Examining storage dir /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current with contents: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:50,809 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(507)) - examining name dir with files: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:50,809 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(510)) - Examining storage dir /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current with contents: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:50,895 [Standby State Checkpointer] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:doWork(404)) - Triggering checkpoint because there have been 5 txns since the last checkpoint, which exceeds the configured threshold 1
2020-12-03 07:22:50,897 [Standby State Checkpointer] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:22:50,907 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage.ckpt_0000000000000000005 using no compression
2020-12-03 07:22:50,912 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/fsimage.ckpt_0000000000000000005 using no compression
2020-12-03 07:22:50,920 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage.ckpt_0000000000000000005 of size 489 bytes saved in 0 seconds .
2020-12-03 07:22:50,920 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/fsimage.ckpt_0000000000000000005 of size 489 bytes saved in 0 seconds .
2020-12-03 07:22:50,980 [Standby State Checkpointer] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:22:51,083 [TransferFsImageUpload-0] INFO  namenode.TransferFsImage (TransferFsImage.java:setTimeout(436)) - Image Transfer timeout configured to 60000 milliseconds
2020-12-03 07:22:51,085 [TransferFsImageUpload-0] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000005, fileSize: 489. Sent total: 489 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:51,110 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(507)) - examining name dir with files: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:51,111 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(510)) - Examining storage dir /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current with contents: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:51,197 [qtp680150616-272] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000005 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000005 took 0.00s.
2020-12-03 07:22:51,199 [qtp680150616-272] INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(141)) - Downloaded file fsimage.ckpt_0000000000000000005 size 489 bytes.
2020-12-03 07:22:51,266 [qtp680150616-272] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:22:51,271 [TransferFsImageUpload-0] INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(241)) - Uploaded image with txid 5 to namenode at http://localhost:13937 in 0.206 seconds
2020-12-03 07:22:51,273 [Standby State Checkpointer] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:doWork(442)) - Checkpoint finished successfully.
2020-12-03 07:22:51,412 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(507)) - examining name dir with files: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000005.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:51,413 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(510)) - Examining storage dir /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current with contents: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000003-0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000005.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/seen_txid
2020-12-03 07:22:51,413 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(507)) - examining name dir with files: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000006,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000003-0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000005,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/VERSION,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000000.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000000,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000005.md5,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/seen_txid
2020-12-03 07:22:51,414 [Listener at localhost/13938] INFO  namenode.FSImageTestUtil (FSImageTestUtil.java:assertNNHasCheckpoints(510)) - Examining storage dir /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current with contents: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000006, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000003-0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000005, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000000.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000000, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000005.md5, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/seen_txid
2020-12-03 07:22:51,701 [IPC Server handler 0 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:51,709 [IPC Server handler 1 on default port 13936] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:51,711 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:22:51,711 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 6, 8
2020-12-03 07:22:51,711 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(608)) - logSyncAll toSyncToTxId=9 lastSyncedTxid=8 mostRecentTxid=9
2020-12-03 07:22:51,714 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(613)) - Done logSyncAll lastWrittenTxId=9 lastSyncedTxid=9 mostRecentTxid=9
2020-12-03 07:22:51,714 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 17 3 2 
2020-12-03 07:22:51,717 [IPC Server handler 1 on default port 39818] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009
2020-12-03 07:22:51,717 [IPC Server handler 0 on default port 33559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000006-0000000000000000009
2020-12-03 07:22:51,717 [IPC Server handler 0 on default port 34146] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000006-0000000000000000009
2020-12-03 07:22:51,719 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000006-0000000000000000009
2020-12-03 07:22:51,720 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000006 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000006-0000000000000000009
2020-12-03 07:22:51,720 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 10
2020-12-03 07:22:52,214 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:52,218 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 6
2020-12-03 07:22:52,218 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 6
2020-12-03 07:22:52,223 [qtp996796369-28] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:52,225 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
Recent opcode offsets: 25 97
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:52,226 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
Recent opcode offsets: 25 97
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:52,276 [Standby State Checkpointer] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:doWork(404)) - Triggering checkpoint because there have been 2 txns since the last checkpoint, which exceeds the configured threshold 1
2020-12-03 07:22:52,276 [Standby State Checkpointer] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:22:52,295 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/fsimage.ckpt_0000000000000000007 using no compression
2020-12-03 07:22:52,295 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage.ckpt_0000000000000000007 using no compression
2020-12-03 07:22:52,301 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/fsimage.ckpt_0000000000000000007 of size 547 bytes saved in 0 seconds .
2020-12-03 07:22:52,304 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage.ckpt_0000000000000000007 of size 547 bytes saved in 0 seconds .
2020-12-03 07:22:52,376 [Standby State Checkpointer] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 3 images with txid >= 0
2020-12-03 07:22:52,540 [TransferFsImageUpload-1] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000007, fileSize: 547. Sent total: 547 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:52,871 [qtp680150616-373] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000007 took 0.00s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000007 took 0.00s.
2020-12-03 07:22:52,872 [qtp680150616-373] INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(141)) - Downloaded file fsimage.ckpt_0000000000000000007 size 547 bytes.
2020-12-03 07:22:52,958 [qtp680150616-373] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 3 images with txid >= 0
2020-12-03 07:22:52,970 [TransferFsImageUpload-1] INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(241)) - Uploaded image with txid 7 to namenode at http://localhost:13937 in 0.433 seconds
2020-12-03 07:22:52,971 [Standby State Checkpointer] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:doWork(442)) - Checkpoint finished successfully.
2020-12-03 07:22:53,231 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:53,232 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:53,232 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:53,235 [qtp996796369-40] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:53,236 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:53,237 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:54,242 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:54,243 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:54,243 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:54,246 [qtp996796369-376] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:54,247 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:54,247 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:55,252 [Edit log tailer] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7@17672e12 expecting start txid #8; suppressed logging for 4 edit reads
2020-12-03 07:22:55,252 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:55,253 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:55,253 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:55,258 [qtp873993427-63] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:55,258 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:55,259 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:56,264 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:56,265 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:56,265 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:56,268 [qtp996796369-28] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:56,270 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:56,272 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:57,277 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:57,277 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:57,278 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:57,280 [qtp996796369-40] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:57,284 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:57,285 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:58,293 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:58,295 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:58,295 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:58,298 [qtp996796369-376] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:58,299 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:58,300 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:22:59,308 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:59,309 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:59,309 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:22:59,312 [qtp996796369-28] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:22:59,313 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:59,315 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:23:00,324 [Edit log tailer] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7@6306b4a7 expecting start txid #8; suppressed logging for 4 edit reads
2020-12-03 07:23:00,324 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:00,326 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:23:00,326 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:23:00,330 [qtp873993427-364] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:00,331 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:00,332 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:23:01,337 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:01,338 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:37503/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:23:01,338 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:23:01,341 [qtp996796369-40] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:01,345 [Edit log tailer] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:01,346 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(505)) - Error while reading edits from disk. Will try again.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:494)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 8 more
2020-12-03 07:23:01,812 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:01,812 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:01,813 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 10, 10
2020-12-03 07:23:01,813 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5e76a2bb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:01,814 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(608)) - logSyncAll toSyncToTxId=11 lastSyncedTxid=10 mostRecentTxid=11
2020-12-03 07:23:01,815 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5942ee04] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:01,822 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:logSyncAll(613)) - Done logSyncAll lastWrittenTxId=11 lastSyncedTxid=11 mostRecentTxid=11
2020-12-03 07:23:01,823 [Listener at localhost/13938] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 10 1 1 
2020-12-03 07:23:01,825 [IPC Server handler 2 on default port 34146] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000010 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000010-0000000000000000011
2020-12-03 07:23:01,825 [IPC Server handler 0 on default port 39818] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000010 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000010-0000000000000000011
2020-12-03 07:23:01,825 [IPC Server handler 3 on default port 33559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000010 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000010-0000000000000000011
2020-12-03 07:23:01,833 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000010 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000010-0000000000000000011
2020-12-03 07:23:01,834 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000010 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000010-0000000000000000011
2020-12-03 07:23:01,842 [CacheReplicationMonitor(1964442851)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:01,843 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 13936
2020-12-03 07:23:01,845 [IPC Server listener on 13936] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 13936
2020-12-03 07:23:01,845 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:01,854 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:01,854 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:01,864 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:01,865 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:01,866 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@39ab59f8{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:01,868 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@64e92d61{HTTP/1.1,[http/1.1]}{localhost:13937}
2020-12-03 07:23:01,869 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66d57c1b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:01,870 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29006752{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:01,878 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:01,878 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:01,880 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:01,885 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:01,890 [IPC Server handler 4 on default port 39818] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:01,890 [IPC Server handler 1 on default port 34146] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:01,893 [IPC Server handler 1 on default port 33559] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:02,048 [IPC Server handler 1 on default port 33559] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:23:02,048 [IPC Server handler 1 on default port 34146] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:23:02,048 [IPC Server handler 4 on default port 39818] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:23:02,049 [IPC Server handler 1 on default port 34146] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:23:02,049 [IPC Server handler 1 on default port 33559] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:23:02,049 [IPC Server handler 4 on default port 39818] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:23:02,050 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 3
2020-12-03 07:23:02,050 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 10
2020-12-03 07:23:02,060 [IPC Server handler 3 on default port 34146] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(10): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) -> startTxId: 10 endTxId: 11 isInProgress: false ; journal id: ns1
2020-12-03 07:23:02,060 [IPC Server handler 3 on default port 39818] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(10): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) -> startTxId: 10 endTxId: 11 isInProgress: false ; journal id: ns1
2020-12-03 07:23:02,060 [IPC Server handler 2 on default port 33559] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(10): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) -> startTxId: 10 endTxId: 11 isInProgress: false ; journal id: ns1
2020-12-03 07:23:02,061 [IPC Server handler 3 on default port 39818] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 10: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 11 ; journal id: ns1
2020-12-03 07:23:02,061 [IPC Server handler 2 on default port 33559] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 10: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 11 ; journal id: ns1
2020-12-03 07:23:02,061 [IPC Server handler 3 on default port 34146] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 10: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 11 ; journal id: ns1
2020-12-03 07:23:02,063 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:39818: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 11
127.0.0.1:33559: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 11
127.0.0.1:34146: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 11
2020-12-03 07:23:02,064 [Listener at localhost/13938] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(346)) - Using longest log: 127.0.0.1:39818=segmentState {
  startTxId: 10
  endTxId: 11
  isInProgress: false
}
lastWriterEpoch: 2
lastCommittedTxId: 11

2020-12-03 07:23:02,070 [IPC Server handler 4 on default port 34146] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(10): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) -> startTxId: 10 endTxId: 11 isInProgress: false ; journal id: ns1
2020-12-03 07:23:02,070 [IPC Server handler 4 on default port 33559] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(10): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) -> startTxId: 10 endTxId: 11 isInProgress: false ; journal id: ns1
2020-12-03 07:23:02,070 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(10): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000010-0000000000000000011,first=0000000000000000010,last=0000000000000000011,inProgress=false,hasCorruptHeader=false) -> startTxId: 10 endTxId: 11 isInProgress: false ; journal id: ns1
2020-12-03 07:23:02,074 [IPC Server handler 4 on default port 34146] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 10 endTxId: 11 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:23:02,074 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 10 endTxId: 11 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:23:02,074 [IPC Server handler 4 on default port 33559] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 10 endTxId: 11 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:23:02,175 [IPC Server handler 2 on default port 39818] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 10: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } acceptedInEpoch: 3 ; journal id: ns1
2020-12-03 07:23:02,176 [IPC Server handler 4 on default port 34146] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 10: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } acceptedInEpoch: 3 ; journal id: ns1
2020-12-03 07:23:02,176 [IPC Server handler 4 on default port 33559] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 10: segmentState { startTxId: 10 endTxId: 11 isInProgress: false } acceptedInEpoch: 3 ; journal id: ns1
2020-12-03 07:23:02,180 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current
2020-12-03 07:23:02,180 [Listener at localhost/13938] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current
2020-12-03 07:23:02,181 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:02,188 [Listener at localhost/13938] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:02,190 [Listener at localhost/13938] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true, http://localhost:36659/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:23:02,191 [Listener at localhost/13938] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'http://localhost:37858/getJournal?jid=ns1&segmentTxId=6&storageInfo=-65%3A687219772%3A1606980164464%3AtestClusterID&inProgressOk=true' to transaction ID 8
2020-12-03 07:23:02,196 [qtp996796369-376] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000006-0000000000000000009, fileSize: 186. Sent total: 186 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:02,198 [Listener at localhost/13938] ERROR namenode.FSImage (FSEditLogLoader.java:loadEditRecords(252)) - Error replaying edit log at offset 169.  Expected transaction ID was 8
java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:304)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:298)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:517)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:498)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.catchupDuringFailover(EditLogTailer.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1235)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1956)
	at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:59)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1800)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1776)
	at org.apache.hadoop.hdfs.MiniDFSCluster.transitionToActive(MiniDFSCluster.java:2643)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits.testFailureToReadEditsOnTransitionToActive(TestFailureToReadEdits.java:332)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:02,200 [Listener at localhost/13938] ERROR namenode.NameNode (NameNode.java:doImmediateShutdown(1932)) - Error encountered requiring NN shutdown. Shutting down immediately.
org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:304)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:298)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:517)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:498)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.catchupDuringFailover(EditLogTailer.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1235)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1956)
	at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:59)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1800)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1776)
	at org.apache.hadoop.hdfs.MiniDFSCluster.transitionToActive(MiniDFSCluster.java:2643)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits.testFailureToReadEditsOnTransitionToActive(TestFailureToReadEdits.java:332)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 55 more
2020-12-03 07:23:02,202 [Listener at localhost/13938] INFO  util.ExitUtil (ExitUtil.java:terminate(210)) - Exiting with status 1: org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
2020-12-03 07:23:02,202 [Listener at localhost/13938] ERROR util.ExitUtil (ExitUtil.java:terminate(213)) - Terminate called
1: org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:265)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.doImmediateShutdown(NameNode.java:1936)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1959)
	at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:59)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1800)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1776)
	at org.apache.hadoop.hdfs.MiniDFSCluster.transitionToActive(MiniDFSCluster.java:2643)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits.testFailureToReadEditsOnTransitionToActive(TestFailureToReadEdits.java:332)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 169.  Expected transaction ID was 8
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:914)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:353)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:304)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:298)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:517)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:498)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.catchupDuringFailover(EditLogTailer.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1235)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1956)
	... 42 more
Caused by: java.io.IOException: failed to read op creating /test3
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:374)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits$LimitedEditLogAnswer$1.answer(TestFailureToReadEdits.java:366)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$$EnhancerByMockitoWithCGLIB$$12c58ae7.readOp(<generated>)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)
	... 55 more
2020-12-03 07:23:02,203 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:02,204 [Listener at localhost/13938] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:02,204 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:02,205 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 13938
2020-12-03 07:23:02,207 [IPC Server listener on 13938] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 13938
2020-12-03 07:23:02,208 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,210 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:02,210 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:02,219 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:02,219 [Listener at localhost/13938] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:02,221 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@701a32{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:02,235 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39aa45a1{HTTP/1.1,[http/1.1]}{localhost:13939}
2020-12-03 07:23:02,236 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61942c1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,236 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63998bf4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,245 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39818
2020-12-03 07:23:02,245 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$30/1604816940@b24eab8] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(171)) - JournalNodeSyncer daemon received Runtime exception.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:169)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:02,247 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,247 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:02,247 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6574a52c{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:02,371 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@35d44772{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:02,373 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15bbf42f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,376 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10163d6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,378 [Listener at localhost/13938] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive; location= null
2020-12-03 07:23:02,378 [Listener at localhost/13938] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null
2020-12-03 07:23:02,380 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33559
2020-12-03 07:23:02,381 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$30/1604816940@390c7cf8] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(171)) - JournalNodeSyncer daemon received Runtime exception.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:169)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:02,382 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,382 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:02,383 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7d9e8ef7{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:02,386 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6acf18bd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:02,387 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71329995{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,388 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f19ac19{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,394 [Listener at localhost/13938] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive; location= null
2020-12-03 07:23:02,394 [Listener at localhost/13938] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null
2020-12-03 07:23:02,397 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$30/1604816940@1d2aed80] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(171)) - JournalNodeSyncer daemon received Runtime exception.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:169)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:02,397 [Listener at localhost/13938] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34146
2020-12-03 07:23:02,399 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@481ba2cf{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:02,404 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,405 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:02,409 [Listener at localhost/13938] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@46b61c56{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:02,409 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50de186c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,409 [Listener at localhost/13938] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@457c9034{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,410 [Listener at localhost/13938] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive; location= null
2020-12-03 07:23:02,411 [Listener at localhost/13938] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null
2020-12-03 07:23:02,412 [Listener at localhost/13938] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:23:02,414 [Listener at localhost/13938] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:23:02,414 [Listener at localhost/13938] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
msx-rc 0
