2020-12-03 07:23:01,753 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:23:02,713 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:02,735 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:02,737 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:02,738 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:02,747 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:02,748 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:02,748 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:02,749 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:02,803 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:02,811 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:02,811 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:02,812 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:02,818 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:02,819 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:02
2020-12-03 07:23:02,822 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:02,824 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:02,827 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:02,827 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:02,857 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:02,858 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:02,871 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:02,872 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:02,872 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:02,873 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:02,874 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:02,874 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:02,874 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:02,874 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:23:02,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:02,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:02,875 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:02,936 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:02,937 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:02,937 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:02,938 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:02,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:02,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:02,964 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:02,965 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:02,973 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:02,973 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:02,974 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:02,974 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:02,982 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:02,988 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:02,994 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:02,994 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:02,995 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:02,995 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:03,006 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:03,006 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:03,007 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:03,014 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:03,015 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:03,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:03,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:03,019 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:03,019 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:03,060 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:03,276 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:03,507 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:03,547 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:03,547 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:03,694 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:03,694 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:03,833 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:03,838 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:03,964 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:04,378 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:04,378 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:04,418 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:04,493 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a56cdac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:04,506 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:04,513 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,534 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4061ms
2020-12-03 07:23:04,679 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:04,683 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:04,684 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:04,706 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:04,722 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:04,722 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:04,723 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:04,760 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:04,760 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:04,770 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36735
2020-12-03 07:23:04,772 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:04,855 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1807f5a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:04,856 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb4f2a9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:04,911 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4dd6fd0a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:04,925 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4bd31064{HTTP/1.1,[http/1.1]}{localhost:36735}
2020-12-03 07:23:04,926 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4453ms
2020-12-03 07:23:04,945 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:04,946 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:04,946 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:04,947 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:04,947 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:04,947 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:04,948 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:04,948 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:04,949 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:04,950 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:04,950 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:04,951 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:04,951 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:04
2020-12-03 07:23:04,952 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:04,952 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:04,953 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:04,953 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:04,957 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:04,958 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:04,958 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:04,959 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:04,959 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:04,959 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:04,959 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:04,960 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:04,961 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:04,961 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:23:04,961 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:04,961 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:04,962 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:04,962 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:04,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:04,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:04,963 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:04,966 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:04,966 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:04,966 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:04,967 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:04,967 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:04,967 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:04,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:04,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:04,968 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:04,969 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:04,970 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:04,970 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:04,970 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:04,971 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:04,971 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:04,971 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:04,972 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:04,972 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:04,972 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:05,038 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:05,072 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:05,076 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:05,077 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:05,077 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:05,078 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:05,125 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:05,133 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:05,133 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:05,138 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:05,139 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:05,216 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:05,217 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 241 msecs
2020-12-03 07:23:05,422 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:05,471 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:05,487 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:05,831 [Listener at localhost/38574] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38574 to access this namenode/service.
2020-12-03 07:23:05,835 [Listener at localhost/38574] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:05,856 [Listener at localhost/38574] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:05,858 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@a4b2d8f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-12-03 07:23:05,873 [Listener at localhost/38574] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:05,874 [Listener at localhost/38574] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:05,874 [Listener at localhost/38574] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:05,875 [Listener at localhost/38574] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:05,879 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:05,879 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:05,880 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:05,880 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:05,880 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:05,880 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:23:05,918 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:05,919 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:05,933 [Listener at localhost/38574] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38574
2020-12-03 07:23:05,974 [Listener at localhost/38574] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:05,974 [Listener at localhost/38574] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:05,987 [Listener at localhost/38574] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 12 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:06,011 [CacheReplicationMonitor(516470401)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:06,026 [Listener at localhost/38574] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:06,110 [Listener at localhost/38574] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:06,146 [Listener at localhost/38574] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:06,192 [Listener at localhost/38574] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:06,198 [Listener at localhost/38574] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:06,202 [Listener at localhost/38574] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:06,208 [Listener at localhost/38574] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:06,210 [Listener at localhost/38574] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:06,217 [Listener at localhost/38574] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:06,229 [Listener at localhost/38574] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44171
2020-12-03 07:23:06,232 [Listener at localhost/38574] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:06,233 [Listener at localhost/38574] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:06,260 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:06,263 [Listener at localhost/38574] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:06,265 [Listener at localhost/38574] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:06,266 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:06,269 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:06,270 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:06,270 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:06,270 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:06,275 [Listener at localhost/38574] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44332
2020-12-03 07:23:06,275 [Listener at localhost/38574] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:06,280 [Listener at localhost/38574] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e70ea3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:06,281 [Listener at localhost/38574] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@675d8c96{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:06,303 [Listener at localhost/38574] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@76ba13c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:06,307 [Listener at localhost/38574] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@eb6449b{HTTP/1.1,[http/1.1]}{localhost:44332}
2020-12-03 07:23:06,308 [Listener at localhost/38574] INFO  server.Server (Server.java:doStart(419)) - Started @5835ms
2020-12-03 07:23:06,761 [Listener at localhost/38574] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43081
2020-12-03 07:23:06,762 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b5bc39d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:06,764 [Listener at localhost/38574] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:06,764 [Listener at localhost/38574] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:07,136 [Listener at localhost/38574] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:07,139 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:07,153 [Listener at localhost/42164] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42164
2020-12-03 07:23:07,172 [Listener at localhost/42164] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:07,173 [Listener at localhost/42164] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:07,193 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:07,202 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:07,203 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:07,209 [Listener at localhost/42164] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:07,212 [Listener at localhost/42164] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:07,214 [Listener at localhost/42164] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:07,224 [Listener at localhost/42164] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:07,225 [Listener at localhost/42164] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,225 [Listener at localhost/42164] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:07,226 [Listener at localhost/42164] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:07,227 [Listener at localhost/42164] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,228 [Listener at localhost/42164] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:07,235 [Listener at localhost/42164] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37531
2020-12-03 07:23:07,235 [Listener at localhost/42164] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:07,236 [Listener at localhost/42164] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:07,237 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,241 [Listener at localhost/42164] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:07,242 [Listener at localhost/42164] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:07,243 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,246 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:07,248 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:07,248 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:07,249 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:07,250 [Listener at localhost/42164] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41496
2020-12-03 07:23:07,250 [Listener at localhost/42164] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:07,254 [Listener at localhost/42164] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aec50a1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:07,255 [Listener at localhost/42164] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70d2e40b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:07,262 [Listener at localhost/42164] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5af9926a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:07,263 [Listener at localhost/42164] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@43c67247{HTTP/1.1,[http/1.1]}{localhost:41496}
2020-12-03 07:23:07,264 [Listener at localhost/42164] INFO  server.Server (Server.java:doStart(419)) - Started @6791ms
2020-12-03 07:23:07,358 [Listener at localhost/42164] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38588
2020-12-03 07:23:07,359 [Listener at localhost/42164] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:07,359 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@726386ed] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:07,359 [Listener at localhost/42164] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:07,360 [Listener at localhost/42164] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:07,362 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:07,367 [Listener at localhost/39846] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39846
2020-12-03 07:23:07,378 [Listener at localhost/39846] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:07,379 [Listener at localhost/39846] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:07,380 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:07,381 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:07,397 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:07,424 [Listener at localhost/39846] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:07,447 [Listener at localhost/39846] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:07,448 [Listener at localhost/39846] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:07,452 [Listener at localhost/39846] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:07,453 [Listener at localhost/39846] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,453 [Listener at localhost/39846] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:07,454 [Listener at localhost/39846] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:07,454 [Listener at localhost/39846] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,454 [Listener at localhost/39846] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:07,463 [Listener at localhost/39846] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35185
2020-12-03 07:23:07,464 [Listener at localhost/39846] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:07,464 [Listener at localhost/39846] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:07,467 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,469 [Listener at localhost/39846] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:07,474 [Listener at localhost/39846] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:07,474 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,477 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:07,478 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:07,478 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:07,478 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:07,480 [Listener at localhost/39846] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41961
2020-12-03 07:23:07,480 [Listener at localhost/39846] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:07,488 [Listener at localhost/39846] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7544a1e4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:07,489 [Listener at localhost/39846] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7957dc72{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:07,498 [Listener at localhost/39846] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@65f87a2c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:07,500 [Listener at localhost/39846] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51684e4a{HTTP/1.1,[http/1.1]}{localhost:41961}
2020-12-03 07:23:07,509 [Listener at localhost/39846] INFO  server.Server (Server.java:doStart(419)) - Started @7036ms
2020-12-03 07:23:07,541 [Listener at localhost/39846] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45219
2020-12-03 07:23:07,542 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38875e7d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:07,542 [Listener at localhost/39846] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:07,543 [Listener at localhost/39846] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:07,543 [Listener at localhost/39846] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:07,546 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:07,554 [Listener at localhost/42079] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42079
2020-12-03 07:23:07,565 [Listener at localhost/42079] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:07,566 [Listener at localhost/42079] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:07,568 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:07,592 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:07,596 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:07,606 [Listener at localhost/42079] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:07,609 [Listener at localhost/42079] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:07,609 [Listener at localhost/42079] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:07,611 [Listener at localhost/42079] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:07,612 [Listener at localhost/42079] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,612 [Listener at localhost/42079] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:07,612 [Listener at localhost/42079] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:07,613 [Listener at localhost/42079] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,613 [Listener at localhost/42079] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:07,614 [Listener at localhost/42079] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36279
2020-12-03 07:23:07,614 [Listener at localhost/42079] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:07,614 [Listener at localhost/42079] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:07,616 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,617 [Listener at localhost/42079] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:07,618 [Listener at localhost/42079] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:07,618 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,621 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:07,622 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:07,622 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:07,622 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:07,623 [Listener at localhost/42079] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33722
2020-12-03 07:23:07,623 [Listener at localhost/42079] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:07,625 [Listener at localhost/42079] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36ac8a63{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:07,629 [Listener at localhost/42079] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52c8295b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:07,639 [Listener at localhost/42079] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22db8f4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:07,641 [Listener at localhost/42079] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b46a8c1{HTTP/1.1,[http/1.1]}{localhost:33722}
2020-12-03 07:23:07,642 [Listener at localhost/42079] INFO  server.Server (Server.java:doStart(419)) - Started @7169ms
2020-12-03 07:23:07,755 [Listener at localhost/42079] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34080
2020-12-03 07:23:07,756 [Listener at localhost/42079] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:07,756 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29caf222] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:07,757 [Listener at localhost/42079] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:07,757 [Listener at localhost/42079] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:07,759 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:07,767 [Listener at localhost/38923] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38923
2020-12-03 07:23:07,771 [Listener at localhost/38923] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:07,772 [Listener at localhost/38923] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:07,772 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:07,773 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:07,773 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:07,805 [Listener at localhost/38923] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:07,847 [Listener at localhost/38923] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:07,848 [Listener at localhost/38923] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:07,849 [Listener at localhost/38923] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:07,852 [Listener at localhost/38923] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,852 [Listener at localhost/38923] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:07,868 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:07,869 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:07,869 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:07,871 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:07,872 [Listener at localhost/38923] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:07,872 [Listener at localhost/38923] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:07,872 [Listener at localhost/38923] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:07,873 [Listener at localhost/38923] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36190
2020-12-03 07:23:07,874 [Listener at localhost/38923] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:07,874 [Listener at localhost/38923] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:07,875 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:07,876 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,889 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:07,890 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:07,893 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:07,895 [Listener at localhost/38923] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:07,896 [Listener at localhost/38923] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:07,897 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:07,900 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:07,901 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:07,901 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:07,902 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:07,903 [Listener at localhost/38923] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42893
2020-12-03 07:23:07,904 [Listener at localhost/38923] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:07,906 [Listener at localhost/38923] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cfd1875{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:07,907 [Listener at localhost/38923] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c444798{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:07,914 [Listener at localhost/38923] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@475b7792{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:07,915 [Listener at localhost/38923] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@751e664e{HTTP/1.1,[http/1.1]}{localhost:42893}
2020-12-03 07:23:07,916 [Listener at localhost/38923] INFO  server.Server (Server.java:doStart(419)) - Started @7443ms
2020-12-03 07:23:07,934 [Listener at localhost/38923] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37765
2020-12-03 07:23:07,934 [Listener at localhost/38923] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:07,935 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@182b435b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:07,935 [Listener at localhost/38923] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:07,935 [Listener at localhost/38923] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:07,936 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:07,941 [Listener at localhost/33296] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33296
2020-12-03 07:23:07,949 [Listener at localhost/33296] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:07,950 [Listener at localhost/33296] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:07,951 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:07,951 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:07,952 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:07,972 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:07,973 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:07,972 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:07,974 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,018 [Listener at localhost/33296] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:08,028 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,028 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,029 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:23:08,034 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,034 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,034 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-44f7349d-132b-4248-b5e0-3098728fd2f8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:23:08,035 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7e85df17-966b-444b-819d-ab7b3d7d489b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:23:08,036 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:23:08,038 [Listener at localhost/33296] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:08,040 [Listener at localhost/33296] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:08,045 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:08,047 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:08,048 [Listener at localhost/33296] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:08,049 [Listener at localhost/33296] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,049 [Listener at localhost/33296] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:08,050 [Listener at localhost/33296] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:08,050 [Listener at localhost/33296] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,051 [Listener at localhost/33296] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:08,052 [Listener at localhost/33296] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40478
2020-12-03 07:23:08,052 [Listener at localhost/33296] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:08,053 [Listener at localhost/33296] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:08,055 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,057 [Listener at localhost/33296] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:08,058 [Listener at localhost/33296] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:08,058 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,061 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:08,062 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:08,062 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:08,062 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:08,063 [Listener at localhost/33296] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33680
2020-12-03 07:23:08,064 [Listener at localhost/33296] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:08,066 [Listener at localhost/33296] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cbf9e9f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:08,067 [Listener at localhost/33296] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a2f016d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:08,076 [Listener at localhost/33296] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3301500b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:08,077 [Listener at localhost/33296] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24b52d3e{HTTP/1.1,[http/1.1]}{localhost:33680}
2020-12-03 07:23:08,077 [Listener at localhost/33296] INFO  server.Server (Server.java:doStart(419)) - Started @7605ms
2020-12-03 07:23:08,106 [Listener at localhost/33296] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42262
2020-12-03 07:23:08,107 [Listener at localhost/33296] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:08,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e9c413e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:08,107 [Listener at localhost/33296] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:08,108 [Listener at localhost/33296] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:08,109 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:08,115 [Listener at localhost/35699] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35699
2020-12-03 07:23:08,121 [Listener at localhost/35699] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:08,122 [Listener at localhost/35699] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:08,122 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:08,138 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,138 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,139 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eae50968-723a-4f1d-a23d-695cbb3a0e55 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:23:08,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:08,139 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:08,140 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:08,150 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:08,153 [Listener at localhost/35699] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:08,155 [Listener at localhost/35699] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:08,156 [Listener at localhost/35699] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:08,159 [Listener at localhost/35699] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:08,160 [Listener at localhost/35699] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,160 [Listener at localhost/35699] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:08,160 [Listener at localhost/35699] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:08,161 [Listener at localhost/35699] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,161 [Listener at localhost/35699] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:08,162 [Listener at localhost/35699] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45505
2020-12-03 07:23:08,162 [Listener at localhost/35699] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:08,162 [Listener at localhost/35699] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:08,164 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,166 [Listener at localhost/35699] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:08,167 [Listener at localhost/35699] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:08,167 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,170 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:08,171 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:08,171 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:08,171 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:08,173 [Listener at localhost/35699] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36109
2020-12-03 07:23:08,173 [Listener at localhost/35699] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:08,175 [Listener at localhost/35699] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13c612bd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:08,176 [Listener at localhost/35699] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b739528{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:08,185 [Listener at localhost/35699] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@51abf713{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:08,187 [Listener at localhost/35699] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@eadb475{HTTP/1.1,[http/1.1]}{localhost:36109}
2020-12-03 07:23:08,187 [Listener at localhost/35699] INFO  server.Server (Server.java:doStart(419)) - Started @7714ms
2020-12-03 07:23:08,209 [Listener at localhost/35699] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33132
2020-12-03 07:23:08,210 [Listener at localhost/35699] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:08,210 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@315df4bb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:08,210 [Listener at localhost/35699] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:08,210 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,211 [Listener at localhost/35699] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:08,211 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,212 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:08,213 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-139348de-064e-4766-8b5f-5d2df28fd2e0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:23:08,218 [Listener at localhost/32790] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:32790
2020-12-03 07:23:08,223 [Listener at localhost/32790] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:08,224 [Listener at localhost/32790] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:08,232 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:08,263 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:08,264 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:08,275 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:08,276 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:08,277 [Listener at localhost/32790] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:08,279 [Listener at localhost/32790] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:08,279 [Listener at localhost/32790] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:08,282 [Listener at localhost/32790] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:08,283 [Listener at localhost/32790] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,283 [Listener at localhost/32790] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:08,283 [Listener at localhost/32790] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:08,284 [Listener at localhost/32790] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,284 [Listener at localhost/32790] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:08,285 [Listener at localhost/32790] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34280
2020-12-03 07:23:08,286 [Listener at localhost/32790] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:08,286 [Listener at localhost/32790] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:08,291 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,294 [Listener at localhost/32790] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:08,295 [Listener at localhost/32790] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:08,295 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,298 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:08,299 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:08,299 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:08,300 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:08,301 [Listener at localhost/32790] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35874
2020-12-03 07:23:08,301 [Listener at localhost/32790] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:08,305 [Listener at localhost/32790] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54336c81{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:08,306 [Listener at localhost/32790] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35e52059{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:08,315 [Listener at localhost/32790] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@59221b97{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:08,317 [Listener at localhost/32790] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ac4944a{HTTP/1.1,[http/1.1]}{localhost:35874}
2020-12-03 07:23:08,318 [Listener at localhost/32790] INFO  server.Server (Server.java:doStart(419)) - Started @7845ms
2020-12-03 07:23:08,323 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,323 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,323 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,323 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,324 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,324 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,324 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,324 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,325 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:23:08,325 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4dee7b81-2ac3-4266-8652-879c18ba3b96 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:23:08,325 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-65fcfd1e-2955-4827-8bc3-6a74713711f5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:23:08,325 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:23:08,392 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,393 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,393 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-915b1da8-abef-4fd8-bf01-a01c0619f8da for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:23:08,427 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,428 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,428 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-20a5adaa-47a8-4524-ad7b-995578afa744 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:23:08,445 [Listener at localhost/32790] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35738
2020-12-03 07:23:08,446 [Listener at localhost/32790] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:08,446 [Listener at localhost/32790] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:08,446 [Listener at localhost/32790] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:08,446 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@39fc6b2c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:08,447 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:08,453 [Listener at localhost/42365] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42365
2020-12-03 07:23:08,459 [Listener at localhost/42365] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:08,459 [Listener at localhost/42365] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:08,460 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:08,462 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:08,462 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:08,466 [Listener at localhost/42365] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:08,468 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:08,468 [Listener at localhost/42365] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:08,469 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:08,469 [Listener at localhost/42365] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:08,470 [Listener at localhost/42365] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:08,471 [Listener at localhost/42365] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,471 [Listener at localhost/42365] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:08,472 [Listener at localhost/42365] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:08,472 [Listener at localhost/42365] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:08,472 [Listener at localhost/42365] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:08,473 [Listener at localhost/42365] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39995
2020-12-03 07:23:08,473 [Listener at localhost/42365] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:08,473 [Listener at localhost/42365] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:08,475 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,482 [Listener at localhost/42365] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:08,483 [Listener at localhost/42365] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:08,483 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:08,486 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:08,486 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:08,487 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:08,487 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:08,488 [Listener at localhost/42365] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41987
2020-12-03 07:23:08,488 [Listener at localhost/42365] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:08,490 [Listener at localhost/42365] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d9fc57a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:08,491 [Listener at localhost/42365] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b4ef7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:08,501 [Listener at localhost/42365] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30457e14{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:08,503 [Listener at localhost/42365] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1af1347d{HTTP/1.1,[http/1.1]}{localhost:41987}
2020-12-03 07:23:08,503 [Listener at localhost/42365] INFO  server.Server (Server.java:doStart(419)) - Started @8030ms
2020-12-03 07:23:08,526 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,527 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,527 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,528 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5c286158-aeaf-4f81-b1e6-53f602ae01de for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:23:08,528 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,529 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0edd2879-4df4-4805-931c-d49cb812c3fd for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:23:08,540 [Listener at localhost/42365] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33706
2020-12-03 07:23:08,542 [Listener at localhost/42365] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:08,542 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20765ed5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:08,542 [Listener at localhost/42365] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:08,543 [Listener at localhost/42365] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:08,545 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:08,550 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41051
2020-12-03 07:23:08,551 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,551 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,551 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,551 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,551 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,551 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,551 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,552 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,556 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,557 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,557 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,557 [Listener at localhost/41051] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:08,557 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,556 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,558 [Listener at localhost/41051] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:08,557 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,559 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574 starting to offer service
2020-12-03 07:23:08,557 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,558 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,563 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:08,563 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:08,568 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38574
2020-12-03 07:23:08,569 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:08,658 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,659 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,659 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f8e74601-7774-40eb-a2fc-1212407c9087 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:23:08,674 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,675 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,675 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,683 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,757 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,758 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,758 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:23:08,771 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,772 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,772 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,772 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,773 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,773 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,773 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,773 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,774 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,774 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,774 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,774 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,776 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,777 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,777 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,777 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,777 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,777 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,778 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,778 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,855 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,856 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,856 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-468480ed-0d13-4fe3-ac85-54b0fc23b846 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:23:08,875 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:23:08,892 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,892 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,892 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,892 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,922 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 17753@aa7bf69976b9
2020-12-03 07:23:08,923 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1754324486. Formatting...
2020-12-03 07:23:08,924 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:08,924 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:08,925 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:08,926 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:08,927 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-98537e8e-24fa-419b-b567-5f2eb72e783c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:23:08,936 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,936 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,937 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,937 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:08,938 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,939 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:08,939 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:08,939 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:09,057 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,058 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,058 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:09,058 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:09,097 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:09,138 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c0ba2203-ddf0-4690-bdc1-443459e69dae
2020-12-03 07:23:09,139 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:09,139 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b2c1889f-1327-4267-bacf-3ca4bed4101c
2020-12-03 07:23:09,139 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33
2020-12-03 07:23:09,138 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5af35291-e71b-4e63-ad53-749abe1b00d0
2020-12-03 07:23:09,148 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,148 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,149 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:09,149 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:09,153 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,153 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,153 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:09,154 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:09,157 [IPC Server handler 1 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,170 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:09,171 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:09,255 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,256 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,256 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:09,256 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:09,274 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d4aa3f9a-f071-443d-b783-c464472740a1
2020-12-03 07:23:09,276 [IPC Server handler 0 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,278 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:09,279 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:09,307 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 13ceaf14-28a4-4201-8c14-6177b852e8b8
2020-12-03 07:23:09,307 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:09,329 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-eae50968-723a-4f1d-a23d-695cbb3a0e55
2020-12-03 07:23:09,330 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-44f7349d-132b-4248-b5e0-3098728fd2f8
2020-12-03 07:23:09,336 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:09,335 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:23:09,337 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca
2020-12-03 07:23:09,341 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:09,361 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-20a5adaa-47a8-4524-ad7b-995578afa744
2020-12-03 07:23:09,362 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:23:09,341 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7e85df17-966b-444b-819d-ab7b3d7d489b
2020-12-03 07:23:09,339 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278
2020-12-03 07:23:09,373 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:09,361 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:09,373 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:09,374 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7
2020-12-03 07:23:09,374 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:09,379 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-139348de-064e-4766-8b5f-5d2df28fd2e0
2020-12-03 07:23:09,381 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4
2020-12-03 07:23:09,381 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:23:09,381 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:09,381 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4dee7b81-2ac3-4266-8652-879c18ba3b96
2020-12-03 07:23:09,381 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:09,381 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,381 [IPC Server handler 7 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,382 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,382 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-868631643-172.17.0.11-1606980183045 is not formatted. Formatting ...
2020-12-03 07:23:09,383 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-868631643-172.17.0.11-1606980183045 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-868631643-172.17.0.11-1606980183045/current
2020-12-03 07:23:09,383 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:09,383 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:09,384 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-65fcfd1e-2955-4827-8bc3-6a74713711f5
2020-12-03 07:23:09,385 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:09,386 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,386 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,386 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5c286158-aeaf-4f81-b1e6-53f602ae01de
2020-12-03 07:23:09,386 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,386 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,387 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,387 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:23:09,388 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,394 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:09,396 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:09,396 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:09,401 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:09,403 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:09,404 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:09,405 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:09,407 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:09,407 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:09,406 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:09,406 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:09,406 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:09,409 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:09,409 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:09,409 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:09,409 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:09,409 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:09,409 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:09,411 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:09,410 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:09,409 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:09,409 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:09,409 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:09,412 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,412 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,412 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,412 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,411 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:09,412 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,413 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,413 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:23:09,413 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:23:09,413 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:23:09,414 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:23:09,414 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:09,414 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:09,414 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:09,414 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:23:09,414 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:23:09,414 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:09,415 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:09,415 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:09,436 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8e2241b2-b5f1-40cf-9b1b-6f6467b96189
2020-12-03 07:23:09,440 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-915b1da8-abef-4fd8-bf01-a01c0619f8da
2020-12-03 07:23:09,441 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:23:09,444 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1
2020-12-03 07:23:09,444 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:23:09,446 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,448 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:09,449 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:09,449 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:09,449 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:09,450 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,450 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:23:09,450 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:23:09,462 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4b1ceee1-a93a-4837-a095-708c8e7f6d5e
2020-12-03 07:23:09,488 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1754324486;bpid=BP-868631643-172.17.0.11-1606980183045;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1754324486;c=1606980183045;bpid=BP-868631643-172.17.0.11-1606980183045;dnuuid=null
2020-12-03 07:23:09,523 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 108ms
2020-12-03 07:23:09,547 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 15c22f71-215f-4109-ba04-91a80e084ccc
2020-12-03 07:23:09,569 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0edd2879-4df4-4805-931c-d49cb812c3fd
2020-12-03 07:23:09,570 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:23:09,574 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-468480ed-0d13-4fe3-ac85-54b0fc23b846
2020-12-03 07:23:09,575 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:23:09,576 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,577 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f8e74601-7774-40eb-a2fc-1212407c9087
2020-12-03 07:23:09,577 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:23:09,579 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:09,585 [IPC Server handler 9 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,586 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:09,587 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:09,594 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-98537e8e-24fa-419b-b567-5f2eb72e783c
2020-12-03 07:23:09,598 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:23:09,599 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:09,603 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:09,603 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:09,603 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:09,604 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,604 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:23:09,604 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:23:09,612 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 197ms
2020-12-03 07:23:09,613 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 200ms
2020-12-03 07:23:09,615 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 201ms
2020-12-03 07:23:09,622 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 207ms
2020-12-03 07:23:09,624 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 210ms
2020-12-03 07:23:09,625 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 211ms
2020-12-03 07:23:09,625 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:09,636 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 223ms
2020-12-03 07:23:09,636 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 223ms
2020-12-03 07:23:09,659 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 245ms
2020-12-03 07:23:09,660 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 245ms
2020-12-03 07:23:09,660 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 247ms
2020-12-03 07:23:09,662 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:09,662 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:09,662 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:09,674 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:09,675 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:09,669 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:09,669 [Thread-300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:09,681 [Thread-300] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,669 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:23:09,664 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:23:09,684 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,678 [Thread-299] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,678 [Thread-305] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,678 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,676 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,684 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,691 [Thread-300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 10ms
2020-12-03 07:23:09,691 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:23:09,693 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 279ms
2020-12-03 07:23:09,694 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 281ms
2020-12-03 07:23:09,694 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:23:09,698 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:23:09,699 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,699 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:23:09,706 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 292ms
2020-12-03 07:23:09,707 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 293ms
2020-12-03 07:23:09,707 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:23:09,708 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,709 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 259ms
2020-12-03 07:23:09,713 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 35ms
2020-12-03 07:23:09,713 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 29ms
2020-12-03 07:23:09,713 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 35ms
2020-12-03 07:23:09,713 [IPC Server handler 6 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,716 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 76ms
2020-12-03 07:23:09,716 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 33ms
2020-12-03 07:23:09,715 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 111ms
2020-12-03 07:23:09,717 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:09,717 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 56ms
2020-12-03 07:23:09,717 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:09,717 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 9ms
2020-12-03 07:23:09,720 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:09,720 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:09,721 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 116ms
2020-12-03 07:23:09,721 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,717 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 303ms
2020-12-03 07:23:09,726 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 9ms
2020-12-03 07:23:09,723 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:09,728 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4dee7b81-2ac3-4266-8652-879c18ba3b96): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,723 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 119ms
2020-12-03 07:23:09,721 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 43ms
2020-12-03 07:23:09,736 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 97ms
2020-12-03 07:23:09,736 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:23:09,723 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:09,737 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5c286158-aeaf-4f81-b1e6-53f602ae01de): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,721 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 270ms
2020-12-03 07:23:09,720 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,720 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 26ms
2020-12-03 07:23:09,766 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 316ms
2020-12-03 07:23:09,766 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 46ms
2020-12-03 07:23:09,766 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:09,766 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:23:09,767 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:23:09,767 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,767 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:23:09,737 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:09,736 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:23:09,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:09,723 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:09,736 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,726 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 314ms
2020-12-03 07:23:09,770 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:23:09,770 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:23:09,770 [Thread-327] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,770 [Thread-328] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,726 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:09,771 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 34ms
2020-12-03 07:23:09,771 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:23:09,769 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-139348de-064e-4766-8b5f-5d2df28fd2e0): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,772 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,769 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,769 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,769 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-44f7349d-132b-4248-b5e0-3098728fd2f8): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,767 [Thread-323] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,767 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,766 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:09,774 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 7ms
2020-12-03 07:23:09,766 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 58ms
2020-12-03 07:23:09,774 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 5ms
2020-12-03 07:23:09,774 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-65fcfd1e-2955-4827-8bc3-6a74713711f5): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,771 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:23:09,775 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 5ms
2020-12-03 07:23:09,775 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 10ms
2020-12-03 07:23:09,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:09,776 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:09,776 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:09,776 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 41ms
2020-12-03 07:23:09,777 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-915b1da8-abef-4fd8-bf01-a01c0619f8da): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,776 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:09,777 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:09,777 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-eae50968-723a-4f1d-a23d-695cbb3a0e55): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,776 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,777 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-468480ed-0d13-4fe3-ac85-54b0fc23b846): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,777 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:09,778 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-0edd2879-4df4-4805-931c-d49cb812c3fd): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,777 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-20a5adaa-47a8-4524-ad7b-995578afa744): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,776 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:09,776 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:09,786 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,783 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 91ms
2020-12-03 07:23:09,786 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7e85df17-966b-444b-819d-ab7b3d7d489b): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,786 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-868631643-172.17.0.11-1606980183045 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 92ms
2020-12-03 07:23:09,790 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-868631643-172.17.0.11-1606980183045: 99ms
2020-12-03 07:23:09,791 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:23:09,791 [Thread-337] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,791 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:23:09,791 [Thread-338] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-868631643-172.17.0.11-1606980183045/current/replicas doesn't exist 
2020-12-03 07:23:09,791 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:23:09,792 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:23:09,792 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-868631643-172.17.0.11-1606980183045: 2ms
2020-12-03 07:23:09,792 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-868631643-172.17.0.11-1606980183045 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7e85df17-966b-444b-819d-ab7b3d7d489b): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4dee7b81-2ac3-4266-8652-879c18ba3b96): no suitable block pools found to scan.  Waiting 1814399928 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-f8e74601-7774-40eb-a2fc-1212407c9087): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-98537e8e-24fa-419b-b567-5f2eb72e783c): finished scanning block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-44f7349d-132b-4248-b5e0-3098728fd2f8): no suitable block pools found to scan.  Waiting 1814399944 ms.
2020-12-03 07:23:09,794 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-98537e8e-24fa-419b-b567-5f2eb72e783c): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-65fcfd1e-2955-4827-8bc3-6a74713711f5): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-0edd2879-4df4-4805-931c-d49cb812c3fd): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:23:09,794 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-f8e74601-7774-40eb-a2fc-1212407c9087): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-eae50968-723a-4f1d-a23d-695cbb3a0e55): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-139348de-064e-4766-8b5f-5d2df28fd2e0): no suitable block pools found to scan.  Waiting 1814399928 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-468480ed-0d13-4fe3-ac85-54b0fc23b846): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7): no suitable block pools found to scan.  Waiting 1814399943 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5c286158-aeaf-4f81-b1e6-53f602ae01de): no suitable block pools found to scan.  Waiting 1814399930 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca): no suitable block pools found to scan.  Waiting 1814399930 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-20a5adaa-47a8-4524-ad7b-995578afa744): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:23:09,793 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-915b1da8-abef-4fd8-bf01-a01c0619f8da): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:23:09,798 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:25 AM with interval of 21600000ms
2020-12-03 07:23:09,799 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:47 AM with interval of 21600000ms
2020-12-03 07:23:09,800 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:31 AM with interval of 21600000ms
2020-12-03 07:23:09,803 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:43 PM with interval of 21600000ms
2020-12-03 07:23:09,803 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:49 AM with interval of 21600000ms
2020-12-03 07:23:09,804 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:42 AM with interval of 21600000ms
2020-12-03 07:23:09,803 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:09 AM with interval of 21600000ms
2020-12-03 07:23:09,803 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:48 PM with interval of 21600000ms
2020-12-03 07:23:09,804 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:23 AM with interval of 21600000ms
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 15c22f71-215f-4109-ba04-91a80e084ccc) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 8e2241b2-b5f1-40cf-9b1b-6f6467b96189) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 13ceaf14-28a4-4201-8c14-6177b852e8b8) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid d4aa3f9a-f071-443d-b783-c464472740a1) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 5af35291-e71b-4e63-ad53-749abe1b00d0) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid b2c1889f-1327-4267-bacf-3ca4bed4101c) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 4b1ceee1-a93a-4837-a095-708c8e7f6d5e) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,814 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid c0ba2203-ddf0-4690-bdc1-443459e69dae) service to localhost/127.0.0.1:38574 beginning handshake with NN
2020-12-03 07:23:09,823 [IPC Server handler 3 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,824 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:09,824 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:09,835 [IPC Server handler 1 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44171, datanodeUuid=c0ba2203-ddf0-4690-bdc1-443459e69dae, infoPort=43081, infoSecurePort=0, ipcPort=42164, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage c0ba2203-ddf0-4690-bdc1-443459e69dae
2020-12-03 07:23:09,837 [IPC Server handler 1 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44171
2020-12-03 07:23:09,838 [IPC Server handler 1 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c0ba2203-ddf0-4690-bdc1-443459e69dae (127.0.0.1:44171).
2020-12-03 07:23:09,841 [IPC Server handler 2 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage 15c22f71-215f-4109-ba04-91a80e084ccc
2020-12-03 07:23:09,841 [IPC Server handler 2 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39995
2020-12-03 07:23:09,845 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid c0ba2203-ddf0-4690-bdc1-443459e69dae) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,845 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,847 [IPC Server handler 2 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 15c22f71-215f-4109-ba04-91a80e084ccc (127.0.0.1:39995).
2020-12-03 07:23:09,848 [IPC Server handler 4 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45505, datanodeUuid=8e2241b2-b5f1-40cf-9b1b-6f6467b96189, infoPort=33132, infoSecurePort=0, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage 8e2241b2-b5f1-40cf-9b1b-6f6467b96189
2020-12-03 07:23:09,849 [IPC Server handler 4 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45505
2020-12-03 07:23:09,849 [IPC Server handler 4 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8e2241b2-b5f1-40cf-9b1b-6f6467b96189 (127.0.0.1:45505).
2020-12-03 07:23:09,850 [IPC Server handler 5 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36190, datanodeUuid=d4aa3f9a-f071-443d-b783-c464472740a1, infoPort=37765, infoSecurePort=0, ipcPort=33296, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage d4aa3f9a-f071-443d-b783-c464472740a1
2020-12-03 07:23:09,867 [IPC Server handler 5 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36190
2020-12-03 07:23:09,868 [IPC Server handler 5 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d4aa3f9a-f071-443d-b783-c464472740a1 (127.0.0.1:36190).
2020-12-03 07:23:09,868 [IPC Server handler 8 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36279, datanodeUuid=b2c1889f-1327-4267-bacf-3ca4bed4101c, infoPort=34080, infoSecurePort=0, ipcPort=38923, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage b2c1889f-1327-4267-bacf-3ca4bed4101c
2020-12-03 07:23:09,868 [IPC Server handler 8 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36279
2020-12-03 07:23:09,869 [IPC Server handler 8 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b2c1889f-1327-4267-bacf-3ca4bed4101c (127.0.0.1:36279).
2020-12-03 07:23:09,869 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 15c22f71-215f-4109-ba04-91a80e084ccc) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,869 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,869 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid d4aa3f9a-f071-443d-b783-c464472740a1) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,869 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,872 [IPC Server handler 0 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34280, datanodeUuid=4b1ceee1-a93a-4837-a095-708c8e7f6d5e, infoPort=35738, infoSecurePort=0, ipcPort=42365, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage 4b1ceee1-a93a-4837-a095-708c8e7f6d5e
2020-12-03 07:23:09,872 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 8e2241b2-b5f1-40cf-9b1b-6f6467b96189) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,873 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid b2c1889f-1327-4267-bacf-3ca4bed4101c) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,873 [IPC Server handler 0 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34280
2020-12-03 07:23:09,873 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,874 [IPC Server handler 0 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4b1ceee1-a93a-4837-a095-708c8e7f6d5e (127.0.0.1:34280).
2020-12-03 07:23:09,874 [IPC Server handler 7 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35185, datanodeUuid=5af35291-e71b-4e63-ad53-749abe1b00d0, infoPort=45219, infoSecurePort=0, ipcPort=42079, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage 5af35291-e71b-4e63-ad53-749abe1b00d0
2020-12-03 07:23:09,873 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,875 [IPC Server handler 7 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35185
2020-12-03 07:23:09,875 [IPC Server handler 7 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5af35291-e71b-4e63-ad53-749abe1b00d0 (127.0.0.1:35185).
2020-12-03 07:23:09,876 [IPC Server handler 9 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40478, datanodeUuid=13ceaf14-28a4-4201-8c14-6177b852e8b8, infoPort=42262, infoSecurePort=0, ipcPort=35699, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage 13ceaf14-28a4-4201-8c14-6177b852e8b8
2020-12-03 07:23:09,876 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 4b1ceee1-a93a-4837-a095-708c8e7f6d5e) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,877 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,877 [IPC Server handler 9 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40478
2020-12-03 07:23:09,877 [IPC Server handler 9 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 13ceaf14-28a4-4201-8c14-6177b852e8b8 (127.0.0.1:40478).
2020-12-03 07:23:09,878 [IPC Server handler 6 on default port 38574] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37531, datanodeUuid=e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33, infoPort=38588, infoSecurePort=0, ipcPort=39846, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) storage e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33
2020-12-03 07:23:09,879 [IPC Server handler 6 on default port 38574] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37531
2020-12-03 07:23:09,879 [IPC Server handler 6 on default port 38574] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33 (127.0.0.1:37531).
2020-12-03 07:23:09,879 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 5af35291-e71b-4e63-ad53-749abe1b00d0) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,879 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,882 [IPC Server handler 3 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7e85df17-966b-444b-819d-ab7b3d7d489b for DN 127.0.0.1:44171
2020-12-03 07:23:09,882 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,884 [IPC Server handler 3 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4 for DN 127.0.0.1:44171
2020-12-03 07:23:09,885 [IPC Server handler 8 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278 for DN 127.0.0.1:36279
2020-12-03 07:23:09,887 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,888 [IPC Server handler 8 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-65fcfd1e-2955-4827-8bc3-6a74713711f5 for DN 127.0.0.1:36279
2020-12-03 07:23:09,890 [IPC Server handler 5 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0edd2879-4df4-4805-931c-d49cb812c3fd for DN 127.0.0.1:34280
2020-12-03 07:23:09,891 [IPC Server handler 5 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-468480ed-0d13-4fe3-ac85-54b0fc23b846 for DN 127.0.0.1:34280
2020-12-03 07:23:09,891 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 13ceaf14-28a4-4201-8c14-6177b852e8b8) service to localhost/127.0.0.1:38574 successfully registered with NN
2020-12-03 07:23:09,892 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38574 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:09,892 [IPC Server handler 4 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-915b1da8-abef-4fd8-bf01-a01c0619f8da for DN 127.0.0.1:45505
2020-12-03 07:23:09,892 [IPC Server handler 4 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1 for DN 127.0.0.1:45505
2020-12-03 07:23:09,892 [IPC Server handler 2 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f8e74601-7774-40eb-a2fc-1212407c9087 for DN 127.0.0.1:39995
2020-12-03 07:23:09,892 [IPC Server handler 2 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-98537e8e-24fa-419b-b567-5f2eb72e783c for DN 127.0.0.1:39995
2020-12-03 07:23:09,894 [IPC Server handler 1 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eae50968-723a-4f1d-a23d-695cbb3a0e55 for DN 127.0.0.1:36190
2020-12-03 07:23:09,894 [IPC Server handler 1 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20a5adaa-47a8-4524-ad7b-995578afa744 for DN 127.0.0.1:36190
2020-12-03 07:23:09,895 [IPC Server handler 7 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca for DN 127.0.0.1:37531
2020-12-03 07:23:09,895 [IPC Server handler 7 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4dee7b81-2ac3-4266-8652-879c18ba3b96 for DN 127.0.0.1:37531
2020-12-03 07:23:09,897 [IPC Server handler 0 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-44f7349d-132b-4248-b5e0-3098728fd2f8 for DN 127.0.0.1:35185
2020-12-03 07:23:09,897 [IPC Server handler 0 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7 for DN 127.0.0.1:35185
2020-12-03 07:23:09,899 [IPC Server handler 9 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-139348de-064e-4766-8b5f-5d2df28fd2e0 for DN 127.0.0.1:40478
2020-12-03 07:23:09,900 [IPC Server handler 9 on default port 38574] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5c286158-aeaf-4f81-b1e6-53f602ae01de for DN 127.0.0.1:40478
2020-12-03 07:23:09,953 [IPC Server handler 6 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:09,962 [IPC Server handler 8 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44171, datanodeUuid=c0ba2203-ddf0-4690-bdc1-443459e69dae, infoPort=43081, infoSecurePort=0, ipcPort=42164, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:09,962 [IPC Server handler 0 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36190, datanodeUuid=d4aa3f9a-f071-443d-b783-c464472740a1, infoPort=37765, infoSecurePort=0, ipcPort=33296, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:09,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3334a4b97f95e0a3: Processing first storage report for DS-7e85df17-966b-444b-819d-ab7b3d7d489b from datanode c0ba2203-ddf0-4690-bdc1-443459e69dae
2020-12-03 07:23:09,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3334a4b97f95e0a3: from storage DS-7e85df17-966b-444b-819d-ab7b3d7d489b node DatanodeRegistration(127.0.0.1:44171, datanodeUuid=c0ba2203-ddf0-4690-bdc1-443459e69dae, infoPort=43081, infoSecurePort=0, ipcPort=42164, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,970 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:09,983 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3334a4b97f95e0a3: Processing first storage report for DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4 from datanode c0ba2203-ddf0-4690-bdc1-443459e69dae
2020-12-03 07:23:09,984 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3334a4b97f95e0a3: from storage DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4 node DatanodeRegistration(127.0.0.1:44171, datanodeUuid=c0ba2203-ddf0-4690-bdc1-443459e69dae, infoPort=43081, infoSecurePort=0, ipcPort=42164, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,984 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd4983965dd22de6a: Processing first storage report for DS-20a5adaa-47a8-4524-ad7b-995578afa744 from datanode d4aa3f9a-f071-443d-b783-c464472740a1
2020-12-03 07:23:09,985 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd4983965dd22de6a: from storage DS-20a5adaa-47a8-4524-ad7b-995578afa744 node DatanodeRegistration(127.0.0.1:36190, datanodeUuid=d4aa3f9a-f071-443d-b783-c464472740a1, infoPort=37765, infoSecurePort=0, ipcPort=33296, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,985 [IPC Server handler 8 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x3334a4b97f95e0a3
2020-12-03 07:23:09,985 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd4983965dd22de6a: Processing first storage report for DS-eae50968-723a-4f1d-a23d-695cbb3a0e55 from datanode d4aa3f9a-f071-443d-b783-c464472740a1
2020-12-03 07:23:09,985 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd4983965dd22de6a: from storage DS-eae50968-723a-4f1d-a23d-695cbb3a0e55 node DatanodeRegistration(127.0.0.1:36190, datanodeUuid=d4aa3f9a-f071-443d-b783-c464472740a1, infoPort=37765, infoSecurePort=0, ipcPort=33296, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,986 [IPC Server handler 0 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd4983965dd22de6a
2020-12-03 07:23:09,996 [IPC Server handler 4 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34280, datanodeUuid=4b1ceee1-a93a-4837-a095-708c8e7f6d5e, infoPort=35738, infoSecurePort=0, ipcPort=42365, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:09,997 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x50c687c811569b31: Processing first storage report for DS-0edd2879-4df4-4805-931c-d49cb812c3fd from datanode 4b1ceee1-a93a-4837-a095-708c8e7f6d5e
2020-12-03 07:23:09,997 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50c687c811569b31: from storage DS-0edd2879-4df4-4805-931c-d49cb812c3fd node DatanodeRegistration(127.0.0.1:34280, datanodeUuid=4b1ceee1-a93a-4837-a095-708c8e7f6d5e, infoPort=35738, infoSecurePort=0, ipcPort=42365, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,997 [IPC Server handler 9 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:09,997 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x425644ccaa3282cd: Processing first storage report for DS-98537e8e-24fa-419b-b567-5f2eb72e783c from datanode 15c22f71-215f-4109-ba04-91a80e084ccc
2020-12-03 07:23:09,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x425644ccaa3282cd: from storage DS-98537e8e-24fa-419b-b567-5f2eb72e783c node DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x50c687c811569b31: Processing first storage report for DS-468480ed-0d13-4fe3-ac85-54b0fc23b846 from datanode 4b1ceee1-a93a-4837-a095-708c8e7f6d5e
2020-12-03 07:23:09,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x50c687c811569b31: from storage DS-468480ed-0d13-4fe3-ac85-54b0fc23b846 node DatanodeRegistration(127.0.0.1:34280, datanodeUuid=4b1ceee1-a93a-4837-a095-708c8e7f6d5e, infoPort=35738, infoSecurePort=0, ipcPort=42365, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x425644ccaa3282cd: Processing first storage report for DS-f8e74601-7774-40eb-a2fc-1212407c9087 from datanode 15c22f71-215f-4109-ba04-91a80e084ccc
2020-12-03 07:23:09,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x425644ccaa3282cd: from storage DS-f8e74601-7774-40eb-a2fc-1212407c9087 node DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:09,999 [IPC Server handler 4 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x50c687c811569b31
2020-12-03 07:23:09,999 [IPC Server handler 9 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x425644ccaa3282cd
2020-12-03 07:23:10,000 [IPC Server handler 2 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45505, datanodeUuid=8e2241b2-b5f1-40cf-9b1b-6f6467b96189, infoPort=33132, infoSecurePort=0, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:10,002 [IPC Server handler 7 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36279, datanodeUuid=b2c1889f-1327-4267-bacf-3ca4bed4101c, infoPort=34080, infoSecurePort=0, ipcPort=38923, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:10,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2cb9737b7bf85e0f: Processing first storage report for DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1 from datanode 8e2241b2-b5f1-40cf-9b1b-6f6467b96189
2020-12-03 07:23:10,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2cb9737b7bf85e0f: from storage DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1 node DatanodeRegistration(127.0.0.1:45505, datanodeUuid=8e2241b2-b5f1-40cf-9b1b-6f6467b96189, infoPort=33132, infoSecurePort=0, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:10,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4df643131fb2602: Processing first storage report for DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278 from datanode b2c1889f-1327-4267-bacf-3ca4bed4101c
2020-12-03 07:23:10,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4df643131fb2602: from storage DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278 node DatanodeRegistration(127.0.0.1:36279, datanodeUuid=b2c1889f-1327-4267-bacf-3ca4bed4101c, infoPort=34080, infoSecurePort=0, ipcPort=38923, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:10,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2cb9737b7bf85e0f: Processing first storage report for DS-915b1da8-abef-4fd8-bf01-a01c0619f8da from datanode 8e2241b2-b5f1-40cf-9b1b-6f6467b96189
2020-12-03 07:23:10,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2cb9737b7bf85e0f: from storage DS-915b1da8-abef-4fd8-bf01-a01c0619f8da node DatanodeRegistration(127.0.0.1:45505, datanodeUuid=8e2241b2-b5f1-40cf-9b1b-6f6467b96189, infoPort=33132, infoSecurePort=0, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:10,007 [IPC Server handler 2 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2cb9737b7bf85e0f
2020-12-03 07:23:10,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4df643131fb2602: Processing first storage report for DS-65fcfd1e-2955-4827-8bc3-6a74713711f5 from datanode b2c1889f-1327-4267-bacf-3ca4bed4101c
2020-12-03 07:23:10,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4df643131fb2602: from storage DS-65fcfd1e-2955-4827-8bc3-6a74713711f5 node DatanodeRegistration(127.0.0.1:36279, datanodeUuid=b2c1889f-1327-4267-bacf-3ca4bed4101c, infoPort=34080, infoSecurePort=0, ipcPort=38923, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:10,008 [IPC Server handler 7 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa4df643131fb2602
2020-12-03 07:23:10,033 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x50c687c811569b31,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:10,034 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:10,038 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd4983965dd22de6a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 82 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:10,038 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa4df643131fb2602,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 85 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:10,039 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:10,039 [IPC Server handler 3 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:23:10,039 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3334a4b97f95e0a3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 82 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:10,041 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2cb9737b7bf85e0f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 86 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:10,038 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:10,041 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:10,041 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:10,041 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x425644ccaa3282cd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 85 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:10,047 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:10,090 [IPC Server handler 5 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:10,101 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(200)) - testReadWithBlockCorrupted: file = /deleted_1_0, dataBlkDelNum = 1, parityBlkDelNum = 0, deleteBlockFile? true
2020-12-03 07:23:10,269 [IPC Server handler 1 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:10,292 [IPC Server handler 6 on default port 38574] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(774)) - *DIR* NameNode.create: file /deleted_1_0 for DFSClient_NONMAPREDUCE_-668486486_1 at 127.0.0.1
2020-12-03 07:23:10,293 [IPC Server handler 6 on default port 38574] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2460)) - DIR* NameSystem.startFile: src=/deleted_1_0, holder=DFSClient_NONMAPREDUCE_-668486486_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-12-03 07:23:10,310 [IPC Server handler 6 on default port 38574] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(579)) - DIR* addFile: deleted_1_0 is added
2020-12-03 07:23:10,315 [IPC Server handler 6 on default port 38574] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(415)) - DIR* NameSystem.startFile: added /deleted_1_0 inode 16386 DFSClient_NONMAPREDUCE_-668486486_1
2020-12-03 07:23:10,328 [IPC Server handler 6 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/deleted_1_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:10,419 [IPC Server handler 4 on default port 38574] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2767)) - BLOCK* getAdditionalBlock: /deleted_1_0  inodeId 16386 for DFSClient_NONMAPREDUCE_-668486486_1
2020-12-03 07:23:10,430 [IPC Server handler 4 on default port 38574] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(524)) - DIR* FSDirectory.addBlock: /deleted_1_0 with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-12-03 07:23:10,430 [IPC Server handler 4 on default port 38574] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:36190, 127.0.0.1:44171, 127.0.0.1:39995, 127.0.0.1:45505, 127.0.0.1:35185, 127.0.0.1:36279, 127.0.0.1:34280, 127.0.0.1:40478, 127.0.0.1:37531 for /deleted_1_0
2020-12-03 07:23:10,431 [IPC Server handler 4 on default port 38574] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(758)) - persistNewBlock: /deleted_1_0 with new block blk_-9223372036854775792_1001, current total block count is 1
2020-12-03 07:23:10,466 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,492 [Thread-352] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,502 [Thread-353] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,510 [Thread-354] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,531 [Thread-355] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,552 [Thread-356] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,642 [Thread-357] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,699 [Thread-358] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:49186 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775787_1001 src: /127.0.0.1:49186 dest: /127.0.0.1:36279
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:53556 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775792_1001 src: /127.0.0.1:53556 dest: /127.0.0.1:36190
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:52664 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775791_1001 src: /127.0.0.1:52664 dest: /127.0.0.1:44171
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:50224 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775785_1001 src: /127.0.0.1:50224 dest: /127.0.0.1:40478
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:54160 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775786_1001 src: /127.0.0.1:54160 dest: /127.0.0.1:34280
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:56148 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775789_1001 src: /127.0.0.1:56148 dest: /127.0.0.1:45505
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:48970 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775788_1001 src: /127.0.0.1:48970 dest: /127.0.0.1:35185
2020-12-03 07:23:10,708 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:60026 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 src: /127.0.0.1:60026 dest: /127.0.0.1:39995
2020-12-03 07:23:10,712 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:10,714 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:33172 [Receiving block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775784_1001 src: /127.0.0.1:33172 dest: /127.0.0.1:37531
2020-12-03 07:23:11,060 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53556, dest: /127.0.0.1:36190, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: d4aa3f9a-f071-443d-b783-c464472740a1, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775792_1001, duration(ns): 294882396
2020-12-03 07:23:11,061 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,068 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52664, dest: /127.0.0.1:44171, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: c0ba2203-ddf0-4690-bdc1-443459e69dae, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775791_1001, duration(ns): 296231641
2020-12-03 07:23:11,069 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,073 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60026, dest: /127.0.0.1:39995, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: 15c22f71-215f-4109-ba04-91a80e084ccc, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001, duration(ns): 310930691
2020-12-03 07:23:11,073 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,077 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56148, dest: /127.0.0.1:45505, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: 8e2241b2-b5f1-40cf-9b1b-6f6467b96189, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775789_1001, duration(ns): 316069334
2020-12-03 07:23:11,077 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,084 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48970, dest: /127.0.0.1:35185, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: 5af35291-e71b-4e63-ad53-749abe1b00d0, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775788_1001, duration(ns): 318369648
2020-12-03 07:23:11,084 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,089 [IPC Server handler 4 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35185, datanodeUuid=5af35291-e71b-4e63-ad53-749abe1b00d0, infoPort=45219, infoSecurePort=0, ipcPort=42079, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,090 [IPC Server handler 1 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45505, datanodeUuid=8e2241b2-b5f1-40cf-9b1b-6f6467b96189, infoPort=33132, infoSecurePort=0, ipcPort=32790, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,090 [IPC Server handler 5 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,091 [IPC Server handler 6 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44171, datanodeUuid=c0ba2203-ddf0-4690-bdc1-443459e69dae, infoPort=43081, infoSecurePort=0, ipcPort=42164, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,091 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:35185 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,091 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,092 [IPC Server handler 7 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36190, datanodeUuid=d4aa3f9a-f071-443d-b783-c464472740a1, infoPort=37765, infoSecurePort=0, ipcPort=33296, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,102 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49186, dest: /127.0.0.1:36279, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: b2c1889f-1327-4267-bacf-3ca4bed4101c, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775787_1001, duration(ns): 327523638
2020-12-03 07:23:11,102 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35185 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,104 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:35185
2020-12-03 07:23:11,105 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35185 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,105 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:45505 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,105 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,105 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:45505 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,105 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:45505
2020-12-03 07:23:11,105 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45505 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,105 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:39995 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,105 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,106 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:39995 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,106 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:39995
2020-12-03 07:23:11,106 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39995 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,106 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:44171 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,106 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,106 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:44171 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,106 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:44171
2020-12-03 07:23:11,106 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44171 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,102 [IPC Server handler 0 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36279, datanodeUuid=b2c1889f-1327-4267-bacf-3ca4bed4101c, infoPort=34080, infoSecurePort=0, ipcPort=38923, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,109 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:36190 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,109 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,109 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:36190 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,109 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:36190
2020-12-03 07:23:11,109 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36190 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,109 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:36279 size 4194181 replicaState = FINALIZED
2020-12-03 07:23:11,109 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,109 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:36279 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,110 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:36279
2020-12-03 07:23:11,110 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36279 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,112 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,119 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54160, dest: /127.0.0.1:34280, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: 4b1ceee1-a93a-4837-a095-708c8e7f6d5e, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775786_1001, duration(ns): 355465864
2020-12-03 07:23:11,120 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,121 [IPC Server handler 8 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34280, datanodeUuid=4b1ceee1-a93a-4837-a095-708c8e7f6d5e, infoPort=35738, infoSecurePort=0, ipcPort=42365, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,122 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:34280 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,122 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,123 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:34280 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,123 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:34280
2020-12-03 07:23:11,123 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34280 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,124 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50224, dest: /127.0.0.1:40478, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: 13ceaf14-28a4-4201-8c14-6177b852e8b8, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775785_1001, duration(ns): 361401708
2020-12-03 07:23:11,124 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,128 [IPC Server handler 2 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40478, datanodeUuid=13ceaf14-28a4-4201-8c14-6177b852e8b8, infoPort=42262, infoSecurePort=0, ipcPort=35699, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,129 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:40478 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,129 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,131 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:40478 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,131 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:40478
2020-12-03 07:23:11,131 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40478 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,131 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33172, dest: /127.0.0.1:37531, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-668486486_1, offset: 0, srvID: e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33, blockid: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775784_1001, duration(ns): 364853131
2020-12-03 07:23:11,131 [PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:11,132 [IPC Server handler 9 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37531, datanodeUuid=e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33, infoPort=38588, infoSecurePort=0, ipcPort=39846, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:11,132 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:37531 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:11,132 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:11,132 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:37531 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:11,133 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:37531
2020-12-03 07:23:11,133 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37531 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:11,137 [IPC Server handler 3 on default port 38574] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /deleted_1_0 for DFSClient_NONMAPREDUCE_-668486486_1
2020-12-03 07:23:11,141 [IPC Server handler 3 on default port 38574] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /deleted_1_0 with 1 blocks is persisted to the file system
2020-12-03 07:23:11,143 [IPC Server handler 3 on default port 38574] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /deleted_1_0 is closed by DFSClient_NONMAPREDUCE_-668486486_1
2020-12-03 07:23:11,147 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(228)) - corruptBlocks on path /deleted_1_0
2020-12-03 07:23:11,150 [IPC Server handler 4 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:11,152 [IPC Server handler 4 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:11,163 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(255)) - Deleting block file BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
2020-12-03 07:23:11,166 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,168 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,168 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,169 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,169 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,170 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,170 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,170 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:256)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,172 [Thread-350] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045/current/finalized/subdir0/subdir0/blk_-9223372036854775790
2020-12-03 07:23:11,174 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(134)) - verifyRead on path /deleted_1_0
2020-12-03 07:23:11,183 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(136)) - verifyRead verifyLength on path /deleted_1_0
2020-12-03 07:23:11,184 [IPC Server handler 1 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:11,185 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(138)) - verifyRead verifyPread on path /deleted_1_0
2020-12-03 07:23:11,189 [IPC Server handler 5 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:11,194 [IPC Server handler 6 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:11,195 [IPC Server handler 6 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:11,253 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,290 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,299 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,316 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:60046 [Sending block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001]] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(226)) - Scheduling blk_-9223372036854775790_1001 replica FinalizedReplica, blk_-9223372036854775790_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045/current/finalized/subdir0/subdir0/blk_-9223372036854775790 for deletion
2020-12-03 07:23:11,319 [Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(334)) - Deleted BP-868631643-172.17.0.11-1606980183045 blk_-9223372036854775790_1001 URI file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045/current/finalized/subdir0/subdir0/blk_-9223372036854775790
2020-12-03 07:23:11,330 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:60046 [Sending block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:readBlock(601)) - opReadBlock BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 received exception java.io.FileNotFoundException: BlockId -9223372036854775790 is not valid.
2020-12-03 07:23:11,332 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:60046 [Sending block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045):Got exception while serving BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 to /127.0.0.1:60046
java.io.FileNotFoundException: BlockId -9223372036854775790 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:311)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:596)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:11,332 [Thread-350] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getRemoteBlockReaderFromTcp(765)) - I/O error constructing remote block reader.
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 received exception java.io.FileNotFoundException: BlockId -9223372036854775790 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:60046, remote=/127.0.0.1:39995, for file /deleted_1_0, for pool BP-868631643-172.17.0.11-1606980183045 block -9223372036854775790_1001
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:854)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:750)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:380)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:644)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:264)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:299)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:330)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,334 [Thread-350] WARN  hdfs.DFSClient (DFSStripedInputStream.java:createBlockReader(281)) - Failed to connect to /127.0.0.1:39995 for blockBP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001
java.io.IOException: Got error, status=ERROR, status message opReadBlock BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001 received exception java.io.FileNotFoundException: BlockId -9223372036854775790 is not valid., for OP_READ_BLOCK, self=/127.0.0.1:60046, remote=/127.0.0.1:39995, for file /deleted_1_0, for pool BP-868631643-172.17.0.11-1606980183045 block -9223372036854775790_1001
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.checkSuccess(BlockReaderRemote.java:440)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.newBlockReader(BlockReaderRemote.java:408)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReader(BlockReaderFactory.java:854)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:750)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:380)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:644)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.createBlockReader(DFSStripedInputStream.java:264)
	at org.apache.hadoop.hdfs.StripeReader.readChunk(StripeReader.java:299)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:330)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.fetchBlockByteRange(DFSStripedInputStream.java:507)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1360)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1324)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:111)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:106)
	at org.apache.hadoop.hdfs.StripedFileTestUtil.verifyPread(StripedFileTestUtil.java:86)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.verifyRead(ReadStripedFileWithDecodingHelper.java:139)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:221)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData.testReadCorruptedDataByDeleting(TestReadStripedFileWithDecodingDeletedData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:11,335 [DataXceiver for client DFSClient_NONMAPREDUCE_-668486486_1 at /127.0.0.1:60046 [Sending block BP-868631643-172.17.0.11-1606980183045:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39995:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:60046 dst: /127.0.0.1:39995
java.io.FileNotFoundException: BlockId -9223372036854775790 is not valid.
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:771)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockReplica(FsDatasetImpl.java:762)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getMetaDataInputStream(FsDatasetImpl.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:311)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:596)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:11,337 [IPC Server handler 7 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:11,338 [IPC Server handler 7 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:11,342 [Thread-350] WARN  hdfs.DFSClient (DFSStripedInputStream.java:reportLostBlock(530)) - [DatanodeInfoWithStorage[127.0.0.1:39995,DS-f8e74601-7774-40eb-a2fc-1212407c9087,DISK]] are unavailable and all striping blocks on them are lost. IgnoredNodes = null
2020-12-03 07:23:11,343 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,347 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,352 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,389 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,879 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:23:13,440 [IPC Server handler 7 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40478, datanodeUuid=13ceaf14-28a4-4201-8c14-6177b852e8b8, infoPort=42262, infoSecurePort=0, ipcPort=35699, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:13,440 [IPC Server handler 3 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39995, datanodeUuid=15c22f71-215f-4109-ba04-91a80e084ccc, infoPort=33706, infoSecurePort=0, ipcPort=41051, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045) 1 blocks.
2020-12-03 07:23:13,440 [IPC Server handler 8 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37531, datanodeUuid=e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33, infoPort=38588, infoSecurePort=0, ipcPort=39846, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:13,440 [IPC Server handler 0 on default port 38574] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35185, datanodeUuid=5af35291-e71b-4e63-ad53-749abe1b00d0, infoPort=45219, infoSecurePort=0, ipcPort=42079, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), reports.length=2
2020-12-03 07:23:13,441 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa9dc56e6b8ba3d9d: Processing first storage report for DS-5c286158-aeaf-4f81-b1e6-53f602ae01de from datanode 13ceaf14-28a4-4201-8c14-6177b852e8b8
2020-12-03 07:23:13,442 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa9dc56e6b8ba3d9d: from storage DS-5c286158-aeaf-4f81-b1e6-53f602ae01de node DatanodeRegistration(127.0.0.1:40478, datanodeUuid=13ceaf14-28a4-4201-8c14-6177b852e8b8, infoPort=42262, infoSecurePort=0, ipcPort=35699, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:13,442 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3891)) - BLOCK* removeStoredBlock: blk_-9223372036854775792_1001 from 127.0.0.1:39995
2020-12-03 07:23:13,444 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-12-03 07:23:13,445 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:23:13,445 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:39995
2020-12-03 07:23:13,445 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39995 receiving: 0, received: 0, deleted: 1
2020-12-03 07:23:13,445 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9d845e0f2f618059: Processing first storage report for DS-4dee7b81-2ac3-4266-8652-879c18ba3b96 from datanode e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33
2020-12-03 07:23:13,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9d845e0f2f618059: from storage DS-4dee7b81-2ac3-4266-8652-879c18ba3b96 node DatanodeRegistration(127.0.0.1:37531, datanodeUuid=e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33, infoPort=38588, infoSecurePort=0, ipcPort=39846, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:13,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x15fd6314475c3c20: Processing first storage report for DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7 from datanode 5af35291-e71b-4e63-ad53-749abe1b00d0
2020-12-03 07:23:13,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15fd6314475c3c20: from storage DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7 node DatanodeRegistration(127.0.0.1:35185, datanodeUuid=5af35291-e71b-4e63-ad53-749abe1b00d0, infoPort=45219, infoSecurePort=0, ipcPort=42079, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:13,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa9dc56e6b8ba3d9d: Processing first storage report for DS-139348de-064e-4766-8b5f-5d2df28fd2e0 from datanode 13ceaf14-28a4-4201-8c14-6177b852e8b8
2020-12-03 07:23:13,446 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775785 on 127.0.0.1:40478 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:13,446 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:40478 size 25165701
2020-12-03 07:23:13,447 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  2 oldPri  2
2020-12-03 07:23:13,447 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:23:13,447 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:23:13,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa9dc56e6b8ba3d9d: from storage DS-139348de-064e-4766-8b5f-5d2df28fd2e0 node DatanodeRegistration(127.0.0.1:40478, datanodeUuid=13ceaf14-28a4-4201-8c14-6177b852e8b8, infoPort=42262, infoSecurePort=0, ipcPort=35699, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:13,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9d845e0f2f618059: Processing first storage report for DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca from datanode e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33
2020-12-03 07:23:13,447 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775784 on 127.0.0.1:37531 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:13,447 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:37531 size 25165701
2020-12-03 07:23:13,448 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  2 oldPri  2
2020-12-03 07:23:13,448 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:23:13,448 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:23:13,448 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9d845e0f2f618059: from storage DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca node DatanodeRegistration(127.0.0.1:37531, datanodeUuid=e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33, infoPort=38588, infoSecurePort=0, ipcPort=39846, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:13,448 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x15fd6314475c3c20: Processing first storage report for DS-44f7349d-132b-4248-b5e0-3098728fd2f8 from datanode 5af35291-e71b-4e63-ad53-749abe1b00d0
2020-12-03 07:23:13,448 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775788 on 127.0.0.1:35185 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:13,448 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:35185 size 25165701
2020-12-03 07:23:13,448 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  2 oldPri  2
2020-12-03 07:23:13,449 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:23:13,449 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:23:13,449 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15fd6314475c3c20: from storage DS-44f7349d-132b-4248-b5e0-3098728fd2f8 node DatanodeRegistration(127.0.0.1:35185, datanodeUuid=5af35291-e71b-4e63-ad53-749abe1b00d0, infoPort=45219, infoSecurePort=0, ipcPort=42079, storageInfo=lv=-57;cid=testClusterID;nsid=1754324486;c=1606980183045), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:13,449 [IPC Server handler 7 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa9dc56e6b8ba3d9d
2020-12-03 07:23:13,449 [IPC Server handler 8 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9d845e0f2f618059
2020-12-03 07:23:13,449 [IPC Server handler 0 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x15fd6314475c3c20
2020-12-03 07:23:13,450 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9d845e0f2f618059,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:13,450 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x15fd6314475c3c20,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 3 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:13,450 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa9dc56e6b8ba3d9d,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 12 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:13,450 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:13,450 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:13,451 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:14,883 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:14,884 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:14,972 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:14,978 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:14,985 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:14,990 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:14,995 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,000 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:17,884 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:17,885 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:20,908 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:20,909 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:23,909 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:23,910 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:26,911 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:26,912 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:29,913 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:29,914 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:30,985 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(140)) - verifyRead verifyStatefulRead on path /deleted_1_0
2020-12-03 07:23:30,990 [IPC Server handler 8 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:30,991 [IPC Server handler 8 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:32,915 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:32,915 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:35,916 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:35,917 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:36,010 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead2 on path /deleted_1_0
2020-12-03 07:23:36,027 [IPC Server handler 9 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:36,030 [IPC Server handler 9 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:36,052 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:36,056 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:36,059 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:36,062 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:36,067 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:36,074 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:38,918 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:38,918 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:41,006 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifySeek on path /deleted_1_0
2020-12-03 07:23:41,009 [IPC Server handler 9 on default port 38574] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:41,010 [IPC Server handler 9 on default port 38574] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/deleted_1_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:41,021 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:41,027 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:41,030 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:41,035 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:41,037 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:41,041 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:41,919 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:41,920 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:44,921 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:44,921 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:47,860 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:47,863 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:23:47,863 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:47,864 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@9257031] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:47,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-f8e74601-7774-40eb-a2fc-1212407c9087) exiting.
2020-12-03 07:23:47,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-98537e8e-24fa-419b-b567-5f2eb72e783c) exiting.
2020-12-03 07:23:47,915 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30457e14{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:47,921 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1af1347d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:47,922 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b4ef7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:47,922 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:47,922 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3d9fc57a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:47,922 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:47,926 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41051
2020-12-03 07:23:47,930 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:47,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:47,936 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:47,936 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 15c22f71-215f-4109-ba04-91a80e084ccc) service to localhost/127.0.0.1:38574
2020-12-03 07:23:47,936 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 15c22f71-215f-4109-ba04-91a80e084ccc)
2020-12-03 07:23:47,937 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:47,938 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:47,938 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:47,947 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:47,947 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:47,949 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:47,949 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:47,954 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:47,955 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:23:47,955 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:47,955 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@10567255] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:47,957 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-468480ed-0d13-4fe3-ac85-54b0fc23b846) exiting.
2020-12-03 07:23:47,957 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-0edd2879-4df4-4805-931c-d49cb812c3fd) exiting.
2020-12-03 07:23:47,997 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@59221b97{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:47,998 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ac4944a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:47,998 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35e52059{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:47,999 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54336c81{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,000 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42365
2020-12-03 07:23:48,024 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,024 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,025 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,028 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 4b1ceee1-a93a-4837-a095-708c8e7f6d5e) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,028 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 4b1ceee1-a93a-4837-a095-708c8e7f6d5e)
2020-12-03 07:23:48,028 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,030 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,030 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,036 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,036 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,037 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,038 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,040 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,040 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:23:48,041 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,041 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@78e16155] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,042 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9da3d5c3-ec23-46de-b8f7-18045ae8eae1) exiting.
2020-12-03 07:23:48,042 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-915b1da8-abef-4fd8-bf01-a01c0619f8da) exiting.
2020-12-03 07:23:48,069 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@51abf713{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,072 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@eadb475{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,072 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b739528{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,073 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13c612bd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,074 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32790
2020-12-03 07:23:48,083 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,086 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,086 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 8e2241b2-b5f1-40cf-9b1b-6f6467b96189) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,086 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 8e2241b2-b5f1-40cf-9b1b-6f6467b96189)
2020-12-03 07:23:48,086 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,087 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,088 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,096 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,099 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,103 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,104 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,109 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,109 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:23:48,114 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7bd69e82] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,115 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,118 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-139348de-064e-4766-8b5f-5d2df28fd2e0) exiting.
2020-12-03 07:23:48,119 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5c286158-aeaf-4f81-b1e6-53f602ae01de) exiting.
2020-12-03 07:23:48,146 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3301500b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,148 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24b52d3e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,148 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a2f016d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,149 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cbf9e9f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,150 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35699
2020-12-03 07:23:48,155 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,156 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,160 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,160 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 13ceaf14-28a4-4201-8c14-6177b852e8b8) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,160 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 13ceaf14-28a4-4201-8c14-6177b852e8b8)
2020-12-03 07:23:48,160 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,161 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,181 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,184 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,184 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,188 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,188 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,193 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,193 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:23:48,193 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,193 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2a2bb0eb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,197 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-20a5adaa-47a8-4524-ad7b-995578afa744) exiting.
2020-12-03 07:23:48,197 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-eae50968-723a-4f1d-a23d-695cbb3a0e55) exiting.
2020-12-03 07:23:48,294 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@475b7792{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,295 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@751e664e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,296 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c444798{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,296 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cfd1875{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,301 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33296
2020-12-03 07:23:48,320 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,320 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,325 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid d4aa3f9a-f071-443d-b783-c464472740a1) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,325 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid d4aa3f9a-f071-443d-b783-c464472740a1)
2020-12-03 07:23:48,325 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,320 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,327 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,331 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,340 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,345 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,349 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,349 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,358 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,358 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:48,358 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,358 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@669253b7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,363 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-65fcfd1e-2955-4827-8bc3-6a74713711f5) exiting.
2020-12-03 07:23:48,363 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-6a3ce8d0-e7ac-4c87-8b4b-31e02314a278) exiting.
2020-12-03 07:23:48,382 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22db8f4{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,383 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b46a8c1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,383 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52c8295b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,384 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@36ac8a63{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,389 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38923
2020-12-03 07:23:48,409 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,409 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,409 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,413 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid b2c1889f-1327-4267-bacf-3ca4bed4101c) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,413 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid b2c1889f-1327-4267-bacf-3ca4bed4101c)
2020-12-03 07:23:48,413 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,414 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,414 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,425 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,425 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,429 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,429 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,436 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,437 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:48,437 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,437 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@200606de] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,442 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-44f7349d-132b-4248-b5e0-3098728fd2f8) exiting.
2020-12-03 07:23:48,442 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-40463efb-c0bc-4d90-bde0-c1646f3c39d7) exiting.
2020-12-03 07:23:48,467 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@65f87a2c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,468 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51684e4a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,469 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7957dc72{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,469 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7544a1e4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,472 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42079
2020-12-03 07:23:48,486 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,491 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,491 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,491 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 5af35291-e71b-4e63-ad53-749abe1b00d0) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,491 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid 5af35291-e71b-4e63-ad53-749abe1b00d0)
2020-12-03 07:23:48,491 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,492 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,497 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,506 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,507 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,511 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,511 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,518 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,518 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:48,518 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,518 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4fbdc0f0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,522 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-91386c93-cd9a-46c4-951a-1d3ffaa6feca) exiting.
2020-12-03 07:23:48,522 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4dee7b81-2ac3-4266-8652-879c18ba3b96) exiting.
2020-12-03 07:23:48,541 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5af9926a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,541 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@43c67247{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,544 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70d2e40b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,544 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aec50a1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,546 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39846
2020-12-03 07:23:48,551 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,551 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,552 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,552 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,553 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid e7c395cb-e3f4-49f6-943f-9b1e1ad3ff33)
2020-12-03 07:23:48,553 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,554 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,555 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,571 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,571 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,576 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,576 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,584 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,584 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:48,585 [Listener at localhost/41051] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:48,585 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@659eef7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:48,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e06c7cbe-1bc6-46c0-9c56-1978f4a11ef4) exiting.
2020-12-03 07:23:48,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7e85df17-966b-444b-819d-ab7b3d7d489b) exiting.
2020-12-03 07:23:48,609 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@76ba13c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:48,609 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@eb6449b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,610 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@675d8c96{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,610 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e70ea3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,612 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42164
2020-12-03 07:23:48,622 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,622 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,628 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:48,628 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid c0ba2203-ddf0-4690-bdc1-443459e69dae) service to localhost/127.0.0.1:38574
2020-12-03 07:23:48,729 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-868631643-172.17.0.11-1606980183045 (Datanode Uuid c0ba2203-ddf0-4690-bdc1-443459e69dae)
2020-12-03 07:23:48,729 [BP-868631643-172.17.0.11-1606980183045 heartbeating to localhost/127.0.0.1:38574] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-868631643-172.17.0.11-1606980183045
2020-12-03 07:23:48,730 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,730 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-868631643-172.17.0.11-1606980183045] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:48,763 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:48,763 [Listener at localhost/41051] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:48,768 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:48,768 [Listener at localhost/41051] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:48,780 [Listener at localhost/41051] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:48,780 [Listener at localhost/41051] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:48,781 [Listener at localhost/41051] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:48,782 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4bff1903] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:48,782 [Listener at localhost/41051] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:23:48,782 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@207ea13] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:48,783 [Listener at localhost/41051] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 52 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 6 1 
2020-12-03 07:23:48,784 [Listener at localhost/41051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:23:48,785 [Listener at localhost/41051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:23:48,786 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:48,786 [CacheReplicationMonitor(516470401)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:48,786 [Listener at localhost/41051] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38574
2020-12-03 07:23:48,797 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,804 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,805 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:48,816 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:48,817 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@a4b2d8f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:48,871 [Listener at localhost/41051] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:48,872 [Listener at localhost/41051] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:48,874 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4dd6fd0a{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:48,876 [Listener at localhost/41051] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4bd31064{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:48,876 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb4f2a9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,877 [Listener at localhost/41051] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1807f5a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:48,883 [Listener at localhost/41051] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:48,911 [Listener at localhost/41051] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:48,912 [Listener at localhost/41051] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
