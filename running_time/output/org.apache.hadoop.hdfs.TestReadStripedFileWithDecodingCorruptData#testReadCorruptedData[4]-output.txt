2020-12-03 07:22:53,136 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:22:54,036 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:54,057 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:54,059 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:54,059 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:54,067 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:54,068 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:54,068 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:54,069 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:54,114 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:54,120 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:54,121 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:54,121 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:54,133 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:54,134 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:54
2020-12-03 07:22:54,144 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:54,147 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,152 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:54,153 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:54,184 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:54,185 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:54,196 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:54,197 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:54,198 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:54,198 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:54,200 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:54,200 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:54,200 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:54,201 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:22:54,201 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:54,201 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:54,201 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:54,250 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:54,251 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:54,251 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:54,251 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:54,274 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:54,274 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,275 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:54,275 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:54,282 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:54,282 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:54,283 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:54,283 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:54,290 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:54,293 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:54,299 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:54,299 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,300 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:54,300 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:54,313 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:54,314 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:54,314 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:54,320 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:54,321 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:54,324 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:54,325 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:54,326 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:54,326 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:54,385 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:54,455 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:54,498 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:54,546 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:54,546 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:54,709 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:54,709 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:54,775 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:54,780 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:54,917 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:55,400 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:55,401 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:55,451 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:55,498 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a56cdac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:55,514 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:55,520 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:55,536 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4054ms
2020-12-03 07:22:55,670 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:55,674 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:55,674 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:55,683 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:55,686 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:55,686 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:55,686 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:55,726 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:55,726 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:55,740 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43822
2020-12-03 07:22:55,742 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:55,808 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1807f5a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:55,810 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb4f2a9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:55,874 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4dd6fd0a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:55,887 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4bd31064{HTTP/1.1,[http/1.1]}{localhost:43822}
2020-12-03 07:22:55,888 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4407ms
2020-12-03 07:22:55,908 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:55,909 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:55,910 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:55,910 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:55,911 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:55,911 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:55,911 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:55,912 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:55,913 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:55,914 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:55,914 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:55,915 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:55,916 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:55
2020-12-03 07:22:55,916 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:55,917 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:55,917 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:55,918 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:55,923 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:55,923 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:55,924 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:55,924 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:55,925 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:55,925 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:55,926 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:55,926 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:55,926 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:55,927 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:22:55,927 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:55,927 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:55,928 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:55,929 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:55,929 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:55,929 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:55,930 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:55,933 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:55,933 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:55,934 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:55,934 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:55,934 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:55,935 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:55,935 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:55,935 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:55,936 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:55,937 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:55,938 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:55,938 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:55,939 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:55,939 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:55,939 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:55,940 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:55,940 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:55,940 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:55,941 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:56,008 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:56,067 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:56,072 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:56,072 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:56,073 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:56,073 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:56,107 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:56,114 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:56,115 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:56,121 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:56,122 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:56,203 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:56,204 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 259 msecs
2020-12-03 07:22:56,426 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:56,478 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:56,504 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:56,842 [Listener at localhost/46121] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46121 to access this namenode/service.
2020-12-03 07:22:56,846 [Listener at localhost/46121] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:56,871 [Listener at localhost/46121] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:56,873 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@a4b2d8f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-12-03 07:22:56,888 [Listener at localhost/46121] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:56,892 [Listener at localhost/46121] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:56,893 [Listener at localhost/46121] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:56,893 [Listener at localhost/46121] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:56,901 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:56,907 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:56,907 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:56,908 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:56,908 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:56,908 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2020-12-03 07:22:56,957 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:56,963 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:56,977 [Listener at localhost/46121] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46121
2020-12-03 07:22:56,982 [Listener at localhost/46121] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:56,982 [Listener at localhost/46121] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:57,001 [Listener at localhost/46121] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 11 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:57,019 [CacheReplicationMonitor(1299708340)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:57,028 [Listener at localhost/46121] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:57,103 [Listener at localhost/46121] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:57,122 [Listener at localhost/46121] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:57,149 [Listener at localhost/46121] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:57,156 [Listener at localhost/46121] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,160 [Listener at localhost/46121] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:57,166 [Listener at localhost/46121] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:57,167 [Listener at localhost/46121] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,172 [Listener at localhost/46121] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:57,178 [Listener at localhost/46121] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34890
2020-12-03 07:22:57,181 [Listener at localhost/46121] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:57,182 [Listener at localhost/46121] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:57,228 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,231 [Listener at localhost/46121] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,240 [Listener at localhost/46121] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:57,241 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,245 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,246 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:57,246 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,246 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,250 [Listener at localhost/46121] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46210
2020-12-03 07:22:57,250 [Listener at localhost/46121] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,252 [Listener at localhost/46121] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e70ea3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,253 [Listener at localhost/46121] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@675d8c96{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,262 [Listener at localhost/46121] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@76ba13c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,264 [Listener at localhost/46121] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@eb6449b{HTTP/1.1,[http/1.1]}{localhost:46210}
2020-12-03 07:22:57,264 [Listener at localhost/46121] INFO  server.Server (Server.java:doStart(419)) - Started @5783ms
2020-12-03 07:22:57,739 [Listener at localhost/46121] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33696
2020-12-03 07:22:57,739 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b5bc39d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,741 [Listener at localhost/46121] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,741 [Listener at localhost/46121] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,762 [Listener at localhost/46121] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,763 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:58,186 [Listener at localhost/39666] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39666
2020-12-03 07:22:58,251 [Listener at localhost/39666] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:58,253 [Listener at localhost/39666] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:58,267 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:58,292 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:58,301 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:58,306 [Listener at localhost/39666] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:58,310 [Listener at localhost/39666] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:58,312 [Listener at localhost/39666] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:58,324 [Listener at localhost/39666] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:58,324 [Listener at localhost/39666] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,324 [Listener at localhost/39666] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:58,325 [Listener at localhost/39666] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:58,326 [Listener at localhost/39666] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,326 [Listener at localhost/39666] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:58,327 [Listener at localhost/39666] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34004
2020-12-03 07:22:58,327 [Listener at localhost/39666] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:58,328 [Listener at localhost/39666] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:58,352 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:58,369 [Listener at localhost/39666] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:58,371 [Listener at localhost/39666] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:58,371 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:58,375 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:58,377 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:58,377 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:58,377 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:58,379 [Listener at localhost/39666] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34484
2020-12-03 07:22:58,379 [Listener at localhost/39666] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:58,402 [Listener at localhost/39666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aec50a1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:58,412 [Listener at localhost/39666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70d2e40b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:58,426 [Listener at localhost/39666] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5af9926a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:58,440 [Listener at localhost/39666] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@43c67247{HTTP/1.1,[http/1.1]}{localhost:34484}
2020-12-03 07:22:58,440 [Listener at localhost/39666] INFO  server.Server (Server.java:doStart(419)) - Started @6959ms
2020-12-03 07:22:58,572 [Listener at localhost/39666] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37876
2020-12-03 07:22:58,572 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@726386ed] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:58,572 [Listener at localhost/39666] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:58,573 [Listener at localhost/39666] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:58,573 [Listener at localhost/39666] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:58,574 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:58,592 [Listener at localhost/34268] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34268
2020-12-03 07:22:58,597 [Listener at localhost/34268] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:58,603 [Listener at localhost/34268] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:58,607 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:58,609 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:58,609 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:58,615 [Listener at localhost/34268] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:58,630 [Listener at localhost/34268] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:58,631 [Listener at localhost/34268] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:58,654 [Listener at localhost/34268] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:58,655 [Listener at localhost/34268] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,656 [Listener at localhost/34268] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:58,657 [Listener at localhost/34268] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:58,657 [Listener at localhost/34268] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,657 [Listener at localhost/34268] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:58,658 [Listener at localhost/34268] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43040
2020-12-03 07:22:58,659 [Listener at localhost/34268] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:58,659 [Listener at localhost/34268] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:58,662 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:58,665 [Listener at localhost/34268] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:58,666 [Listener at localhost/34268] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:58,666 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:58,670 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:58,672 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:58,672 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:58,672 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:58,674 [Listener at localhost/34268] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40935
2020-12-03 07:22:58,674 [Listener at localhost/34268] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:58,693 [Listener at localhost/34268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:58,694 [Listener at localhost/34268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:58,705 [Listener at localhost/34268] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3d4d3fe7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:58,711 [Listener at localhost/34268] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:40935}
2020-12-03 07:22:58,712 [Listener at localhost/34268] INFO  server.Server (Server.java:doStart(419)) - Started @7231ms
2020-12-03 07:22:58,745 [Listener at localhost/34268] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33890
2020-12-03 07:22:58,746 [Listener at localhost/34268] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:58,746 [Listener at localhost/34268] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:58,747 [Listener at localhost/34268] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:58,746 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ce1f601] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:58,748 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:58,754 [Listener at localhost/40753] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40753
2020-12-03 07:22:58,760 [Listener at localhost/40753] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:58,761 [Listener at localhost/40753] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:58,768 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:58,788 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:58,788 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:58,801 [Listener at localhost/40753] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:58,804 [Listener at localhost/40753] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:58,804 [Listener at localhost/40753] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:58,823 [Listener at localhost/40753] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:58,823 [Listener at localhost/40753] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,824 [Listener at localhost/40753] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:58,824 [Listener at localhost/40753] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:58,824 [Listener at localhost/40753] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:58,825 [Listener at localhost/40753] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:58,826 [Listener at localhost/40753] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35085
2020-12-03 07:22:58,826 [Listener at localhost/40753] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:58,826 [Listener at localhost/40753] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:58,827 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:58,829 [Listener at localhost/40753] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:58,831 [Listener at localhost/40753] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:58,831 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:58,834 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:58,840 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:58,840 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:58,841 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:58,842 [Listener at localhost/40753] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45665
2020-12-03 07:22:58,842 [Listener at localhost/40753] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:58,860 [Listener at localhost/40753] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66d23e4a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:58,866 [Listener at localhost/40753] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d9d1b69{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:58,889 [Listener at localhost/40753] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@581d969c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:58,890 [Listener at localhost/40753] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22db8f4{HTTP/1.1,[http/1.1]}{localhost:45665}
2020-12-03 07:22:58,890 [Listener at localhost/40753] INFO  server.Server (Server.java:doStart(419)) - Started @7409ms
2020-12-03 07:22:59,033 [Listener at localhost/40753] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33843
2020-12-03 07:22:59,035 [Listener at localhost/40753] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:59,035 [Listener at localhost/40753] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:59,036 [Listener at localhost/40753] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,035 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d572e62] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,055 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,063 [Listener at localhost/39560] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39560
2020-12-03 07:22:59,069 [Listener at localhost/39560] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:59,069 [Listener at localhost/39560] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:59,070 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:59,071 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,071 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:59,085 [Listener at localhost/39560] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:59,094 [Listener at localhost/39560] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:59,095 [Listener at localhost/39560] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:59,110 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,111 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,110 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,110 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,111 [Listener at localhost/39560] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:59,112 [Listener at localhost/39560] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,112 [Listener at localhost/39560] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:59,113 [Listener at localhost/39560] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:59,113 [Listener at localhost/39560] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,115 [Listener at localhost/39560] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:59,116 [Listener at localhost/39560] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37921
2020-12-03 07:22:59,116 [Listener at localhost/39560] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:59,117 [Listener at localhost/39560] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:59,117 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,118 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,116 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,118 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,123 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,125 [Listener at localhost/39560] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:59,127 [Listener at localhost/39560] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:59,127 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,130 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:59,131 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:59,131 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:59,132 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:59,133 [Listener at localhost/39560] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46789
2020-12-03 07:22:59,133 [Listener at localhost/39560] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:59,135 [Listener at localhost/39560] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cfd1875{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:59,136 [Listener at localhost/39560] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c444798{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:59,149 [Listener at localhost/39560] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@475b7792{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:59,159 [Listener at localhost/39560] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@751e664e{HTTP/1.1,[http/1.1]}{localhost:46789}
2020-12-03 07:22:59,160 [Listener at localhost/39560] INFO  server.Server (Server.java:doStart(419)) - Started @7679ms
2020-12-03 07:22:59,178 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,178 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,180 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,181 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,182 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:59,184 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:59,189 [Listener at localhost/39560] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46507
2020-12-03 07:22:59,190 [Listener at localhost/39560] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:59,190 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@182b435b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,190 [Listener at localhost/39560] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:59,196 [Listener at localhost/39560] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,197 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,205 [Listener at localhost/43477] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43477
2020-12-03 07:22:59,223 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,224 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,224 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c7f4901c-286b-4846-87d8-5cd11f80cf33 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:59,225 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,225 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,226 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:59,237 [Listener at localhost/43477] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:59,238 [Listener at localhost/43477] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:59,239 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:59,248 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,248 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:59,282 [Listener at localhost/43477] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:59,298 [Listener at localhost/43477] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:59,299 [Listener at localhost/43477] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:59,304 [Listener at localhost/43477] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:59,304 [Listener at localhost/43477] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,304 [Listener at localhost/43477] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:59,305 [Listener at localhost/43477] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:59,305 [Listener at localhost/43477] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,306 [Listener at localhost/43477] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:59,307 [Listener at localhost/43477] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44290
2020-12-03 07:22:59,307 [Listener at localhost/43477] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:59,307 [Listener at localhost/43477] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:59,310 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,312 [Listener at localhost/43477] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:59,313 [Listener at localhost/43477] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:59,313 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,316 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:59,316 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,326 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,326 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:59,327 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:59,327 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:59,328 [Listener at localhost/43477] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40813
2020-12-03 07:22:59,329 [Listener at localhost/43477] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:59,331 [Listener at localhost/43477] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cbf9e9f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:59,332 [Listener at localhost/43477] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a2f016d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:59,342 [Listener at localhost/43477] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3301500b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:59,344 [Listener at localhost/43477] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24b52d3e{HTTP/1.1,[http/1.1]}{localhost:40813}
2020-12-03 07:22:59,344 [Listener at localhost/43477] INFO  server.Server (Server.java:doStart(419)) - Started @7863ms
2020-12-03 07:22:59,352 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,352 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,353 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:59,362 [Listener at localhost/43477] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43836
2020-12-03 07:22:59,363 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e9c413e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,363 [Listener at localhost/43477] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:59,364 [Listener at localhost/43477] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:59,365 [Listener at localhost/43477] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,366 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,383 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,384 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,383 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,384 [Listener at localhost/37638] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37638
2020-12-03 07:22:59,384 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,384 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,384 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,385 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:59,385 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e4dde564-dfa3-40d7-b46c-61762e2fb668 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:59,385 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:22:59,390 [Listener at localhost/37638] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:59,390 [Listener at localhost/37638] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:59,391 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:59,392 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,392 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:59,399 [Listener at localhost/37638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:59,401 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,402 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,402 [Listener at localhost/37638] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:59,403 [Listener at localhost/37638] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:59,413 [Listener at localhost/37638] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:59,414 [Listener at localhost/37638] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,415 [Listener at localhost/37638] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:59,416 [Listener at localhost/37638] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:59,416 [Listener at localhost/37638] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,417 [Listener at localhost/37638] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:59,418 [Listener at localhost/37638] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38310
2020-12-03 07:22:59,418 [Listener at localhost/37638] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:59,418 [Listener at localhost/37638] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:59,423 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,427 [Listener at localhost/37638] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:59,427 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,428 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,428 [Listener at localhost/37638] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:59,428 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-41992268-fb7b-4b13-a3ac-ac889aadb055 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:59,428 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,431 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:59,432 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:59,432 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:59,432 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:59,434 [Listener at localhost/37638] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41990
2020-12-03 07:22:59,434 [Listener at localhost/37638] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:59,438 [Listener at localhost/37638] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b739528{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:59,439 [Listener at localhost/37638] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41de5768{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:59,460 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,461 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,461 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-70288939-373e-45bd-99f3-27f73324f03c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:22:59,469 [Listener at localhost/37638] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4d4d48a6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:59,470 [Listener at localhost/37638] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@315df4bb{HTTP/1.1,[http/1.1]}{localhost:41990}
2020-12-03 07:22:59,478 [Listener at localhost/37638] INFO  server.Server (Server.java:doStart(419)) - Started @7997ms
2020-12-03 07:22:59,509 [Listener at localhost/37638] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42906
2020-12-03 07:22:59,511 [Listener at localhost/37638] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:59,511 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5cad8b7d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,512 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,511 [Listener at localhost/37638] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:59,512 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,513 [Listener at localhost/37638] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,514 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,514 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,514 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,519 [Listener at localhost/37799] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37799
2020-12-03 07:22:59,525 [Listener at localhost/37799] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:59,525 [Listener at localhost/37799] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:59,526 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:59,530 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,530 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:59,536 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,538 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,539 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,539 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,541 [Listener at localhost/37799] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:59,542 [Listener at localhost/37799] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:59,543 [Listener at localhost/37799] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:59,543 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,544 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,544 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,545 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,545 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,551 [Listener at localhost/37799] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:59,557 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,557 [Listener at localhost/37799] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,558 [Listener at localhost/37799] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:59,559 [Listener at localhost/37799] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:59,559 [Listener at localhost/37799] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,559 [Listener at localhost/37799] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:59,560 [Listener at localhost/37799] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39214
2020-12-03 07:22:59,561 [Listener at localhost/37799] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:59,561 [Listener at localhost/37799] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:59,583 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,586 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,587 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,593 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,593 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,595 [Listener at localhost/37799] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:59,596 [Listener at localhost/37799] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:59,596 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,597 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,597 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,598 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:22:59,598 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:59,599 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:59,599 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:59,599 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:59,600 [Listener at localhost/37799] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40126
2020-12-03 07:22:59,600 [Listener at localhost/37799] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:59,613 [Listener at localhost/37799] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1556f2dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:59,614 [Listener at localhost/37799] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62577d6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:59,626 [Listener at localhost/37799] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6ac4944a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:59,631 [Listener at localhost/37799] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a772895{HTTP/1.1,[http/1.1]}{localhost:40126}
2020-12-03 07:22:59,632 [Listener at localhost/37799] INFO  server.Server (Server.java:doStart(419)) - Started @8151ms
2020-12-03 07:22:59,674 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,688 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,688 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,688 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:22:59,688 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,689 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e1c9468d-d607-49e1-bf56-528d08a12f43 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:22:59,735 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,736 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,736 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,736 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,736 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,737 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,737 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,737 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,748 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,748 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,749 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,749 [Listener at localhost/37799] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44299
2020-12-03 07:22:59,749 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,750 [Listener at localhost/37799] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:59,750 [Listener at localhost/37799] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:59,751 [Listener at localhost/37799] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,750 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@704b2127] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,757 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,767 [Listener at localhost/43884] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43884
2020-12-03 07:22:59,801 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,801 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,802 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,802 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,817 [Listener at localhost/43884] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:59,817 [Listener at localhost/43884] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:59,825 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,826 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,826 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,826 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,828 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:59,879 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,879 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:22:59,879 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:59,886 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:22:59,886 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:22:59,886 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:22:59,887 [Listener at localhost/43884] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:59,888 [Listener at localhost/43884] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:59,888 [Listener at localhost/43884] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:59,889 [Listener at localhost/43884] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:59,890 [Listener at localhost/43884] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,890 [Listener at localhost/43884] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:59,890 [Listener at localhost/43884] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:59,890 [Listener at localhost/43884] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:59,891 [Listener at localhost/43884] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:59,892 [Listener at localhost/43884] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35023
2020-12-03 07:22:59,893 [Listener at localhost/43884] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:59,893 [Listener at localhost/43884] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:59,894 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,896 [Listener at localhost/43884] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:59,896 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:59,896 [Listener at localhost/43884] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:59,897 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:59,899 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:59,899 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:59,901 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:59,901 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:59,908 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:59,909 [Listener at localhost/43884] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37271
2020-12-03 07:22:59,911 [Listener at localhost/43884] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:59,910 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,912 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,913 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,913 [Listener at localhost/43884] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d4ab71a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:59,914 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,915 [Listener at localhost/43884] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1af05b03{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:59,925 [Listener at localhost/43884] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1af1347d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:59,926 [Listener at localhost/43884] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:37271}
2020-12-03 07:22:59,926 [Listener at localhost/43884] INFO  server.Server (Server.java:doStart(419)) - Started @8445ms
2020-12-03 07:22:59,933 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,933 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,935 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:22:59,944 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,945 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:22:59,945 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:22:59,945 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:22:59,953 [Listener at localhost/43884] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40485
2020-12-03 07:22:59,954 [Listener at localhost/43884] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:59,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b582111] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:59,954 [Listener at localhost/43884] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:59,954 [Listener at localhost/43884] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:59,955 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:59,959 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42203
2020-12-03 07:22:59,969 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:22:59,970 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:22:59,970 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5b53edda-0737-4df7-b184-e012a6ef225f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:22:59,971 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:22:59,978 [Listener at localhost/42203] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:59,979 [Listener at localhost/42203] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:59,984 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121 starting to offer service
2020-12-03 07:22:59,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:59,994 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:00,016 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46121
2020-12-03 07:23:00,019 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:00,066 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:23:00,066 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3
2020-12-03 07:23:00,066 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 467b8ef8-63a3-4223-aa82-6d73332dda4f
2020-12-03 07:23:00,067 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:23:00,067 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5354e553-b153-41a9-aa27-5e80ce459dfe
2020-12-03 07:23:00,068 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:23:00,090 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:23:00,091 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,091 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,091 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,091 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,121 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,121 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,122 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,122 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,174 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 997a129e-2f17-458f-b3b4-dafca2c4c514
2020-12-03 07:23:00,243 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:23:00,244 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:23:00,244 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:23:00,276 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5ae5eec0-b290-4696-9a42-85746dd47998
2020-12-03 07:23:00,277 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:23:00,289 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,290 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,290 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,291 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,319 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 7057@1d453410403c
2020-12-03 07:23:00,320 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1454577274. Formatting...
2020-12-03 07:23:00,321 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3f6f434c-6dad-4de2-8043-723f67cc82a0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:23:00,326 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab
2020-12-03 07:23:00,327 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d
2020-12-03 07:23:00,326 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9
2020-12-03 07:23:00,328 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:00,328 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:00,329 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:23:00,331 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c7f4901c-286b-4846-87d8-5cd11f80cf33
2020-12-03 07:23:00,331 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:00,354 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8
2020-12-03 07:23:00,355 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:00,355 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288
2020-12-03 07:23:00,361 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:00,368 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2
2020-12-03 07:23:00,370 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,371 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0
2020-12-03 07:23:00,372 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:23:00,372 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:00,374 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,372 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e4dde564-dfa3-40d7-b46c-61762e2fb668
2020-12-03 07:23:00,380 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:00,380 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,374 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,398 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-41992268-fb7b-4b13-a3ac-ac889aadb055
2020-12-03 07:23:00,398 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:00,401 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:00,402 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:00,403 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:00,413 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,396 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:00,425 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:00,427 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:00,429 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:00,429 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:00,427 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:00,429 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:00,431 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:00,431 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:00,431 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:00,431 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:00,431 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:00,437 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:00,436 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:00,431 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:00,437 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:23:00,437 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,431 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:00,438 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,437 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:00,437 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,470 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5a8ba81a-2e71-447e-85db-a3cc8b381485
2020-12-03 07:23:00,474 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:00,474 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:00,465 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:23:00,464 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,484 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,484 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,485 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,485 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,486 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:23:00,464 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:23:00,483 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,475 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:00,475 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:00,492 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,493 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,493 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:23:00,494 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,494 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:00,496 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-70288939-373e-45bd-99f3-27f73324f03c
2020-12-03 07:23:00,496 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:23:00,494 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:00,494 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,520 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f
2020-12-03 07:23:00,521 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:23:00,521 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,523 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:00,532 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:00,532 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:00,533 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:00,545 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,546 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:23:00,546 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:23:00,575 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a
2020-12-03 07:23:00,584 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 111ms
2020-12-03 07:23:00,586 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e1c9468d-d607-49e1-bf56-528d08a12f43
2020-12-03 07:23:00,586 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:23:00,592 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e
2020-12-03 07:23:00,597 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:23:00,598 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,603 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:00,603 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:00,604 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:00,604 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:00,639 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 151ms
2020-12-03 07:23:00,639 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 144ms
2020-12-03 07:23:00,640 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 94ms
2020-12-03 07:23:00,640 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 146ms
2020-12-03 07:23:00,642 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 156ms
2020-12-03 07:23:00,642 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,643 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,643 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 168ms
2020-12-03 07:23:00,643 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,643 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,643 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,649 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 148ms
2020-12-03 07:23:00,649 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 161ms
2020-12-03 07:23:00,649 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 161ms
2020-12-03 07:23:00,647 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 161ms
2020-12-03 07:23:00,646 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,646 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 162ms
2020-12-03 07:23:00,646 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 173ms
2020-12-03 07:23:00,650 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 212ms
2020-12-03 07:23:00,650 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:23:00,649 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,650 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:23:00,651 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1236643807-172.17.0.4-1606980174365 is not formatted. Formatting ...
2020-12-03 07:23:00,651 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1236643807-172.17.0.4-1606980174365 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1236643807-172.17.0.4-1606980174365/current
2020-12-03 07:23:00,652 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 165ms
2020-12-03 07:23:00,655 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 218ms
2020-12-03 07:23:00,656 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:23:00,656 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,658 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 112ms
2020-12-03 07:23:00,659 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 113ms
2020-12-03 07:23:00,660 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:23:00,660 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:23:00,698 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:23:00,698 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:23:00,712 [Thread-296] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,712 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:23:00,698 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:23:00,695 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 40ms
2020-12-03 07:23:00,695 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:23:00,695 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:23:00,718 [Thread-298] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,718 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,695 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:23:00,660 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,718 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,716 [Thread-294] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,711 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:23:00,703 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:23:00,702 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,702 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:23:00,701 [Thread-295] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,719 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 4ms
2020-12-03 07:23:00,719 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,720 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:00,722 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 4ms
2020-12-03 07:23:00,722 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 23ms
2020-12-03 07:23:00,719 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,719 [Thread-299] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,719 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:23:00,723 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 4ms
2020-12-03 07:23:00,723 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-12-03 07:23:00,723 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 72ms
2020-12-03 07:23:00,719 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 59ms
2020-12-03 07:23:00,718 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:23:00,724 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 73ms
2020-12-03 07:23:00,724 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 22ms
2020-12-03 07:23:00,723 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 67ms
2020-12-03 07:23:00,724 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 65ms
2020-12-03 07:23:00,722 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 72ms
2020-12-03 07:23:00,724 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 73ms
2020-12-03 07:23:00,735 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:23:00,741 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:23:00,741 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:23:00,741 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:23:00,737 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:23:00,735 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:23:00,742 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-41992268-fb7b-4b13-a3ac-ac889aadb055): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,735 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:23:00,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:23:00,735 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:23:00,737 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:23:00,737 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:23:00,747 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,748 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e4dde564-dfa3-40d7-b46c-61762e2fb668): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,748 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,747 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:23:00,748 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,747 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:23:00,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,756 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c7f4901c-286b-4846-87d8-5cd11f80cf33): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,758 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1454577274;bpid=BP-1236643807-172.17.0.4-1606980174365;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1454577274;c=1606980174365;bpid=BP-1236643807-172.17.0.4-1606980174365;dnuuid=null
2020-12-03 07:23:00,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,742 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,753 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 102ms
2020-12-03 07:23:00,748 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-70288939-373e-45bd-99f3-27f73324f03c): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,761 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 110ms
2020-12-03 07:23:00,761 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 111ms
2020-12-03 07:23:00,762 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:23:00,762 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:23:00,762 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,762 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,763 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:23:00,764 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 2ms
2020-12-03 07:23:00,764 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 2ms
2020-12-03 07:23:00,764 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:23:00,765 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:23:00,765 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,765 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e1c9468d-d607-49e1-bf56-528d08a12f43): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-70288939-373e-45bd-99f3-27f73324f03c): no suitable block pools found to scan.  Waiting 1814399966 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e4dde564-dfa3-40d7-b46c-61762e2fb668): no suitable block pools found to scan.  Waiting 1814399966 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-41992268-fb7b-4b13-a3ac-ac889aadb055): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,772 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e1c9468d-d607-49e1-bf56-528d08a12f43): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:23:00,772 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:23:00,772 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,775 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:47 PM with interval of 21600000ms
2020-12-03 07:23:00,775 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:35 AM with interval of 21600000ms
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c7f4901c-286b-4846-87d8-5cd11f80cf33): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,771 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:00,775 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:06 AM with interval of 21600000ms
2020-12-03 07:23:00,775 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:32 AM with interval of 21600000ms
2020-12-03 07:23:00,775 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:02 AM with interval of 21600000ms
2020-12-03 07:23:00,775 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:26 AM with interval of 21600000ms
2020-12-03 07:23:00,775 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:17 AM with interval of 21600000ms
2020-12-03 07:23:00,787 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,793 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 467b8ef8-63a3-4223-aa82-6d73332dda4f) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,793 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5a8ba81a-2e71-447e-85db-a3cc8b381485) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,793 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5354e553-b153-41a9-aa27-5e80ce459dfe) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,795 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 997a129e-2f17-458f-b3b4-dafca2c4c514) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,795 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5ae5eec0-b290-4696-9a42-85746dd47998) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,795 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:00,817 [IPC Server handler 9 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35085, datanodeUuid=467b8ef8-63a3-4223-aa82-6d73332dda4f, infoPort=33843, infoSecurePort=0, ipcPort=39560, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 467b8ef8-63a3-4223-aa82-6d73332dda4f
2020-12-03 07:23:00,820 [IPC Server handler 9 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35085
2020-12-03 07:23:00,820 [IPC Server handler 9 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 467b8ef8-63a3-4223-aa82-6d73332dda4f (127.0.0.1:35085).
2020-12-03 07:23:00,827 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34890, datanodeUuid=04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3, infoPort=33696, infoSecurePort=0, ipcPort=39666, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3
2020-12-03 07:23:00,827 [IPC Server handler 4 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34890
2020-12-03 07:23:00,828 [IPC Server handler 4 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3 (127.0.0.1:34890).
2020-12-03 07:23:00,828 [IPC Server handler 6 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=5354e553-b153-41a9-aa27-5e80ce459dfe, infoPort=37876, infoSecurePort=0, ipcPort=34268, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 5354e553-b153-41a9-aa27-5e80ce459dfe
2020-12-03 07:23:00,839 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,839 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,840 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 467b8ef8-63a3-4223-aa82-6d73332dda4f) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,840 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,844 [IPC Server handler 6 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34004
2020-12-03 07:23:00,844 [IPC Server handler 6 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5354e553-b153-41a9-aa27-5e80ce459dfe (127.0.0.1:34004).
2020-12-03 07:23:00,845 [IPC Server handler 2 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37921, datanodeUuid=5ae5eec0-b290-4696-9a42-85746dd47998, infoPort=46507, infoSecurePort=0, ipcPort=43477, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 5ae5eec0-b290-4696-9a42-85746dd47998
2020-12-03 07:23:00,845 [IPC Server handler 2 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37921
2020-12-03 07:23:00,845 [IPC Server handler 2 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5ae5eec0-b290-4696-9a42-85746dd47998 (127.0.0.1:37921).
2020-12-03 07:23:00,846 [IPC Server handler 3 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38310, datanodeUuid=45dc658f-8c5b-4c7b-ba4e-092b430b5f8a, infoPort=42906, infoSecurePort=0, ipcPort=37799, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a
2020-12-03 07:23:00,846 [IPC Server handler 3 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38310
2020-12-03 07:23:00,846 [IPC Server handler 3 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a (127.0.0.1:38310).
2020-12-03 07:23:00,847 [IPC Server handler 0 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44290, datanodeUuid=5a8ba81a-2e71-447e-85db-a3cc8b381485, infoPort=43836, infoSecurePort=0, ipcPort=37638, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 5a8ba81a-2e71-447e-85db-a3cc8b381485
2020-12-03 07:23:00,847 [IPC Server handler 0 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44290
2020-12-03 07:23:00,847 [IPC Server handler 0 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5a8ba81a-2e71-447e-85db-a3cc8b381485 (127.0.0.1:44290).
2020-12-03 07:23:00,848 [IPC Server handler 1 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43040, datanodeUuid=997a129e-2f17-458f-b3b4-dafca2c4c514, infoPort=33890, infoSecurePort=0, ipcPort=40753, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 997a129e-2f17-458f-b3b4-dafca2c4c514
2020-12-03 07:23:00,848 [IPC Server handler 1 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43040
2020-12-03 07:23:00,848 [IPC Server handler 1 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 997a129e-2f17-458f-b3b4-dafca2c4c514 (127.0.0.1:43040).
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5ae5eec0-b290-4696-9a42-85746dd47998) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5354e553-b153-41a9-aa27-5e80ce459dfe) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5a8ba81a-2e71-447e-85db-a3cc8b381485) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,859 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,852 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 997a129e-2f17-458f-b3b4-dafca2c4c514) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:00,862 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:00,885 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6c70f687-3aeb-4abe-8750-5375a27f0c1c
2020-12-03 07:23:00,888 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d
2020-12-03 07:23:00,889 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:23:00,891 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3f6f434c-6dad-4de2-8043-723f67cc82a0
2020-12-03 07:23:00,892 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:23:00,893 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,895 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:00,896 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:00,896 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:00,896 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:00,898 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,899 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:23:00,899 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:23:00,928 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a
2020-12-03 07:23:00,938 [IPC Server handler 7 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9 for DN 127.0.0.1:37921
2020-12-03 07:23:00,950 [IPC Server handler 7 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0 for DN 127.0.0.1:37921
2020-12-03 07:23:00,953 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5b53edda-0737-4df7-b184-e012a6ef225f
2020-12-03 07:23:00,954 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:23:00,953 [IPC Server handler 4 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab for DN 127.0.0.1:34004
2020-12-03 07:23:00,958 [IPC Server handler 4 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e4dde564-dfa3-40d7-b46c-61762e2fb668 for DN 127.0.0.1:34004
2020-12-03 07:23:00,959 [IPC Server handler 6 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-70288939-373e-45bd-99f3-27f73324f03c for DN 127.0.0.1:44290
2020-12-03 07:23:00,959 [IPC Server handler 6 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f for DN 127.0.0.1:44290
2020-12-03 07:23:00,959 [IPC Server handler 2 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288 for DN 127.0.0.1:43040
2020-12-03 07:23:00,960 [IPC Server handler 2 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-41992268-fb7b-4b13-a3ac-ac889aadb055 for DN 127.0.0.1:43040
2020-12-03 07:23:00,961 [IPC Server handler 5 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7f4901c-286b-4846-87d8-5cd11f80cf33 for DN 127.0.0.1:35085
2020-12-03 07:23:00,961 [IPC Server handler 5 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2 for DN 127.0.0.1:35085
2020-12-03 07:23:00,962 [IPC Server handler 9 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d for DN 127.0.0.1:34890
2020-12-03 07:23:00,962 [IPC Server handler 9 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8 for DN 127.0.0.1:34890
2020-12-03 07:23:00,963 [IPC Server handler 8 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e1c9468d-d607-49e1-bf56-528d08a12f43 for DN 127.0.0.1:38310
2020-12-03 07:23:00,963 [IPC Server handler 8 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e for DN 127.0.0.1:38310
2020-12-03 07:23:00,963 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84
2020-12-03 07:23:00,965 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:23:00,966 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:00,967 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 69ms
2020-12-03 07:23:00,968 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:00,969 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:00,969 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:00,969 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:00,971 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,971 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:23:00,971 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:23:00,973 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 73ms
2020-12-03 07:23:00,973 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 74ms
2020-12-03 07:23:00,973 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:23:00,973 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:23:00,973 [Thread-336] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,974 [Thread-337] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:00,974 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:23:00,981 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 7ms
2020-12-03 07:23:00,982 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 9ms
2020-12-03 07:23:00,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:23:00,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:23:00,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-3f6f434c-6dad-4de2-8043-723f67cc82a0): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:00,993 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-3f6f434c-6dad-4de2-8043-723f67cc82a0): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:00,993 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:00,998 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:25 AM with interval of 21600000ms
2020-12-03 07:23:01,003 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 6c70f687-3aeb-4abe-8750-5375a27f0c1c) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:01,013 [IPC Server handler 3 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35023, datanodeUuid=6c70f687-3aeb-4abe-8750-5375a27f0c1c, infoPort=40485, infoSecurePort=0, ipcPort=42203, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 6c70f687-3aeb-4abe-8750-5375a27f0c1c
2020-12-03 07:23:01,013 [IPC Server handler 3 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35023
2020-12-03 07:23:01,013 [IPC Server handler 3 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6c70f687-3aeb-4abe-8750-5375a27f0c1c (127.0.0.1:35023).
2020-12-03 07:23:01,014 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 6c70f687-3aeb-4abe-8750-5375a27f0c1c) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:01,015 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:01,025 [IPC Server handler 0 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d for DN 127.0.0.1:35023
2020-12-03 07:23:01,025 [IPC Server handler 0 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3f6f434c-6dad-4de2-8043-723f67cc82a0 for DN 127.0.0.1:35023
2020-12-03 07:23:01,045 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 74ms
2020-12-03 07:23:01,050 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1236643807-172.17.0.4-1606980174365 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 79ms
2020-12-03 07:23:01,057 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1236643807-172.17.0.4-1606980174365: 86ms
2020-12-03 07:23:01,058 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:23:01,058 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:23:01,058 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:01,058 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1236643807-172.17.0.4-1606980174365/current/replicas doesn't exist 
2020-12-03 07:23:01,059 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:23:01,065 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 7ms
2020-12-03 07:23:01,065 [IPC Server handler 2 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44290, datanodeUuid=5a8ba81a-2e71-447e-85db-a3cc8b381485, infoPort=43836, infoSecurePort=0, ipcPort=37638, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,075 [IPC Server handler 6 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43040, datanodeUuid=997a129e-2f17-458f-b3b4-dafca2c4c514, infoPort=33890, infoSecurePort=0, ipcPort=40753, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,065 [IPC Server handler 5 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35085, datanodeUuid=467b8ef8-63a3-4223-aa82-6d73332dda4f, infoPort=33843, infoSecurePort=0, ipcPort=39560, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,065 [IPC Server handler 9 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=5354e553-b153-41a9-aa27-5e80ce459dfe, infoPort=37876, infoSecurePort=0, ipcPort=34268, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,080 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x91051078931f33a2: Processing first storage report for DS-70288939-373e-45bd-99f3-27f73324f03c from datanode 5a8ba81a-2e71-447e-85db-a3cc8b381485
2020-12-03 07:23:01,072 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34890, datanodeUuid=04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3, infoPort=33696, infoSecurePort=0, ipcPort=39666, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,072 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37921, datanodeUuid=5ae5eec0-b290-4696-9a42-85746dd47998, infoPort=46507, infoSecurePort=0, ipcPort=43477, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,065 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1236643807-172.17.0.4-1606980174365: 9ms
2020-12-03 07:23:01,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:23:01,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1236643807-172.17.0.4-1606980174365 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:23:01,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,082 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-5b53edda-0737-4df7-b184-e012a6ef225f): finished scanning block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,082 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:40 AM with interval of 21600000ms
2020-12-03 07:23:01,082 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:01,083 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a) service to localhost/127.0.0.1:46121 beginning handshake with NN
2020-12-03 07:23:01,084 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-5b53edda-0737-4df7-b184-e012a6ef225f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:01,084 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x91051078931f33a2: from storage DS-70288939-373e-45bd-99f3-27f73324f03c node DatanodeRegistration(127.0.0.1:44290, datanodeUuid=5a8ba81a-2e71-447e-85db-a3cc8b381485, infoPort=43836, infoSecurePort=0, ipcPort=37638, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,084 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x26feb1331d491011: Processing first storage report for DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2 from datanode 467b8ef8-63a3-4223-aa82-6d73332dda4f
2020-12-03 07:23:01,085 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x26feb1331d491011: from storage DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2 node DatanodeRegistration(127.0.0.1:35085, datanodeUuid=467b8ef8-63a3-4223-aa82-6d73332dda4f, infoPort=33843, infoSecurePort=0, ipcPort=39560, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x22df18a215bb302e: Processing first storage report for DS-e4dde564-dfa3-40d7-b46c-61762e2fb668 from datanode 5354e553-b153-41a9-aa27-5e80ce459dfe
2020-12-03 07:23:01,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x22df18a215bb302e: from storage DS-e4dde564-dfa3-40d7-b46c-61762e2fb668 node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=5354e553-b153-41a9-aa27-5e80ce459dfe, infoPort=37876, infoSecurePort=0, ipcPort=34268, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x811c1fac5439dfd3: Processing first storage report for DS-41992268-fb7b-4b13-a3ac-ac889aadb055 from datanode 997a129e-2f17-458f-b3b4-dafca2c4c514
2020-12-03 07:23:01,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x811c1fac5439dfd3: from storage DS-41992268-fb7b-4b13-a3ac-ac889aadb055 node DatanodeRegistration(127.0.0.1:43040, datanodeUuid=997a129e-2f17-458f-b3b4-dafca2c4c514, infoPort=33890, infoSecurePort=0, ipcPort=40753, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3bd672ce9207f266: Processing first storage report for DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d from datanode 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3
2020-12-03 07:23:01,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3bd672ce9207f266: from storage DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d node DatanodeRegistration(127.0.0.1:34890, datanodeUuid=04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3, infoPort=33696, infoSecurePort=0, ipcPort=39666, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfa11d8af0558a462: Processing first storage report for DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0 from datanode 5ae5eec0-b290-4696-9a42-85746dd47998
2020-12-03 07:23:01,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfa11d8af0558a462: from storage DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0 node DatanodeRegistration(127.0.0.1:37921, datanodeUuid=5ae5eec0-b290-4696-9a42-85746dd47998, infoPort=46507, infoSecurePort=0, ipcPort=43477, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x91051078931f33a2: Processing first storage report for DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f from datanode 5a8ba81a-2e71-447e-85db-a3cc8b381485
2020-12-03 07:23:01,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x91051078931f33a2: from storage DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f node DatanodeRegistration(127.0.0.1:44290, datanodeUuid=5a8ba81a-2e71-447e-85db-a3cc8b381485, infoPort=43836, infoSecurePort=0, ipcPort=37638, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x26feb1331d491011: Processing first storage report for DS-c7f4901c-286b-4846-87d8-5cd11f80cf33 from datanode 467b8ef8-63a3-4223-aa82-6d73332dda4f
2020-12-03 07:23:01,088 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x26feb1331d491011: from storage DS-c7f4901c-286b-4846-87d8-5cd11f80cf33 node DatanodeRegistration(127.0.0.1:35085, datanodeUuid=467b8ef8-63a3-4223-aa82-6d73332dda4f, infoPort=33843, infoSecurePort=0, ipcPort=39560, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,088 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x22df18a215bb302e: Processing first storage report for DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab from datanode 5354e553-b153-41a9-aa27-5e80ce459dfe
2020-12-03 07:23:01,088 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x22df18a215bb302e: from storage DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab node DatanodeRegistration(127.0.0.1:34004, datanodeUuid=5354e553-b153-41a9-aa27-5e80ce459dfe, infoPort=37876, infoSecurePort=0, ipcPort=34268, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,088 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x811c1fac5439dfd3: Processing first storage report for DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288 from datanode 997a129e-2f17-458f-b3b4-dafca2c4c514
2020-12-03 07:23:01,088 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x811c1fac5439dfd3: from storage DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288 node DatanodeRegistration(127.0.0.1:43040, datanodeUuid=997a129e-2f17-458f-b3b4-dafca2c4c514, infoPort=33890, infoSecurePort=0, ipcPort=40753, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,089 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3bd672ce9207f266: Processing first storage report for DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8 from datanode 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3
2020-12-03 07:23:01,089 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3bd672ce9207f266: from storage DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8 node DatanodeRegistration(127.0.0.1:34890, datanodeUuid=04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3, infoPort=33696, infoSecurePort=0, ipcPort=39666, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,089 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfa11d8af0558a462: Processing first storage report for DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9 from datanode 5ae5eec0-b290-4696-9a42-85746dd47998
2020-12-03 07:23:01,089 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfa11d8af0558a462: from storage DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9 node DatanodeRegistration(127.0.0.1:37921, datanodeUuid=5ae5eec0-b290-4696-9a42-85746dd47998, infoPort=46507, infoSecurePort=0, ipcPort=43477, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,089 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39214, datanodeUuid=9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a, infoPort=44299, infoSecurePort=0, ipcPort=43884, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) storage 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a
2020-12-03 07:23:01,090 [IPC Server handler 7 on default port 46121] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39214
2020-12-03 07:23:01,090 [IPC Server handler 7 on default port 46121] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a (127.0.0.1:39214).
2020-12-03 07:23:01,090 [IPC Server handler 2 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x91051078931f33a2
2020-12-03 07:23:01,091 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a) service to localhost/127.0.0.1:46121 successfully registered with NN
2020-12-03 07:23:01,091 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46121 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:01,091 [IPC Server handler 5 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x26feb1331d491011
2020-12-03 07:23:01,092 [IPC Server handler 9 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x22df18a215bb302e
2020-12-03 07:23:01,093 [IPC Server handler 6 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x811c1fac5439dfd3
2020-12-03 07:23:01,094 [IPC Server handler 4 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x3bd672ce9207f266
2020-12-03 07:23:01,094 [IPC Server handler 8 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xfa11d8af0558a462
2020-12-03 07:23:01,103 [IPC Server handler 3 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5b53edda-0737-4df7-b184-e012a6ef225f for DN 127.0.0.1:39214
2020-12-03 07:23:01,104 [IPC Server handler 3 on default port 46121] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84 for DN 127.0.0.1:39214
2020-12-03 07:23:01,118 [IPC Server handler 0 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39214, datanodeUuid=9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a, infoPort=44299, infoSecurePort=0, ipcPort=43884, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:01,118 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x86a28e6d9d81198: Processing first storage report for DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84 from datanode 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a
2020-12-03 07:23:01,118 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x86a28e6d9d81198: from storage DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84 node DatanodeRegistration(127.0.0.1:39214, datanodeUuid=9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a, infoPort=44299, infoSecurePort=0, ipcPort=43884, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,119 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x86a28e6d9d81198: Processing first storage report for DS-5b53edda-0737-4df7-b184-e012a6ef225f from datanode 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a
2020-12-03 07:23:01,119 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x86a28e6d9d81198: from storage DS-5b53edda-0737-4df7-b184-e012a6ef225f node DatanodeRegistration(127.0.0.1:39214, datanodeUuid=9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a, infoPort=44299, infoSecurePort=0, ipcPort=43884, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:01,119 [IPC Server handler 0 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x86a28e6d9d81198
2020-12-03 07:23:01,130 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x91051078931f33a2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 14 msec to generate and 117 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,130 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,131 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x22df18a215bb302e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 14 msec to generate and 112 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,131 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,131 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfa11d8af0558a462,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 17 msec to generate and 111 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,131 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,132 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x26feb1331d491011,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 26 msec to generate and 112 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,132 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,138 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x811c1fac5439dfd3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 26 msec to generate and 125 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,138 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,140 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3bd672ce9207f266,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 26 msec to generate and 127 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,140 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x86a28e6d9d81198,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 29 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:01,140 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,140 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:01,183 [IPC Server handler 1 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,203 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:01,232 [IPC Server handler 7 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,295 [IPC Server handler 3 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:01,320 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(200)) - testReadWithBlockCorrupted: file = /corrupted_2_1, dataBlkDelNum = 2, parityBlkDelNum = 1, deleteBlockFile? false
2020-12-03 07:23:01,547 [IPC Server handler 8 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,569 [IPC Server handler 5 on default port 46121] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(774)) - *DIR* NameNode.create: file /corrupted_2_1 for DFSClient_NONMAPREDUCE_-519250595_1 at 127.0.0.1
2020-12-03 07:23:01,570 [IPC Server handler 5 on default port 46121] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2460)) - DIR* NameSystem.startFile: src=/corrupted_2_1, holder=DFSClient_NONMAPREDUCE_-519250595_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-12-03 07:23:01,586 [IPC Server handler 5 on default port 46121] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(579)) - DIR* addFile: corrupted_2_1 is added
2020-12-03 07:23:01,589 [IPC Server handler 5 on default port 46121] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(415)) - DIR* NameSystem.startFile: added /corrupted_2_1 inode 16386 DFSClient_NONMAPREDUCE_-519250595_1
2020-12-03 07:23:01,602 [IPC Server handler 5 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_2_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:01,707 [IPC Server handler 9 on default port 46121] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2767)) - BLOCK* getAdditionalBlock: /corrupted_2_1  inodeId 16386 for DFSClient_NONMAPREDUCE_-519250595_1
2020-12-03 07:23:01,722 [IPC Server handler 9 on default port 46121] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(524)) - DIR* FSDirectory.addBlock: /corrupted_2_1 with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-12-03 07:23:01,723 [IPC Server handler 9 on default port 46121] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:37921, 127.0.0.1:38310, 127.0.0.1:34890, 127.0.0.1:43040, 127.0.0.1:35085, 127.0.0.1:39214, 127.0.0.1:44290, 127.0.0.1:34004, 127.0.0.1:35023 for /corrupted_2_1
2020-12-03 07:23:01,725 [IPC Server handler 9 on default port 46121] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(758)) - persistNewBlock: /corrupted_2_1 with new block blk_-9223372036854775792_1001, current total block count is 1
2020-12-03 07:23:01,766 [Thread-352] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,803 [Thread-353] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,843 [Thread-354] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,844 [Thread-355] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,844 [Thread-357] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,895 [Thread-356] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,003 [Thread-358] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,019 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:40260 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775788_1001 src: /127.0.0.1:40260 dest: /127.0.0.1:35085
2020-12-03 07:23:02,030 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:39474 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 src: /127.0.0.1:39474 dest: /127.0.0.1:38310
2020-12-03 07:23:02,076 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:47230 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 src: /127.0.0.1:47230 dest: /127.0.0.1:39214
2020-12-03 07:23:02,076 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:33692 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775790_1001 src: /127.0.0.1:33692 dest: /127.0.0.1:34890
2020-12-03 07:23:02,076 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:41240 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775789_1001 src: /127.0.0.1:41240 dest: /127.0.0.1:43040
2020-12-03 07:23:02,085 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:34412 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775792_1001 src: /127.0.0.1:34412 dest: /127.0.0.1:37921
2020-12-03 07:23:02,087 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,100 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:36800 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775786_1001 src: /127.0.0.1:36800 dest: /127.0.0.1:44290
2020-12-03 07:23:02,101 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:42396 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 src: /127.0.0.1:42396 dest: /127.0.0.1:34004
2020-12-03 07:23:02,224 [Thread-360] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,226 [DataXceiver for client DFSClient_NONMAPREDUCE_-519250595_1 at /127.0.0.1:42966 [Receiving block BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775784_1001 src: /127.0.0.1:42966 dest: /127.0.0.1:35023
2020-12-03 07:23:02,554 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34412, dest: /127.0.0.1:37921, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 5ae5eec0-b290-4696-9a42-85746dd47998, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775792_1001, duration(ns): 446809236
2020-12-03 07:23:02,554 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,562 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39474, dest: /127.0.0.1:38310, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001, duration(ns): 464422648
2020-12-03 07:23:02,563 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,572 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33692, dest: /127.0.0.1:34890, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775790_1001, duration(ns): 476600635
2020-12-03 07:23:02,572 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,578 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41240, dest: /127.0.0.1:43040, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 997a129e-2f17-458f-b3b4-dafca2c4c514, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775789_1001, duration(ns): 481494924
2020-12-03 07:23:02,578 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,592 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40260, dest: /127.0.0.1:35085, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 467b8ef8-63a3-4223-aa82-6d73332dda4f, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775788_1001, duration(ns): 483059936
2020-12-03 07:23:02,592 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,594 [IPC Server handler 9 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38310, datanodeUuid=45dc658f-8c5b-4c7b-ba4e-092b430b5f8a, infoPort=42906, infoSecurePort=0, ipcPort=37799, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,594 [IPC Server handler 2 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43040, datanodeUuid=997a129e-2f17-458f-b3b4-dafca2c4c514, infoPort=33890, infoSecurePort=0, ipcPort=40753, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,594 [IPC Server handler 6 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35085, datanodeUuid=467b8ef8-63a3-4223-aa82-6d73332dda4f, infoPort=33843, infoSecurePort=0, ipcPort=39560, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,607 [IPC Server handler 5 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34890, datanodeUuid=04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3, infoPort=33696, infoSecurePort=0, ipcPort=39666, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,615 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47230, dest: /127.0.0.1:39214, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001, duration(ns): 512771813
2020-12-03 07:23:02,615 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,617 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37921, datanodeUuid=5ae5eec0-b290-4696-9a42-85746dd47998, infoPort=46507, infoSecurePort=0, ipcPort=43477, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,617 [IPC Server handler 0 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39214, datanodeUuid=9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a, infoPort=44299, infoSecurePort=0, ipcPort=43884, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,621 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:43040 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,622 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,622 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36800, dest: /127.0.0.1:44290, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 5a8ba81a-2e71-447e-85db-a3cc8b381485, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775786_1001, duration(ns): 460379881
2020-12-03 07:23:02,623 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,625 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44290, datanodeUuid=5a8ba81a-2e71-447e-85db-a3cc8b381485, infoPort=43836, infoSecurePort=0, ipcPort=37638, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,625 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:43040 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,627 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42396, dest: /127.0.0.1:34004, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 5354e553-b153-41a9-aa27-5e80ce459dfe, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001, duration(ns): 508758793
2020-12-03 07:23:02,627 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,628 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34004, datanodeUuid=5354e553-b153-41a9-aa27-5e80ce459dfe, infoPort=37876, infoSecurePort=0, ipcPort=34268, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,633 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:43040
2020-12-03 07:23:02,634 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43040 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,634 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:38310 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,634 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,634 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:38310 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,634 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:38310
2020-12-03 07:23:02,634 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38310 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,634 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:35085 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,635 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,635 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35085 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,636 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:35085
2020-12-03 07:23:02,636 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35085 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,636 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:34890 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,636 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42966, dest: /127.0.0.1:35023, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-519250595_1, offset: 0, srvID: 6c70f687-3aeb-4abe-8750-5375a27f0c1c, blockid: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775784_1001, duration(ns): 406672912
2020-12-03 07:23:02,636 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,636 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:34890 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,636 [PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:02,636 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:34890
2020-12-03 07:23:02,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34890 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,637 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:37921 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,637 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:37921 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:37921
2020-12-03 07:23:02,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37921 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,637 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35023, datanodeUuid=6c70f687-3aeb-4abe-8750-5375a27f0c1c, infoPort=40485, infoSecurePort=0, ipcPort=42203, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365) 1 blocks.
2020-12-03 07:23:02,637 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:39214 size 4194181 replicaState = FINALIZED
2020-12-03 07:23:02,637 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:39214 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:39214
2020-12-03 07:23:02,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39214 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,638 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:44290 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,638 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:44290 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:44290
2020-12-03 07:23:02,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44290 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,638 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:34004 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,638 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:34004 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,639 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:34004
2020-12-03 07:23:02,639 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34004 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,639 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:35023 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,639 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:02,639 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35023 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:02,639 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:35023
2020-12-03 07:23:02,639 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35023 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:02,642 [IPC Server handler 8 on default port 46121] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /corrupted_2_1 for DFSClient_NONMAPREDUCE_-519250595_1
2020-12-03 07:23:02,647 [IPC Server handler 8 on default port 46121] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /corrupted_2_1 with 1 blocks is persisted to the file system
2020-12-03 07:23:02,650 [IPC Server handler 8 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /corrupted_2_1 is closed by DFSClient_NONMAPREDUCE_-519250595_1
2020-12-03 07:23:02,654 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(228)) - corruptBlocks on path /corrupted_2_1
2020-12-03 07:23:02,669 [IPC Server handler 2 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:02,671 [IPC Server handler 2 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,686 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(259)) - Corrupting block file BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
2020-12-03 07:23:02,692 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,694 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,695 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,695 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,696 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,697 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,699 [Thread-351] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1236643807-172.17.0.4-1606980174365/current/finalized/subdir0/subdir0/blk_-9223372036854775791
2020-12-03 07:23:02,699 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,700 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,700 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(259)) - Corrupting block file BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
2020-12-03 07:23:02,700 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,701 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,702 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,702 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,703 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,704 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,705 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,705 [Thread-351] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1236643807-172.17.0.4-1606980174365/current/finalized/subdir0/subdir0/blk_-9223372036854775787
2020-12-03 07:23:02,706 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,706 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(259)) - Corrupting block file BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
2020-12-03 07:23:02,707 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,707 [Thread-351] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1236643807-172.17.0.4-1606980174365/current/finalized/subdir0/subdir0/blk_-9223372036854775785
2020-12-03 07:23:02,708 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,708 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,709 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,713 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,714 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,715 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,715 [Thread-351] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:02,715 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(134)) - verifyRead on path /corrupted_2_1
2020-12-03 07:23:02,722 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(136)) - verifyRead verifyLength on path /corrupted_2_1
2020-12-03 07:23:02,725 [IPC Server handler 6 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,726 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(138)) - verifyRead verifyPread on path /corrupted_2_1
2020-12-03 07:23:02,731 [IPC Server handler 9 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,737 [IPC Server handler 5 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:02,738 [IPC Server handler 5 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,782 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,815 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,819 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:02,820 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,831 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,841 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,849 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,880 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:02,928 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:23:02,950 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,957 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:02,959 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:02,961 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:03,031 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:03,032 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775792_1001 added as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:03,033 [IPC Server handler 4 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-12-03 07:23:03,033 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:23:03,034 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:03,034 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775792_1001 added as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:03,034 [IPC Server handler 4 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:03,034 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:23:03,035 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:03,035 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:03,035 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775792_1001 added as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:03,035 [IPC Server handler 4 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:03,036 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:03,036 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:03,905 [IPC Server handler 6 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38310, datanodeUuid=45dc658f-8c5b-4c7b-ba4e-092b430b5f8a, infoPort=42906, infoSecurePort=0, ipcPort=37799, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:03,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2652ac1ac6803346: Processing first storage report for DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e from datanode 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a
2020-12-03 07:23:03,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2652ac1ac6803346: from storage DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e node DatanodeRegistration(127.0.0.1:38310, datanodeUuid=45dc658f-8c5b-4c7b-ba4e-092b430b5f8a, infoPort=42906, infoSecurePort=0, ipcPort=37799, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,906 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2652ac1ac6803346: Processing first storage report for DS-e1c9468d-d607-49e1-bf56-528d08a12f43 from datanode 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a
2020-12-03 07:23:03,906 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775791 on 127.0.0.1:38310 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:03,906 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:38310 size 25165701
2020-12-03 07:23:03,906 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 6 oldExpectedReplicas  9 curPri  0 oldPri  0
2020-12-03 07:23:03,906 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:03,907 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:03,907 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2652ac1ac6803346: from storage DS-e1c9468d-d607-49e1-bf56-528d08a12f43 node DatanodeRegistration(127.0.0.1:38310, datanodeUuid=45dc658f-8c5b-4c7b-ba4e-092b430b5f8a, infoPort=42906, infoSecurePort=0, ipcPort=37799, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,907 [IPC Server handler 6 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2652ac1ac6803346
2020-12-03 07:23:03,908 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2652ac1ac6803346,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 11 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:03,908 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:04,109 [IPC Server handler 0 on default port 46121] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35023, datanodeUuid=6c70f687-3aeb-4abe-8750-5375a27f0c1c, infoPort=40485, infoSecurePort=0, ipcPort=42203, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), reports.length=2
2020-12-03 07:23:04,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x311eca7b039bdfee: Processing first storage report for DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d from datanode 6c70f687-3aeb-4abe-8750-5375a27f0c1c
2020-12-03 07:23:04,110 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775784 on 127.0.0.1:35023 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:04,110 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:35023 size 25165701
2020-12-03 07:23:04,111 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 6 oldExpectedReplicas  9 curPri  0 oldPri  0
2020-12-03 07:23:04,111 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:04,111 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:04,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x311eca7b039bdfee: from storage DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d node DatanodeRegistration(127.0.0.1:35023, datanodeUuid=6c70f687-3aeb-4abe-8750-5375a27f0c1c, infoPort=40485, infoSecurePort=0, ipcPort=42203, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:04,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x311eca7b039bdfee: Processing first storage report for DS-3f6f434c-6dad-4de2-8043-723f67cc82a0 from datanode 6c70f687-3aeb-4abe-8750-5375a27f0c1c
2020-12-03 07:23:04,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x311eca7b039bdfee: from storage DS-3f6f434c-6dad-4de2-8043-723f67cc82a0 node DatanodeRegistration(127.0.0.1:35023, datanodeUuid=6c70f687-3aeb-4abe-8750-5375a27f0c1c, infoPort=40485, infoSecurePort=0, ipcPort=42203, storageInfo=lv=-57;cid=testClusterID;nsid=1454577274;c=1606980174365), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:04,112 [IPC Server handler 0 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x311eca7b039bdfee
2020-12-03 07:23:04,113 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x311eca7b039bdfee,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:04,113 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:05,930 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:05,931 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:05,986 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:05,994 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:06,008 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:06,011 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:06,019 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:06,056 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:06,058 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:06,126 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:06,127 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:06,127 [IPC Server handler 4 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:06,127 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:06,128 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:06,128 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:06,128 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:06,128 [IPC Server handler 4 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:06,128 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:06,128 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:06,129 [IPC Server handler 4 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:06,129 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:06,129 [IPC Server handler 4 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:06,129 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:06,129 [IPC Server handler 4 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:08,879 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:08,885 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:08,895 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:08,913 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:08,934 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:08,934 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:08,934 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:08,939 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:09,009 [IPC Server handler 3 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:09,009 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:09,010 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:09,011 [IPC Server handler 3 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:09,011 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:09,011 [IPC Server handler 3 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:09,011 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:09,011 [IPC Server handler 3 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:11,937 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:11,937 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:11,961 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,965 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:11,970 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,977 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:11,984 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:11,987 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:12,058 [IPC Server handler 1 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:12,058 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:12,059 [IPC Server handler 1 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:12,059 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:12,059 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:12,059 [IPC Server handler 1 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:12,059 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:12,060 [IPC Server handler 1 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:12,060 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:12,060 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:12,060 [IPC Server handler 1 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:12,060 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:12,060 [IPC Server handler 1 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:12,061 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:12,061 [IPC Server handler 1 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:14,938 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:14,938 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:15,676 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,683 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,690 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,692 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,694 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:15,697 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,699 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,701 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:15,702 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,707 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,710 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:15,712 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:15,781 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:15,781 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:15,782 [IPC Server handler 7 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:15,782 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:15,782 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:15,782 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:15,783 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:15,783 [IPC Server handler 7 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:15,783 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:15,783 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:15,783 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:15,783 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:15,784 [IPC Server handler 7 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:15,784 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:15,784 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:17,939 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:17,939 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:18,403 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:18,408 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:18,411 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:18,414 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:18,426 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:18,428 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:18,476 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:18,477 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:18,477 [IPC Server handler 7 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:18,477 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:18,477 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:18,477 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:18,477 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:18,478 [IPC Server handler 7 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:20,921 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:20,927 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 from DatanodeInfoWithStorage[127.0.0.1:39214,DS-5b53edda-0737-4df7-b184-e012a6ef225f,DISK] at 0
2020-12-03 07:23:20,929 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:20,931 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:38310,DS-e1c9468d-d607-49e1-bf56-528d08a12f43,DISK] at 0
2020-12-03 07:23:20,940 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:20,941 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:20,942 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:20,943 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 from DatanodeInfoWithStorage[127.0.0.1:34004,DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab,DISK] at 0
2020-12-03 07:23:21,002 [IPC Server handler 8 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775787_1001 on datanode: 127.0.0.1:39214
2020-12-03 07:23:21,003 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:39214 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:21,003 [IPC Server handler 8 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:21,003 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:21,003 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:21,003 [IPC Server handler 8 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775785_1001 on datanode: 127.0.0.1:34004
2020-12-03 07:23:21,004 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34004 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:21,004 [IPC Server handler 8 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:21,004 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:21,004 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:21,004 [IPC Server handler 8 on default port 46121] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-1236643807-172.17.0.4-1606980174365:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:38310
2020-12-03 07:23:21,004 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:38310 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:21,005 [IPC Server handler 8 on default port 46121] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-12-03 07:23:21,005 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 0
2020-12-03 07:23:21,005 [IPC Server handler 8 on default port 46121] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-12-03 07:23:23,123 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:23,129 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:23,941 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:23,941 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:24,958 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(140)) - verifyRead verifyStatefulRead on path /corrupted_2_1
2020-12-03 07:23:24,960 [IPC Server handler 8 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:24,961 [IPC Server handler 8 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,980 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:24,982 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:26,942 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:26,942 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:29,676 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead2 on path /corrupted_2_1
2020-12-03 07:23:29,684 [IPC Server handler 0 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:29,685 [IPC Server handler 0 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:29,730 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:29,732 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:29,734 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:29,736 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:29,743 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:29,745 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:29,943 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:29,943 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:32,944 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:32,944 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:34,531 [Thread-351] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifySeek on path /corrupted_2_1
2020-12-03 07:23:34,534 [IPC Server handler 9 on default port 46121] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:34,535 [IPC Server handler 9 on default port 46121] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,547 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,550 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,553 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,556 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,558 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,560 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,945 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:35,945 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:38,962 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:38,963 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:41,343 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:41,345 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:23:41,346 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,346 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@75201592] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,348 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-3f6f434c-6dad-4de2-8043-723f67cc82a0) exiting.
2020-12-03 07:23:41,348 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-60cd8075-8259-49cc-b9ea-eaacc7f3ff1d) exiting.
2020-12-03 07:23:41,376 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1af1347d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,382 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,383 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1af05b03{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,383 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d4ab71a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,386 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42203
2020-12-03 07:23:41,394 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,396 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,396 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 6c70f687-3aeb-4abe-8750-5375a27f0c1c) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,397 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 6c70f687-3aeb-4abe-8750-5375a27f0c1c)
2020-12-03 07:23:41,397 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,398 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,399 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,409 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,409 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,410 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,410 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,418 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,418 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:23:41,419 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,419 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@e362c57] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-5b53edda-0737-4df7-b184-e012a6ef225f) exiting.
2020-12-03 07:23:41,420 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-39e9a2a3-6aed-4635-b52c-6b6156b84d84) exiting.
2020-12-03 07:23:41,458 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6ac4944a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,458 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a772895{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,459 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62577d6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,459 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1556f2dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,460 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43884
2020-12-03 07:23:41,467 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,471 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,482 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,483 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,483 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 9d5a7d1b-bc62-44d6-abe1-bece7a8bd99a)
2020-12-03 07:23:41,483 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,484 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,488 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,493 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,494 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,495 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,496 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,498 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,499 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:23:41,499 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,499 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1968a49c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,501 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e1c9468d-d607-49e1-bf56-528d08a12f43) exiting.
2020-12-03 07:23:41,501 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-b5db70d9-df9a-46fb-8805-3e4f2af1b25e) exiting.
2020-12-03 07:23:41,524 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4d4d48a6{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,525 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@315df4bb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,526 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41de5768{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,526 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b739528{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,527 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37799
2020-12-03 07:23:41,530 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,534 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,536 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,536 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 45dc658f-8c5b-4c7b-ba4e-092b430b5f8a)
2020-12-03 07:23:41,536 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,537 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,537 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,544 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,545 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,546 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,546 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,549 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,550 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:23:41,550 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,550 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7bd69e82] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,552 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-70288939-373e-45bd-99f3-27f73324f03c) exiting.
2020-12-03 07:23:41,552 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2665d0f8-ddc1-482d-b5d2-1afa295e314f) exiting.
2020-12-03 07:23:41,594 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3301500b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,597 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24b52d3e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,598 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a2f016d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,598 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cbf9e9f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,602 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37638
2020-12-03 07:23:41,631 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,635 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,635 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,636 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5a8ba81a-2e71-447e-85db-a3cc8b381485) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,636 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5a8ba81a-2e71-447e-85db-a3cc8b381485)
2020-12-03 07:23:41,636 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,637 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,637 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,677 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,678 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,681 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,681 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,688 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,689 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:23:41,689 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,689 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2a2bb0eb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,692 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3ff62906-d7fd-4bde-b518-f6ee785ab6a0) exiting.
2020-12-03 07:23:41,692 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-7b2b6d79-d6e4-4d00-b066-44d36eac83d9) exiting.
2020-12-03 07:23:41,723 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@475b7792{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,729 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@751e664e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,730 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c444798{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,730 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cfd1875{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,732 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43477
2020-12-03 07:23:41,743 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,743 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,746 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,746 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5ae5eec0-b290-4696-9a42-85746dd47998) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,746 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5ae5eec0-b290-4696-9a42-85746dd47998)
2020-12-03 07:23:41,746 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,748 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,748 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,756 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,756 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,758 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,759 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,763 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,763 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:41,763 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,764 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@f5c79a6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,767 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-6f988fd0-a53e-47e3-b630-2f7fb9a12ab2) exiting.
2020-12-03 07:23:41,767 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c7f4901c-286b-4846-87d8-5cd11f80cf33) exiting.
2020-12-03 07:23:41,791 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@581d969c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,792 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22db8f4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,792 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d9d1b69{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,793 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66d23e4a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,794 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39560
2020-12-03 07:23:41,803 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,804 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,806 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 467b8ef8-63a3-4223-aa82-6d73332dda4f) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,806 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 467b8ef8-63a3-4223-aa82-6d73332dda4f)
2020-12-03 07:23:41,806 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,806 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,807 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,807 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,814 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,815 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,817 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,817 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,822 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,822 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:41,822 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,822 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c25b8a7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,825 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-41992268-fb7b-4b13-a3ac-ac889aadb055) exiting.
2020-12-03 07:23:41,826 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-822e2a85-6896-4fdb-9ea8-fcf9039ab288) exiting.
2020-12-03 07:23:41,848 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3d4d3fe7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,849 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,849 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,850 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,851 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40753
2020-12-03 07:23:41,859 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,860 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,860 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,863 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 997a129e-2f17-458f-b3b4-dafca2c4c514) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,863 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 997a129e-2f17-458f-b3b4-dafca2c4c514)
2020-12-03 07:23:41,863 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,868 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,873 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,877 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,877 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,881 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,881 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,889 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,890 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:41,891 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,891 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4fbdc0f0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9f41f50f-11fb-4957-be29-3fdbdd7b0bab) exiting.
2020-12-03 07:23:41,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e4dde564-dfa3-40d7-b46c-61762e2fb668) exiting.
2020-12-03 07:23:41,926 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5af9926a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:41,927 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@43c67247{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:41,927 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70d2e40b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:41,928 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aec50a1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:41,929 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34268
2020-12-03 07:23:41,946 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:41,946 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:41,947 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5354e553-b153-41a9-aa27-5e80ce459dfe) service to localhost/127.0.0.1:46121
2020-12-03 07:23:41,947 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 5354e553-b153-41a9-aa27-5e80ce459dfe)
2020-12-03 07:23:41,947 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:41,948 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:41,948 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,963 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:41,967 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:41,971 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:41,972 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:41,972 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:41,976 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:41,976 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:41,985 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:41,986 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:41,986 [Listener at localhost/42203] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:41,986 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@659eef7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:41,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0719dcf2-8d7c-40f1-95b0-16ad1a51d8d8) exiting.
2020-12-03 07:23:41,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-325e8bbb-3c5b-43e5-aab3-6f9b4fe2366d) exiting.
2020-12-03 07:23:42,023 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@76ba13c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:42,024 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@eb6449b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:42,024 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@675d8c96{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:42,025 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e70ea3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:42,026 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39666
2020-12-03 07:23:42,042 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:42,043 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:42,047 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:42,048 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3) service to localhost/127.0.0.1:46121
2020-12-03 07:23:42,153 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1236643807-172.17.0.4-1606980174365 (Datanode Uuid 04aa2e2a-a0d5-42ce-9d57-f2ce59886ed3)
2020-12-03 07:23:42,153 [BP-1236643807-172.17.0.4-1606980174365 heartbeating to localhost/127.0.0.1:46121] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1236643807-172.17.0.4-1606980174365
2020-12-03 07:23:42,161 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:42,164 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1236643807-172.17.0.4-1606980174365] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:42,209 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:42,210 [Listener at localhost/42203] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:42,216 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:42,216 [Listener at localhost/42203] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:42,232 [Listener at localhost/42203] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:42,232 [Listener at localhost/42203] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:42,232 [Listener at localhost/42203] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:42,233 [Listener at localhost/42203] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:23:42,234 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@207ea13] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:42,235 [Listener at localhost/42203] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 3 2 
2020-12-03 07:23:42,235 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4bff1903] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:42,237 [Listener at localhost/42203] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:23:42,237 [Listener at localhost/42203] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:23:42,238 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:42,240 [CacheReplicationMonitor(1299708340)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:42,240 [Listener at localhost/42203] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46121
2020-12-03 07:23:42,248 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:42,249 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:42,254 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:42,254 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:42,260 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@a4b2d8f] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:42,301 [Listener at localhost/42203] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:42,302 [Listener at localhost/42203] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:42,304 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4dd6fd0a{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:42,305 [Listener at localhost/42203] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4bd31064{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:42,306 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb4f2a9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:42,306 [Listener at localhost/42203] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1807f5a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:42,308 [Listener at localhost/42203] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:42,337 [Listener at localhost/42203] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:42,338 [Listener at localhost/42203] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
