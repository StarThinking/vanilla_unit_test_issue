2020-12-03 07:19:28,269 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=11
Formatting using clusterid: testClusterID
2020-12-03 07:19:29,227 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:29,242 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:29,243 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:29,244 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:29,269 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:29,269 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:29,272 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:29,273 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:19:29,347 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:29,355 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:19:29,355 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:29,356 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:29,362 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:29,363 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:29
2020-12-03 07:19:29,366 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:29,367 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,371 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:19:29,371 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:29,393 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:29,393 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = true
2020-12-03 07:19:29,394 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(617)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-12-03 07:19:29,433 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:29,434 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:29,434 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:29,434 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:29,436 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:19:29,436 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:29,437 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:29,437 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:19:29,438 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:29,438 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:29,438 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:29,488 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:19:29,488 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:29,489 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:29,489 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:29,511 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:29,511 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:19:29,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:29,519 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:29,519 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:29,520 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:29,520 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:29,528 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:29,532 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:29,539 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:29,540 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:19:29,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:29,553 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:29,553 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:29,554 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:29,561 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:29,561 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:29,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:29,565 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:29,565 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:19:29,566 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:29,602 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:29,772 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:19:29,894 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:19:29,932 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:29,935 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:30,095 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:30,109 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:30,180 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:19:30,186 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:30,752 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:19:30,877 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:19:30,878 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:19:30,915 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:19:30,967 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bab3f1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:30,995 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:19:31,004 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:31,028 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3841ms
2020-12-03 07:19:31,194 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:31,199 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:31,199 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:31,211 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:31,215 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:31,215 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:31,215 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:31,251 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:31,252 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:31,268 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39620
2020-12-03 07:19:31,271 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:31,330 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b66c0fb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:31,338 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24c1b2d2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:31,404 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@62833051{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:31,420 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fc4780b{HTTP/1.1,[http/1.1]}{localhost:39620}
2020-12-03 07:19:31,421 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4234ms
2020-12-03 07:19:31,440 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:31,441 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:31,441 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:31,441 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:31,442 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:31,442 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:31,442 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:31,443 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:19:31,444 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:31,445 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:31,445 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:31,446 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:31,447 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:31
2020-12-03 07:19:31,447 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:31,447 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,448 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:31,448 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:31,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:31,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = true
2020-12-03 07:19:31,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(617)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-12-03 07:19:31,456 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:31,456 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:31,456 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:31,456 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:31,456 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:19:31,457 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:31,457 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:31,457 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:19:31,457 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:31,457 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:31,458 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:31,458 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:31,458 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,459 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:31,459 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:31,462 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:31,462 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:31,462 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:31,463 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:31,463 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:31,463 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:31,463 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:31,464 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,464 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:31,465 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:31,466 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:31,466 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:31,466 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:31,467 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:31,467 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:31,467 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:31,467 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:31,468 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:31,468 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:31,519 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:31,586 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:31,590 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:19:31,590 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:19:31,591 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:31,591 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:31,624 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:31,633 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:31,633 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:19:31,638 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:19:31,639 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:19:31,755 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:31,756 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 286 msecs
2020-12-03 07:19:31,975 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:19:32,020 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:32,034 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:32,493 [Listener at localhost/38468] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38468 to access this namenode/service.
2020-12-03 07:19:32,497 [Listener at localhost/38468] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:32,550 [Listener at localhost/38468] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:32,585 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@29a5f4e7] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(263)) - Updating block keys
2020-12-03 07:19:32,587 [Listener at localhost/38468] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:19:32,588 [Listener at localhost/38468] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:32,588 [Listener at localhost/38468] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:32,589 [Listener at localhost/38468] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:32,595 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:19:32,595 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:19:32,595 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:19:32,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:19:32,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:19:32,596 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:19:32,658 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:32,675 [Listener at localhost/38468] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38468
2020-12-03 07:19:32,675 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:32,682 [Listener at localhost/38468] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:19:32,683 [Listener at localhost/38468] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:19:32,694 [Listener at localhost/38468] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 11 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:19:32,701 [CacheReplicationMonitor(609079010)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:19:32,710 [Listener at localhost/38468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:32,808 [Listener at localhost/38468] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:32,839 [Listener at localhost/38468] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:32,892 [Listener at localhost/38468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:32,901 [Listener at localhost/38468] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:32,905 [Listener at localhost/38468] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:32,912 [Listener at localhost/38468] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:32,914 [Listener at localhost/38468] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:32,919 [Listener at localhost/38468] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:32,932 [Listener at localhost/38468] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35278
2020-12-03 07:19:32,936 [Listener at localhost/38468] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:32,936 [Listener at localhost/38468] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:32,960 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:32,962 [Listener at localhost/38468] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:32,964 [Listener at localhost/38468] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:32,964 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:32,969 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:32,970 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:32,971 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:32,971 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:32,977 [Listener at localhost/38468] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37714
2020-12-03 07:19:32,978 [Listener at localhost/38468] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:32,981 [Listener at localhost/38468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@569bf9eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:32,982 [Listener at localhost/38468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@274872f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:33,004 [Listener at localhost/38468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fcbe147{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:33,006 [Listener at localhost/38468] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@235f4c10{HTTP/1.1,[http/1.1]}{localhost:37714}
2020-12-03 07:19:33,006 [Listener at localhost/38468] INFO  server.Server (Server.java:doStart(419)) - Started @5819ms
2020-12-03 07:19:33,516 [Listener at localhost/38468] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44637
2020-12-03 07:19:33,521 [Listener at localhost/38468] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:33,521 [Listener at localhost/38468] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:33,531 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56b78e55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,264 [Listener at localhost/38468] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,267 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,284 [Listener at localhost/38428] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38428
2020-12-03 07:19:34,310 [Listener at localhost/38428] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,312 [Listener at localhost/38428] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,330 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:34,340 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,340 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,350 [Listener at localhost/38428] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:34,353 [Listener at localhost/38428] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:34,354 [Listener at localhost/38428] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:34,356 [Listener at localhost/38428] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,388 [Listener at localhost/38428] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,389 [Listener at localhost/38428] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,390 [Listener at localhost/38428] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,390 [Listener at localhost/38428] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,391 [Listener at localhost/38428] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,392 [Listener at localhost/38428] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38381
2020-12-03 07:19:34,392 [Listener at localhost/38428] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,393 [Listener at localhost/38428] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,395 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,397 [Listener at localhost/38428] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,398 [Listener at localhost/38428] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,399 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,404 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,407 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,416 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,417 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,418 [Listener at localhost/38428] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38429
2020-12-03 07:19:34,418 [Listener at localhost/38428] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,428 [Listener at localhost/38428] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71e9a896{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,450 [Listener at localhost/38428] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@408b35bf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,462 [Listener at localhost/38428] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@615f972{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:34,463 [Listener at localhost/38428] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@285f09de{HTTP/1.1,[http/1.1]}{localhost:38429}
2020-12-03 07:19:34,463 [Listener at localhost/38428] INFO  server.Server (Server.java:doStart(419)) - Started @7277ms
2020-12-03 07:19:34,624 [Listener at localhost/38428] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46751
2020-12-03 07:19:34,627 [Listener at localhost/38428] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,627 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31500940] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,628 [Listener at localhost/38428] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,632 [Listener at localhost/38428] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,633 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,648 [Listener at localhost/40838] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40838
2020-12-03 07:19:34,653 [Listener at localhost/40838] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,654 [Listener at localhost/40838] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,655 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:34,674 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,675 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,682 [Listener at localhost/40838] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:34,698 [Listener at localhost/40838] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:34,700 [Listener at localhost/40838] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:34,701 [Listener at localhost/40838] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,702 [Listener at localhost/40838] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,702 [Listener at localhost/40838] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,703 [Listener at localhost/40838] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,703 [Listener at localhost/40838] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,704 [Listener at localhost/40838] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,705 [Listener at localhost/40838] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44458
2020-12-03 07:19:34,705 [Listener at localhost/40838] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,705 [Listener at localhost/40838] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,707 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,710 [Listener at localhost/40838] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,711 [Listener at localhost/40838] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,711 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,713 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,714 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,714 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,715 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,716 [Listener at localhost/40838] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33995
2020-12-03 07:19:34,716 [Listener at localhost/40838] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,718 [Listener at localhost/40838] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@425357dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,718 [Listener at localhost/40838] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@210386e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,726 [Listener at localhost/40838] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5528a42c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:34,732 [Listener at localhost/40838] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a551a63{HTTP/1.1,[http/1.1]}{localhost:33995}
2020-12-03 07:19:34,733 [Listener at localhost/40838] INFO  server.Server (Server.java:doStart(419)) - Started @7546ms
2020-12-03 07:19:34,798 [Listener at localhost/40838] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36494
2020-12-03 07:19:34,799 [Listener at localhost/40838] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,799 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edb61b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,799 [Listener at localhost/40838] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,800 [Listener at localhost/40838] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,802 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,808 [Listener at localhost/39168] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39168
2020-12-03 07:19:34,820 [Listener at localhost/39168] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:34,820 [Listener at localhost/39168] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:34,821 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:34,824 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:34,824 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:34,845 [Listener at localhost/39168] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:34,848 [Listener at localhost/39168] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:34,849 [Listener at localhost/39168] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:34,851 [Listener at localhost/39168] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:34,852 [Listener at localhost/39168] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,852 [Listener at localhost/39168] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:34,853 [Listener at localhost/39168] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:34,853 [Listener at localhost/39168] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,854 [Listener at localhost/39168] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:34,855 [Listener at localhost/39168] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42902
2020-12-03 07:19:34,856 [Listener at localhost/39168] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:34,856 [Listener at localhost/39168] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:34,860 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,862 [Listener at localhost/39168] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,864 [Listener at localhost/39168] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:34,865 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,868 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,869 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:34,869 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,869 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,872 [Listener at localhost/39168] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38933
2020-12-03 07:19:34,872 [Listener at localhost/39168] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,874 [Listener at localhost/39168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ecf9fb3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,876 [Listener at localhost/39168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27f9e982{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,886 [Listener at localhost/39168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@588ab592{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:34,887 [Listener at localhost/39168] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c8b96ec{HTTP/1.1,[http/1.1]}{localhost:38933}
2020-12-03 07:19:34,887 [Listener at localhost/39168] INFO  server.Server (Server.java:doStart(419)) - Started @7700ms
2020-12-03 07:19:34,974 [Listener at localhost/39168] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43976
2020-12-03 07:19:34,975 [Listener at localhost/39168] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:34,975 [Listener at localhost/39168] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:34,975 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d8f2f3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,976 [Listener at localhost/39168] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:34,977 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:34,991 [Listener at localhost/41789] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41789
2020-12-03 07:19:34,998 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:34,998 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:34,998 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,001 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,001 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,002 [Listener at localhost/41789] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,001 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,012 [Listener at localhost/41789] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,015 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,017 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,017 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,021 [Listener at localhost/41789] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:35,022 [Listener at localhost/41789] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:35,024 [Listener at localhost/41789] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:35,026 [Listener at localhost/41789] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,027 [Listener at localhost/41789] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,027 [Listener at localhost/41789] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,027 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,028 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,028 [Listener at localhost/41789] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,029 [Listener at localhost/41789] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,029 [Listener at localhost/41789] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,030 [Listener at localhost/41789] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39751
2020-12-03 07:19:35,030 [Listener at localhost/41789] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,030 [Listener at localhost/41789] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,031 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,033 [Listener at localhost/41789] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,034 [Listener at localhost/41789] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,034 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,036 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,037 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,037 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,037 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,039 [Listener at localhost/41789] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35831
2020-12-03 07:19:35,039 [Listener at localhost/41789] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,054 [Listener at localhost/41789] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a7b503d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,055 [Listener at localhost/41789] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62c5bbdc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,064 [Listener at localhost/41789] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c321bdb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,067 [Listener at localhost/41789] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24855019{HTTP/1.1,[http/1.1]}{localhost:35831}
2020-12-03 07:19:35,068 [Listener at localhost/41789] INFO  server.Server (Server.java:doStart(419)) - Started @7881ms
2020-12-03 07:19:35,083 [Listener at localhost/41789] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36416
2020-12-03 07:19:35,084 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d4d8fcf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,084 [Listener at localhost/41789] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,084 [Listener at localhost/41789] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,085 [Listener at localhost/41789] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,086 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,091 [Listener at localhost/39279] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39279
2020-12-03 07:19:35,096 [Listener at localhost/39279] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,096 [Listener at localhost/39279] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,097 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,099 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,099 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,109 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,110 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,135 [Listener at localhost/39279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:35,137 [Listener at localhost/39279] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:35,138 [Listener at localhost/39279] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:35,145 [Listener at localhost/39279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,145 [Listener at localhost/39279] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,145 [Listener at localhost/39279] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,146 [Listener at localhost/39279] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,146 [Listener at localhost/39279] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,147 [Listener at localhost/39279] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,148 [Listener at localhost/39279] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38737
2020-12-03 07:19:35,148 [Listener at localhost/39279] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,149 [Listener at localhost/39279] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,150 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,152 [Listener at localhost/39279] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,153 [Listener at localhost/39279] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,154 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,156 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,157 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,157 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,157 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,158 [Listener at localhost/39279] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44285
2020-12-03 07:19:35,159 [Listener at localhost/39279] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,161 [Listener at localhost/39279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7674a051{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,162 [Listener at localhost/39279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6754ef00{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,171 [Listener at localhost/39279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@10ad20cb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,172 [Listener at localhost/39279] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7dd712e8{HTTP/1.1,[http/1.1]}{localhost:44285}
2020-12-03 07:19:35,172 [Listener at localhost/39279] INFO  server.Server (Server.java:doStart(419)) - Started @7985ms
2020-12-03 07:19:35,188 [Listener at localhost/39279] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38841
2020-12-03 07:19:35,189 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22ee2d0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,189 [Listener at localhost/39279] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,189 [Listener at localhost/39279] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,190 [Listener at localhost/39279] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,190 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,194 [Listener at localhost/43738] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43738
2020-12-03 07:19:35,198 [Listener at localhost/43738] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,199 [Listener at localhost/43738] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,199 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,201 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,204 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,205 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,205 [Listener at localhost/43738] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:35,207 [Listener at localhost/43738] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:35,208 [Listener at localhost/43738] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:35,209 [Listener at localhost/43738] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,210 [Listener at localhost/43738] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,210 [Listener at localhost/43738] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,210 [Listener at localhost/43738] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,211 [Listener at localhost/43738] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,211 [Listener at localhost/43738] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,212 [Listener at localhost/43738] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45744
2020-12-03 07:19:35,212 [Listener at localhost/43738] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,213 [Listener at localhost/43738] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,214 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,216 [Listener at localhost/43738] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,217 [Listener at localhost/43738] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,218 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,220 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,222 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,223 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,223 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,224 [Listener at localhost/43738] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37109
2020-12-03 07:19:35,225 [Listener at localhost/43738] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,227 [Listener at localhost/43738] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@437e951d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,228 [Listener at localhost/43738] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63a5e46c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,238 [Listener at localhost/43738] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58cd06cb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,239 [Listener at localhost/43738] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3be8821f{HTTP/1.1,[http/1.1]}{localhost:37109}
2020-12-03 07:19:35,239 [Listener at localhost/43738] INFO  server.Server (Server.java:doStart(419)) - Started @8052ms
2020-12-03 07:19:35,249 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,250 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,250 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,250 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,252 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,252 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,252 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,253 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e03586cd-799a-4009-879e-2a01dbcc1778 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:19:35,253 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:19:35,254 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:19:35,259 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,261 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-48c46482-5cc2-4c39-93b8-21acd949cfdb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:19:35,324 [Listener at localhost/43738] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39466
2020-12-03 07:19:35,325 [Listener at localhost/43738] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,325 [Listener at localhost/43738] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,326 [Listener at localhost/43738] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,327 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,334 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b65e559] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,338 [Listener at localhost/41097] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41097
2020-12-03 07:19:35,345 [Listener at localhost/41097] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,345 [Listener at localhost/41097] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,346 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,348 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,349 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,354 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,354 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,354 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,354 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,357 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,358 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,368 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:19:35,369 [Listener at localhost/41097] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:35,371 [Listener at localhost/41097] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:35,372 [Listener at localhost/41097] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:35,372 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-713daf49-61b2-4dc4-8024-a0de6fc8e326 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:19:35,373 [Listener at localhost/41097] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,373 [Listener at localhost/41097] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,374 [Listener at localhost/41097] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,374 [Listener at localhost/41097] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,375 [Listener at localhost/41097] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,375 [Listener at localhost/41097] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,376 [Listener at localhost/41097] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42920
2020-12-03 07:19:35,377 [Listener at localhost/41097] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,377 [Listener at localhost/41097] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,379 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,381 [Listener at localhost/41097] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,382 [Listener at localhost/41097] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,382 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,384 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,385 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,385 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,385 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,386 [Listener at localhost/41097] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40960
2020-12-03 07:19:35,386 [Listener at localhost/41097] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,388 [Listener at localhost/41097] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d71adc2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,389 [Listener at localhost/41097] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a1d3c1a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,397 [Listener at localhost/41097] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3fcdcf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,398 [Listener at localhost/41097] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7668d560{HTTP/1.1,[http/1.1]}{localhost:40960}
2020-12-03 07:19:35,399 [Listener at localhost/41097] INFO  server.Server (Server.java:doStart(419)) - Started @8212ms
2020-12-03 07:19:35,503 [Listener at localhost/41097] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37036
2020-12-03 07:19:35,504 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@126be319] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,504 [Listener at localhost/41097] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,504 [Listener at localhost/41097] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,505 [Listener at localhost/41097] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,506 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,512 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38382
2020-12-03 07:19:35,519 [Listener at localhost/38382] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,519 [Listener at localhost/38382] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,520 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,522 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,522 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,527 [Listener at localhost/38382] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:35,527 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,529 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,530 [Listener at localhost/38382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:35,530 [Listener at localhost/38382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:35,532 [Listener at localhost/38382] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,533 [Listener at localhost/38382] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,533 [Listener at localhost/38382] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,534 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,535 [Listener at localhost/38382] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,536 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,537 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46254
2020-12-03 07:19:35,538 [Listener at localhost/38382] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,538 [Listener at localhost/38382] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,540 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,542 [Listener at localhost/38382] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,542 [Listener at localhost/38382] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,543 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,545 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,546 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,547 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,547 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,548 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43325
2020-12-03 07:19:35,548 [Listener at localhost/38382] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,551 [Listener at localhost/38382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27f0ad19{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,552 [Listener at localhost/38382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@38d5b107{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,560 [Listener at localhost/38382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6e0d4a8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,562 [Listener at localhost/38382] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@64d7b720{HTTP/1.1,[http/1.1]}{localhost:43325}
2020-12-03 07:19:35,562 [Listener at localhost/38382] INFO  server.Server (Server.java:doStart(419)) - Started @8376ms
2020-12-03 07:19:35,583 [Listener at localhost/38382] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33870
2020-12-03 07:19:35,584 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bb3d42d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,584 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,585 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,586 [Listener at localhost/38382] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,587 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,592 [Listener at localhost/37513] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37513
2020-12-03 07:19:35,598 [Listener at localhost/37513] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,598 [Listener at localhost/37513] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,599 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,601 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,601 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,608 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,618 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,618 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ed54c4f4-675f-4f00-9d55-36749307cf06 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:19:35,623 [Listener at localhost/37513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:35,624 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,625 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,625 [Listener at localhost/37513] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:35,625 [Listener at localhost/37513] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:35,626 [Listener at localhost/37513] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,629 [Listener at localhost/37513] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,629 [Listener at localhost/37513] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,630 [Listener at localhost/37513] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,630 [Listener at localhost/37513] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,630 [Listener at localhost/37513] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,631 [Listener at localhost/37513] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35394
2020-12-03 07:19:35,632 [Listener at localhost/37513] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,632 [Listener at localhost/37513] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,635 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,637 [Listener at localhost/37513] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,638 [Listener at localhost/37513] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,638 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,641 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,641 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,641 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,642 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,642 [Listener at localhost/37513] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45751
2020-12-03 07:19:35,643 [Listener at localhost/37513] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,649 [Listener at localhost/37513] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@9fecdf1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,650 [Listener at localhost/37513] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b0f7d9d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,658 [Listener at localhost/37513] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e1162e7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,659 [Listener at localhost/37513] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79c3f01f{HTTP/1.1,[http/1.1]}{localhost:45751}
2020-12-03 07:19:35,659 [Listener at localhost/37513] INFO  server.Server (Server.java:doStart(419)) - Started @8472ms
2020-12-03 07:19:35,680 [Listener at localhost/37513] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41353
2020-12-03 07:19:35,681 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@350b3a17] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,681 [Listener at localhost/37513] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,681 [Listener at localhost/37513] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,681 [Listener at localhost/37513] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,682 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,686 [Listener at localhost/43741] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43741
2020-12-03 07:19:35,692 [Listener at localhost/43741] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,693 [Listener at localhost/43741] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,694 [Thread-259] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,696 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,697 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,701 [Listener at localhost/43741] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:35,702 [Listener at localhost/43741] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:35,703 [Thread-259] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,704 [Thread-259] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,705 [Listener at localhost/43741] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:35,707 [Listener at localhost/43741] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:35,708 [Listener at localhost/43741] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,708 [Listener at localhost/43741] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:35,708 [Listener at localhost/43741] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:35,709 [Listener at localhost/43741] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,709 [Listener at localhost/43741] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:35,710 [Listener at localhost/43741] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45165
2020-12-03 07:19:35,710 [Listener at localhost/43741] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:35,710 [Listener at localhost/43741] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:35,711 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,713 [Listener at localhost/43741] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,714 [Listener at localhost/43741] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:35,714 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,717 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,717 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:35,718 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,718 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,719 [Listener at localhost/43741] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40333
2020-12-03 07:19:35,719 [Listener at localhost/43741] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,721 [Listener at localhost/43741] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5fa05212{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,722 [Listener at localhost/43741] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c09d180{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,722 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,722 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,725 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-816cb48b-853e-4641-b6d6-bdee5b222ce4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:19:35,739 [Listener at localhost/43741] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1bf0f6f6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:35,741 [Listener at localhost/43741] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@56bc3fac{HTTP/1.1,[http/1.1]}{localhost:40333}
2020-12-03 07:19:35,742 [Listener at localhost/43741] INFO  server.Server (Server.java:doStart(419)) - Started @8554ms
2020-12-03 07:19:35,762 [Listener at localhost/43741] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45398
2020-12-03 07:19:35,763 [Listener at localhost/43741] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:35,763 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ba45490] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,763 [Listener at localhost/43741] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:35,764 [Listener at localhost/43741] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,765 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:35,768 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46220
2020-12-03 07:19:35,775 [Listener at localhost/46220] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:35,775 [Listener at localhost/46220] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:35,776 [Thread-281] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468 starting to offer service
2020-12-03 07:19:35,779 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,779 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:35,788 [Thread-281] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38468
2020-12-03 07:19:35,790 [Thread-281] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:35,857 [Thread-259] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,857 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,858 [Thread-259] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,858 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,863 [Thread-259] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-56ac4e85-2390-4531-8d9e-5c86ec942373 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:19:35,864 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-91487303-6e14-4b85-83fe-85944ef4a63b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:19:35,990 [Thread-281] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,990 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,990 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,990 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,990 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,990 [Thread-281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,991 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,992 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,992 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:35,993 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:35,995 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:19:35,995 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f39b7684-4dca-4f42-8a99-898e62e34395 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:19:35,996 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:19:35,996 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:19:35,996 [Thread-281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bfbd2513-c18e-4a24-824a-10a29dbfade0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 
2020-12-03 07:19:36,119 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,119 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,119 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,120 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,121 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:19:36,123 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6707b574-cb60-40c9-b999-0e2b495a7f33 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:19:36,360 [IPC Server handler 8 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,370 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,370 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,375 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,375 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,378 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-809db8f8-d556-4081-8ed9-b31e740408b3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:19:36,473 [IPC Server handler 9 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,474 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,474 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,498 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,499 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,504 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:19:36,524 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,525 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,525 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,525 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,525 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,525 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,526 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,526 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,529 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,529 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,530 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,530 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,533 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,533 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,534 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,534 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,577 [IPC Server handler 6 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,578 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,578 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,622 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,623 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,622 [Thread-259] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,623 [Thread-259] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,629 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:19:36,630 [Thread-259] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:19:36,636 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,637 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,637 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,637 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,647 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,647 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,647 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,648 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,680 [IPC Server handler 5 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,681 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,681 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,765 [Thread-281] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 275@1d453410403c
2020-12-03 07:19:36,765 [Thread-281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 is not formatted for namespace 1644253551. Formatting...
2020-12-03 07:19:36,772 [Thread-281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e6dcea4b-0326-42ee-aa5b-f044135f8802 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 
2020-12-03 07:19:36,784 [IPC Server handler 4 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,785 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,785 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,888 [IPC Server handler 3 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,889 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,889 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:36,903 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,903 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:36,903 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:36,903 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:36,992 [IPC Server handler 2 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:36,993 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:36,993 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,037 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,038 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,039 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,039 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,039 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,039 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,039 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,040 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,039 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,039 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,043 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,042 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,042 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,043 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,043 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,043 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,046 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,046 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,046 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,046 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,096 [IPC Server handler 1 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,097 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,098 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,174 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,174 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,174 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,175 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,180 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,180 [Thread-259] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,181 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,181 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,181 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,181 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,182 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,182 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,190 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,190 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,191 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,191 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,206 [IPC Server handler 8 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,207 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,207 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,310 [IPC Server handler 9 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,311 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,311 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,351 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,351 [Thread-281] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,351 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,351 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,413 [IPC Server handler 6 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,414 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,414 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,482 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,483 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,483 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,483 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,517 [IPC Server handler 5 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,518 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,518 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,613 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:37,613 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:37,613 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:37,615 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:37,621 [IPC Server handler 4 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,621 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,622 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,624 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,625 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,625 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,625 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,725 [IPC Server handler 3 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,726 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,726 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,765 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:37,765 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:37,775 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,775 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,775 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,775 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,786 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,787 [Thread-259] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,787 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,787 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,829 [IPC Server handler 2 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,830 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,830 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,918 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,918 [Thread-281] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:37,918 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 and block pool id BP-1138391729-172.17.0.4-1606979969588 is not formatted. Formatting ...
2020-12-03 07:19:37,918 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1138391729-172.17.0.4-1606979969588 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1138391729-172.17.0.4-1606979969588/current
2020-12-03 07:19:37,934 [IPC Server handler 1 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,935 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,937 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,040 [IPC Server handler 0 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,041 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,042 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,071 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:38,144 [IPC Server handler 7 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,145 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,145 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,226 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 728449f2-4f4d-4a15-aa4c-0c8f3086e81a
2020-12-03 07:19:38,226 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6b9a1d03-2217-4bb4-85f0-4bc32ca81791
2020-12-03 07:19:38,226 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 13e78348-374d-4e1d-9c71-0f826bf4629d
2020-12-03 07:19:38,226 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:38,226 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fdc38d5a-a512-4b6d-82e2-0065e10facf5
2020-12-03 07:19:38,248 [IPC Server handler 9 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,249 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,249 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,329 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID eab78a87-0942-4d97-82b1-e000f7f2adbc
2020-12-03 07:19:38,330 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d591218b-badd-4bcd-8346-c3805ce14075
2020-12-03 07:19:38,330 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:38,330 [Thread-259] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:38,356 [IPC Server handler 6 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,357 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,358 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,386 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926
2020-12-03 07:19:38,387 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:19:38,387 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894
2020-12-03 07:19:38,387 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-48c46482-5cc2-4c39-93b8-21acd949cfdb
2020-12-03 07:19:38,389 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:19:38,393 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:19:38,394 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-713daf49-61b2-4dc4-8024-a0de6fc8e326
2020-12-03 07:19:38,394 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:19:38,398 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef
2020-12-03 07:19:38,400 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:19:38,400 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1
2020-12-03 07:19:38,400 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:19:38,403 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc
2020-12-03 07:19:38,403 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:19:38,403 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7
2020-12-03 07:19:38,404 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:19:38,409 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f39b7684-4dca-4f42-8a99-898e62e34395
2020-12-03 07:19:38,409 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:19:38,411 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,411 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,411 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,412 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e03586cd-799a-4009-879e-2a01dbcc1778
2020-12-03 07:19:38,411 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,413 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:19:38,414 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6707b574-cb60-40c9-b999-0e2b495a7f33
2020-12-03 07:19:38,415 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:19:38,415 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,416 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708
2020-12-03 07:19:38,418 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:19:38,418 [Thread-281] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1644253551;bpid=BP-1138391729-172.17.0.4-1606979969588;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1644253551;c=1606979969588;bpid=BP-1138391729-172.17.0.4-1606979969588;dnuuid=null
2020-12-03 07:19:38,418 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,430 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:38,433 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:38,435 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:38,436 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:38,437 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:38,438 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:38,445 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:38,446 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:38,454 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:38,454 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:38,473 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,471 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:38,474 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:38,475 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:38,476 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,467 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:38,477 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:38,477 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:38,478 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,463 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:38,461 [IPC Server handler 5 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,480 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:38,460 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:38,455 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:38,480 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:38,477 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:38,477 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:38,477 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:38,484 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,484 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,486 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:38,475 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:38,481 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:38,480 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:38,509 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,480 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:38,511 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,511 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:38,508 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:38,511 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,512 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 241be1e6-4177-4c62-86a0-889e82446242
2020-12-03 07:19:38,513 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:38,515 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:38,517 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:38,521 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ed54c4f4-675f-4f00-9d55-36749307cf06
2020-12-03 07:19:38,532 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:38,533 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:19:38,521 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:38,546 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-809db8f8-d556-4081-8ed9-b31e740408b3
2020-12-03 07:19:38,561 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:19:38,569 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,571 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:38,579 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 771b196e-4591-4d5c-8e5a-de33229e6c5f
2020-12-03 07:19:38,634 [Thread-259] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 978f49f7-d934-4a41-8259-c450192add09
2020-12-03 07:19:38,678 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0
2020-12-03 07:19:38,685 [IPC Server handler 3 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,686 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,686 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,687 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-56ac4e85-2390-4531-8d9e-5c86ec942373
2020-12-03 07:19:38,687 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:19:38,690 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:38,690 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:38,690 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:38,692 [Thread-281] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 81132b72-024a-499b-9534-f37df49d6b01
2020-12-03 07:19:38,697 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05
2020-12-03 07:19:38,697 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:19:38,697 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,699 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:38,699 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-816cb48b-853e-4641-b6d6-bdee5b222ce4
2020-12-03 07:19:38,700 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:19:38,804 [Thread-259] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:38,804 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:38,805 [Thread-259] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:38,808 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-91487303-6e14-4b85-83fe-85944ef4a63b
2020-12-03 07:19:38,808 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:19:38,810 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d
2020-12-03 07:19:38,811 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:19:38,811 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,815 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:38,828 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:38,831 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:38,832 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:38,840 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bfbd2513-c18e-4a24-824a-10a29dbfade0
2020-12-03 07:19:38,841 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:19:38,843 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296
2020-12-03 07:19:38,843 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:19:38,844 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,845 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:38,847 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:38,847 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:38,847 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:38,863 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e6dcea4b-0326-42ee-aa5b-f044135f8802
2020-12-03 07:19:38,863 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:19:38,864 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:38,866 [Thread-281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:38,869 [Thread-281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:38,869 [Thread-281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:38,870 [Thread-281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:38,894 [IPC Server handler 1 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,896 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:38,896 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:38,896 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,897 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:38,897 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:38,903 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,904 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 423ms
2020-12-03 07:19:38,904 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:19:38,904 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:19:38,905 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,907 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:38,908 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,912 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:38,941 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:38,954 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 438ms
2020-12-03 07:19:38,955 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 474ms
2020-12-03 07:19:38,955 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 444ms
2020-12-03 07:19:38,971 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 490ms
2020-12-03 07:19:38,971 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 439ms
2020-12-03 07:19:38,978 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:19:38,979 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:19:38,982 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 473ms
2020-12-03 07:19:38,982 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:19:38,983 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 465ms
2020-12-03 07:19:38,983 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 472ms
2020-12-03 07:19:38,971 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 494ms
2020-12-03 07:19:38,984 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 498ms
2020-12-03 07:19:38,979 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:19:38,985 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 498ms
2020-12-03 07:19:38,985 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 512ms
2020-12-03 07:19:38,986 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:38,987 [Thread-358] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,004 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:39,004 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 18ms
2020-12-03 07:19:39,005 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:39,006 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 460ms
2020-12-03 07:19:39,006 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 495ms
2020-12-03 07:19:39,006 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:39,007 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:39,009 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 495ms
2020-12-03 07:19:39,009 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 500ms
2020-12-03 07:19:39,010 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:39,011 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:39,011 [Thread-365] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:39,011 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 533ms
2020-12-03 07:19:39,012 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:39,013 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:39,013 [Thread-372] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:39,013 [Thread-371] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:39,028 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 123ms
2020-12-03 07:19:39,011 [Thread-357] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,011 [Thread-365] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,030 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 19ms
2020-12-03 07:19:39,011 [Thread-362] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,007 [Thread-361] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,039 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 143ms
2020-12-03 07:19:39,012 [Thread-364] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,005 [Thread-359] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,039 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 33ms
2020-12-03 07:19:39,030 [Thread-365] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 19ms
2020-12-03 07:19:39,013 [Thread-369] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,041 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 55ms
2020-12-03 07:19:39,041 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 28ms
2020-12-03 07:19:39,007 [Thread-356] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,040 [IPC Server handler 0 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,013 [Thread-372] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,040 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 36ms
2020-12-03 07:19:39,013 [Thread-371] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,040 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 28ms
2020-12-03 07:19:39,044 [Thread-371] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 32ms
2020-12-03 07:19:39,045 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:39,044 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 37ms
2020-12-03 07:19:39,044 [Thread-372] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 31ms
2020-12-03 07:19:39,043 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,045 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,041 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 30ms
2020-12-03 07:19:39,046 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 39ms
2020-12-03 07:19:39,004 [Thread-360] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,046 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 61ms
2020-12-03 07:19:39,047 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 43ms
2020-12-03 07:19:39,047 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 61ms
2020-12-03 07:19:39,048 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,052 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 40ms
2020-12-03 07:19:39,076 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 66ms
2020-12-03 07:19:39,076 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:39,077 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-6707b574-cb60-40c9-b999-0e2b495a7f33): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,077 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:39,077 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,045 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:39,080 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e03586cd-799a-4009-879e-2a01dbcc1778): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,046 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:39,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,047 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:39,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f39b7684-4dca-4f42-8a99-898e62e34395): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,047 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:39,082 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-713daf49-61b2-4dc4-8024-a0de6fc8e326): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,047 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:39,048 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:39,082 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,083 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,054 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:39,053 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:39,083 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,048 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:39,093 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,083 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-48c46482-5cc2-4c39-93b8-21acd949cfdb): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,097 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-12-03 07:19:39,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f39b7684-4dca-4f42-8a99-898e62e34395): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-12-03 07:19:39,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-713daf49-61b2-4dc4-8024-a0de6fc8e326): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:19:39,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e03586cd-799a-4009-879e-2a01dbcc1778): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:19:39,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-12-03 07:19:39,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-6707b574-cb60-40c9-b999-0e2b495a7f33): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:19:39,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:19:39,114 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc): no suitable block pools found to scan.  Waiting 1814399933 ms.
2020-12-03 07:19:39,115 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 210ms
2020-12-03 07:19:39,115 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708): no suitable block pools found to scan.  Waiting 1814399930 ms.
2020-12-03 07:19:39,116 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 212ms
2020-12-03 07:19:39,116 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:19:39,116 [Thread-385] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,117 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:19:39,132 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef): no suitable block pools found to scan.  Waiting 1814399944 ms.
2020-12-03 07:19:39,136 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-48c46482-5cc2-4c39-93b8-21acd949cfdb): no suitable block pools found to scan.  Waiting 1814399916 ms.
2020-12-03 07:19:39,146 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-12-03 07:19:39,154 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:38 AM with interval of 21600000ms
2020-12-03 07:19:39,155 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:55 PM with interval of 21600000ms
2020-12-03 07:19:39,155 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:40 AM with interval of 21600000ms
2020-12-03 07:19:39,155 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:40 AM with interval of 21600000ms
2020-12-03 07:19:39,155 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:49 AM with interval of 21600000ms
2020-12-03 07:19:39,190 [IPC Server handler 8 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,197 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 214ms
2020-12-03 07:19:39,199 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 302ms
2020-12-03 07:19:39,200 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 303ms
2020-12-03 07:19:39,200 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:19:39,200 [Thread-386] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,200 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:39,200 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 1ms
2020-12-03 07:19:39,201 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 85ms
2020-12-03 07:19:39,202 [Thread-259] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:44 AM with interval of 21600000ms
2020-12-03 07:19:39,202 [Thread-392] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,202 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:39,202 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:19:39,202 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 3ms
2020-12-03 07:19:39,202 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:19:39,202 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:40 AM with interval of 21600000ms
2020-12-03 07:19:39,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,202 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 218ms
2020-12-03 07:19:39,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-56ac4e85-2390-4531-8d9e-5c86ec942373): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,203 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 291ms
2020-12-03 07:19:39,204 [Thread-398] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:19:39,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:19:39,204 [Thread-398] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,204 [Thread-399] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:19:39,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-56ac4e85-2390-4531-8d9e-5c86ec942373): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:19:39,204 [Thread-399] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,208 [Thread-399] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 4ms
2020-12-03 07:19:39,217 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 310ms
2020-12-03 07:19:39,217 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 6b9a1d03-2217-4bb4-85f0-4bc32ca81791) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,216 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 237ms
2020-12-03 07:19:39,214 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 728449f2-4f4d-4a15-aa4c-0c8f3086e81a) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,214 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid d591218b-badd-4bcd-8346-c3805ce14075) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,213 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,223 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,209 [Thread-398] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 5ms
2020-12-03 07:19:39,220 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 978f49f7-d934-4a41-8259-c450192add09) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,220 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 13e78348-374d-4e1d-9c71-0f826bf4629d) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,224 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 245ms
2020-12-03 07:19:39,225 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1138391729-172.17.0.4-1606979969588 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 282ms
2020-12-03 07:19:39,219 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid fdc38d5a-a512-4b6d-82e2-0065e10facf5) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,217 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid eab78a87-0942-4d97-82b1-e000f7f2adbc) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,219 [Thread-393] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,225 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 313ms
2020-12-03 07:19:39,226 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 24ms
2020-12-03 07:19:39,224 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 20ms
2020-12-03 07:19:39,226 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 27ms
2020-12-03 07:19:39,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:39,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:19:39,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-809db8f8-d556-4081-8ed9-b31e740408b3): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:19:39,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:39,235 [Thread-400] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:19:39,238 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ed54c4f4-675f-4f00-9d55-36749307cf06): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,240 [Thread-400] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,240 [Thread-400] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 3ms
2020-12-03 07:19:39,241 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ed54c4f4-675f-4f00-9d55-36749307cf06): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-12-03 07:19:39,233 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1138391729-172.17.0.4-1606979969588: 329ms
2020-12-03 07:19:39,233 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-809db8f8-d556-4081-8ed9-b31e740408b3): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:19:39,233 [Thread-281] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:34 PM with interval of 21600000ms
2020-12-03 07:19:39,233 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:00 AM with interval of 21600000ms
2020-12-03 07:19:39,227 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-bfbd2513-c18e-4a24-824a-10a29dbfade0): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,241 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:39,242 [Thread-407] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,243 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-bfbd2513-c18e-4a24-824a-10a29dbfade0): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:19:39,239 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:19:39,238 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-e6dcea4b-0326-42ee-aa5b-f044135f8802): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,260 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 241be1e6-4177-4c62-86a0-889e82446242) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,260 [Thread-403] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,258 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 81132b72-024a-499b-9534-f37df49d6b01) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,258 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:39,257 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 15ms
2020-12-03 07:19:39,261 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 3ms
2020-12-03 07:19:39,261 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-e6dcea4b-0326-42ee-aa5b-f044135f8802): no suitable block pools found to scan.  Waiting 1814399966 ms.
2020-12-03 07:19:39,261 [Thread-406] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1138391729-172.17.0.4-1606979969588/current/replicas doesn't exist 
2020-12-03 07:19:39,263 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 37ms
2020-12-03 07:19:39,263 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:19:39,263 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 2ms
2020-12-03 07:19:39,264 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1138391729-172.17.0.4-1606979969588: 23ms
2020-12-03 07:19:39,264 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,264 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:50 AM with interval of 21600000ms
2020-12-03 07:19:39,264 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:39,265 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:19:39,265 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-816cb48b-853e-4641-b6d6-bdee5b222ce4): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,264 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:19:39,266 [IPC Server handler 6 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 6b9a1d03-2217-4bb4-85f0-4bc32ca81791
2020-12-03 07:19:39,264 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:55 AM with interval of 21600000ms
2020-12-03 07:19:39,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-91487303-6e14-4b85-83fe-85944ef4a63b): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,266 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-91487303-6e14-4b85-83fe-85944ef4a63b): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:19:39,265 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1138391729-172.17.0.4-1606979969588 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:39,280 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 771b196e-4591-4d5c-8e5a-de33229e6c5f) service to localhost/127.0.0.1:38468 beginning handshake with NN
2020-12-03 07:19:39,280 [IPC Server handler 6 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44458
2020-12-03 07:19:39,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-816cb48b-853e-4641-b6d6-bdee5b222ce4): no suitable block pools found to scan.  Waiting 1814399986 ms.
2020-12-03 07:19:39,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296): finished scanning block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,282 [IPC Server handler 6 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6b9a1d03-2217-4bb4-85f0-4bc32ca81791 (127.0.0.1:44458).
2020-12-03 07:19:39,282 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:19:39,287 [IPC Server handler 5 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 81132b72-024a-499b-9534-f37df49d6b01
2020-12-03 07:19:39,288 [IPC Server handler 5 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45165
2020-12-03 07:19:39,291 [IPC Server handler 5 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81132b72-024a-499b-9534-f37df49d6b01 (127.0.0.1:45165).
2020-12-03 07:19:39,291 [IPC Server handler 3 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage d591218b-badd-4bcd-8346-c3805ce14075
2020-12-03 07:19:39,292 [IPC Server handler 3 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38737
2020-12-03 07:19:39,292 [IPC Server handler 3 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d591218b-badd-4bcd-8346-c3805ce14075 (127.0.0.1:38737).
2020-12-03 07:19:39,293 [IPC Server handler 4 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45744, datanodeUuid=241be1e6-4177-4c62-86a0-889e82446242, infoPort=39466, infoSecurePort=0, ipcPort=41097, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 241be1e6-4177-4c62-86a0-889e82446242
2020-12-03 07:19:39,293 [IPC Server handler 4 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45744
2020-12-03 07:19:39,293 [IPC Server handler 4 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 241be1e6-4177-4c62-86a0-889e82446242 (127.0.0.1:45744).
2020-12-03 07:19:39,293 [IPC Server handler 2 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 978f49f7-d934-4a41-8259-c450192add09
2020-12-03 07:19:39,294 [IPC Server handler 2 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35394
2020-12-03 07:19:39,294 [IPC Server handler 2 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 978f49f7-d934-4a41-8259-c450192add09 (127.0.0.1:35394).
2020-12-03 07:19:39,294 [IPC Server handler 0 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39751, datanodeUuid=eab78a87-0942-4d97-82b1-e000f7f2adbc, infoPort=36416, infoSecurePort=0, ipcPort=39279, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage eab78a87-0942-4d97-82b1-e000f7f2adbc
2020-12-03 07:19:39,294 [IPC Server handler 0 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39751
2020-12-03 07:19:39,294 [IPC Server handler 0 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN eab78a87-0942-4d97-82b1-e000f7f2adbc (127.0.0.1:39751).
2020-12-03 07:19:39,295 [IPC Server handler 1 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage fdc38d5a-a512-4b6d-82e2-0065e10facf5
2020-12-03 07:19:39,295 [IPC Server handler 1 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42902
2020-12-03 07:19:39,295 [IPC Server handler 1 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fdc38d5a-a512-4b6d-82e2-0065e10facf5 (127.0.0.1:42902).
2020-12-03 07:19:39,296 [IPC Server handler 7 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42920, datanodeUuid=771b196e-4591-4d5c-8e5a-de33229e6c5f, infoPort=37036, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 771b196e-4591-4d5c-8e5a-de33229e6c5f
2020-12-03 07:19:39,296 [IPC Server handler 7 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42920
2020-12-03 07:19:39,296 [IPC Server handler 7 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 771b196e-4591-4d5c-8e5a-de33229e6c5f (127.0.0.1:42920).
2020-12-03 07:19:39,297 [IPC Server handler 8 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35278, datanodeUuid=728449f2-4f4d-4a15-aa4c-0c8f3086e81a, infoPort=44637, infoSecurePort=0, ipcPort=38428, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 728449f2-4f4d-4a15-aa4c-0c8f3086e81a
2020-12-03 07:19:39,297 [IPC Server handler 8 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35278
2020-12-03 07:19:39,297 [IPC Server handler 8 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 728449f2-4f4d-4a15-aa4c-0c8f3086e81a (127.0.0.1:35278).
2020-12-03 07:19:39,297 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid eab78a87-0942-4d97-82b1-e000f7f2adbc) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,297 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 81132b72-024a-499b-9534-f37df49d6b01) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,297 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,298 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,298 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,300 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 978f49f7-d934-4a41-8259-c450192add09) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,300 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 728449f2-4f4d-4a15-aa4c-0c8f3086e81a) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,300 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,297 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,302 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid fdc38d5a-a512-4b6d-82e2-0065e10facf5) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,302 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 241be1e6-4177-4c62-86a0-889e82446242) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,303 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,297 [IPC Server handler 9 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 13e78348-374d-4e1d-9c71-0f826bf4629d
2020-12-03 07:19:39,297 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 6b9a1d03-2217-4bb4-85f0-4bc32ca81791) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,303 [IPC Server handler 9 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38381
2020-12-03 07:19:39,303 [IPC Server handler 9 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 13e78348-374d-4e1d-9c71-0f826bf4629d (127.0.0.1:38381).
2020-12-03 07:19:39,304 [IPC Server handler 6 on default port 38468] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46254, datanodeUuid=7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, infoPort=33870, infoSecurePort=0, ipcPort=37513, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588) storage 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0
2020-12-03 07:19:39,302 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,300 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 771b196e-4591-4d5c-8e5a-de33229e6c5f) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,300 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid d591218b-badd-4bcd-8346-c3805ce14075) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,300 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,304 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,304 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,305 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,305 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,305 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,304 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,303 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,311 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,311 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,305 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,305 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,304 [IPC Server handler 6 on default port 38468] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46254
2020-12-03 07:19:39,304 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,316 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,316 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,314 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,314 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,314 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 13e78348-374d-4e1d-9c71-0f826bf4629d) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,320 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,322 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,322 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,314 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,317 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,316 [IPC Server handler 6 on default port 38468] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0 (127.0.0.1:46254).
2020-12-03 07:19:39,324 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,330 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0) service to localhost/127.0.0.1:38468 successfully registered with NN
2020-12-03 07:19:39,330 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1615)) - Block token params received from NN: for block pool BP-1138391729-172.17.0.4-1606979969588 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-12-03 07:19:39,330 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(233)) - Setting block keys
2020-12-03 07:19:39,330 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38468 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:39,340 [IPC Server handler 5 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,349 [IPC Server handler 2 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bfbd2513-c18e-4a24-824a-10a29dbfade0 for DN 127.0.0.1:45165
2020-12-03 07:19:39,350 [IPC Server handler 2 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e6dcea4b-0326-42ee-aa5b-f044135f8802 for DN 127.0.0.1:45165
2020-12-03 07:19:39,350 [IPC Server handler 5 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e03586cd-799a-4009-879e-2a01dbcc1778 for DN 127.0.0.1:35278
2020-12-03 07:19:39,353 [IPC Server handler 5 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708 for DN 127.0.0.1:35278
2020-12-03 07:19:39,353 [IPC Server handler 0 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-816cb48b-853e-4641-b6d6-bdee5b222ce4 for DN 127.0.0.1:42920
2020-12-03 07:19:39,353 [IPC Server handler 0 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296 for DN 127.0.0.1:42920
2020-12-03 07:19:39,354 [IPC Server handler 8 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-713daf49-61b2-4dc4-8024-a0de6fc8e326 for DN 127.0.0.1:39751
2020-12-03 07:19:39,354 [IPC Server handler 8 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc for DN 127.0.0.1:39751
2020-12-03 07:19:39,354 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:35278
2020-12-03 07:19:39,354 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,354 [IPC Server handler 7 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926 for DN 127.0.0.1:38381
2020-12-03 07:19:39,355 [IPC Server handler 7 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f39b7684-4dca-4f42-8a99-898e62e34395 for DN 127.0.0.1:38381
2020-12-03 07:19:39,355 [IPC Server handler 4 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed54c4f4-675f-4f00-9d55-36749307cf06 for DN 127.0.0.1:45744
2020-12-03 07:19:39,355 [IPC Server handler 4 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-809db8f8-d556-4081-8ed9-b31e740408b3 for DN 127.0.0.1:45744
2020-12-03 07:19:39,355 [IPC Server handler 1 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef for DN 127.0.0.1:38737
2020-12-03 07:19:39,356 [IPC Server handler 1 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6707b574-cb60-40c9-b999-0e2b495a7f33 for DN 127.0.0.1:38737
2020-12-03 07:19:39,356 [IPC Server handler 3 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-48c46482-5cc2-4c39-93b8-21acd949cfdb for DN 127.0.0.1:42902
2020-12-03 07:19:39,356 [IPC Server handler 3 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1 for DN 127.0.0.1:42902
2020-12-03 07:19:39,356 [IPC Server handler 9 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-91487303-6e14-4b85-83fe-85944ef4a63b for DN 127.0.0.1:46254
2020-12-03 07:19:39,356 [IPC Server handler 9 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d for DN 127.0.0.1:46254
2020-12-03 07:19:39,357 [IPC Server handler 6 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56ac4e85-2390-4531-8d9e-5c86ec942373 for DN 127.0.0.1:35394
2020-12-03 07:19:39,357 [IPC Server handler 6 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05 for DN 127.0.0.1:35394
2020-12-03 07:19:39,369 [IPC Server handler 3 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894 for DN 127.0.0.1:44458
2020-12-03 07:19:39,369 [IPC Server handler 3 on default port 38468] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7 for DN 127.0.0.1:44458
2020-12-03 07:19:39,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdab9318827c94ae0: Processing first storage report for DS-713daf49-61b2-4dc4-8024-a0de6fc8e326 from datanode eab78a87-0942-4d97-82b1-e000f7f2adbc
2020-12-03 07:19:39,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdab9318827c94ae0: from storage DS-713daf49-61b2-4dc4-8024-a0de6fc8e326 node DatanodeRegistration(127.0.0.1:39751, datanodeUuid=eab78a87-0942-4d97-82b1-e000f7f2adbc, infoPort=36416, infoSecurePort=0, ipcPort=39279, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3c428dc6f01f5a06: Processing first storage report for DS-f39b7684-4dca-4f42-8a99-898e62e34395 from datanode 13e78348-374d-4e1d-9c71-0f826bf4629d
2020-12-03 07:19:39,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3c428dc6f01f5a06: from storage DS-f39b7684-4dca-4f42-8a99-898e62e34395 node DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x643c798a47bb1faf: Processing first storage report for DS-e6dcea4b-0326-42ee-aa5b-f044135f8802 from datanode 81132b72-024a-499b-9534-f37df49d6b01
2020-12-03 07:19:39,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x643c798a47bb1faf: from storage DS-e6dcea4b-0326-42ee-aa5b-f044135f8802 node DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb7bbfd7c255e0ea8: Processing first storage report for DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296 from datanode 771b196e-4591-4d5c-8e5a-de33229e6c5f
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb7bbfd7c255e0ea8: from storage DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296 node DatanodeRegistration(127.0.0.1:42920, datanodeUuid=771b196e-4591-4d5c-8e5a-de33229e6c5f, infoPort=37036, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xda195697ed8ed553: Processing first storage report for DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708 from datanode 728449f2-4f4d-4a15-aa4c-0c8f3086e81a
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xda195697ed8ed553: from storage DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708 node DatanodeRegistration(127.0.0.1:35278, datanodeUuid=728449f2-4f4d-4a15-aa4c-0c8f3086e81a, infoPort=44637, infoSecurePort=0, ipcPort=38428, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc09a95bfca12c395: Processing first storage report for DS-ed54c4f4-675f-4f00-9d55-36749307cf06 from datanode 241be1e6-4177-4c62-86a0-889e82446242
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc09a95bfca12c395: from storage DS-ed54c4f4-675f-4f00-9d55-36749307cf06 node DatanodeRegistration(127.0.0.1:45744, datanodeUuid=241be1e6-4177-4c62-86a0-889e82446242, infoPort=39466, infoSecurePort=0, ipcPort=41097, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdab9318827c94ae0: Processing first storage report for DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc from datanode eab78a87-0942-4d97-82b1-e000f7f2adbc
2020-12-03 07:19:39,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdab9318827c94ae0: from storage DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc node DatanodeRegistration(127.0.0.1:39751, datanodeUuid=eab78a87-0942-4d97-82b1-e000f7f2adbc, infoPort=36416, infoSecurePort=0, ipcPort=39279, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3c428dc6f01f5a06: Processing first storage report for DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926 from datanode 13e78348-374d-4e1d-9c71-0f826bf4629d
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3c428dc6f01f5a06: from storage DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926 node DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x643c798a47bb1faf: Processing first storage report for DS-bfbd2513-c18e-4a24-824a-10a29dbfade0 from datanode 81132b72-024a-499b-9534-f37df49d6b01
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x643c798a47bb1faf: from storage DS-bfbd2513-c18e-4a24-824a-10a29dbfade0 node DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb7bbfd7c255e0ea8: Processing first storage report for DS-816cb48b-853e-4641-b6d6-bdee5b222ce4 from datanode 771b196e-4591-4d5c-8e5a-de33229e6c5f
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb7bbfd7c255e0ea8: from storage DS-816cb48b-853e-4641-b6d6-bdee5b222ce4 node DatanodeRegistration(127.0.0.1:42920, datanodeUuid=771b196e-4591-4d5c-8e5a-de33229e6c5f, infoPort=37036, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xda195697ed8ed553: Processing first storage report for DS-e03586cd-799a-4009-879e-2a01dbcc1778 from datanode 728449f2-4f4d-4a15-aa4c-0c8f3086e81a
2020-12-03 07:19:39,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xda195697ed8ed553: from storage DS-e03586cd-799a-4009-879e-2a01dbcc1778 node DatanodeRegistration(127.0.0.1:35278, datanodeUuid=728449f2-4f4d-4a15-aa4c-0c8f3086e81a, infoPort=44637, infoSecurePort=0, ipcPort=38428, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc09a95bfca12c395: Processing first storage report for DS-809db8f8-d556-4081-8ed9-b31e740408b3 from datanode 241be1e6-4177-4c62-86a0-889e82446242
2020-12-03 07:19:39,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc09a95bfca12c395: from storage DS-809db8f8-d556-4081-8ed9-b31e740408b3 node DatanodeRegistration(127.0.0.1:45744, datanodeUuid=241be1e6-4177-4c62-86a0-889e82446242, infoPort=39466, infoSecurePort=0, ipcPort=41097, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:39,437 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc09a95bfca12c395,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,437 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x643c798a47bb1faf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,438 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,437 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdab9318827c94ae0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,437 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3c428dc6f01f5a06,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,437 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xda195697ed8ed553,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,437 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb7bbfd7c255e0ea8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:39,438 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,438 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,438 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,438 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,438 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:39,457 [IPC Server handler 2 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,461 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:39,496 [IPC Server handler 7 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/striped	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:19:39,524 [IPC Server handler 8 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/striped	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:19:39,530 [IPC Server handler 3 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,536 [Thread-416] INFO  hdfs.TestFileChecksum (TestFileChecksum.java:testStripedFileChecksumWithMissedDataBlocksRangeQuery(290)) - Checksum file:/striped/stripedFileChecksum1, requested length:188743680
2020-12-03 07:19:40,558 [IPC Server handler 3 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,607 [IPC Server handler 8 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/striped/stripedFileChecksum1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:41,172 [IPC Server handler 7 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:45165, 127.0.0.1:44458, 127.0.0.1:38737, 127.0.0.1:42902, 127.0.0.1:35278, 127.0.0.1:35394, 127.0.0.1:38381, 127.0.0.1:45744, 127.0.0.1:46254 for /striped/stripedFileChecksum1
2020-12-03 07:19:41,212 [Thread-417] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,248 [Thread-418] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,293 [Thread-419] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,329 [Thread-420] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,383 [Thread-421] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:41,392 [Thread-422] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,401 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bab3f1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2695ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@350b3a17] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2693ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bb3d42d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2707ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d8f2f3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2850ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22ee2d0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2707ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d4d8fcf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2708ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31500940] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2710ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56b78e55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2849ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ba45490] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2849ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,403 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b65e559] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2849ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,402 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edb61b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2848ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,402 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@126be319] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2849ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1434ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1529ms
2020-12-03 07:19:44,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x85522a362619f31b: Processing first storage report for DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d from datanode 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0
2020-12-03 07:19:44,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x85522a362619f31b: from storage DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d node DatanodeRegistration(127.0.0.1:46254, datanodeUuid=7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, infoPort=33870, infoSecurePort=0, ipcPort=37513, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x98d1b33e21f3be6b: Processing first storage report for DS-6707b574-cb60-40c9-b999-0e2b495a7f33 from datanode d591218b-badd-4bcd-8346-c3805ce14075
2020-12-03 07:19:44,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x98d1b33e21f3be6b: from storage DS-6707b574-cb60-40c9-b999-0e2b495a7f33 node DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,504 [Thread-423] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x85522a362619f31b: Processing first storage report for DS-91487303-6e14-4b85-83fe-85944ef4a63b from datanode 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0
2020-12-03 07:19:44,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x85522a362619f31b: from storage DS-91487303-6e14-4b85-83fe-85944ef4a63b node DatanodeRegistration(127.0.0.1:46254, datanodeUuid=7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, infoPort=33870, infoSecurePort=0, ipcPort=37513, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,531 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3d38d9fcbe0e91b3: Processing first storage report for DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894 from datanode 6b9a1d03-2217-4bb4-85f0-4bc32ca81791
2020-12-03 07:19:44,532 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3d38d9fcbe0e91b3: from storage DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894 node DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,532 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x98d1b33e21f3be6b: Processing first storage report for DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef from datanode d591218b-badd-4bcd-8346-c3805ce14075
2020-12-03 07:19:44,532 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x98d1b33e21f3be6b: from storage DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef node DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,533 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3d38d9fcbe0e91b3: Processing first storage report for DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7 from datanode 6b9a1d03-2217-4bb4-85f0-4bc32ca81791
2020-12-03 07:19:44,533 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3d38d9fcbe0e91b3: from storage DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7 node DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd6809bbd1cc7a85: Processing first storage report for DS-48c46482-5cc2-4c39-93b8-21acd949cfdb from datanode fdc38d5a-a512-4b6d-82e2-0065e10facf5
2020-12-03 07:19:44,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd6809bbd1cc7a85: from storage DS-48c46482-5cc2-4c39-93b8-21acd949cfdb node DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd6809bbd1cc7a85: Processing first storage report for DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1 from datanode fdc38d5a-a512-4b6d-82e2-0065e10facf5
2020-12-03 07:19:44,538 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd6809bbd1cc7a85: from storage DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1 node DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,545 [Thread-424] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,561 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x85522a362619f31b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 128 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,562 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:44,562 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3d38d9fcbe0e91b3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 59 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,562 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd6809bbd1cc7a85,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,562 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:44,562 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:44,562 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x98d1b33e21f3be6b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 128 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,565 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:44,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2fc801e48aeafd30: Processing first storage report for DS-56ac4e85-2390-4531-8d9e-5c86ec942373 from datanode 978f49f7-d934-4a41-8259-c450192add09
2020-12-03 07:19:44,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2fc801e48aeafd30: from storage DS-56ac4e85-2390-4531-8d9e-5c86ec942373 node DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,583 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2fc801e48aeafd30: Processing first storage report for DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05 from datanode 978f49f7-d934-4a41-8259-c450192add09
2020-12-03 07:19:44,583 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2fc801e48aeafd30: from storage DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05 node DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:44,604 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2fc801e48aeafd30,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:44,604 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:44,614 [Thread-425] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:52326 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775784_1001 src: /127.0.0.1:52326 dest: /127.0.0.1:46254
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45448 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 src: /127.0.0.1:45448 dest: /127.0.0.1:44458
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:49396 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 src: /127.0.0.1:49396 dest: /127.0.0.1:35394
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47016 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 src: /127.0.0.1:47016 dest: /127.0.0.1:38381
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:33926 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 src: /127.0.0.1:33926 dest: /127.0.0.1:42902
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:44876 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 src: /127.0.0.1:44876 dest: /127.0.0.1:38737
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53212 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775788_1001 src: /127.0.0.1:53212 dest: /127.0.0.1:35278
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40466 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775785_1001 src: /127.0.0.1:40466 dest: /127.0.0.1:45744
2020-12-03 07:19:44,639 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45686 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 src: /127.0.0.1:45686 dest: /127.0.0.1:45165
2020-12-03 07:19:45,091 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44876, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001, duration(ns): 358884321
2020-12-03 07:19:45,097 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45448, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001, duration(ns): 374908668
2020-12-03 07:19:45,100 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,100 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,097 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47016, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001, duration(ns): 357728283
2020-12-03 07:19:45,094 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45686, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001, duration(ns): 355212458
2020-12-03 07:19:45,094 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53212, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775788_1001, duration(ns): 335765481
2020-12-03 07:19:45,104 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,092 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49396, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001, duration(ns): 356411923
2020-12-03 07:19:45,125 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,104 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,094 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40466, dest: /127.0.0.1:45744, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 241be1e6-4177-4c62-86a0-889e82446242, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775785_1001, duration(ns): 381052343
2020-12-03 07:19:45,091 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52326, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775784_1001, duration(ns): 373135584
2020-12-03 07:19:45,145 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,094 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33926, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001, duration(ns): 376892626
2020-12-03 07:19:45,148 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,145 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,104 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,187 [IPC Server handler 1 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:39751, 127.0.0.1:45744, 127.0.0.1:42920, 127.0.0.1:35278, 127.0.0.1:38381, 127.0.0.1:38737, 127.0.0.1:44458, 127.0.0.1:46254, 127.0.0.1:45165 for /striped/stripedFileChecksum1
2020-12-03 07:19:45,203 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,216 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:39894 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002 src: /127.0.0.1:39894 dest: /127.0.0.1:39751
2020-12-03 07:19:45,252 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,253 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,258 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40614 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775775_1002 src: /127.0.0.1:40614 dest: /127.0.0.1:45744
2020-12-03 07:19:45,281 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:38310 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775774_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775774_1002 src: /127.0.0.1:38310 dest: /127.0.0.1:42920
2020-12-03 07:19:45,308 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,322 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53458 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775773_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775773_1002 src: /127.0.0.1:53458 dest: /127.0.0.1:35278
2020-12-03 07:19:45,328 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,355 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,365 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45142 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775771_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775771_1002 src: /127.0.0.1:45142 dest: /127.0.0.1:38737
2020-12-03 07:19:45,366 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,376 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47202 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775772_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775772_1002 src: /127.0.0.1:47202 dest: /127.0.0.1:38381
2020-12-03 07:19:45,396 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,401 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45720 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775770_1002 src: /127.0.0.1:45720 dest: /127.0.0.1:44458
2020-12-03 07:19:45,403 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,419 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:52500 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775769_1002 src: /127.0.0.1:52500 dest: /127.0.0.1:46254
2020-12-03 07:19:45,423 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45968 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775768_1002 src: /127.0.0.1:45968 dest: /127.0.0.1:45165
2020-12-03 07:19:45,701 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47202, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775772_1002, duration(ns): 301905245
2020-12-03 07:19:45,701 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52500, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775769_1002, duration(ns): 269840647
2020-12-03 07:19:45,702 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38310, dest: /127.0.0.1:42920, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 771b196e-4591-4d5c-8e5a-de33229e6c5f, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775774_1002, duration(ns): 409008624
2020-12-03 07:19:45,701 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,702 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,702 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,706 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40614, dest: /127.0.0.1:45744, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 241be1e6-4177-4c62-86a0-889e82446242, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775775_1002, duration(ns): 430068718
2020-12-03 07:19:45,707 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,707 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45968, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775768_1002, duration(ns): 272481796
2020-12-03 07:19:45,708 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53458, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775773_1002, duration(ns): 374776193
2020-12-03 07:19:45,708 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,711 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45720, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775770_1002, duration(ns): 295891597
2020-12-03 07:19:45,718 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45142, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775771_1002, duration(ns): 332773227
2020-12-03 07:19:45,720 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,708 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,718 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,718 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39894, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002, duration(ns): 476529098
2020-12-03 07:19:45,733 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,744 [IPC Server handler 3 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775760_1003, replicas=127.0.0.1:39751, 127.0.0.1:38381, 127.0.0.1:45744, 127.0.0.1:38737, 127.0.0.1:46254, 127.0.0.1:42902, 127.0.0.1:42920, 127.0.0.1:35278, 127.0.0.1:35394 for /striped/stripedFileChecksum1
2020-12-03 07:19:45,751 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,755 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,758 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,761 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,766 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,774 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,778 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45250 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775757_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775757_1003 src: /127.0.0.1:45250 dest: /127.0.0.1:38737
2020-12-03 07:19:45,779 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40036 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003 src: /127.0.0.1:40036 dest: /127.0.0.1:39751
2020-12-03 07:19:45,780 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:34306 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775755_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775755_1003 src: /127.0.0.1:34306 dest: /127.0.0.1:42902
2020-12-03 07:19:45,780 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:52602 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775756_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775756_1003 src: /127.0.0.1:52602 dest: /127.0.0.1:46254
2020-12-03 07:19:45,789 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40758 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775758_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775758_1003 src: /127.0.0.1:40758 dest: /127.0.0.1:45744
2020-12-03 07:19:45,789 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47308 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775759_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775759_1003 src: /127.0.0.1:47308 dest: /127.0.0.1:38381
2020-12-03 07:19:45,798 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,837 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,844 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53602 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775753_1003 src: /127.0.0.1:53602 dest: /127.0.0.1:35278
2020-12-03 07:19:45,861 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,866 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:38466 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775754_1003 src: /127.0.0.1:38466 dest: /127.0.0.1:42920
2020-12-03 07:19:45,870 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:49786 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775752_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775752_1003 src: /127.0.0.1:49786 dest: /127.0.0.1:35394
2020-12-03 07:19:46,216 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49786, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775752_1003, duration(ns): 298888676
2020-12-03 07:19:46,217 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,217 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47308, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775759_1003, duration(ns): 401828546
2020-12-03 07:19:46,216 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40036, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003, duration(ns): 413952938
2020-12-03 07:19:46,228 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,216 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45250, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775757_1003, duration(ns): 414272385
2020-12-03 07:19:46,257 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,258 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,254 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53602, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775753_1003, duration(ns): 318467449
2020-12-03 07:19:46,264 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,229 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40758, dest: /127.0.0.1:45744, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 241be1e6-4177-4c62-86a0-889e82446242, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775758_1003, duration(ns): 407033717
2020-12-03 07:19:46,276 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,227 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52602, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775756_1003, duration(ns): 431023522
2020-12-03 07:19:46,224 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34306, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775755_1003, duration(ns): 414620540
2020-12-03 07:19:46,288 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,221 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38466, dest: /127.0.0.1:42920, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 771b196e-4591-4d5c-8e5a-de33229e6c5f, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775754_1003, duration(ns): 320460662
2020-12-03 07:19:46,289 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,289 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,297 [IPC Server handler 5 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775744_1004, replicas=127.0.0.1:35278, 127.0.0.1:38737, 127.0.0.1:35394, 127.0.0.1:39751, 127.0.0.1:44458, 127.0.0.1:45165, 127.0.0.1:42902, 127.0.0.1:46254, 127.0.0.1:38381 for /striped/stripedFileChecksum1
2020-12-03 07:19:46,306 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,308 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53708 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004 src: /127.0.0.1:53708 dest: /127.0.0.1:35278
2020-12-03 07:19:46,333 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,334 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45384 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775743_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775743_1004 src: /127.0.0.1:45384 dest: /127.0.0.1:38737
2020-12-03 07:19:46,338 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,340 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,342 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:49900 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775742_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775742_1004 src: /127.0.0.1:49900 dest: /127.0.0.1:35394
2020-12-03 07:19:46,351 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40180 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775741_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775741_1004 src: /127.0.0.1:40180 dest: /127.0.0.1:39751
2020-12-03 07:19:46,375 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,378 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,380 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46206 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775739_1004 src: /127.0.0.1:46206 dest: /127.0.0.1:45165
2020-12-03 07:19:46,380 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45964 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775740_1004 src: /127.0.0.1:45964 dest: /127.0.0.1:44458
2020-12-03 07:19:46,468 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,472 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,478 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:34450 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775738_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775738_1004 src: /127.0.0.1:34450 dest: /127.0.0.1:42902
2020-12-03 07:19:46,479 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:52754 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775737_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775737_1004 src: /127.0.0.1:52754 dest: /127.0.0.1:46254
2020-12-03 07:19:46,524 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,550 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47478 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775736_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775736_1004 src: /127.0.0.1:47478 dest: /127.0.0.1:38381
2020-12-03 07:19:46,833 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34450, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775738_1004, duration(ns): 329994157
2020-12-03 07:19:46,833 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,847 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46206, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775739_1004, duration(ns): 428717712
2020-12-03 07:19:46,847 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,850 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45384, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775743_1004, duration(ns): 472002888
2020-12-03 07:19:46,855 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,854 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45964, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775740_1004, duration(ns): 385029246
2020-12-03 07:19:46,854 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47478, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775736_1004, duration(ns): 259939056
2020-12-03 07:19:46,856 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,856 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,853 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52754, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775737_1004, duration(ns): 314732974
2020-12-03 07:19:46,856 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53708, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004, duration(ns): 537269683
2020-12-03 07:19:46,856 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,856 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,855 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49900, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775742_1004, duration(ns): 470766817
2020-12-03 07:19:46,862 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,862 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40180, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775741_1004, duration(ns): 489194671
2020-12-03 07:19:46,867 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:46,873 [IPC Server handler 3 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775728_1005, replicas=127.0.0.1:45165, 127.0.0.1:42902, 127.0.0.1:39751, 127.0.0.1:35278, 127.0.0.1:42920, 127.0.0.1:38737, 127.0.0.1:44458, 127.0.0.1:45744, 127.0.0.1:38381 for /striped/stripedFileChecksum1
2020-12-03 07:19:46,884 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,884 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,885 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,887 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,889 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,891 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,899 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,902 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,908 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:46,969 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46322 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005 src: /127.0.0.1:46322 dest: /127.0.0.1:45165
2020-12-03 07:19:46,975 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47594 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775720_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775720_1005 src: /127.0.0.1:47594 dest: /127.0.0.1:38381
2020-12-03 07:19:46,975 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:38720 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775724_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775724_1005 src: /127.0.0.1:38720 dest: /127.0.0.1:42920
2020-12-03 07:19:46,976 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46100 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775722_1005 src: /127.0.0.1:46100 dest: /127.0.0.1:44458
2020-12-03 07:19:46,976 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53846 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775725_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775725_1005 src: /127.0.0.1:53846 dest: /127.0.0.1:35278
2020-12-03 07:19:46,979 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:41040 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775721_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775721_1005 src: /127.0.0.1:41040 dest: /127.0.0.1:45744
2020-12-03 07:19:46,979 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45520 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775723_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775723_1005 src: /127.0.0.1:45520 dest: /127.0.0.1:38737
2020-12-03 07:19:47,014 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:34558 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775727_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775727_1005 src: /127.0.0.1:34558 dest: /127.0.0.1:42902
2020-12-03 07:19:47,014 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40304 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775726_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775726_1005 src: /127.0.0.1:40304 dest: /127.0.0.1:39751
2020-12-03 07:19:47,185 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38720, dest: /127.0.0.1:42920, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 771b196e-4591-4d5c-8e5a-de33229e6c5f, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775724_1005, duration(ns): 202692691
2020-12-03 07:19:47,197 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,189 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34558, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775727_1005, duration(ns): 150196708
2020-12-03 07:19:47,197 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,206 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46100, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775722_1005, duration(ns): 203122477
2020-12-03 07:19:47,206 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,207 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46322, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005, duration(ns): 211544732
2020-12-03 07:19:47,207 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,208 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53846, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775725_1005, duration(ns): 164099201
2020-12-03 07:19:47,209 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,209 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45520, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775723_1005, duration(ns): 182642564
2020-12-03 07:19:47,209 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,210 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40304, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775726_1005, duration(ns): 173577442
2020-12-03 07:19:47,212 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,215 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47594, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775720_1005, duration(ns): 210040417
2020-12-03 07:19:47,215 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,216 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41040, dest: /127.0.0.1:45744, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 241be1e6-4177-4c62-86a0-889e82446242, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775721_1005, duration(ns): 152268644
2020-12-03 07:19:47,216 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,225 [IPC Server handler 3 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775712_1006, replicas=127.0.0.1:35394, 127.0.0.1:42920, 127.0.0.1:45744, 127.0.0.1:38737, 127.0.0.1:46254, 127.0.0.1:35278, 127.0.0.1:44458, 127.0.0.1:38381, 127.0.0.1:45165 for /striped/stripedFileChecksum1
2020-12-03 07:19:47,237 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,239 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:50126 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775712_1006 src: /127.0.0.1:50126 dest: /127.0.0.1:35394
2020-12-03 07:19:47,239 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,242 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:38818 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775711_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775711_1006 src: /127.0.0.1:38818 dest: /127.0.0.1:42920
2020-12-03 07:19:47,244 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,247 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:41126 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775710_1006 src: /127.0.0.1:41126 dest: /127.0.0.1:45744
2020-12-03 07:19:47,247 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,265 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45620 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775709_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775709_1006 src: /127.0.0.1:45620 dest: /127.0.0.1:38737
2020-12-03 07:19:47,265 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,267 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,269 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53958 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775707_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775707_1006 src: /127.0.0.1:53958 dest: /127.0.0.1:35278
2020-12-03 07:19:47,271 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:52972 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775708_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775708_1006 src: /127.0.0.1:52972 dest: /127.0.0.1:46254
2020-12-03 07:19:47,281 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,287 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,288 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46210 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775706_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775706_1006 src: /127.0.0.1:46210 dest: /127.0.0.1:44458
2020-12-03 07:19:47,291 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,293 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46454 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775704_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775704_1006 src: /127.0.0.1:46454 dest: /127.0.0.1:45165
2020-12-03 07:19:47,305 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47704 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775705_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775705_1006 src: /127.0.0.1:47704 dest: /127.0.0.1:38381
2020-12-03 07:19:47,566 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46210, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775706_1006, duration(ns): 260994887
2020-12-03 07:19:47,566 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45620, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775709_1006, duration(ns): 298602676
2020-12-03 07:19:47,566 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,566 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53958, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775707_1006, duration(ns): 294806137
2020-12-03 07:19:47,566 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,573 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,577 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47704, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775705_1006, duration(ns): 261439226
2020-12-03 07:19:47,577 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46454, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775704_1006, duration(ns): 276692749
2020-12-03 07:19:47,577 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50126, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775712_1006, duration(ns): 324421255
2020-12-03 07:19:47,578 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,578 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38818, dest: /127.0.0.1:42920, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 771b196e-4591-4d5c-8e5a-de33229e6c5f, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775711_1006, duration(ns): 324258411
2020-12-03 07:19:47,578 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,579 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,579 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52972, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775708_1006, duration(ns): 294756151
2020-12-03 07:19:47,578 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41126, dest: /127.0.0.1:45744, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 241be1e6-4177-4c62-86a0-889e82446242, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775710_1006, duration(ns): 303577874
2020-12-03 07:19:47,578 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,582 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,582 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:47,588 [IPC Server handler 4 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775696_1007, replicas=127.0.0.1:38381, 127.0.0.1:44458, 127.0.0.1:35394, 127.0.0.1:39751, 127.0.0.1:46254, 127.0.0.1:38737, 127.0.0.1:45165, 127.0.0.1:45744, 127.0.0.1:35278 for /striped/stripedFileChecksum1
2020-12-03 07:19:47,599 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,599 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,601 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47776 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775696_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775696_1007 src: /127.0.0.1:47776 dest: /127.0.0.1:38381
2020-12-03 07:19:47,601 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46290 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775695_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775695_1007 src: /127.0.0.1:46290 dest: /127.0.0.1:44458
2020-12-03 07:19:47,602 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,606 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,607 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40514 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775693_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775693_1007 src: /127.0.0.1:40514 dest: /127.0.0.1:39751
2020-12-03 07:19:47,608 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:50232 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775694_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775694_1007 src: /127.0.0.1:50232 dest: /127.0.0.1:35394
2020-12-03 07:19:47,613 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,614 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,623 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53076 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775692_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775692_1007 src: /127.0.0.1:53076 dest: /127.0.0.1:46254
2020-12-03 07:19:47,624 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,626 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,626 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46544 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775690_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775690_1007 src: /127.0.0.1:46544 dest: /127.0.0.1:45165
2020-12-03 07:19:47,630 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:47,630 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:41242 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775689_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775689_1007 src: /127.0.0.1:41242 dest: /127.0.0.1:45744
2020-12-03 07:19:47,631 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:54066 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775688_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775688_1007 src: /127.0.0.1:54066 dest: /127.0.0.1:35278
2020-12-03 07:19:47,644 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45728 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775691_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775691_1007 src: /127.0.0.1:45728 dest: /127.0.0.1:38737
2020-12-03 07:19:48,101 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50232, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775694_1007, duration(ns): 483437450
2020-12-03 07:19:48,102 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41242, dest: /127.0.0.1:45744, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 241be1e6-4177-4c62-86a0-889e82446242, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775689_1007, duration(ns): 467687043
2020-12-03 07:19:48,102 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47776, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775696_1007, duration(ns): 499799389
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53076, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775692_1007, duration(ns): 474216503
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40514, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775693_1007, duration(ns): 492930352
2020-12-03 07:19:48,102 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45728, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775691_1007, duration(ns): 447676972
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,108 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46544, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775690_1007, duration(ns): 475041976
2020-12-03 07:19:48,103 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46290, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775695_1007, duration(ns): 496139447
2020-12-03 07:19:48,109 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,102 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54066, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775688_1007, duration(ns): 467189077
2020-12-03 07:19:48,109 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,109 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,121 [IPC Server handler 4 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775680_1008, replicas=127.0.0.1:44458, 127.0.0.1:35278, 127.0.0.1:35394, 127.0.0.1:39751, 127.0.0.1:46254, 127.0.0.1:38381, 127.0.0.1:45165, 127.0.0.1:42902, 127.0.0.1:38737 for /striped/stripedFileChecksum1
2020-12-03 07:19:48,128 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,129 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,130 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46492 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775680_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775680_1008 src: /127.0.0.1:46492 dest: /127.0.0.1:44458
2020-12-03 07:19:48,131 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:54252 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775679_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775679_1008 src: /127.0.0.1:54252 dest: /127.0.0.1:35278
2020-12-03 07:19:48,132 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,133 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:50436 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775678_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775678_1008 src: /127.0.0.1:50436 dest: /127.0.0.1:35394
2020-12-03 07:19:48,133 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,136 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40716 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775677_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775677_1008 src: /127.0.0.1:40716 dest: /127.0.0.1:39751
2020-12-03 07:19:48,137 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,138 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53282 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775676_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775676_1008 src: /127.0.0.1:53282 dest: /127.0.0.1:46254
2020-12-03 07:19:48,139 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,143 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47998 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775675_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775675_1008 src: /127.0.0.1:47998 dest: /127.0.0.1:38381
2020-12-03 07:19:48,159 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,161 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46780 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775674_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775674_1008 src: /127.0.0.1:46780 dest: /127.0.0.1:45165
2020-12-03 07:19:48,162 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,165 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:35022 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775673_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775673_1008 src: /127.0.0.1:35022 dest: /127.0.0.1:42902
2020-12-03 07:19:48,167 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,170 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:45978 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775672_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775672_1008 src: /127.0.0.1:45978 dest: /127.0.0.1:38737
2020-12-03 07:19:48,356 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40716, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775677_1008, duration(ns): 206043737
2020-12-03 07:19:48,357 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775677_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,357 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46780, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775674_1008, duration(ns): 193988484
2020-12-03 07:19:48,357 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45978, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775672_1008, duration(ns): 184028052
2020-12-03 07:19:48,357 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50436, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775678_1008, duration(ns): 220778166
2020-12-03 07:19:48,356 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46492, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775680_1008, duration(ns): 222353016
2020-12-03 07:19:48,357 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,357 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,358 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775678_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,358 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,358 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54252, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775679_1008, duration(ns): 225686500
2020-12-03 07:19:48,358 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775679_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,360 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35022, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775673_1008, duration(ns): 193377342
2020-12-03 07:19:48,360 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,361 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47998, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775675_1008, duration(ns): 204719084
2020-12-03 07:19:48,361 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775675_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,362 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53282, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775676_1008, duration(ns): 217206930
2020-12-03 07:19:48,364 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775676_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,367 [IPC Server handler 4 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775664_1009, replicas=127.0.0.1:39751, 127.0.0.1:46254, 127.0.0.1:42902, 127.0.0.1:45165, 127.0.0.1:35278, 127.0.0.1:38737, 127.0.0.1:38381, 127.0.0.1:42920, 127.0.0.1:35394 for /striped/stripedFileChecksum1
2020-12-03 07:19:48,375 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,377 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,378 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:40870 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775664_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775664_1009 src: /127.0.0.1:40870 dest: /127.0.0.1:39751
2020-12-03 07:19:48,379 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53432 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775663_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775663_1009 src: /127.0.0.1:53432 dest: /127.0.0.1:46254
2020-12-03 07:19:48,380 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,382 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,384 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,385 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46904 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775661_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775661_1009 src: /127.0.0.1:46904 dest: /127.0.0.1:45165
2020-12-03 07:19:48,385 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:35136 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775662_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775662_1009 src: /127.0.0.1:35136 dest: /127.0.0.1:42902
2020-12-03 07:19:48,387 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,388 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:54426 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775660_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775660_1009 src: /127.0.0.1:54426 dest: /127.0.0.1:35278
2020-12-03 07:19:48,388 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46098 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775659_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775659_1009 src: /127.0.0.1:46098 dest: /127.0.0.1:38737
2020-12-03 07:19:48,396 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,401 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,405 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:48170 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775658_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775658_1009 src: /127.0.0.1:48170 dest: /127.0.0.1:38381
2020-12-03 07:19:48,405 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:39314 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775657_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775657_1009 src: /127.0.0.1:39314 dest: /127.0.0.1:42920
2020-12-03 07:19:48,407 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:50628 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775656_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775656_1009 src: /127.0.0.1:50628 dest: /127.0.0.1:35394
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53432, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775663_1009, duration(ns): 209125482
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46098, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775659_1009, duration(ns): 194697119
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46904, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775661_1009, duration(ns): 204231291
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54426, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775660_1009, duration(ns): 200314680
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40870, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775664_1009, duration(ns): 211180432
2020-12-03 07:19:48,592 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,592 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50628, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775656_1009, duration(ns): 180141200
2020-12-03 07:19:48,592 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,592 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35136, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775662_1009, duration(ns): 204206548
2020-12-03 07:19:48,591 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,593 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,598 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39314, dest: /127.0.0.1:42920, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 771b196e-4591-4d5c-8e5a-de33229e6c5f, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775657_1009, duration(ns): 189973011
2020-12-03 07:19:48,598 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,602 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48170, dest: /127.0.0.1:38381, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 13e78348-374d-4e1d-9c71-0f826bf4629d, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775658_1009, duration(ns): 194550372
2020-12-03 07:19:48,602 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,612 [IPC Server handler 4 on default port 38468] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775648_1010, replicas=127.0.0.1:42920, 127.0.0.1:35278, 127.0.0.1:46254, 127.0.0.1:44458, 127.0.0.1:39751, 127.0.0.1:42902, 127.0.0.1:35394, 127.0.0.1:38737, 127.0.0.1:45165 for /striped/stripedFileChecksum1
2020-12-03 07:19:48,617 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,619 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:39410 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775648_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775648_1010 src: /127.0.0.1:39410 dest: /127.0.0.1:42920
2020-12-03 07:19:48,622 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,625 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,626 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,627 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:54542 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775647_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775647_1010 src: /127.0.0.1:54542 dest: /127.0.0.1:35278
2020-12-03 07:19:48,627 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46792 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775645_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775645_1010 src: /127.0.0.1:46792 dest: /127.0.0.1:44458
2020-12-03 07:19:48,628 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,630 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,631 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:35274 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775643_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775643_1010 src: /127.0.0.1:35274 dest: /127.0.0.1:42902
2020-12-03 07:19:48,634 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:41012 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775644_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775644_1010 src: /127.0.0.1:41012 dest: /127.0.0.1:39751
2020-12-03 07:19:48,637 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:53564 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775646_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775646_1010 src: /127.0.0.1:53564 dest: /127.0.0.1:46254
2020-12-03 07:19:48,644 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,645 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:46236 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775641_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775641_1010 src: /127.0.0.1:46236 dest: /127.0.0.1:38737
2020-12-03 07:19:48,645 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:50744 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775642_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775642_1010 src: /127.0.0.1:50744 dest: /127.0.0.1:35394
2020-12-03 07:19:48,646 [DataStreamer for file /striped/stripedFileChecksum1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:48,647 [DataXceiver for client DFSClient_NONMAPREDUCE_-421484687_1 at /127.0.0.1:47052 [Receiving block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775640_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775640_1010 src: /127.0.0.1:47052 dest: /127.0.0.1:45165
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46792, dest: /127.0.0.1:44458, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 6b9a1d03-2217-4bb4-85f0-4bc32ca81791, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775645_1010, duration(ns): 172383118
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54542, dest: /127.0.0.1:35278, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 728449f2-4f4d-4a15-aa4c-0c8f3086e81a, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775647_1010, duration(ns): 174075586
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39410, dest: /127.0.0.1:42920, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 771b196e-4591-4d5c-8e5a-de33229e6c5f, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775648_1010, duration(ns): 181832291
2020-12-03 07:19:48,804 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775647_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,804 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46236, dest: /127.0.0.1:38737, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: d591218b-badd-4bcd-8346-c3805ce14075, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775641_1010, duration(ns): 156702463
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41012, dest: /127.0.0.1:39751, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: eab78a87-0942-4d97-82b1-e000f7f2adbc, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775644_1010, duration(ns): 167124190
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50744, dest: /127.0.0.1:35394, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 978f49f7-d934-4a41-8259-c450192add09, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775642_1010, duration(ns): 149930433
2020-12-03 07:19:48,804 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,804 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,804 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35274, dest: /127.0.0.1:42902, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: fdc38d5a-a512-4b6d-82e2-0065e10facf5, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775643_1010, duration(ns): 170466984
2020-12-03 07:19:48,804 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47052, dest: /127.0.0.1:45165, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 81132b72-024a-499b-9534-f37df49d6b01, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775640_1010, duration(ns): 153494127
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53564, dest: /127.0.0.1:46254, bytes: 6291456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-421484687_1, offset: 0, srvID: 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0, blockid: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775646_1010, duration(ns): 158315817
2020-12-03 07:19:48,803 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775645_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,805 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775646_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,805 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,805 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775643_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,805 [PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775644_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:48,820 [IPC Server handler 4 on default port 38468] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /striped/stripedFileChecksum1 is closed by DFSClient_NONMAPREDUCE_-421484687_1
2020-12-03 07:19:48,834 [IPC Server handler 6 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,855 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-e03586cd-799a-4009-879e-2a01dbcc1778,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:48,937 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:extractChecksumProperties(430)) - set bytesPerCRC=512, crcPerBlock=12288
2020-12-03 07:19:48,937 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK]: blockChecksum=e199faa66ca34a63cc13e2c4448e3716, blockChecksumType=MD5CRC
2020-12-03 07:19:48,938 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39751,DS-713daf49-61b2-4dc4-8024-a0de6fc8e326,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-713daf49-61b2-4dc4-8024-a0de6fc8e326,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-809db8f8-d556-4081-8ed9-b31e740408b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-816cb48b-853e-4641-b6d6-bdee5b222ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-f39b7684-4dca-4f42-8a99-898e62e34395,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-6707b574-cb60-40c9-b999-0e2b495a7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-e6dcea4b-0326-42ee-aa5b-f044135f8802,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:48,961 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:39751,DS-713daf49-61b2-4dc4-8024-a0de6fc8e326,DISK]: blockChecksum=4b648ddfb75e52fc4ab8acf75e7116cf, blockChecksumType=MD5CRC
2020-12-03 07:19:48,962 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:39751,DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-e03586cd-799a-4009-879e-2a01dbcc1778,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:48,985 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:39751,DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc,DISK]: blockChecksum=67708555cca0bd9ee68540924fa61776, blockChecksumType=MD5CRC
2020-12-03 07:19:48,985 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35278,DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775744_1004; getBlockSize()=37748736; corrupt=false; offset=113246208; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-6707b574-cb60-40c9-b999-0e2b495a7f33,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-713daf49-61b2-4dc4-8024-a0de6fc8e326,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-f39b7684-4dca-4f42-8a99-898e62e34395,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,012 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:35278,DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708,DISK]: blockChecksum=4b0b124b13c998a25d246802f733b088, blockChecksumType=MD5CRC
2020-12-03 07:19:49,013 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45165,DS-e6dcea4b-0326-42ee-aa5b-f044135f8802,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775728_1005; getBlockSize()=37748736; corrupt=false; offset=150994944; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-e6dcea4b-0326-42ee-aa5b-f044135f8802,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-e03586cd-799a-4009-879e-2a01dbcc1778,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-816cb48b-853e-4641-b6d6-bdee5b222ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-809db8f8-d556-4081-8ed9-b31e740408b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK]]; indices=[0, 1, 2, 3, 4, 5, 6, 7, 8]}
2020-12-03 07:19:49,031 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(718)) - got reply from DatanodeInfoWithStorage[127.0.0.1:45165,DS-e6dcea4b-0326-42ee-aa5b-f044135f8802,DISK]: blockChecksum=51cd424ab95d87cdb83537c2851632ce, blockChecksumType=MD5CRC
2020-12-03 07:19:49,042 [IPC Server handler 7 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:49,053 [Thread-416] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,053 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4ae33a11] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,055 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e03586cd-799a-4009-879e-2a01dbcc1778) exiting.
2020-12-03 07:19:49,055 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-3b7beb7c-a04b-4e7e-bc8d-12f407236708) exiting.
2020-12-03 07:19:49,099 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fcbe147{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,104 [Thread-416] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@235f4c10{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,106 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@274872f8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,108 [Thread-416] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@569bf9eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,117 [Thread-416] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38428
2020-12-03 07:19:49,122 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,128 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,128 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 728449f2-4f4d-4a15-aa4c-0c8f3086e81a) service to localhost/127.0.0.1:38468
2020-12-03 07:19:49,128 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 728449f2-4f4d-4a15-aa4c-0c8f3086e81a)
2020-12-03 07:19:49,129 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:49,131 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,134 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,144 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,144 [Thread-416] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,145 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,145 [Thread-416] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,152 [Thread-416] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,154 [Thread-416] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:35278, removeBlocksFromBlockMap true
2020-12-03 07:19:49,158 [Thread-416] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:35278
2020-12-03 07:19:49,165 [IPC Server handler 3 on default port 38468] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/striped/stripedFileChecksum1	dst=null	perm=null	proto=rpc
2020-12-03 07:19:49,174 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,206 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,235 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,238 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,240 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,241 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,243 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,254 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[0]=DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,254 [DataXceiver for client /127.0.0.1:47548 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:47548 dst: /127.0.0.1:45165
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,260 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,273 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,275 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,277 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,280 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,282 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,284 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,290 [DataXceiver for client /127.0.0.1:47348 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:47348 dst: /127.0.0.1:44458
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,291 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[1]=DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,295 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,305 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,307 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,309 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,311 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,312 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,314 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,344 [DataXceiver for client /127.0.0.1:46796 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:46796 dst: /127.0.0.1:38737
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,345 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[2]=DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,348 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,359 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,361 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,367 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,379 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,388 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,406 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,410 [DataXceiver for client /127.0.0.1:35870 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:35870 dst: /127.0.0.1:42902
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,411 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[3]=DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,415 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,434 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,452 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,454 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,464 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,472 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,474 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,478 [DataXceiver for client /127.0.0.1:51390 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:51390 dst: /127.0.0.1:35394
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,496 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[4]=DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,507 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,534 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,538 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,611 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,625 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,631 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,636 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,650 [DataXceiver for client /127.0.0.1:48990 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:48990 dst: /127.0.0.1:38381
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,664 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[5]=DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,667 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,677 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,716 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,719 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,721 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,722 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,724 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,728 [DataXceiver for client /127.0.0.1:42512 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45744:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:42512 dst: /127.0.0.1:45744
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,729 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[6]=DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,731 [Thread-416] DEBUG hdfs.FileChecksumHelper (FileChecksumHelper.java:tryDatanode(698)) - write to DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]: BLOCK_GROUP_CHECKSUM, blockGroup=LocatedStripedBlock{BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-bfbd2513-c18e-4a24-824a-10a29dbfade0,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-48c46482-5cc2-4c39-93b8-21acd949cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-56ac4e85-2390-4531-8d9e-5c86ec942373,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ed54c4f4-675f-4f00-9d55-36749307cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
2020-12-03 07:19:49,746 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,748 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,750 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,753 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,757 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,758 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:49,763 [DataXceiver for client /127.0.0.1:54410 [Getting checksum for block groupBP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:46254:DataXceiver error processing BLOCK_GROUP_CHECKSUM operation  src: /127.0.0.1:54410 dst: /127.0.0.1:46254
java.lang.UnsupportedOperationException
	at java.nio.ByteBuffer.array(ByteBuffer.java:994)
	at org.apache.hadoop.hdfs.server.datanode.erasurecode.StripedBlockChecksumReconstructor.reconstruct(StripedBlockChecksumReconstructor.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.recalculateChecksum(BlockChecksumHelper.java:711)
	at org.apache.hadoop.hdfs.server.datanode.BlockChecksumHelper$BlockGroupNonStripedChecksumComputer.compute(BlockChecksumHelper.java:489)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockGroupChecksum(DataXceiver.java:1047)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opStripedBlockChecksum(Receiver.java:327)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:119)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,763 [Thread-416] WARN  hdfs.FileChecksumHelper (FileChecksumHelper.java:checksumBlockGroup(679)) - src=/striped/stripedFileChecksum1, datanodes[7]=DatanodeInfoWithStorage[127.0.0.1:46254,DS-91487303-6e14-4b85-83fe-85944ef4a63b,DISK]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.tryDatanode(FileChecksumHelper.java:709)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlockGroup(FileChecksumHelper.java:664)
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:638)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:19:49,767 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:19:49,769 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:19:49,770 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,770 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@44d70181] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,778 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-e6dcea4b-0326-42ee-aa5b-f044135f8802) exiting.
2020-12-03 07:19:49,778 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-bfbd2513-c18e-4a24-824a-10a29dbfade0) exiting.
2020-12-03 07:19:49,803 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1bf0f6f6{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,804 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@56bc3fac{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,805 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c09d180{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,806 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5fa05212{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,814 [DataXceiver for client  at /127.0.0.1:47566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,815 [DataXceiver for client  at /127.0.0.1:47566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,815 [DataXceiver for client  at /127.0.0.1:47566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47566
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,818 [DataXceiver for client  at /127.0.0.1:47620 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,819 [DataXceiver for client  at /127.0.0.1:47890 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,819 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46220
2020-12-03 07:19:49,819 [DataXceiver for client  at /127.0.0.1:47834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,818 [DataXceiver for client  at /127.0.0.1:47776 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,818 [DataXceiver for client  at /127.0.0.1:47700 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,818 [DataXceiver for client  at /127.0.0.1:47650 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,818 [DataXceiver for client  at /127.0.0.1:47598 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,838 [DataXceiver for client  at /127.0.0.1:47566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47566 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,819 [DataXceiver for client  at /127.0.0.1:47620 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,840 [DataXceiver for client  at /127.0.0.1:47620 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47620
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,840 [DataXceiver for client  at /127.0.0.1:47598 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,840 [DataXceiver for client  at /127.0.0.1:47598 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47598
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,841 [DataXceiver for client  at /127.0.0.1:47650 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,856 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,853 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,858 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,858 [DataXceiver for client  at /127.0.0.1:47700 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,858 [DataXceiver for client  at /127.0.0.1:47650 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47650
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,858 [DataXceiver for client  at /127.0.0.1:47620 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47620 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,858 [DataXceiver for client  at /127.0.0.1:47598 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47598 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,864 [DataXceiver for client  at /127.0.0.1:47650 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47650 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,864 [DataXceiver for client  at /127.0.0.1:47700 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47700
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,874 [DataXceiver for client  at /127.0.0.1:47700 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47700 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,864 [DataXceiver for client  at /127.0.0.1:47776 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,864 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 81132b72-024a-499b-9534-f37df49d6b01) service to localhost/127.0.0.1:38468
2020-12-03 07:19:49,880 [DataXceiver for client  at /127.0.0.1:47776 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47776
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,880 [DataXceiver for client  at /127.0.0.1:47834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,880 [DataXceiver for client  at /127.0.0.1:47776 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47776 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,880 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 81132b72-024a-499b-9534-f37df49d6b01)
2020-12-03 07:19:49,887 [DataXceiver for client  at /127.0.0.1:47834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47834
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,880 [DataXceiver for client  at /127.0.0.1:47890 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 on DS-bfbd2513-c18e-4a24-824a-10a29dbfade0, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,891 [DataXceiver for client  at /127.0.0.1:47834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47834 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,894 [DataXceiver for client  at /127.0.0.1:47890 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:45165, datanodeUuid=81132b72-024a-499b-9534-f37df49d6b01, infoPort=45398, infoSecurePort=0, ipcPort=46220, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001 to /127.0.0.1:47890
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,891 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:49,903 [DataXceiver for client  at /127.0.0.1:47890 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45165:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47890 dst: /127.0.0.1:45165
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,910 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,918 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,923 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,926 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,927 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,929 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,933 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,934 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:19:49,934 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,934 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@777c9dc9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,936 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-56ac4e85-2390-4531-8d9e-5c86ec942373) exiting.
2020-12-03 07:19:49,937 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-cb81a93f-4e60-47fa-96d7-e823f5de7c05) exiting.
2020-12-03 07:19:49,961 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e1162e7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,962 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@79c3f01f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,963 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b0f7d9d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,963 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@9fecdf1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51306 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51600 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43741
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51496 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51422 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51378 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51284 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,965 [DataXceiver for client  at /127.0.0.1:51328 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,971 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,971 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,971 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,969 [DataXceiver for client  at /127.0.0.1:51306 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,975 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 978f49f7-d934-4a41-8259-c450192add09) service to localhost/127.0.0.1:38468
2020-12-03 07:19:49,979 [DataXceiver for client  at /127.0.0.1:51306 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51306
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,979 [DataXceiver for client  at /127.0.0.1:51328 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,980 [DataXceiver for client  at /127.0.0.1:51306 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51306 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,979 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 978f49f7-d934-4a41-8259-c450192add09)
2020-12-03 07:19:49,983 [DataXceiver for client  at /127.0.0.1:51328 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51328
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,980 [DataXceiver for client  at /127.0.0.1:51284 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:49,992 [DataXceiver for client  at /127.0.0.1:51328 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51328 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,995 [DataXceiver for client  at /127.0.0.1:51284 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51284
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:49,993 [DataXceiver for client  at /127.0.0.1:51378 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,001 [DataXceiver for client  at /127.0.0.1:51284 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51284 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,013 [DataXceiver for client  at /127.0.0.1:51378 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51378
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,001 [DataXceiver for client  at /127.0.0.1:51422 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,020 [DataXceiver for client  at /127.0.0.1:51566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,022 [DataXceiver for client  at /127.0.0.1:51422 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51422
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,020 [DataXceiver for client  at /127.0.0.1:51378 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51378 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,022 [DataXceiver for client  at /127.0.0.1:51422 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51422 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,022 [DataXceiver for client  at /127.0.0.1:51566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51566
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,022 [DataXceiver for client  at /127.0.0.1:51496 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,029 [DataXceiver for client  at /127.0.0.1:51566 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51566 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,031 [DataXceiver for client  at /127.0.0.1:51496 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51496
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,029 [DataXceiver for client  at /127.0.0.1:51600 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 on DS-56ac4e85-2390-4531-8d9e-5c86ec942373, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,037 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,039 [DataXceiver for client  at /127.0.0.1:51600 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:35394, datanodeUuid=978f49f7-d934-4a41-8259-c450192add09, infoPort=41353, infoSecurePort=0, ipcPort=43741, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001 to /127.0.0.1:51600
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,037 [DataXceiver for client  at /127.0.0.1:51496 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51496 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,039 [DataXceiver for client  at /127.0.0.1:51600 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35394:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:51600 dst: /127.0.0.1:35394
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,047 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,056 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,056 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,057 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,059 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,059 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,063 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,063 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:19:50,064 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,064 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a8b5227] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,066 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-91487303-6e14-4b85-83fe-85944ef4a63b) exiting.
2020-12-03 07:19:50,066 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-16a8192b-cdfe-4ddd-aad6-333fefea2b8d) exiting.
2020-12-03 07:19:50,090 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6e0d4a8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,091 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@64d7b720{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,091 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@38d5b107{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,091 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27f0ad19{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,093 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37513
2020-12-03 07:19:50,094 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,094 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,098 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,098 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,099 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 7c367df7-70ba-4c3d-8a7d-f3b8508a09d0)
2020-12-03 07:19:50,099 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,108 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,111 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,129 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,129 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,132 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,132 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,137 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,138 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:19:50,138 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,138 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3d829787] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,141 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-54c0a6ee-a35f-4147-a35b-fb6ee7ff1296) exiting.
2020-12-03 07:19:50,142 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-816cb48b-853e-4641-b6d6-bdee5b222ce4) exiting.
2020-12-03 07:19:50,160 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3fcdcf{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,161 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7668d560{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,161 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a1d3c1a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,162 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d71adc2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,163 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38382
2020-12-03 07:19:50,166 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,166 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,166 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,170 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 771b196e-4591-4d5c-8e5a-de33229e6c5f) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,170 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 771b196e-4591-4d5c-8e5a-de33229e6c5f)
2020-12-03 07:19:50,170 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,172 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,172 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,181 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,182 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,185 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,185 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,191 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,191 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:19:50,191 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,192 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3f3c966c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,201 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ed54c4f4-675f-4f00-9d55-36749307cf06) exiting.
2020-12-03 07:19:50,201 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-809db8f8-d556-4081-8ed9-b31e740408b3) exiting.
2020-12-03 07:19:50,221 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58cd06cb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,221 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3be8821f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,222 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63a5e46c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,222 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@437e951d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,224 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41097
2020-12-03 07:19:50,226 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,226 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,226 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,226 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 241be1e6-4177-4c62-86a0-889e82446242) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,227 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 241be1e6-4177-4c62-86a0-889e82446242)
2020-12-03 07:19:50,231 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,233 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,238 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,246 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,247 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,250 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,250 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,259 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,260 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:19:50,260 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,260 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2b27cc70] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-6707b574-cb60-40c9-b999-0e2b495a7f33) exiting.
2020-12-03 07:19:50,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef) exiting.
2020-12-03 07:19:50,357 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@10ad20cb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,358 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7dd712e8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,358 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6754ef00{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,359 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7674a051{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,361 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43738
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:46848 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:46810 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:46766 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:46900 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:46972 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,387 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid d591218b-badd-4bcd-8346-c3805ce14075) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,387 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid d591218b-badd-4bcd-8346-c3805ce14075)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:47082 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:46788 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,363 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,362 [DataXceiver for client  at /127.0.0.1:46848 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,388 [DataXceiver for client  at /127.0.0.1:46848 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:46848
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,361 [DataXceiver for client  at /127.0.0.1:47046 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,411 [DataXceiver for client  at /127.0.0.1:46848 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:46848 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,411 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,394 [DataXceiver for client  at /127.0.0.1:46788 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,424 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,424 [DataXceiver for client  at /127.0.0.1:46788 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:46788
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,424 [DataXceiver for client  at /127.0.0.1:47082 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,427 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,434 [DataXceiver for client  at /127.0.0.1:47082 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:47082
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,434 [DataXceiver for client  at /127.0.0.1:46972 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,434 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,434 [DataXceiver for client  at /127.0.0.1:46788 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:46788 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,438 [DataXceiver for client  at /127.0.0.1:46972 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:46972
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,435 [DataXceiver for client  at /127.0.0.1:46900 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,435 [DataXceiver for client  at /127.0.0.1:47082 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47082 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,434 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,461 [DataXceiver for client  at /127.0.0.1:46900 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:46900
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,461 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,461 [DataXceiver for client  at /127.0.0.1:46766 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,472 [DataXceiver for client  at /127.0.0.1:46810 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,473 [DataXceiver for client  at /127.0.0.1:47046 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 on DS-fc0f5be6-3d82-4c3f-94fa-1ab567efaaef, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,473 [DataXceiver for client  at /127.0.0.1:47046 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:47046
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,473 [DataXceiver for client  at /127.0.0.1:47046 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47046 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,450 [DataXceiver for client  at /127.0.0.1:46972 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:46972 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,473 [DataXceiver for client  at /127.0.0.1:46810 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:46810
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,472 [DataXceiver for client  at /127.0.0.1:46766 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38737, datanodeUuid=d591218b-badd-4bcd-8346-c3805ce14075, infoPort=38841, infoSecurePort=0, ipcPort=43738, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001 to /127.0.0.1:46766
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,469 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,469 [DataXceiver for client  at /127.0.0.1:46900 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:46900 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,462 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,512 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:19:50,512 [DataXceiver for client  at /127.0.0.1:46766 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:46766 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,508 [DataXceiver for client  at /127.0.0.1:46810 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38737:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:46810 dst: /127.0.0.1:38737
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,517 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@50b8ae8d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,517 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,522 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-713daf49-61b2-4dc4-8024-a0de6fc8e326) exiting.
2020-12-03 07:19:50,522 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-d5aa525b-e716-4d4f-b52b-3c13b258ccdc) exiting.
2020-12-03 07:19:50,540 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c321bdb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,541 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24855019{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,542 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62c5bbdc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,542 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a7b503d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,543 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39279
2020-12-03 07:19:50,545 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,545 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,545 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,545 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid eab78a87-0942-4d97-82b1-e000f7f2adbc) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,553 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid eab78a87-0942-4d97-82b1-e000f7f2adbc)
2020-12-03 07:19:50,553 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,554 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,564 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,568 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,568 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,572 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,572 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,579 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,580 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:19:50,580 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,580 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@324dcd31] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,585 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-48c46482-5cc2-4c39-93b8-21acd949cfdb) exiting.
2020-12-03 07:19:50,585 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-e1c619ad-d0b3-4ffb-b37a-2a306bb916a1) exiting.
2020-12-03 07:19:50,604 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@588ab592{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,605 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c8b96ec{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,605 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27f9e982{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,605 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ecf9fb3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,607 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41789
2020-12-03 07:19:50,612 [DataXceiver for client  at /127.0.0.1:35952 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,607 [DataXceiver for client  at /127.0.0.1:35902 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,607 [DataXceiver for client  at /127.0.0.1:35840 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,607 [DataXceiver for client  at /127.0.0.1:36024 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,607 [DataXceiver for client  at /127.0.0.1:36098 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,607 [DataXceiver for client  at /127.0.0.1:36134 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,607 [DataXceiver for client  at /127.0.0.1:35818 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,618 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,617 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,617 [DataXceiver for client  at /127.0.0.1:35952 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,620 [DataXceiver for client  at /127.0.0.1:35818 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,620 [DataXceiver for client  at /127.0.0.1:35818 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:35818
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,617 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,625 [DataXceiver for client  at /127.0.0.1:35818 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:35818 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,620 [DataXceiver for client  at /127.0.0.1:35952 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:35952
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,620 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid fdc38d5a-a512-4b6d-82e2-0065e10facf5) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,632 [DataXceiver for client  at /127.0.0.1:36134 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,644 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid fdc38d5a-a512-4b6d-82e2-0065e10facf5)
2020-12-03 07:19:50,644 [DataXceiver for client  at /127.0.0.1:35952 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:35952 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,644 [DataXceiver for client  at /127.0.0.1:36134 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:36134
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,644 [DataXceiver for client  at /127.0.0.1:36098 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:36134 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:36134 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,653 [DataXceiver for client  at /127.0.0.1:36098 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:36098
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,650 [DataXceiver for client  at /127.0.0.1:36024 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,659 [DataXceiver for client  at /127.0.0.1:36098 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:36098 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,663 [DataXceiver for client  at /127.0.0.1:36024 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:36024
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,659 [DataXceiver for client  at /127.0.0.1:35840 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,669 [DataXceiver for client  at /127.0.0.1:36024 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:36024 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,673 [DataXceiver for client  at /127.0.0.1:35840 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:35840
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,673 [DataXceiver for client  at /127.0.0.1:35902 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 on DS-48c46482-5cc2-4c39-93b8-21acd949cfdb, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,679 [DataXceiver for client  at /127.0.0.1:35840 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:35840 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,680 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,710 [DataXceiver for client  at /127.0.0.1:35902 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:42902, datanodeUuid=fdc38d5a-a512-4b6d-82e2-0065e10facf5, infoPort=43976, infoSecurePort=0, ipcPort=41789, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001 to /127.0.0.1:35902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,711 [DataXceiver for client  at /127.0.0.1:35902 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:42902:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:35902 dst: /127.0.0.1:42902
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,717 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,720 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,743 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,743 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,747 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,763 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,785 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,785 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:19:50,786 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,786 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77b7ffa4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,791 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894) exiting.
2020-12-03 07:19:50,791 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f016ee71-a6a7-45ae-a516-e6bcf98eced7) exiting.
2020-12-03 07:19:50,807 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5528a42c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,808 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a551a63{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,809 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@210386e0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,809 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@425357dd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,810 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39168
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47538 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47652 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47420 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47472 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47610 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47360 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47382 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,810 [DataXceiver for client  at /127.0.0.1:47338 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,811 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,811 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,811 [DataXceiver for client  at /127.0.0.1:47538 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,811 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,813 [DataXceiver for client  at /127.0.0.1:47338 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,813 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 6b9a1d03-2217-4bb4-85f0-4bc32ca81791) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,813 [DataXceiver for client  at /127.0.0.1:47382 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,813 [DataXceiver for client  at /127.0.0.1:47338 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47338
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,813 [DataXceiver for client  at /127.0.0.1:47538 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47538
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,819 [DataXceiver for client  at /127.0.0.1:47382 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47382
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,819 [DataXceiver for client  at /127.0.0.1:47360 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,819 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 6b9a1d03-2217-4bb4-85f0-4bc32ca81791)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47360 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47360
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47610 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47382 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47382 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47338 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47338 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47538 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47538 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47610 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47610
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47472 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,843 [DataXceiver for client  at /127.0.0.1:47610 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47610 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,825 [DataXceiver for client  at /127.0.0.1:47360 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47360 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,844 [DataXceiver for client  at /127.0.0.1:47472 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47472
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,844 [DataXceiver for client  at /127.0.0.1:47420 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,857 [DataXceiver for client  at /127.0.0.1:47472 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47472 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,858 [DataXceiver for client  at /127.0.0.1:47420 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47420
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,857 [DataXceiver for client  at /127.0.0.1:47652 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 on DS-de84284c-5266-4eaa-8cf2-9c2f43cc2894, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,865 [DataXceiver for client  at /127.0.0.1:47420 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47420 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,865 [DataXceiver for client  at /127.0.0.1:47652 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:44458, datanodeUuid=6b9a1d03-2217-4bb4-85f0-4bc32ca81791, infoPort=36494, infoSecurePort=0, ipcPort=39168, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001 to /127.0.0.1:47652
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,865 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:50,876 [DataXceiver for client  at /127.0.0.1:47652 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:44458:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:47652 dst: /127.0.0.1:44458
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,885 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,885 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,888 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,889 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,893 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,893 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,894 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,894 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:19:50,894 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,894 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2449cff7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,898 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f39b7684-4dca-4f42-8a99-898e62e34395) exiting.
2020-12-03 07:19:50,898 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926) exiting.
2020-12-03 07:19:50,918 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@615f972{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,919 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@285f09de{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,919 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@408b35bf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,919 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71e9a896{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,921 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40838
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:48878 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:49118 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:49150 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:48856 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:49050 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:48834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:48934 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,921 [DataXceiver for client  at /127.0.0.1:48974 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (BlockSender.java:sendPacket(675)) - BlockSender.sendChunks() exception: 
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,922 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,922 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,922 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,922 [DataXceiver for client  at /127.0.0.1:48878 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,947 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 13e78348-374d-4e1d-9c71-0f826bf4629d) service to localhost/127.0.0.1:38468
2020-12-03 07:19:50,953 [DataXceiver for client  at /127.0.0.1:48974 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,954 [DataXceiver for client  at /127.0.0.1:48878 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:48878
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,954 [DataXceiver for client  at /127.0.0.1:48974 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:48974
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,954 [DataXceiver for client  at /127.0.0.1:48934 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,959 [DataXceiver for client  at /127.0.0.1:48974 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48974 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,959 [DataXceiver for client  at /127.0.0.1:48878 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48878 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,959 [DataXceiver for client  at /127.0.0.1:48934 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:48934
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,959 [DataXceiver for client  at /127.0.0.1:48834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,973 [DataXceiver for client  at /127.0.0.1:48934 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48934 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,973 [DataXceiver for client  at /127.0.0.1:48834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:48834
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,973 [DataXceiver for client  at /127.0.0.1:49050 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,979 [DataXceiver for client  at /127.0.0.1:48856 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:50,979 [DataXceiver for client  at /127.0.0.1:48834 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48834 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,979 [DataXceiver for client  at /127.0.0.1:49050 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:49050
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,980 [DataXceiver for client  at /127.0.0.1:48856 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:48856
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:50,979 [DataXceiver for client  at /127.0.0.1:49150 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:51,022 [DataXceiver for client  at /127.0.0.1:48856 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:48856 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:51,022 [DataXceiver for client  at /127.0.0.1:49050 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49050 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:51,022 [DataXceiver for client  at /127.0.0.1:49150 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:49150
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:51,022 [DataXceiver for client  at /127.0.0.1:49118 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] INFO  datanode.BlockScanner (BlockScanner.java:markSuspectBlock(342)) - Not scanning suspicious block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 on DS-d3a8257f-c2fb-4cec-8c53-6eb59758a926, because there is no volume scanner for that storageId.
2020-12-03 07:19:51,023 [DataXceiver for client  at /127.0.0.1:49150 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49150 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:51,023 [DataXceiver for client  at /127.0.0.1:49118 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] WARN  datanode.DataNode (DataXceiver.java:readBlock(646)) - DatanodeRegistration(127.0.0.1:38381, datanodeUuid=13e78348-374d-4e1d-9c71-0f826bf4629d, infoPort=46751, infoSecurePort=0, ipcPort=40838, storageInfo=lv=-57;cid=testClusterID;nsid=1644253551;c=1606979969588):Got exception while serving BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001 to /127.0.0.1:49118
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:51,023 [DataXceiver for client  at /127.0.0.1:49118 [Sending block BP-1138391729-172.17.0.4-1606979969588:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38381:DataXceiver error processing READ_BLOCK operation  src: /127.0.0.1:49118 dst: /127.0.0.1:38381
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 480000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:245)
	at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:172)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:220)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:637)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:829)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:776)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:610)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:152)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:104)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:51,060 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1138391729-172.17.0.4-1606979969588 (Datanode Uuid 13e78348-374d-4e1d-9c71-0f826bf4629d)
2020-12-03 07:19:51,060 [BP-1138391729-172.17.0.4-1606979969588 heartbeating to localhost/127.0.0.1:38468] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1138391729-172.17.0.4-1606979969588
2020-12-03 07:19:51,061 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:51,062 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1138391729-172.17.0.4-1606979969588] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:51,066 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:51,066 [Listener at localhost/46220] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:51,069 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:51,069 [Listener at localhost/46220] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:51,070 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:51,070 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:19:51,070 [Listener at localhost/46220] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:19:51,070 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38428
2020-12-03 07:19:51,071 [Listener at localhost/46220] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-728449f2-4f4d-4a15-aa4c-0c8f3086e81a
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-728449f2-4f4d-4a15-aa4c-0c8f3086e81a
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.TestFileChecksum.tearDown(TestFileChecksum.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:19:51,071 [Listener at localhost/46220] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:19:51,072 [Listener at localhost/46220] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:19:51,072 [Listener at localhost/46220] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:19:51,074 [Listener at localhost/46220] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:19:51,075 [Listener at localhost/46220] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:19:51,080 [Listener at localhost/46220] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:51,080 [Listener at localhost/46220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:51,081 [Listener at localhost/46220] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:51,081 [Listener at localhost/46220] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 36
2020-12-03 07:19:51,081 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@150ab4ed] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:19:51,082 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@a8c1f44] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:19:51,082 [Listener at localhost/46220] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 37 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 11 Number of syncs: 27 SyncTimes(ms): 2 2 
2020-12-03 07:19:51,620 [Listener at localhost/46220] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000037
2020-12-03 07:19:51,643 [Listener at localhost/46220] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000037
2020-12-03 07:19:51,644 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:19:51,644 [CacheReplicationMonitor(609079010)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:19:51,656 [Listener at localhost/46220] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38468
2020-12-03 07:19:51,657 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:51,657 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:51,658 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:51,658 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:51,711 [Listener at localhost/46220] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:51,711 [Listener at localhost/46220] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:51,713 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@62833051{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:51,714 [Listener at localhost/46220] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fc4780b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:51,714 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24c1b2d2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:51,714 [Listener at localhost/46220] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b66c0fb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
msx-rc 1
