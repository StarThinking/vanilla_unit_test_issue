2020-12-03 07:22:49,393 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-12-03 07:22:50,230 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:50,249 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:50,251 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:50,251 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:50,278 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:50,278 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:50,279 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:50,280 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:50,335 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:50,341 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:50,342 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:50,342 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:50,349 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:50,350 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:50
2020-12-03 07:22:50,353 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:50,355 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:50,358 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:50,359 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:50,384 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:50,384 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:50,394 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:50,395 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:50,395 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:50,395 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:50,396 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:50,397 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:50,397 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:50,397 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:50,398 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:50,398 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:50,398 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:50,440 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:50,440 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:50,441 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:50,441 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:50,458 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:50,458 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:50,459 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:50,459 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:50,465 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:50,466 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:50,466 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:50,467 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:50,473 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: true, skipCaptureAccessTimeOnlyChange: true, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:50,476 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:50,483 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:50,484 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:50,484 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:50,484 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:50,495 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:50,496 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:50,496 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:50,501 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:50,501 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:50,504 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:50,504 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:50,505 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:50,505 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:50,544 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:50,669 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:50,786 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:50,825 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:50,825 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:50,996 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:50,996 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:51,065 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:51,071 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:51,201 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:51,457 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:51,458 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:51,494 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:51,550 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b03b9fe] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:51,576 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:51,582 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:51,598 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3404ms
2020-12-03 07:22:51,752 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:51,758 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:51,759 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:51,772 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:51,776 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:51,776 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:51,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:51,812 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:51,812 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:51,824 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42166
2020-12-03 07:22:51,827 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:51,891 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4dc27487{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:51,893 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dfd3c81{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:51,952 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6692b6c6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:51,965 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7354b8c5{HTTP/1.1,[http/1.1]}{localhost:42166}
2020-12-03 07:22:51,966 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3772ms
2020-12-03 07:22:51,983 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:51,984 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:51,984 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:51,985 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:51,985 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:51,985 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:51,986 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:51,986 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:51,987 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:51,988 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:51,988 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:51,989 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:51,990 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:51
2020-12-03 07:22:51,990 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:51,990 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:51,990 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:51,991 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:51,996 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:51,996 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:51,997 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:51,997 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:51,997 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:51,998 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:51,998 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:51,998 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:51,998 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:51,999 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:51,999 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:51,999 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:51,999 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:52,000 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:52,000 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,001 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:52,001 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:52,004 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:52,004 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:52,004 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:52,005 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:52,005 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: true, skipCaptureAccessTimeOnlyChange: true, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:52,005 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:52,005 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:52,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:52,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:52,008 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:52,008 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:52,008 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:52,008 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:52,009 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:52,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:52,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:52,019 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:52,074 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:52,108 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:52,112 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:52,113 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:52,114 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:52,114 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:52,149 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:52,157 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:52,158 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:52,163 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:52,164 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:52,253 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:52,253 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 229 msecs
2020-12-03 07:22:52,454 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:52,496 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:52,511 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:52,794 [Listener at localhost/38499] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38499 to access this namenode/service.
2020-12-03 07:22:52,798 [Listener at localhost/38499] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:52,820 [Listener at localhost/38499] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:52,839 [Listener at localhost/38499] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:52,840 [Listener at localhost/38499] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:52,840 [Listener at localhost/38499] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:52,841 [Listener at localhost/38499] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:52,847 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:52,847 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:52,847 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:52,847 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:52,848 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:52,848 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:22:52,887 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:52,892 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:52,914 [Listener at localhost/38499] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38499
2020-12-03 07:22:52,919 [Listener at localhost/38499] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:52,919 [Listener at localhost/38499] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:52,944 [Listener at localhost/38499] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 24 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:52,949 [CacheReplicationMonitor(700462778)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:52,961 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:53,036 [Listener at localhost/38499] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:53,056 [Listener at localhost/38499] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:53,076 [Listener at localhost/38499] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:53,081 [Listener at localhost/38499] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:53,084 [Listener at localhost/38499] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:53,090 [Listener at localhost/38499] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:53,091 [Listener at localhost/38499] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:53,096 [Listener at localhost/38499] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:53,103 [Listener at localhost/38499] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46064
2020-12-03 07:22:53,105 [Listener at localhost/38499] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:53,105 [Listener at localhost/38499] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:53,131 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:53,133 [Listener at localhost/38499] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:53,134 [Listener at localhost/38499] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:53,135 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:53,138 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:53,140 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:53,140 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:53,141 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:53,146 [Listener at localhost/38499] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39861
2020-12-03 07:22:53,146 [Listener at localhost/38499] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:53,149 [Listener at localhost/38499] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@675d8c96{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:53,150 [Listener at localhost/38499] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ed3b1f5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:53,160 [Listener at localhost/38499] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7c351808{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:53,162 [Listener at localhost/38499] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@180e6ac4{HTTP/1.1,[http/1.1]}{localhost:39861}
2020-12-03 07:22:53,163 [Listener at localhost/38499] INFO  server.Server (Server.java:doStart(419)) - Started @4969ms
2020-12-03 07:22:53,494 [Listener at localhost/38499] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39413
2020-12-03 07:22:53,496 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1494b84d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:53,498 [Listener at localhost/38499] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:53,498 [Listener at localhost/38499] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:53,736 [Listener at localhost/38499] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:53,737 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:53,770 [Listener at localhost/33109] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33109
2020-12-03 07:22:53,792 [Listener at localhost/33109] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:53,794 [Listener at localhost/33109] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:53,809 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38499 starting to offer service
2020-12-03 07:22:53,817 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:53,818 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:53,843 [Listener at localhost/33109] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:53,851 [Listener at localhost/33109] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:53,852 [Listener at localhost/33109] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:53,869 [Listener at localhost/33109] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:53,870 [Listener at localhost/33109] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:53,870 [Listener at localhost/33109] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:53,871 [Listener at localhost/33109] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:53,872 [Listener at localhost/33109] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:53,872 [Listener at localhost/33109] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:53,873 [Listener at localhost/33109] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36537
2020-12-03 07:22:53,874 [Listener at localhost/33109] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:53,874 [Listener at localhost/33109] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:53,889 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:53,892 [Listener at localhost/33109] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:53,900 [Listener at localhost/33109] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:53,901 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:53,904 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:53,906 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:53,906 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:53,906 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:53,908 [Listener at localhost/33109] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44706
2020-12-03 07:22:53,908 [Listener at localhost/33109] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:53,912 [Listener at localhost/33109] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70d2e40b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:53,913 [Listener at localhost/33109] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a0e1b5e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:53,921 [Listener at localhost/33109] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@fac80{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:53,922 [Listener at localhost/33109] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@726386ed{HTTP/1.1,[http/1.1]}{localhost:44706}
2020-12-03 07:22:53,923 [Listener at localhost/33109] INFO  server.Server (Server.java:doStart(419)) - Started @5730ms
2020-12-03 07:22:54,000 [Listener at localhost/33109] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33118
2020-12-03 07:22:54,001 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@14bb2297] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:54,001 [Listener at localhost/33109] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:54,001 [Listener at localhost/33109] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:54,002 [Listener at localhost/33109] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:54,004 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:54,010 [Listener at localhost/46430] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46430
2020-12-03 07:22:54,017 [Listener at localhost/46430] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:54,018 [Listener at localhost/46430] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:54,019 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38499 starting to offer service
2020-12-03 07:22:54,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:54,027 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:54,036 [Listener at localhost/46430] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:54,038 [Listener at localhost/46430] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:54,038 [Listener at localhost/46430] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:54,040 [Listener at localhost/46430] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:54,041 [Listener at localhost/46430] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:54,041 [Listener at localhost/46430] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:54,041 [Listener at localhost/46430] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:54,042 [Listener at localhost/46430] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:54,042 [Listener at localhost/46430] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:54,043 [Listener at localhost/46430] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34511
2020-12-03 07:22:54,043 [Listener at localhost/46430] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:54,043 [Listener at localhost/46430] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:54,045 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:54,047 [Listener at localhost/46430] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:54,048 [Listener at localhost/46430] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:54,049 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:54,051 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:54,055 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:54,055 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:54,056 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:54,057 [Listener at localhost/46430] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36755
2020-12-03 07:22:54,057 [Listener at localhost/46430] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:54,060 [Listener at localhost/46430] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70e0accd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:54,061 [Listener at localhost/46430] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ab72419{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:54,069 [Listener at localhost/46430] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@51684e4a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:54,070 [Listener at localhost/46430] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ce1f601{HTTP/1.1,[http/1.1]}{localhost:36755}
2020-12-03 07:22:54,070 [Listener at localhost/46430] INFO  server.Server (Server.java:doStart(419)) - Started @5877ms
2020-12-03 07:22:54,099 [Listener at localhost/46430] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41263
2020-12-03 07:22:54,100 [Listener at localhost/46430] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:54,100 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e886a5b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:54,100 [Listener at localhost/46430] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:54,101 [Listener at localhost/46430] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:54,102 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:54,107 [Listener at localhost/46386] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46386
2020-12-03 07:22:54,114 [Listener at localhost/46386] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:54,115 [Listener at localhost/46386] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:54,116 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38499 starting to offer service
2020-12-03 07:22:54,117 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:54,117 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:54,226 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38499
2020-12-03 07:22:54,226 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38499
2020-12-03 07:22:54,226 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38499
2020-12-03 07:22:54,228 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:54,228 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:54,228 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:54,296 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:54,296 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:54,296 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:54,299 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1498337845. Formatting...
2020-12-03 07:22:54,299 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1498337845. Formatting...
2020-12-03 07:22:54,299 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1498337845. Formatting...
2020-12-03 07:22:54,302 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:54,302 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-56229615-8750-471e-8bd1-05a9f20ec6e3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:54,302 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5d798812-e27d-4202-95c6-ae08fb78842d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:54,434 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:54,434 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:54,435 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1498337845. Formatting...
2020-12-03 07:22:54,435 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1498337845. Formatting...
2020-12-03 07:22:54,435 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:54,435 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:54,435 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d3986514-fbea-4b97-9a2a-6ab349396662 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:54,436 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1498337845. Formatting...
2020-12-03 07:22:54,436 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:54,523 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,523 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,524 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,524 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,524 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-2001890259-172.17.0.3-1606980170531 is not formatted. Formatting ...
2020-12-03 07:22:54,524 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2001890259-172.17.0.3-1606980170531 is not formatted. Formatting ...
2020-12-03 07:22:54,524 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001890259-172.17.0.3-1606980170531 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001890259-172.17.0.3-1606980170531/current
2020-12-03 07:22:54,524 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001890259-172.17.0.3-1606980170531 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001890259-172.17.0.3-1606980170531/current
2020-12-03 07:22:54,529 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,530 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,530 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-2001890259-172.17.0.3-1606980170531 is not formatted. Formatting ...
2020-12-03 07:22:54,530 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001890259-172.17.0.3-1606980170531 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001890259-172.17.0.3-1606980170531/current
2020-12-03 07:22:54,630 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,638 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:54,639 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:54,676 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,677 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,677 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-2001890259-172.17.0.3-1606980170531 is not formatted. Formatting ...
2020-12-03 07:22:54,678 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001890259-172.17.0.3-1606980170531 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001890259-172.17.0.3-1606980170531/current
2020-12-03 07:22:54,678 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,682 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,683 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2001890259-172.17.0.3-1606980170531 is not formatted. Formatting ...
2020-12-03 07:22:54,683 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001890259-172.17.0.3-1606980170531 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001890259-172.17.0.3-1606980170531/current
2020-12-03 07:22:54,681 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,684 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:54,684 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-2001890259-172.17.0.3-1606980170531 is not formatted. Formatting ...
2020-12-03 07:22:54,685 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001890259-172.17.0.3-1606980170531 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001890259-172.17.0.3-1606980170531/current
2020-12-03 07:22:54,741 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,743 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:54,743 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:54,804 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1498337845;bpid=BP-2001890259-172.17.0.3-1606980170531;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1498337845;c=1606980170531;bpid=BP-2001890259-172.17.0.3-1606980170531;dnuuid=null
2020-12-03 07:22:54,837 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1498337845;bpid=BP-2001890259-172.17.0.3-1606980170531;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1498337845;c=1606980170531;bpid=BP-2001890259-172.17.0.3-1606980170531;dnuuid=null
2020-12-03 07:22:54,837 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1498337845;bpid=BP-2001890259-172.17.0.3-1606980170531;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1498337845;c=1606980170531;bpid=BP-2001890259-172.17.0.3-1606980170531;dnuuid=null
2020-12-03 07:22:54,845 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,846 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:54,847 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:54,949 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,950 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:54,950 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:54,975 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:55,009 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:22:55,009 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:55,052 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,053 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:55,054 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:55,123 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b
2020-12-03 07:22:55,123 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:55,126 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e
2020-12-03 07:22:55,126 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:55,123 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-56229615-8750-471e-8bd1-05a9f20ec6e3
2020-12-03 07:22:55,127 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:55,129 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d3986514-fbea-4b97-9a2a-6ab349396662
2020-12-03 07:22:55,130 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:55,154 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5d798812-e27d-4202-95c6-ae08fb78842d
2020-12-03 07:22:55,155 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:55,173 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,174 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:55,174 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:55,174 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52
2020-12-03 07:22:55,174 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:55,176 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:55,178 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:55,178 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:55,185 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:55,186 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:55,187 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:55,196 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:55,196 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:55,196 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:55,199 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:55,199 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:55,199 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:55,200 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:55,200 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:55,201 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,201 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,202 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:55,202 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:55,209 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:55,210 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:55,215 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:55,215 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,218 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:55,220 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:55,240 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2001890259-172.17.0.3-1606980170531 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 38ms
2020-12-03 07:22:55,242 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2001890259-172.17.0.3-1606980170531 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 21ms
2020-12-03 07:22:55,249 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2001890259-172.17.0.3-1606980170531 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 47ms
2020-12-03 07:22:55,249 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2001890259-172.17.0.3-1606980170531 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 40ms
2020-12-03 07:22:55,250 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2001890259-172.17.0.3-1606980170531: 48ms
2020-12-03 07:22:55,252 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:55,252 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:55,252 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001890259-172.17.0.3-1606980170531/current/replicas doesn't exist 
2020-12-03 07:22:55,252 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001890259-172.17.0.3-1606980170531/current/replicas doesn't exist 
2020-12-03 07:22:55,254 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2001890259-172.17.0.3-1606980170531 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 44ms
2020-12-03 07:22:55,254 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2001890259-172.17.0.3-1606980170531: 52ms
2020-12-03 07:22:55,254 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-12-03 07:22:55,254 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 2ms
2020-12-03 07:22:55,254 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:55,254 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:55,255 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001890259-172.17.0.3-1606980170531/current/replicas doesn't exist 
2020-12-03 07:22:55,255 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001890259-172.17.0.3-1606980170531/current/replicas doesn't exist 
2020-12-03 07:22:55,254 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531: 3ms
2020-12-03 07:22:55,255 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:22:55,255 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:22:55,255 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531: 1ms
2020-12-03 07:22:55,255 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2001890259-172.17.0.3-1606980170531 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 37ms
2020-12-03 07:22:55,256 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2001890259-172.17.0.3-1606980170531: 40ms
2020-12-03 07:22:55,256 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:55,256 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:55,256 [Thread-142] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001890259-172.17.0.3-1606980170531/current/replicas doesn't exist 
2020-12-03 07:22:55,256 [Thread-143] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001890259-172.17.0.3-1606980170531/current/replicas doesn't exist 
2020-12-03 07:22:55,257 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:22:55,257 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:22:55,257 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2001890259-172.17.0.3-1606980170531: 2ms
2020-12-03 07:22:55,258 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:55,258 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:55,259 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:55,259 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b): finished scanning block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,259 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-d3986514-fbea-4b97-9a2a-6ab349396662): finished scanning block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,259 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52): finished scanning block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:55,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-5d798812-e27d-4202-95c6-ae08fb78842d): finished scanning block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:55,270 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e): finished scanning block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,270 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2001890259-172.17.0.3-1606980170531 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:55,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-56229615-8750-471e-8bd1-05a9f20ec6e3): finished scanning block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,280 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,286 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:55,287 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:55,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:22:55,303 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:22:55,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-5d798812-e27d-4202-95c6-ae08fb78842d): no suitable block pools found to scan.  Waiting 1814399954 ms.
2020-12-03 07:22:55,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-12-03 07:22:55,306 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-56229615-8750-471e-8bd1-05a9f20ec6e3): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-12-03 07:22:55,307 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-d3986514-fbea-4b97-9a2a-6ab349396662): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:22:55,314 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:25 AM with interval of 21600000ms
2020-12-03 07:22:55,315 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:39 AM with interval of 21600000ms
2020-12-03 07:22:55,315 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:07 AM with interval of 21600000ms
2020-12-03 07:22:55,326 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid c11f44ab-f5e6-4293-b26d-a06a2f820b97) service to localhost/127.0.0.1:38499 beginning handshake with NN
2020-12-03 07:22:55,326 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 55be54f4-86d7-4f62-b000-a769e7241054) service to localhost/127.0.0.1:38499 beginning handshake with NN
2020-12-03 07:22:55,326 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 902025f0-b976-41d2-8180-c0512b1a46d3) service to localhost/127.0.0.1:38499 beginning handshake with NN
2020-12-03 07:22:55,337 [IPC Server handler 5 on default port 38499] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531) storage 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:22:55,341 [IPC Server handler 5 on default port 38499] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46064
2020-12-03 07:22:55,341 [IPC Server handler 5 on default port 38499] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 55be54f4-86d7-4f62-b000-a769e7241054 (127.0.0.1:46064).
2020-12-03 07:22:55,344 [IPC Server handler 6 on default port 38499] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531) storage c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:55,345 [IPC Server handler 6 on default port 38499] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34511
2020-12-03 07:22:55,345 [IPC Server handler 6 on default port 38499] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c11f44ab-f5e6-4293-b26d-a06a2f820b97 (127.0.0.1:34511).
2020-12-03 07:22:55,346 [IPC Server handler 7 on default port 38499] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531) storage 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:55,346 [IPC Server handler 7 on default port 38499] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36537
2020-12-03 07:22:55,346 [IPC Server handler 7 on default port 38499] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 902025f0-b976-41d2-8180-c0512b1a46d3 (127.0.0.1:36537).
2020-12-03 07:22:55,348 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 902025f0-b976-41d2-8180-c0512b1a46d3) service to localhost/127.0.0.1:38499 successfully registered with NN
2020-12-03 07:22:55,348 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38499 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:55,348 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid c11f44ab-f5e6-4293-b26d-a06a2f820b97) service to localhost/127.0.0.1:38499 successfully registered with NN
2020-12-03 07:22:55,349 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38499 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:55,351 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 55be54f4-86d7-4f62-b000-a769e7241054) service to localhost/127.0.0.1:38499 successfully registered with NN
2020-12-03 07:22:55,351 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38499 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:55,369 [IPC Server handler 8 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b for DN 127.0.0.1:36537
2020-12-03 07:22:55,370 [IPC Server handler 8 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e for DN 127.0.0.1:36537
2020-12-03 07:22:55,371 [IPC Server handler 9 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56229615-8750-471e-8bd1-05a9f20ec6e3 for DN 127.0.0.1:46064
2020-12-03 07:22:55,371 [IPC Server handler 9 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d3986514-fbea-4b97-9a2a-6ab349396662 for DN 127.0.0.1:46064
2020-12-03 07:22:55,372 [IPC Server handler 1 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d798812-e27d-4202-95c6-ae08fb78842d for DN 127.0.0.1:34511
2020-12-03 07:22:55,372 [IPC Server handler 1 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 for DN 127.0.0.1:34511
2020-12-03 07:22:55,391 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,400 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:55,416 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8f4d3214d144f357: Processing first storage report for DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 from datanode c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:55,419 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4d3214d144f357: from storage DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 node DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:55,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x43cb5a5a300c5d50: Processing first storage report for DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b from datanode 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:55,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43cb5a5a300c5d50: from storage DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b node DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:55,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44d95ac98bd47e0e: Processing first storage report for DS-d3986514-fbea-4b97-9a2a-6ab349396662 from datanode 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:22:55,420 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d95ac98bd47e0e: from storage DS-d3986514-fbea-4b97-9a2a-6ab349396662 node DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:55,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x43cb5a5a300c5d50: Processing first storage report for DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e from datanode 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:55,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43cb5a5a300c5d50: from storage DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e node DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:55,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8f4d3214d144f357: Processing first storage report for DS-5d798812-e27d-4202-95c6-ae08fb78842d from datanode c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:55,422 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4d3214d144f357: from storage DS-5d798812-e27d-4202-95c6-ae08fb78842d node DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:55,423 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44d95ac98bd47e0e: Processing first storage report for DS-56229615-8750-471e-8bd1-05a9f20ec6e3 from datanode 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:22:55,423 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d95ac98bd47e0e: from storage DS-56229615-8750-471e-8bd1-05a9f20ec6e3 node DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:55,424 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:55,447 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/level_0_A	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:55,469 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x44d95ac98bd47e0e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 77 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:55,469 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x43cb5a5a300c5d50,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 76 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:55,470 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,469 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8f4d3214d144f357,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 76 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:55,470 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,470 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:55,506 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/level_0_A/flume.log	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:55,600 [IPC Server handler 1 on default port 38499] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:46064, 127.0.0.1:36537, 127.0.0.1:34511 for /level_0_A/flume.log
2020-12-03 07:22:55,624 [Thread-154] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,695 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55664 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001 src: /127.0.0.1:55664 dest: /127.0.0.1:46064
2020-12-03 07:22:55,720 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55664 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,722 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42696 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001 src: /127.0.0.1:42696 dest: /127.0.0.1:36537
2020-12-03 07:22:55,724 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42696 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,727 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50310 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001 src: /127.0.0.1:50310 dest: /127.0.0.1:34511
2020-12-03 07:22:55,783 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50310, dest: /127.0.0.1:34511, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: c11f44ab-f5e6-4293-b26d-a06a2f820b97, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, duration(ns): 35652348
2020-12-03 07:22:55,783 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:55,791 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42696, dest: /127.0.0.1:36537, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 902025f0-b976-41d2-8180-c0512b1a46d3, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, duration(ns): 43976963
2020-12-03 07:22:55,792 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511] terminating
2020-12-03 07:22:55,796 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55664, dest: /127.0.0.1:46064, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 55be54f4-86d7-4f62-b000-a769e7241054, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, duration(ns): 50114209
2020-12-03 07:22:55,796 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511] terminating
2020-12-03 07:22:55,809 [IPC Server handler 9 on default port 38499] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:46064, 127.0.0.1:34511, 127.0.0.1:36537 for /level_0_A/flume.log
2020-12-03 07:22:55,812 [DataStreamer for file /level_0_A/flume.log] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,815 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55670 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002 src: /127.0.0.1:55670 dest: /127.0.0.1:46064
2020-12-03 07:22:55,816 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55670 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,819 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50314 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002 src: /127.0.0.1:50314 dest: /127.0.0.1:34511
2020-12-03 07:22:55,820 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50314 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,821 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42704 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002 src: /127.0.0.1:42704 dest: /127.0.0.1:36537
2020-12-03 07:22:55,836 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42704, dest: /127.0.0.1:36537, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 902025f0-b976-41d2-8180-c0512b1a46d3, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, duration(ns): 12794095
2020-12-03 07:22:55,837 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:55,840 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36537]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50314, dest: /127.0.0.1:34511, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: c11f44ab-f5e6-4293-b26d-a06a2f820b97, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, duration(ns): 16043691
2020-12-03 07:22:55,841 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36537]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36537] terminating
2020-12-03 07:22:55,847 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34511, 127.0.0.1:36537]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55670, dest: /127.0.0.1:46064, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 55be54f4-86d7-4f62-b000-a769e7241054, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, duration(ns): 21781166
2020-12-03 07:22:55,847 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34511, 127.0.0.1:36537]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34511, 127.0.0.1:36537] terminating
2020-12-03 07:22:55,852 [IPC Server handler 6 on default port 38499] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /level_0_A/flume.log is closed by DFSClient_NONMAPREDUCE_-870020909_1
2020-12-03 07:22:55,865 [IPC Server handler 1 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/level_0_A/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,871 [Thread-153] INFO  snapshot.SnapshotTestHelper (SnapshotTestHelper.java:createSnapshot(133)) - createSnapshot flume_snap_1 for /level_0_A
2020-12-03 07:22:55,875 [IPC Server handler 8 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,882 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=allowSnapshot	src=/level_0_A	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,899 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSnapshot	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:22:55,910 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/level_0_A	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,914 [IPC Server handler 9 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,926 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/.snapshot/flume_snap_1/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:55,935 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_1	dst=/level_0_A	perm=null	proto=rpc
2020-12-03 07:22:55,948 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:22:55,949 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_1 and current directory under directory /level_0_A:
M	.

2020-12-03 07:22:55,949 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between current directory and snapshot flume_snap_1 under directory /level_0_A:
M	.


2020-12-03 07:22:55,953 [IPC Server handler 6 on default port 38499] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:46064, 127.0.0.1:36537, 127.0.0.1:34511 for /level_0_A/flume.log
2020-12-03 07:22:55,956 [Thread-170] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,958 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55676 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003 src: /127.0.0.1:55676 dest: /127.0.0.1:46064
2020-12-03 07:22:55,961 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55676 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,963 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42708 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003 src: /127.0.0.1:42708 dest: /127.0.0.1:36537
2020-12-03 07:22:55,964 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42708 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,965 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50322 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003 src: /127.0.0.1:50322 dest: /127.0.0.1:34511
2020-12-03 07:22:55,976 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50322, dest: /127.0.0.1:34511, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: c11f44ab-f5e6-4293-b26d-a06a2f820b97, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, duration(ns): 8273596
2020-12-03 07:22:55,976 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:55,979 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42708, dest: /127.0.0.1:36537, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 902025f0-b976-41d2-8180-c0512b1a46d3, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, duration(ns): 10797849
2020-12-03 07:22:55,980 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511] terminating
2020-12-03 07:22:55,983 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55676, dest: /127.0.0.1:46064, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 55be54f4-86d7-4f62-b000-a769e7241054, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, duration(ns): 14494055
2020-12-03 07:22:55,983 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511] terminating
2020-12-03 07:22:55,986 [IPC Server handler 0 on default port 38499] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:46064, 127.0.0.1:36537, 127.0.0.1:34511 for /level_0_A/flume.log
2020-12-03 07:22:55,988 [DataStreamer for file /level_0_A/flume.log] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,989 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55682 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004 src: /127.0.0.1:55682 dest: /127.0.0.1:46064
2020-12-03 07:22:55,990 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55682 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,993 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42714 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004 src: /127.0.0.1:42714 dest: /127.0.0.1:36537
2020-12-03 07:22:55,994 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42714 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:55,995 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50328 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004 src: /127.0.0.1:50328 dest: /127.0.0.1:34511
2020-12-03 07:22:56,201 [IPC Server handler 7 on default port 38499] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /level_0_A/flume.log for DFSClient_NONMAPREDUCE_-870020909_1
2020-12-03 07:22:56,203 [Thread-153] INFO  snapshot.SnapshotTestHelper (SnapshotTestHelper.java:createSnapshot(133)) - createSnapshot flume_snap_2 for /level_0_A
2020-12-03 07:22:56,204 [IPC Server handler 9 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,207 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=allowSnapshot	src=/level_0_A	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,210 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSnapshot	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_2	perm=null	proto=rpc
2020-12-03 07:22:56,213 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/level_0_A	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,219 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,221 [IPC Server handler 1 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/.snapshot/flume_snap_2/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,224 [IPC Server handler 8 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_1	dst=/level_0_A	perm=null	proto=rpc
2020-12-03 07:22:56,226 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:22:56,227 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_1 and current directory under directory /level_0_A:
M	.
M	./flume.log

2020-12-03 07:22:56,227 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between current directory and snapshot flume_snap_1 under directory /level_0_A:
M	.
M	./flume.log


2020-12-03 07:22:56,228 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_2	dst=/level_0_A	perm=null	proto=rpc
2020-12-03 07:22:56,230 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_2	perm=null	proto=rpc
2020-12-03 07:22:56,231 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_2 and current directory under directory /level_0_A:
M	.

2020-12-03 07:22:56,231 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between current directory and snapshot flume_snap_2 under directory /level_0_A:
M	.


2020-12-03 07:22:56,244 [IPC Server handler 9 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_1	dst=/level_0_A/.snapshot/flume_snap_2	perm=null	proto=rpc
2020-12-03 07:22:56,264 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_2	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:22:56,266 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_1 and snapshot flume_snap_2 under directory /level_0_A:
M	.
M	./flume.log

2020-12-03 07:22:56,266 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between snapshot flume_snap_2 and snapshot flume_snap_1 under directory /level_0_A:
M	.
M	./flume.log


2020-12-03 07:22:56,293 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50328, dest: /127.0.0.1:34511, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: c11f44ab-f5e6-4293-b26d-a06a2f820b97, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, duration(ns): 295625168
2020-12-03 07:22:56,293 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:56,296 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42714, dest: /127.0.0.1:36537, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 902025f0-b976-41d2-8180-c0512b1a46d3, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, duration(ns): 299242171
2020-12-03 07:22:56,297 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34511] terminating
2020-12-03 07:22:56,299 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55682, dest: /127.0.0.1:46064, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 55be54f4-86d7-4f62-b000-a769e7241054, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, duration(ns): 301638941
2020-12-03 07:22:56,299 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36537, 127.0.0.1:34511] terminating
2020-12-03 07:22:56,302 [IPC Server handler 1 on default port 38499] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:46064, 127.0.0.1:34511, 127.0.0.1:36537 for /level_0_A/flume.log
2020-12-03 07:22:56,304 [DataStreamer for file /level_0_A/flume.log] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:56,305 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55694 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005 src: /127.0.0.1:55694 dest: /127.0.0.1:46064
2020-12-03 07:22:56,306 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:55694 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:56,310 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50338 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005 src: /127.0.0.1:50338 dest: /127.0.0.1:34511
2020-12-03 07:22:56,312 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:50338 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:56,313 [DataXceiver for client DFSClient_NONMAPREDUCE_-870020909_1 at /127.0.0.1:42728 [Receiving block BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005 src: /127.0.0.1:42728 dest: /127.0.0.1:36537
2020-12-03 07:22:56,331 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42728, dest: /127.0.0.1:36537, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 902025f0-b976-41d2-8180-c0512b1a46d3, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, duration(ns): 14675551
2020-12-03 07:22:56,332 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:56,334 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36537]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50338, dest: /127.0.0.1:34511, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: c11f44ab-f5e6-4293-b26d-a06a2f820b97, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, duration(ns): 18377771
2020-12-03 07:22:56,335 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36537]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36537] terminating
2020-12-03 07:22:56,337 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34511, 127.0.0.1:36537]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55694, dest: /127.0.0.1:46064, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-870020909_1, offset: 0, srvID: 55be54f4-86d7-4f62-b000-a769e7241054, blockid: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, duration(ns): 20879922
2020-12-03 07:22:56,338 [PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34511, 127.0.0.1:36537]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001890259-172.17.0.3-1606980170531:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34511, 127.0.0.1:36537] terminating
2020-12-03 07:22:56,339 [IPC Server handler 7 on default port 38499] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /level_0_A/flume.log for DFSClient_NONMAPREDUCE_-870020909_1
2020-12-03 07:22:56,342 [IPC Server handler 9 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/.snapshot/flume_snap_1/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,344 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/.snapshot/flume_snap_2/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,346 [IPC Server handler 3 on default port 38499] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /level_0_A/flume.log is closed by DFSClient_NONMAPREDUCE_-870020909_1
2020-12-03 07:22:56,348 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,350 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/.snapshot/flume_snap_1/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,351 [IPC Server handler 1 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/level_0_A/.snapshot/flume_snap_2/flume.log	dst=null	perm=null	proto=rpc
2020-12-03 07:22:56,354 [IPC Server handler 8 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_1	dst=/level_0_A	perm=null	proto=rpc
2020-12-03 07:22:56,356 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:22:56,356 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_1 and current directory under directory /level_0_A:
M	.
M	./flume.log

2020-12-03 07:22:56,357 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between current directory and snapshot flume_snap_1 under directory /level_0_A:
M	.
M	./flume.log


2020-12-03 07:22:56,358 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_2	dst=/level_0_A	perm=null	proto=rpc
2020-12-03 07:22:56,361 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A	dst=/level_0_A/.snapshot/flume_snap_2	perm=null	proto=rpc
2020-12-03 07:22:56,361 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_2 and current directory under directory /level_0_A:
M	.
M	./flume.log

2020-12-03 07:22:56,362 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between current directory and snapshot flume_snap_2 under directory /level_0_A:
M	.
M	./flume.log


2020-12-03 07:22:56,364 [IPC Server handler 9 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_1	dst=/level_0_A/.snapshot/flume_snap_2	perm=null	proto=rpc
2020-12-03 07:22:56,366 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_2	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:22:56,367 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_1 and snapshot flume_snap_2 under directory /level_0_A:
M	.
M	./flume.log

2020-12-03 07:22:56,368 [Thread-153] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between snapshot flume_snap_2 and snapshot flume_snap_1 under directory /level_0_A:
M	.
M	./flume.log


2020-12-03 07:22:56,373 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38499
2020-12-03 07:22:56,376 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d95ac98bd47e0f: from storage DS-d3986514-fbea-4b97-9a2a-6ab349396662 node DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:56,376 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d95ac98bd47e0f: from storage DS-56229615-8750-471e-8bd1-05a9f20ec6e3 node DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:56,377 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x44d95ac98bd47e0f,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:56,377 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:56,473 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38499
2020-12-03 07:22:56,476 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43cb5a5a300c5d51: from storage DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b node DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:56,476 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43cb5a5a300c5d51: from storage DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e node DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:56,477 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x43cb5a5a300c5d51,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:56,477 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:56,573 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:38499
2020-12-03 07:22:56,579 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4d3214d144f358: from storage DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 node DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:56,580 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4d3214d144f358: from storage DS-5d798812-e27d-4202-95c6-ae08fb78842d node DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:56,581 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8f4d3214d144f358,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:56,581 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:56,669 [Thread-153] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4674)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-12-03 07:22:56,669 [Thread-153] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:22:56,670 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 28
2020-12-03 07:22:56,670 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 29 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 4 Number of syncs: 26 SyncTimes(ms): 5 2 
2020-12-03 07:22:56,672 [Thread-153] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000029
2020-12-03 07:22:56,672 [Thread-153] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000029
2020-12-03 07:22:56,681 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000029 using no compression
2020-12-03 07:22:56,684 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000029 using no compression
2020-12-03 07:22:56,713 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000029 of size 930 bytes saved in 0 seconds .
2020-12-03 07:22:56,713 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000029 of size 930 bytes saved in 0 seconds .
2020-12-03 07:22:56,808 [Thread-153] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:22:56,960 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 30
2020-12-03 07:22:57,122 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4500)) - New namespace image has been created
2020-12-03 07:22:57,122 [Thread-153] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 4 secs
2020-12-03 07:22:57,123 [Thread-153] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 3 datanodes
2020-12-03 07:22:57,123 [Thread-153] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:57,123 [Thread-153] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:57,123 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:57,124 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 30, 30
2020-12-03 07:22:57,124 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5827af16] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:57,125 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 2 
2020-12-03 07:22:57,126 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@62dae540] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:57,126 [Thread-153] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000030 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000030-0000000000000000031
2020-12-03 07:22:57,127 [Thread-153] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000030 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000030-0000000000000000031
2020-12-03 07:22:57,128 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:57,134 [CacheReplicationMonitor(700462778)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:57,136 [Thread-153] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38499
2020-12-03 07:22:57,141 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:57,142 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:57,143 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:57,143 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:57,188 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:57,188 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:57,193 [Thread-153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6692b6c6{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:57,198 [Thread-153] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7354b8c5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:57,198 [Thread-153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dfd3c81{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:57,199 [Thread-153] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4dc27487{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:57,214 [Thread-153] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:57,214 [Thread-153] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:57,215 [Thread-153] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:38499
2020-12-03 07:22:57,215 [Thread-153] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:38499 to access this namenode/service.
2020-12-03 07:22:57,222 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19658fc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,222 [Thread-153] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:42166
2020-12-03 07:22:57,223 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,225 [Thread-153] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,226 [Thread-153] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:57,226 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,229 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,230 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:57,230 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,230 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,232 [Thread-153] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:57,232 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:57,233 [Thread-153] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42166
2020-12-03 07:22:57,233 [Thread-153] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,236 [Thread-153] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@389de3d0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,237 [Thread-153] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c443572{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,245 [Thread-153] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1010f36{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:57,247 [Thread-153] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4fa3eff9{HTTP/1.1,[http/1.1]}{localhost:42166}
2020-12-03 07:22:57,247 [Thread-153] INFO  server.Server (Server.java:doStart(419)) - Started @9054ms
2020-12-03 07:22:57,249 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:57,250 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:57,250 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:57,250 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:57,250 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:57,250 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:57,251 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:57,251 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:57,251 [Thread-153] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,252 [Thread-153] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:57,252 [Thread-153] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:57,252 [Thread-153] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:57,253 [Thread-153] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:57
2020-12-03 07:22:57,253 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:57,253 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,253 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:57,253 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:57,265 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:57,265 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:57,266 [Thread-153] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:57,266 [Thread-153] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:57,266 [Thread-153] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:57,266 [Thread-153] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:57,266 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:57,266 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:57,267 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:57,267 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:57,267 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:57,267 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:57,267 [Thread-153] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:57,267 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:57,268 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,268 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:57,268 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:57,274 [Thread-153] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:57,274 [Thread-153] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:57,274 [Thread-153] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:57,275 [Thread-153] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:57,275 [Thread-153] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: true, skipCaptureAccessTimeOnlyChange: true, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:57,275 [Thread-153] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:57,275 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:57,275 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,275 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:57,276 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:57,277 [Thread-153] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:57,277 [Thread-153] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:57,278 [Thread-153] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:57,278 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:57,278 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:57,278 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:57,278 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:57,278 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:57,279 [Thread-153] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:57,360 [Thread-153] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:57,412 [Thread-153] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7517@a8d7f59b5459
2020-12-03 07:22:57,415 [Thread-153] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:57,415 [Thread-153] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:57,416 [Thread-153] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000029, cpktTxId=0000000000000000029)
2020-12-03 07:22:57,420 [Thread-153] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 3 INodes.
2020-12-03 07:22:57,424 [Thread-153] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:57,424 [Thread-153] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 29 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000029
2020-12-03 07:22:57,427 [Thread-153] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@331701bc expecting start txid #30
2020-12-03 07:22:57,427 [Thread-153] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000030-0000000000000000031, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000030-0000000000000000031 maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:57,428 [Thread-153] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000030-0000000000000000031' to transaction ID 30
2020-12-03 07:22:57,465 [Thread-153] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000030-0000000000000000031, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000030-0000000000000000031) of total size 42.0, total edits 2.0, total load time 12.0 ms
2020-12-03 07:22:57,465 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:57,466 [Thread-153] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 32
2020-12-03 07:22:57,659 [Thread-153] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:57,659 [Thread-153] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 379 msecs
2020-12-03 07:22:57,660 [Thread-153] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:38499
2020-12-03 07:22:57,660 [Thread-153] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,662 [Socket Reader #1 for port 38499] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 38499
2020-12-03 07:22:57,667 [Listener at localhost/38499] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:57,697 [Listener at localhost/38499] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:57,700 [Listener at localhost/38499] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 5.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:22:57,705 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,705 [IPC Server listener on 38499] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 38499: starting
2020-12-03 07:22:57,707 [Listener at localhost/38499] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38499
2020-12-03 07:22:57,707 [Listener at localhost/38499] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:57,707 [Listener at localhost/38499] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:57,708 [Listener at localhost/38499] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=15360
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:57,710 [Listener at localhost/38499] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:22:57,710 [CacheReplicationMonitor(1035696648)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:58,711 [Listener at localhost/38499] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:22:59,371 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "a8d7f59b5459/172.17.0.3"; destination host is: "localhost":38499; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy24.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:22:59,474 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:38499 with active state
2020-12-03 07:22:59,476 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 902025f0-b976-41d2-8180-c0512b1a46d3) service to localhost/127.0.0.1:38499 beginning handshake with NN
2020-12-03 07:22:59,478 [IPC Server handler 2 on default port 38499] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531) storage 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:59,478 [IPC Server handler 2 on default port 38499] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36537
2020-12-03 07:22:59,478 [IPC Server handler 2 on default port 38499] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 902025f0-b976-41d2-8180-c0512b1a46d3 (127.0.0.1:36537).
2020-12-03 07:22:59,479 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 902025f0-b976-41d2-8180-c0512b1a46d3) service to localhost/127.0.0.1:38499 successfully registered with NN
2020-12-03 07:22:59,482 [IPC Server handler 3 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b for DN 127.0.0.1:36537
2020-12-03 07:22:59,482 [IPC Server handler 3 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e for DN 127.0.0.1:36537
2020-12-03 07:22:59,487 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x43cb5a5a300c5d52: Processing first storage report for DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b from datanode 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:59,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43cb5a5a300c5d52: from storage DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b node DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 3, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x43cb5a5a300c5d52: Processing first storage report for DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e from datanode 902025f0-b976-41d2-8180-c0512b1a46d3
2020-12-03 07:22:59,488 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:59,489 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:22:59,489 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 1 secs
2020-12-03 07:22:59,489 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:22:59,490 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:59,492 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43cb5a5a300c5d52: from storage DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e node DatanodeRegistration(127.0.0.1:36537, datanodeUuid=902025f0-b976-41d2-8180-c0512b1a46d3, infoPort=33118, infoSecurePort=0, ipcPort=46430, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 2, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,497 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 5
2020-12-03 07:22:59,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:59,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 4
2020-12-03 07:22:59,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:59,498 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:59,498 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-12-03 07:22:59,502 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x43cb5a5a300c5d52,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,503 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:59,570 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:38499 with active state
2020-12-03 07:22:59,571 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid c11f44ab-f5e6-4293-b26d-a06a2f820b97) service to localhost/127.0.0.1:38499 beginning handshake with NN
2020-12-03 07:22:59,573 [IPC Server handler 7 on default port 38499] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531) storage c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:59,573 [IPC Server handler 7 on default port 38499] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34511
2020-12-03 07:22:59,573 [IPC Server handler 7 on default port 38499] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c11f44ab-f5e6-4293-b26d-a06a2f820b97 (127.0.0.1:34511).
2020-12-03 07:22:59,574 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid c11f44ab-f5e6-4293-b26d-a06a2f820b97) service to localhost/127.0.0.1:38499 successfully registered with NN
2020-12-03 07:22:59,576 [IPC Server handler 8 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d798812-e27d-4202-95c6-ae08fb78842d for DN 127.0.0.1:34511
2020-12-03 07:22:59,577 [IPC Server handler 8 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 for DN 127.0.0.1:34511
2020-12-03 07:22:59,579 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8f4d3214d144f359: Processing first storage report for DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 from datanode c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:59,579 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4d3214d144f359: from storage DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52 node DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,580 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8f4d3214d144f359: Processing first storage report for DS-5d798812-e27d-4202-95c6-ae08fb78842d from datanode c11f44ab-f5e6-4293-b26d-a06a2f820b97
2020-12-03 07:22:59,580 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4d3214d144f359: from storage DS-5d798812-e27d-4202-95c6-ae08fb78842d node DatanodeRegistration(127.0.0.1:34511, datanodeUuid=c11f44ab-f5e6-4293-b26d-a06a2f820b97, infoPort=41263, infoSecurePort=0, ipcPort=46386, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,581 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8f4d3214d144f359,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,581 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:22:59,711 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2191)) - Restarted the namenode
2020-12-03 07:22:59,721 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,722 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:59,722 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:59,824 [IPC Server handler 1 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,826 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:59,826 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:59,927 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,928 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:59,929 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,030 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,031 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,031 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,133 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,134 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,134 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,236 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,237 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,237 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,338 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,339 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,340 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,441 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,442 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,442 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,544 [IPC Server handler 8 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,545 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,545 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,647 [IPC Server handler 0 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,648 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,648 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,750 [IPC Server handler 1 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,751 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,751 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,853 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,854 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,854 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:00,956 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,957 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:00,957 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,058 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,060 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,060 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,161 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,162 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,162 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,264 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,265 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,265 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,367 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,368 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,368 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,469 [IPC Server handler 8 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,470 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,471 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,572 [IPC Server handler 9 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,573 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,574 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,675 [IPC Server handler 1 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,677 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,677 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,778 [IPC Server handler 2 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,779 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,780 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,881 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,883 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,883 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:01,984 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,985 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:01,985 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,087 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,088 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,089 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,190 [IPC Server handler 6 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,191 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,192 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,293 [IPC Server handler 7 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,294 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,294 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,371 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:38499 with active state
2020-12-03 07:23:02,372 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 55be54f4-86d7-4f62-b000-a769e7241054) service to localhost/127.0.0.1:38499 beginning handshake with NN
2020-12-03 07:23:02,373 [IPC Server handler 0 on default port 38499] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531) storage 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:23:02,374 [IPC Server handler 0 on default port 38499] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46064
2020-12-03 07:23:02,374 [IPC Server handler 0 on default port 38499] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 55be54f4-86d7-4f62-b000-a769e7241054 (127.0.0.1:46064).
2020-12-03 07:23:02,375 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 55be54f4-86d7-4f62-b000-a769e7241054) service to localhost/127.0.0.1:38499 successfully registered with NN
2020-12-03 07:23:02,377 [IPC Server handler 1 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56229615-8750-471e-8bd1-05a9f20ec6e3 for DN 127.0.0.1:46064
2020-12-03 07:23:02,377 [IPC Server handler 1 on default port 38499] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d3986514-fbea-4b97-9a2a-6ab349396662 for DN 127.0.0.1:46064
2020-12-03 07:23:02,380 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44d95ac98bd47e10: Processing first storage report for DS-d3986514-fbea-4b97-9a2a-6ab349396662 from datanode 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:23:02,380 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d95ac98bd47e10: from storage DS-d3986514-fbea-4b97-9a2a-6ab349396662 node DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 2, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,380 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44d95ac98bd47e10: Processing first storage report for DS-56229615-8750-471e-8bd1-05a9f20ec6e3 from datanode 55be54f4-86d7-4f62-b000-a769e7241054
2020-12-03 07:23:02,381 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d95ac98bd47e10: from storage DS-56229615-8750-471e-8bd1-05a9f20ec6e3 node DatanodeRegistration(127.0.0.1:46064, datanodeUuid=55be54f4-86d7-4f62-b000-a769e7241054, infoPort=39413, infoSecurePort=0, ipcPort=33109, storageInfo=lv=-57;cid=testClusterID;nsid=1498337845;c=1606980170531), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,382 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x44d95ac98bd47e10,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:02,382 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:23:02,397 [IPC Server handler 3 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,398 [Listener at localhost/38499] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:02,400 [IPC Server handler 4 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_1	dst=/level_0_A/.snapshot/flume_snap_2	perm=null	proto=rpc
2020-12-03 07:23:02,403 [IPC Server handler 5 on default port 38499] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=computeSnapshotDiff	src=/level_0_A/.snapshot/flume_snap_2	dst=/level_0_A/.snapshot/flume_snap_1	perm=null	proto=rpc
2020-12-03 07:23:02,404 [Listener at localhost/38499] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2410)) - Difference between snapshot flume_snap_1 and snapshot flume_snap_2 under directory /level_0_A:
M	.
M	./flume.log

2020-12-03 07:23:02,404 [Listener at localhost/38499] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:verifySnapshotDiffReport(2411)) - Difference between snapshot flume_snap_2 and snapshot flume_snap_1 under directory /level_0_A:
M	.
M	./flume.log


2020-12-03 07:23:02,404 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:02,405 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:02,406 [Listener at localhost/46386] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:02,406 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@750fe12e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:02,407 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-45d7095f-a26d-4a6f-8cd0-40779c6ddf52) exiting.
2020-12-03 07:23:02,407 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-5d798812-e27d-4202-95c6-ae08fb78842d) exiting.
2020-12-03 07:23:02,429 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@51684e4a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:02,430 [Listener at localhost/46386] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ce1f601{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:02,430 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ab72419{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,431 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70e0accd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,433 [Listener at localhost/46386] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46386
2020-12-03 07:23:02,436 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:02,438 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,441 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:02,442 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid c11f44ab-f5e6-4293-b26d-a06a2f820b97) service to localhost/127.0.0.1:38499
2020-12-03 07:23:02,442 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid c11f44ab-f5e6-4293-b26d-a06a2f820b97)
2020-12-03 07:23:02,442 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:23:02,443 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001890259-172.17.0.3-1606980170531] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:02,444 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001890259-172.17.0.3-1606980170531] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:02,446 [Listener at localhost/46386] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:02,447 [Listener at localhost/46386] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:02,447 [Listener at localhost/46386] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:02,447 [Listener at localhost/46386] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:02,449 [Listener at localhost/46386] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:02,450 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:02,450 [Listener at localhost/46386] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:02,450 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6bc28a83] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:02,451 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-727e4b4f-f81e-45f2-8d8f-cf721c21ff4e) exiting.
2020-12-03 07:23:02,451 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-816c8e8e-6e23-4b41-9a20-4c9fd7e49c9b) exiting.
2020-12-03 07:23:02,588 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 902025f0-b976-41d2-8180-c0512b1a46d3) service to localhost/127.0.0.1:38499
2020-12-03 07:23:02,588 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 902025f0-b976-41d2-8180-c0512b1a46d3)
2020-12-03 07:23:02,588 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:23:02,589 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001890259-172.17.0.3-1606980170531] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:02,590 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001890259-172.17.0.3-1606980170531] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:02,656 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@fac80{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:02,657 [Listener at localhost/46386] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@726386ed{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:02,658 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a0e1b5e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,659 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70d2e40b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,664 [Listener at localhost/46386] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46430
2020-12-03 07:23:02,666 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:02,668 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,672 [Listener at localhost/46386] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:02,672 [Listener at localhost/46386] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:02,673 [Listener at localhost/46386] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:02,674 [Listener at localhost/46386] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:02,678 [Listener at localhost/46386] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:02,678 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:02,679 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2488b073] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:02,679 [Listener at localhost/46386] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:02,682 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-56229615-8750-471e-8bd1-05a9f20ec6e3) exiting.
2020-12-03 07:23:02,682 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-d3986514-fbea-4b97-9a2a-6ab349396662) exiting.
2020-12-03 07:23:02,719 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7c351808{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:02,720 [Listener at localhost/46386] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@180e6ac4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:02,720 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ed3b1f5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,721 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@675d8c96{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,722 [Listener at localhost/46386] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33109
2020-12-03 07:23:02,725 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:02,725 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,727 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:02,729 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 55be54f4-86d7-4f62-b000-a769e7241054) service to localhost/127.0.0.1:38499
2020-12-03 07:23:02,729 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2001890259-172.17.0.3-1606980170531 (Datanode Uuid 55be54f4-86d7-4f62-b000-a769e7241054)
2020-12-03 07:23:02,729 [BP-2001890259-172.17.0.3-1606980170531 heartbeating to localhost/127.0.0.1:38499] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2001890259-172.17.0.3-1606980170531
2020-12-03 07:23:02,730 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001890259-172.17.0.3-1606980170531] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:02,734 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001890259-172.17.0.3-1606980170531] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:02,735 [Listener at localhost/46386] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:02,736 [Listener at localhost/46386] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:02,737 [Listener at localhost/46386] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:02,737 [Listener at localhost/46386] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:02,743 [Listener at localhost/46386] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:02,744 [Listener at localhost/46386] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:02,744 [Listener at localhost/46386] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:02,746 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@705a8a5e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:02,746 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@313b2402] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:02,746 [Listener at localhost/46386] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 32, 32
2020-12-03 07:23:02,757 [Listener at localhost/46386] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 31 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-12-03 07:23:02,758 [Listener at localhost/46386] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000032 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000032-0000000000000000033
2020-12-03 07:23:02,760 [Listener at localhost/46386] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000032 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000032-0000000000000000033
2020-12-03 07:23:02,762 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:02,762 [CacheReplicationMonitor(1035696648)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:02,772 [Listener at localhost/46386] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38499
2020-12-03 07:23:02,793 [IPC Server listener on 38499] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 38499
2020-12-03 07:23:02,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:02,795 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:02,795 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:02,807 [Listener at localhost/46386] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:02,808 [Listener at localhost/46386] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:02,822 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1010f36{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:02,825 [Listener at localhost/46386] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4fa3eff9{HTTP/1.1,[http/1.1]}{localhost:42166}
2020-12-03 07:23:02,829 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c443572{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:02,833 [Listener at localhost/46386] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@389de3d0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:02,836 [Listener at localhost/46386] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:23:02,851 [Listener at localhost/46386] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:23:02,852 [Listener at localhost/46386] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
msx-rc 0
