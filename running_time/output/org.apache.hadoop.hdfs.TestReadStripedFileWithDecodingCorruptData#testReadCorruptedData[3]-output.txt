2020-12-03 07:22:51,005 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:22:51,958 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:51,981 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:51,983 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:51,984 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:51,996 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:51,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:51,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:51,999 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:52,048 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:52,055 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:52,055 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:52,056 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:52,071 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:52,076 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:52
2020-12-03 07:22:52,083 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:52,087 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,093 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:52,093 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:52,124 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:52,125 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:52,134 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:52,135 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:52,135 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:52,136 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:52,137 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:52,137 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:52,137 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:52,137 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:22:52,138 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:52,138 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:52,138 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:52,185 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:52,186 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:52,187 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:52,187 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:52,211 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:52,211 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:52,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:52,220 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:52,220 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:52,221 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:52,222 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:52,231 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:52,235 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:52,243 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:52,244 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,244 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:52,245 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:52,258 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:52,258 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:52,259 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:52,289 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:52,289 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:52,293 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:52,293 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,294 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:52,294 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:52,357 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:52,451 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:52,498 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:52,545 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:52,545 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:52,724 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:52,728 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:52,780 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:52,785 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:52,924 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:53,379 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:53,382 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:53,427 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:53,491 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a56cdac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:53,514 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:53,523 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:53,545 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4186ms
2020-12-03 07:22:53,706 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:53,711 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:53,711 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:53,723 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:53,726 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:53,727 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:53,727 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:53,766 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:53,766 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:53,781 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35774
2020-12-03 07:22:53,785 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:53,850 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1807f5a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:53,853 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb4f2a9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:53,905 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4dd6fd0a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:53,919 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@295ace64{HTTP/1.1,[http/1.1]}{localhost:35774}
2020-12-03 07:22:53,920 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4561ms
2020-12-03 07:22:53,950 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:53,951 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:53,951 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:53,952 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:53,952 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:53,952 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:53,953 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:53,953 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:53,954 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:53,955 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:53,956 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:53,956 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:53,957 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:53
2020-12-03 07:22:53,957 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:53,958 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:53,958 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:53,958 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:53,964 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:53,964 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:53,965 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:53,965 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:53,966 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:53,966 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:53,966 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:53,967 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:53,967 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:53,967 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:22:53,968 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:53,968 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:53,968 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:53,969 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:53,969 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:53,970 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:53,970 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:53,973 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:53,973 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:53,974 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:53,974 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:53,974 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:53,975 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:53,975 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:53,975 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:53,976 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:53,976 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:53,977 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:53,978 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:53,978 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:53,978 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:53,978 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:53,979 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:53,979 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:53,980 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:53,980 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:54,035 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:54,060 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:54,064 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:54,065 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:54,066 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:54,066 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:54,105 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:54,114 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:54,115 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:54,122 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:54,123 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:54,229 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:54,230 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 246 msecs
2020-12-03 07:22:54,456 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:54,507 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:54,524 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:54,875 [Listener at localhost/33556] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33556 to access this namenode/service.
2020-12-03 07:22:54,890 [Listener at localhost/33556] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:54,915 [Listener at localhost/33556] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:54,917 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@1fdfafd2] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-12-03 07:22:54,928 [Listener at localhost/33556] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:54,931 [Listener at localhost/33556] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:54,932 [Listener at localhost/33556] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:54,932 [Listener at localhost/33556] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:54,939 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:54,939 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:54,939 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:54,943 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:54,944 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:54,944 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-12-03 07:22:54,993 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:55,021 [Listener at localhost/33556] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33556
2020-12-03 07:22:55,023 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:55,055 [Listener at localhost/33556] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:55,056 [Listener at localhost/33556] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:55,090 [Listener at localhost/33556] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 34 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:55,097 [CacheReplicationMonitor(2103819430)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:55,122 [Listener at localhost/33556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:55,235 [Listener at localhost/33556] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:55,256 [Listener at localhost/33556] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:55,309 [Listener at localhost/33556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:55,320 [Listener at localhost/33556] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:55,324 [Listener at localhost/33556] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:55,329 [Listener at localhost/33556] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:55,331 [Listener at localhost/33556] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:55,337 [Listener at localhost/33556] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:55,347 [Listener at localhost/33556] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44129
2020-12-03 07:22:55,350 [Listener at localhost/33556] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:55,351 [Listener at localhost/33556] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:55,371 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:55,385 [Listener at localhost/33556] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:55,387 [Listener at localhost/33556] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:55,388 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:55,396 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:55,397 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:55,398 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:55,398 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:55,402 [Listener at localhost/33556] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37666
2020-12-03 07:22:55,402 [Listener at localhost/33556] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:55,404 [Listener at localhost/33556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@acb0951{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:55,405 [Listener at localhost/33556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@267f474e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:55,413 [Listener at localhost/33556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3faf2e7d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:55,416 [Listener at localhost/33556] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@35892295{HTTP/1.1,[http/1.1]}{localhost:37666}
2020-12-03 07:22:55,417 [Listener at localhost/33556] INFO  server.Server (Server.java:doStart(419)) - Started @6057ms
2020-12-03 07:22:55,811 [Listener at localhost/33556] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44095
2020-12-03 07:22:55,812 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f130eaf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:55,814 [Listener at localhost/33556] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:55,814 [Listener at localhost/33556] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:55,839 [Listener at localhost/33556] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:55,845 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:56,101 [Listener at localhost/34423] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34423
2020-12-03 07:22:56,132 [Listener at localhost/34423] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:56,133 [Listener at localhost/34423] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:56,159 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:56,166 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:56,166 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:56,175 [Listener at localhost/34423] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:56,192 [Listener at localhost/34423] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:56,197 [Listener at localhost/34423] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:56,215 [Listener at localhost/34423] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:56,235 [Listener at localhost/34423] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,236 [Listener at localhost/34423] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:56,238 [Listener at localhost/34423] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:56,241 [Listener at localhost/34423] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,242 [Listener at localhost/34423] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:56,243 [Listener at localhost/34423] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35006
2020-12-03 07:22:56,244 [Listener at localhost/34423] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:56,245 [Listener at localhost/34423] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:56,248 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,250 [Listener at localhost/34423] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,251 [Listener at localhost/34423] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:56,251 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,253 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,255 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:56,255 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,255 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,256 [Listener at localhost/34423] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35445
2020-12-03 07:22:56,257 [Listener at localhost/34423] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:56,267 [Listener at localhost/34423] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ad3a1bb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:56,269 [Listener at localhost/34423] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@324c64cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:56,277 [Listener at localhost/34423] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e3cee7b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:56,280 [Listener at localhost/34423] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@71e9a896{HTTP/1.1,[http/1.1]}{localhost:35445}
2020-12-03 07:22:56,290 [Listener at localhost/34423] INFO  server.Server (Server.java:doStart(419)) - Started @6931ms
2020-12-03 07:22:56,463 [Listener at localhost/34423] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43477
2020-12-03 07:22:56,467 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@408b35bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:56,476 [Listener at localhost/34423] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:56,476 [Listener at localhost/34423] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:56,477 [Listener at localhost/34423] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:56,478 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:56,485 [Listener at localhost/42901] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42901
2020-12-03 07:22:56,513 [Listener at localhost/42901] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:56,514 [Listener at localhost/42901] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:56,515 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:56,516 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:56,517 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:56,521 [Listener at localhost/42901] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:56,537 [Listener at localhost/42901] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:56,538 [Listener at localhost/42901] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:56,540 [Listener at localhost/42901] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:56,541 [Listener at localhost/42901] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,542 [Listener at localhost/42901] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:56,542 [Listener at localhost/42901] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:56,543 [Listener at localhost/42901] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,543 [Listener at localhost/42901] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:56,547 [Listener at localhost/42901] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36413
2020-12-03 07:22:56,548 [Listener at localhost/42901] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:56,548 [Listener at localhost/42901] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:56,555 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,560 [Listener at localhost/42901] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,561 [Listener at localhost/42901] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:56,562 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,565 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,566 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:56,567 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,567 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,568 [Listener at localhost/42901] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43256
2020-12-03 07:22:56,568 [Listener at localhost/42901] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:56,574 [Listener at localhost/42901] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@750fe12e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:56,575 [Listener at localhost/42901] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e587920{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:56,613 [Listener at localhost/42901] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@133e019b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:56,614 [Listener at localhost/42901] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41382722{HTTP/1.1,[http/1.1]}{localhost:43256}
2020-12-03 07:22:56,615 [Listener at localhost/42901] INFO  server.Server (Server.java:doStart(419)) - Started @7255ms
2020-12-03 07:22:56,686 [Listener at localhost/42901] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40272
2020-12-03 07:22:56,688 [Listener at localhost/42901] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:56,688 [Listener at localhost/42901] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:56,689 [Listener at localhost/42901] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:56,690 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:56,693 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@425357dd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:56,703 [Listener at localhost/42916] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42916
2020-12-03 07:22:56,710 [Listener at localhost/42916] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:56,711 [Listener at localhost/42916] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:56,712 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:56,712 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:56,713 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:56,718 [Listener at localhost/42916] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:56,721 [Listener at localhost/42916] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:56,721 [Listener at localhost/42916] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:56,732 [Listener at localhost/42916] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:56,733 [Listener at localhost/42916] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,733 [Listener at localhost/42916] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:56,735 [Listener at localhost/42916] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:56,735 [Listener at localhost/42916] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,736 [Listener at localhost/42916] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:56,737 [Listener at localhost/42916] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43188
2020-12-03 07:22:56,739 [Listener at localhost/42916] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:56,740 [Listener at localhost/42916] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:56,742 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,745 [Listener at localhost/42916] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,747 [Listener at localhost/42916] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:56,747 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,751 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,752 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:56,753 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,753 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,754 [Listener at localhost/42916] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40574
2020-12-03 07:22:56,754 [Listener at localhost/42916] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:56,761 [Listener at localhost/42916] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@669253b7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:56,762 [Listener at localhost/42916] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51a06cbe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:56,772 [Listener at localhost/42916] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@ecf9fb3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:56,778 [Listener at localhost/42916] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2d35442b{HTTP/1.1,[http/1.1]}{localhost:40574}
2020-12-03 07:22:56,779 [Listener at localhost/42916] INFO  server.Server (Server.java:doStart(419)) - Started @7420ms
2020-12-03 07:22:56,896 [Listener at localhost/42916] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44647
2020-12-03 07:22:56,897 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4593ff34] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:56,897 [Listener at localhost/42916] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:56,897 [Listener at localhost/42916] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:56,897 [Listener at localhost/42916] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:56,898 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:56,918 [Listener at localhost/44206] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44206
2020-12-03 07:22:56,932 [Listener at localhost/44206] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:56,933 [Listener at localhost/44206] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:56,936 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:56,940 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:56,940 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:56,960 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:56,960 [Listener at localhost/44206] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:56,965 [Listener at localhost/44206] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:56,965 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:56,968 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:56,969 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:56,970 [Listener at localhost/44206] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:56,967 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:56,966 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:56,970 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:56,972 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:56,974 [Listener at localhost/44206] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:56,975 [Listener at localhost/44206] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,976 [Listener at localhost/44206] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:56,978 [Listener at localhost/44206] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:56,979 [Listener at localhost/44206] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,979 [Listener at localhost/44206] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:56,980 [Listener at localhost/44206] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36365
2020-12-03 07:22:56,980 [Listener at localhost/44206] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:56,981 [Listener at localhost/44206] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:56,982 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,985 [Listener at localhost/44206] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,986 [Listener at localhost/44206] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:56,986 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,989 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,990 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:56,990 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,991 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,993 [Listener at localhost/44206] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33693
2020-12-03 07:22:57,008 [Listener at localhost/44206] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,015 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,016 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,015 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,017 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,018 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:57,018 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:57,020 [Listener at localhost/44206] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a2bb0eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,021 [Listener at localhost/44206] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d0566ba{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,031 [Listener at localhost/44206] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a7b503d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,033 [Listener at localhost/44206] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@512d92b{HTTP/1.1,[http/1.1]}{localhost:33693}
2020-12-03 07:22:57,033 [Listener at localhost/44206] INFO  server.Server (Server.java:doStart(419)) - Started @7674ms
2020-12-03 07:22:57,040 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,040 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,041 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,042 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:57,043 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,045 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:57,060 [Listener at localhost/44206] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36217
2020-12-03 07:22:57,060 [Listener at localhost/44206] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,061 [Listener at localhost/44206] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,062 [Listener at localhost/44206] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,061 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bdf6bb7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,063 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,074 [Listener at localhost/43409] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43409
2020-12-03 07:22:57,080 [Listener at localhost/43409] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:57,081 [Listener at localhost/43409] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:57,082 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:57,086 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:57,087 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:57,088 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,088 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,092 [Listener at localhost/43409] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:57,094 [Listener at localhost/43409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:57,094 [Listener at localhost/43409] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:57,096 [Listener at localhost/43409] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:57,096 [Listener at localhost/43409] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,096 [Listener at localhost/43409] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:57,098 [Listener at localhost/43409] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:57,098 [Listener at localhost/43409] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,098 [Listener at localhost/43409] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:57,099 [Listener at localhost/43409] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37459
2020-12-03 07:22:57,099 [Listener at localhost/43409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:57,100 [Listener at localhost/43409] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:57,101 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,103 [Listener at localhost/43409] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,104 [Listener at localhost/43409] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:57,104 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,107 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,108 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:57,108 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,109 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,110 [Listener at localhost/43409] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40273
2020-12-03 07:22:57,110 [Listener at localhost/43409] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,114 [Listener at localhost/43409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7bd69e82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,115 [Listener at localhost/43409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51b01960{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,123 [Listener at localhost/43409] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a7704c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,124 [Listener at localhost/43409] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6754ef00{HTTP/1.1,[http/1.1]}{localhost:40273}
2020-12-03 07:22:57,124 [Listener at localhost/43409] INFO  server.Server (Server.java:doStart(419)) - Started @7765ms
2020-12-03 07:22:57,142 [Listener at localhost/43409] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36990
2020-12-03 07:22:57,143 [Listener at localhost/43409] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,143 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@323e8306] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,143 [Listener at localhost/43409] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,144 [Listener at localhost/43409] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,144 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,157 [Listener at localhost/42624] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42624
2020-12-03 07:22:57,164 [Listener at localhost/42624] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:57,164 [Listener at localhost/42624] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:57,165 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:57,169 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,175 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,172 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:57,181 [Listener at localhost/42624] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:57,179 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,185 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,185 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-11d702bc-9bdd-47a1-a5f2-1a215015b377 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:22:57,187 [Listener at localhost/42624] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:57,189 [Listener at localhost/42624] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:57,189 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:57,191 [Listener at localhost/42624] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:57,191 [Listener at localhost/42624] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,191 [Listener at localhost/42624] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:57,192 [Listener at localhost/42624] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:57,192 [Listener at localhost/42624] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,193 [Listener at localhost/42624] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:57,196 [Listener at localhost/42624] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36727
2020-12-03 07:22:57,196 [Listener at localhost/42624] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:57,196 [Listener at localhost/42624] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:57,197 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,199 [Listener at localhost/42624] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,211 [Listener at localhost/42624] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:57,211 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,214 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,215 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:57,215 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,215 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,216 [Listener at localhost/42624] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46622
2020-12-03 07:22:57,217 [Listener at localhost/42624] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,219 [Listener at localhost/42624] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54a3ab8f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,222 [Listener at localhost/42624] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a1ebcff{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,231 [Listener at localhost/42624] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@63a5e46c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,232 [Listener at localhost/42624] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e8e8651{HTTP/1.1,[http/1.1]}{localhost:46622}
2020-12-03 07:22:57,232 [Listener at localhost/42624] INFO  server.Server (Server.java:doStart(419)) - Started @7873ms
2020-12-03 07:22:57,245 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,245 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,245 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,246 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,246 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,246 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:57,246 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:57,247 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,248 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-be96871d-4685-4cb2-b5a5-ab6d502ac360 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:22:57,268 [Listener at localhost/42624] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46091
2020-12-03 07:22:57,273 [Listener at localhost/42624] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,273 [Listener at localhost/42624] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,274 [Listener at localhost/42624] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,274 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@271f18d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,276 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,281 [Listener at localhost/35906] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35906
2020-12-03 07:22:57,288 [Listener at localhost/35906] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:57,289 [Listener at localhost/35906] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:57,289 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:57,292 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,292 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,296 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,297 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,296 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,297 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,298 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:57,351 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1efa175c-f495-434d-bae9-1f6dda15846c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:57,352 [Listener at localhost/35906] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:57,351 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:57,351 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:57,360 [Listener at localhost/35906] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:57,363 [Listener at localhost/35906] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:57,368 [Listener at localhost/35906] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:57,368 [Listener at localhost/35906] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,368 [Listener at localhost/35906] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:57,369 [Listener at localhost/35906] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:57,369 [Listener at localhost/35906] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,369 [Listener at localhost/35906] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:57,370 [Listener at localhost/35906] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43065
2020-12-03 07:22:57,370 [Listener at localhost/35906] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:57,370 [Listener at localhost/35906] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:57,372 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,373 [Listener at localhost/35906] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,374 [Listener at localhost/35906] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:57,374 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,376 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,378 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:57,379 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,379 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,380 [Listener at localhost/35906] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39091
2020-12-03 07:22:57,380 [Listener at localhost/35906] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,385 [Listener at localhost/35906] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10567255{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,386 [Listener at localhost/35906] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c4ee95c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,424 [Listener at localhost/35906] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3add81c4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,426 [Listener at localhost/35906] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@492f5b62{HTTP/1.1,[http/1.1]}{localhost:39091}
2020-12-03 07:22:57,427 [Listener at localhost/35906] INFO  server.Server (Server.java:doStart(419)) - Started @8067ms
2020-12-03 07:22:57,562 [Listener at localhost/35906] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38779
2020-12-03 07:22:57,563 [Listener at localhost/35906] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,563 [Listener at localhost/35906] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,563 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c65121] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,564 [Listener at localhost/35906] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,565 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,568 [Listener at localhost/34336] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34336
2020-12-03 07:22:57,575 [Listener at localhost/34336] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:57,575 [Listener at localhost/34336] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:57,577 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,577 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,582 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:57,598 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:57,598 [Listener at localhost/34336] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:57,599 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:57,601 [Listener at localhost/34336] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:57,602 [Listener at localhost/34336] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:57,604 [Listener at localhost/34336] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:57,604 [Listener at localhost/34336] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,604 [Listener at localhost/34336] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:57,605 [Listener at localhost/34336] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:57,615 [Listener at localhost/34336] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:57,616 [Listener at localhost/34336] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:57,617 [Listener at localhost/34336] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33535
2020-12-03 07:22:57,618 [Listener at localhost/34336] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:57,618 [Listener at localhost/34336] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:57,624 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,626 [Listener at localhost/34336] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:57,631 [Listener at localhost/34336] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:57,632 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:57,635 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:57,636 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:57,636 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:57,636 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:57,637 [Listener at localhost/34336] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36035
2020-12-03 07:22:57,638 [Listener at localhost/34336] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:57,640 [Listener at localhost/34336] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31198ceb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:57,641 [Listener at localhost/34336] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75201592{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,650 [Listener at localhost/34336] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27f0ad19{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,651 [Listener at localhost/34336] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@54e81b21{HTTP/1.1,[http/1.1]}{localhost:36035}
2020-12-03 07:22:57,651 [Listener at localhost/34336] INFO  server.Server (Server.java:doStart(419)) - Started @8292ms
2020-12-03 07:22:57,654 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,656 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,656 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:22:57,654 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,657 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,658 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a56fb054-8f03-4051-8e81-893ebcf4e852 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:22:57,685 [Listener at localhost/34336] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42952
2020-12-03 07:22:57,686 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6650813a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,686 [Listener at localhost/34336] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,686 [Listener at localhost/34336] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,687 [Listener at localhost/34336] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,688 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,696 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34526
2020-12-03 07:22:57,708 [Listener at localhost/34526] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:57,709 [Listener at localhost/34526] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:57,709 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,710 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,712 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:22:57,712 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556 starting to offer service
2020-12-03 07:22:57,739 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,739 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,760 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33556
2020-12-03 07:22:57,765 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:57,774 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,775 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,777 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,777 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,781 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,781 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,782 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,782 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,790 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,790 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,790 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,791 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,791 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,791 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,793 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,793 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,823 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,824 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,824 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-52f6da26-8467-4836-beaa-bc7025da3d08 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:22:57,880 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,881 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,881 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5114e173-3b3c-4489-bece-91c8fe32cd03 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:22:57,934 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:57,943 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,944 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,944 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,944 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,956 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,956 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,958 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:22:57,959 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:57,960 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:57,960 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0890bb71-321f-4cae-8aa2-540c52234ef2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:22:57,990 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,992 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,993 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,992 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:57,994 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,994 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,993 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:57,996 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:57,994 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,000 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,001 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,001 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,036 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,036 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,037 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,037 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,037 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,037 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,038 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,038 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,126 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,127 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,127 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,127 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,152 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 8378@4c2c7c544001
2020-12-03 07:22:58,152 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1770548440. Formatting...
2020-12-03 07:22:58,155 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,168 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:22:58,183 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,187 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,187 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,187 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,188 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,188 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,187 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,192 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,192 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,211 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,211 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,227 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,227 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,228 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,228 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,352 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,425 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,427 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f4cd2c65-00ba-436e-bc9e-747a1d3c4049
2020-12-03 07:22:58,426 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 87d2b441-cfb3-4464-a313-36d6eaa163f9
2020-12-03 07:22:58,438 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,438 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,439 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,439 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,439 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2cae3155-407a-4ada-b6de-3a4ce502c279
2020-12-03 07:22:58,442 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 89059d77-c6e8-4d17-9e2e-f1c5202c92f6
2020-12-03 07:22:58,444 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,444 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,444 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,444 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,444 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,448 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,448 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,448 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,499 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998
2020-12-03 07:22:58,566 [IPC Server handler 1 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:58,577 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:58,577 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:58,588 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,589 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,589 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-631318316-172.17.0.2-1606980172338 is not formatted. Formatting ...
2020-12-03 07:22:58,589 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-631318316-172.17.0.2-1606980172338 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-631318316-172.17.0.2-1606980172338/current
2020-12-03 07:22:58,601 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9caae05a-cc37-4f41-84a4-131bde04ea30
2020-12-03 07:22:58,601 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,602 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,653 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229
2020-12-03 07:22:58,654 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:58,653 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39
2020-12-03 07:22:58,658 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:58,654 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-be96871d-4685-4cb2-b5a5-ab6d502ac360
2020-12-03 07:22:58,659 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:22:58,660 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2
2020-12-03 07:22:58,660 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:58,663 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-11d702bc-9bdd-47a1-a5f2-1a215015b377
2020-12-03 07:22:58,663 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:22:58,655 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b
2020-12-03 07:22:58,664 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:58,667 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5
2020-12-03 07:22:58,667 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:58,674 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1
2020-12-03 07:22:58,675 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:58,676 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,676 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,676 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09
2020-12-03 07:22:58,676 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:22:58,685 [IPC Server handler 7 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:58,686 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,687 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-52f6da26-8467-4836-beaa-bc7025da3d08
2020-12-03 07:22:58,687 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:22:58,687 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:58,688 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:58,688 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,690 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1efa175c-f495-434d-bae9-1f6dda15846c
2020-12-03 07:22:58,690 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:58,691 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,700 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:58,701 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:58,704 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:58,706 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:58,707 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06
2020-12-03 07:22:58,709 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:58,709 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,710 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:58,711 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:58,717 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:58,717 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:58,719 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:58,719 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1770548440;bpid=BP-631318316-172.17.0.2-1606980172338;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1770548440;c=1606980172338;bpid=BP-631318316-172.17.0.2-1606980172338;dnuuid=null
2020-12-03 07:22:58,720 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:58,721 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:58,721 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:58,721 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:58,721 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:58,721 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:58,721 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:58,733 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:58,732 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:58,735 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:58,721 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:58,721 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:58,738 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:58,738 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:58,737 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,736 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,733 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:58,739 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,739 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,738 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,740 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:58,740 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:58,740 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:58,740 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:58,742 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:58,748 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:58,749 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:58,749 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:58,750 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,750 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:58,750 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:58,751 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:58,751 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:58,754 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d291e966-f226-4f4d-8cf8-a56f618a3e23
2020-12-03 07:22:58,754 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d
2020-12-03 07:22:58,758 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a56fb054-8f03-4051-8e81-893ebcf4e852
2020-12-03 07:22:58,759 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:22:58,761 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2
2020-12-03 07:22:58,761 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:22:58,761 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0890bb71-321f-4cae-8aa2-540c52234ef2
2020-12-03 07:22:58,762 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:22:58,762 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,765 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3
2020-12-03 07:22:58,765 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:22:58,766 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,766 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:58,768 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:58,769 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:58,769 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:58,770 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:58,770 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:58,770 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:58,771 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:58,771 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,771 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:58,772 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:58,789 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:58,793 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:58,793 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:58,793 [IPC Server handler 5 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:58,794 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:58,795 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:58,815 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 754beefe-30e4-4177-9a0e-0e6118511d00
2020-12-03 07:22:58,838 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 66ms
2020-12-03 07:22:58,838 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 98ms
2020-12-03 07:22:58,874 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 102ms
2020-12-03 07:22:58,898 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5114e173-3b3c-4489-bece-91c8fe32cd03
2020-12-03 07:22:58,903 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:22:58,910 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 139ms
2020-12-03 07:22:58,913 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:58,913 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:58,913 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95
2020-12-03 07:22:58,913 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:22:58,914 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:58,915 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:58,913 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:58,917 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:58,917 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:58,917 [IPC Server handler 6 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:58,918 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:58,932 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 189ms
2020-12-03 07:22:58,936 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 23ms
2020-12-03 07:22:58,942 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 202ms
2020-12-03 07:22:58,978 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 238ms
2020-12-03 07:22:58,913 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:58,984 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:58,985 [Thread-303] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:58,985 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 72ms
2020-12-03 07:22:58,987 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 75ms
2020-12-03 07:22:58,987 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:58,994 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:58,998 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 12ms
2020-12-03 07:22:58,996 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:59,052 [Thread-304] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:58,995 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:59,039 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,053 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:22:59,029 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 236ms
2020-12-03 07:22:59,026 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:59,084 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 335ms
2020-12-03 07:22:59,080 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,088 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 337ms
2020-12-03 07:22:59,075 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:59,054 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 71ms
2020-12-03 07:22:59,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:59,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:59,111 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 317ms
2020-12-03 07:22:59,109 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:59,109 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 369ms
2020-12-03 07:22:59,097 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 348ms
2020-12-03 07:22:59,142 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 352ms
2020-12-03 07:22:59,084 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,153 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:59,153 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,141 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 399ms
2020-12-03 07:22:59,153 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 415ms
2020-12-03 07:22:59,154 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3): no suitable block pools found to scan.  Waiting 1814399864 ms.
2020-12-03 07:22:59,154 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:22:59,154 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:59,154 [Thread-312] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,155 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:17 PM with interval of 21600000ms
2020-12-03 07:22:59,155 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 417ms
2020-12-03 07:22:59,141 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:22:59,140 [IPC Server handler 9 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,157 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:59,157 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:59,137 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2): no suitable block pools found to scan.  Waiting 1814399858 ms.
2020-12-03 07:22:59,137 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 388ms
2020-12-03 07:22:59,132 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 381ms
2020-12-03 07:22:59,164 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 424ms
2020-12-03 07:22:59,127 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 376ms
2020-12-03 07:22:59,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,110 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 359ms
2020-12-03 07:22:59,165 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:22:59,164 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 424ms
2020-12-03 07:22:59,163 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:59,165 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 415ms
2020-12-03 07:22:59,165 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,166 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:22:59,167 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 13ms
2020-12-03 07:22:59,184 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:59,184 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,185 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 33ms
2020-12-03 07:22:59,186 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:05 PM with interval of 21600000ms
2020-12-03 07:22:59,186 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:59,187 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-0890bb71-321f-4cae-8aa2-540c52234ef2): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,156 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:54 AM with interval of 21600000ms
2020-12-03 07:22:59,182 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:59,200 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,179 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,179 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:59,216 [Thread-313] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,212 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:59,212 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:59,224 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:59,224 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 24ms
2020-12-03 07:22:59,226 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,212 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:59,253 [Thread-328] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,254 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:22:59,260 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 40ms
2020-12-03 07:22:59,200 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-12-03 07:22:59,200 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-0890bb71-321f-4cae-8aa2-540c52234ef2): no suitable block pools found to scan.  Waiting 1814399985 ms.
2020-12-03 07:22:59,187 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:59,261 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 105ms
2020-12-03 07:22:59,253 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 2cae3155-407a-4ada-b6de-3a4ce502c279) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,239 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid d291e966-f226-4f4d-8cf8-a56f618a3e23) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:59,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-a56fb054-8f03-4051-8e81-893ebcf4e852): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,224 [Thread-326] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,224 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,275 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 51ms
2020-12-03 07:22:59,224 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:59,224 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:59,223 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-12-03 07:22:59,277 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,275 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 51ms
2020-12-03 07:22:59,269 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 128ms
2020-12-03 07:22:59,268 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-12-03 07:22:59,279 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 115ms
2020-12-03 07:22:59,280 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:22 AM with interval of 21600000ms
2020-12-03 07:22:59,281 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:59,300 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-52f6da26-8467-4836-beaa-bc7025da3d08): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,268 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-a56fb054-8f03-4051-8e81-893ebcf4e852): no suitable block pools found to scan.  Waiting 1814399917 ms.
2020-12-03 07:22:59,264 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 99ms
2020-12-03 07:22:59,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-52f6da26-8467-4836-beaa-bc7025da3d08): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:22:59,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:59,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,304 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:02 AM with interval of 21600000ms
2020-12-03 07:22:59,262 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:59,305 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:59,262 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:59 AM with interval of 21600000ms
2020-12-03 07:22:59,304 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:59,306 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,296 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 9caae05a-cc37-4f41-84a4-131bde04ea30) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,295 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-631318316-172.17.0.2-1606980172338 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 185ms
2020-12-03 07:22:59,293 [IPC Server handler 1 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36727, datanodeUuid=1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d, infoPort=46091, infoSecurePort=0, ipcPort=35906, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d
2020-12-03 07:22:59,293 [IPC Server handler 8 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,280 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:59,310 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:59,311 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:59,311 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-631318316-172.17.0.2-1606980172338: 258ms
2020-12-03 07:22:59,311 [IPC Server handler 1 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36727
2020-12-03 07:22:59,311 [IPC Server handler 1 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d (127.0.0.1:36727).
2020-12-03 07:22:59,312 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:59,278 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:22:59,278 [Thread-329] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,277 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 123ms
2020-12-03 07:22:59,315 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 37ms
2020-12-03 07:22:59,312 [Thread-339] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:59,310 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1efa175c-f495-434d-bae9-1f6dda15846c): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,316 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:37 AM with interval of 21600000ms
2020-12-03 07:22:59,317 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:59,317 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1efa175c-f495-434d-bae9-1f6dda15846c): no suitable block pools found to scan.  Waiting 1814399944 ms.
2020-12-03 07:22:59,310 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be96871d-4685-4cb2-b5a5-ab6d502ac360): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,317 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-11d702bc-9bdd-47a1-a5f2-1a215015b377): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,306 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:59,317 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 5ms
2020-12-03 07:22:59,316 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 152ms
2020-12-03 07:22:59,317 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be96871d-4685-4cb2-b5a5-ab6d502ac360): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:22:59,318 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-11d702bc-9bdd-47a1-a5f2-1a215015b377): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:59,318 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:59,319 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:59,319 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,320 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:59,321 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 87d2b441-cfb3-4464-a313-36d6eaa163f9) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,321 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:59,321 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 89059d77-c6e8-4d17-9e2e-f1c5202c92f6) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,321 [Thread-340] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-631318316-172.17.0.2-1606980172338/current/replicas doesn't exist 
2020-12-03 07:22:59,322 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:22:59,327 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:17 AM with interval of 21600000ms
2020-12-03 07:22:59,327 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-631318316-172.17.0.2-1606980172338: 17ms
2020-12-03 07:22:59,328 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,329 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-12-03 07:22:59,329 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:59,330 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-5114e173-3b3c-4489-bece-91c8fe32cd03): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,331 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-5114e173-3b3c-4489-bece-91c8fe32cd03): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:59,331 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,331 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,327 [IPC Server handler 7 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43065, datanodeUuid=d291e966-f226-4f4d-8cf8-a56f618a3e23, infoPort=38779, infoSecurePort=0, ipcPort=34336, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage d291e966-f226-4f4d-8cf8-a56f618a3e23
2020-12-03 07:22:59,337 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid f4cd2c65-00ba-436e-bc9e-747a1d3c4049) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,337 [IPC Server handler 7 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43065
2020-12-03 07:22:59,331 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-631318316-172.17.0.2-1606980172338 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:59,338 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,330 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09): finished scanning block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,328 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:23 AM with interval of 21600000ms
2020-12-03 07:22:59,351 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:22:59,339 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-12-03 07:22:59,338 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,370 [IPC Server handler 7 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d291e966-f226-4f4d-8cf8-a56f618a3e23 (127.0.0.1:43065).
2020-12-03 07:22:59,375 [IPC Server handler 5 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44129, datanodeUuid=2cae3155-407a-4ada-b6de-3a4ce502c279, infoPort=44095, infoSecurePort=0, ipcPort=34423, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 2cae3155-407a-4ada-b6de-3a4ce502c279
2020-12-03 07:22:59,375 [IPC Server handler 5 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44129
2020-12-03 07:22:59,375 [IPC Server handler 5 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2cae3155-407a-4ada-b6de-3a4ce502c279 (127.0.0.1:44129).
2020-12-03 07:22:59,376 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid d291e966-f226-4f4d-8cf8-a56f618a3e23) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,376 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,376 [IPC Server handler 6 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37459, datanodeUuid=9caae05a-cc37-4f41-84a4-131bde04ea30, infoPort=36990, infoSecurePort=0, ipcPort=42624, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 9caae05a-cc37-4f41-84a4-131bde04ea30
2020-12-03 07:22:59,377 [IPC Server handler 6 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37459
2020-12-03 07:22:59,377 [IPC Server handler 6 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9caae05a-cc37-4f41-84a4-131bde04ea30 (127.0.0.1:37459).
2020-12-03 07:22:59,377 [IPC Server handler 4 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43188, datanodeUuid=87d2b441-cfb3-4464-a313-36d6eaa163f9, infoPort=44647, infoSecurePort=0, ipcPort=44206, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 87d2b441-cfb3-4464-a313-36d6eaa163f9
2020-12-03 07:22:59,378 [IPC Server handler 4 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43188
2020-12-03 07:22:59,378 [IPC Server handler 4 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 87d2b441-cfb3-4464-a313-36d6eaa163f9 (127.0.0.1:43188).
2020-12-03 07:22:59,379 [IPC Server handler 3 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35006, datanodeUuid=f4cd2c65-00ba-436e-bc9e-747a1d3c4049, infoPort=43477, infoSecurePort=0, ipcPort=42901, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage f4cd2c65-00ba-436e-bc9e-747a1d3c4049
2020-12-03 07:22:59,379 [IPC Server handler 3 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35006
2020-12-03 07:22:59,379 [IPC Server handler 3 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f4cd2c65-00ba-436e-bc9e-747a1d3c4049 (127.0.0.1:35006).
2020-12-03 07:22:59,379 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 2cae3155-407a-4ada-b6de-3a4ce502c279) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,361 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 754beefe-30e4-4177-9a0e-0e6118511d00) service to localhost/127.0.0.1:33556 beginning handshake with NN
2020-12-03 07:22:59,380 [IPC Server handler 2 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36413, datanodeUuid=89059d77-c6e8-4d17-9e2e-f1c5202c92f6, infoPort=40272, infoSecurePort=0, ipcPort=42916, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 89059d77-c6e8-4d17-9e2e-f1c5202c92f6
2020-12-03 07:22:59,380 [IPC Server handler 2 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36413
2020-12-03 07:22:59,381 [IPC Server handler 2 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 89059d77-c6e8-4d17-9e2e-f1c5202c92f6 (127.0.0.1:36413).
2020-12-03 07:22:59,382 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 89059d77-c6e8-4d17-9e2e-f1c5202c92f6) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,382 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,379 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,379 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 87d2b441-cfb3-4464-a313-36d6eaa163f9) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,383 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,379 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 9caae05a-cc37-4f41-84a4-131bde04ea30) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,383 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,381 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid f4cd2c65-00ba-436e-bc9e-747a1d3c4049) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,387 [IPC Server handler 0 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36365, datanodeUuid=7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998, infoPort=36217, infoSecurePort=0, ipcPort=43409, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998
2020-12-03 07:22:59,387 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,389 [IPC Server handler 0 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36365
2020-12-03 07:22:59,389 [IPC Server handler 0 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998 (127.0.0.1:36365).
2020-12-03 07:22:59,391 [IPC Server handler 0 on default port 33556] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33535, datanodeUuid=754beefe-30e4-4177-9a0e-0e6118511d00, infoPort=42952, infoSecurePort=0, ipcPort=34526, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) storage 754beefe-30e4-4177-9a0e-0e6118511d00
2020-12-03 07:22:59,391 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,392 [IPC Server handler 0 on default port 33556] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33535
2020-12-03 07:22:59,392 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,392 [IPC Server handler 0 on default port 33556] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 754beefe-30e4-4177-9a0e-0e6118511d00 (127.0.0.1:33535).
2020-12-03 07:22:59,393 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 754beefe-30e4-4177-9a0e-0e6118511d00) service to localhost/127.0.0.1:33556 successfully registered with NN
2020-12-03 07:22:59,394 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33556 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:59,428 [IPC Server handler 8 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-11d702bc-9bdd-47a1-a5f2-1a215015b377 for DN 127.0.0.1:36365
2020-12-03 07:22:59,429 [IPC Server handler 8 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09 for DN 127.0.0.1:36365
2020-12-03 07:22:59,431 [IPC Server handler 7 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a56fb054-8f03-4051-8e81-893ebcf4e852 for DN 127.0.0.1:43065
2020-12-03 07:22:59,466 [IPC Server handler 7 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0890bb71-321f-4cae-8aa2-540c52234ef2 for DN 127.0.0.1:43065
2020-12-03 07:22:59,510 [IPC Server handler 3 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5114e173-3b3c-4489-bece-91c8fe32cd03 for DN 127.0.0.1:33535
2020-12-03 07:22:59,514 [IPC Server handler 3 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95 for DN 127.0.0.1:33535
2020-12-03 07:22:59,515 [IPC Server handler 1 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39 for DN 127.0.0.1:36413
2020-12-03 07:22:59,517 [IPC Server handler 1 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1efa175c-f495-434d-bae9-1f6dda15846c for DN 127.0.0.1:36413
2020-12-03 07:22:59,517 [IPC Server handler 4 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b for DN 127.0.0.1:43188
2020-12-03 07:22:59,517 [IPC Server handler 4 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1 for DN 127.0.0.1:43188
2020-12-03 07:22:59,517 [IPC Server handler 7 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2 for DN 127.0.0.1:36727
2020-12-03 07:22:59,517 [IPC Server handler 7 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3 for DN 127.0.0.1:36727
2020-12-03 07:22:59,521 [IPC Server handler 6 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,521 [IPC Server handler 5 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-be96871d-4685-4cb2-b5a5-ab6d502ac360 for DN 127.0.0.1:37459
2020-12-03 07:22:59,521 [IPC Server handler 5 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-52f6da26-8467-4836-beaa-bc7025da3d08 for DN 127.0.0.1:37459
2020-12-03 07:22:59,522 [IPC Server handler 0 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5 for DN 127.0.0.1:44129
2020-12-03 07:22:59,522 [IPC Server handler 0 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06 for DN 127.0.0.1:44129
2020-12-03 07:22:59,522 [IPC Server handler 9 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229 for DN 127.0.0.1:35006
2020-12-03 07:22:59,522 [IPC Server handler 9 on default port 33556] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2 for DN 127.0.0.1:35006
2020-12-03 07:22:59,549 [IPC Server handler 8 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36365, datanodeUuid=7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998, infoPort=36217, infoSecurePort=0, ipcPort=43409, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:22:59,553 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:33535
2020-12-03 07:22:59,553 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:59,558 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x56e5c9dee661edf9: Processing first storage report for DS-11d702bc-9bdd-47a1-a5f2-1a215015b377 from datanode 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998
2020-12-03 07:22:59,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x56e5c9dee661edf9: from storage DS-11d702bc-9bdd-47a1-a5f2-1a215015b377 node DatanodeRegistration(127.0.0.1:36365, datanodeUuid=7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998, infoPort=36217, infoSecurePort=0, ipcPort=43409, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,564 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33535, datanodeUuid=754beefe-30e4-4177-9a0e-0e6118511d00, infoPort=42952, infoSecurePort=0, ipcPort=34526, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:22:59,576 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x101d381c806d26de: Processing first storage report for DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95 from datanode 754beefe-30e4-4177-9a0e-0e6118511d00
2020-12-03 07:22:59,576 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x101d381c806d26de: from storage DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95 node DatanodeRegistration(127.0.0.1:33535, datanodeUuid=754beefe-30e4-4177-9a0e-0e6118511d00, infoPort=42952, infoSecurePort=0, ipcPort=34526, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,576 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x56e5c9dee661edf9: Processing first storage report for DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09 from datanode 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998
2020-12-03 07:22:59,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x56e5c9dee661edf9: from storage DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09 node DatanodeRegistration(127.0.0.1:36365, datanodeUuid=7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998, infoPort=36217, infoSecurePort=0, ipcPort=43409, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x101d381c806d26de: Processing first storage report for DS-5114e173-3b3c-4489-bece-91c8fe32cd03 from datanode 754beefe-30e4-4177-9a0e-0e6118511d00
2020-12-03 07:22:59,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x101d381c806d26de: from storage DS-5114e173-3b3c-4489-bece-91c8fe32cd03 node DatanodeRegistration(127.0.0.1:33535, datanodeUuid=754beefe-30e4-4177-9a0e-0e6118511d00, infoPort=42952, infoSecurePort=0, ipcPort=34526, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,581 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43188, datanodeUuid=87d2b441-cfb3-4464-a313-36d6eaa163f9, infoPort=44647, infoSecurePort=0, ipcPort=44206, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:22:59,583 [IPC Server handler 8 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x56e5c9dee661edf9
2020-12-03 07:22:59,583 [IPC Server handler 2 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x101d381c806d26de
2020-12-03 07:22:59,583 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb0278532e7abfaff: Processing first storage report for DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1 from datanode 87d2b441-cfb3-4464-a313-36d6eaa163f9
2020-12-03 07:22:59,584 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb0278532e7abfaff: from storage DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1 node DatanodeRegistration(127.0.0.1:43188, datanodeUuid=87d2b441-cfb3-4464-a313-36d6eaa163f9, infoPort=44647, infoSecurePort=0, ipcPort=44206, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,587 [IPC Server handler 1 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36413, datanodeUuid=89059d77-c6e8-4d17-9e2e-f1c5202c92f6, infoPort=40272, infoSecurePort=0, ipcPort=42916, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:22:59,587 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbfb87e42c713545e: Processing first storage report for DS-1efa175c-f495-434d-bae9-1f6dda15846c from datanode 89059d77-c6e8-4d17-9e2e-f1c5202c92f6
2020-12-03 07:22:59,587 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbfb87e42c713545e: from storage DS-1efa175c-f495-434d-bae9-1f6dda15846c node DatanodeRegistration(127.0.0.1:36413, datanodeUuid=89059d77-c6e8-4d17-9e2e-f1c5202c92f6, infoPort=40272, infoSecurePort=0, ipcPort=42916, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,595 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbfb87e42c713545e: Processing first storage report for DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39 from datanode 89059d77-c6e8-4d17-9e2e-f1c5202c92f6
2020-12-03 07:22:59,595 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbfb87e42c713545e: from storage DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39 node DatanodeRegistration(127.0.0.1:36413, datanodeUuid=89059d77-c6e8-4d17-9e2e-f1c5202c92f6, infoPort=40272, infoSecurePort=0, ipcPort=42916, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb0278532e7abfaff: Processing first storage report for DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b from datanode 87d2b441-cfb3-4464-a313-36d6eaa163f9
2020-12-03 07:22:59,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb0278532e7abfaff: from storage DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b node DatanodeRegistration(127.0.0.1:43188, datanodeUuid=87d2b441-cfb3-4464-a313-36d6eaa163f9, infoPort=44647, infoSecurePort=0, ipcPort=44206, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,597 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36727, datanodeUuid=1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d, infoPort=46091, infoSecurePort=0, ipcPort=35906, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:22:59,597 [IPC Server handler 1 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xbfb87e42c713545e
2020-12-03 07:22:59,597 [IPC Server handler 3 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb0278532e7abfaff
2020-12-03 07:22:59,597 [IPC Server handler 7 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43065, datanodeUuid=d291e966-f226-4f4d-8cf8-a56f618a3e23, infoPort=38779, infoSecurePort=0, ipcPort=34336, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:22:59,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc5215968e079703d: Processing first storage report for DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2 from datanode 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d
2020-12-03 07:22:59,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc5215968e079703d: from storage DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2 node DatanodeRegistration(127.0.0.1:36727, datanodeUuid=1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d, infoPort=46091, infoSecurePort=0, ipcPort=35906, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3539934bfbea8864: Processing first storage report for DS-0890bb71-321f-4cae-8aa2-540c52234ef2 from datanode d291e966-f226-4f4d-8cf8-a56f618a3e23
2020-12-03 07:22:59,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3539934bfbea8864: from storage DS-0890bb71-321f-4cae-8aa2-540c52234ef2 node DatanodeRegistration(127.0.0.1:43065, datanodeUuid=d291e966-f226-4f4d-8cf8-a56f618a3e23, infoPort=38779, infoSecurePort=0, ipcPort=34336, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc5215968e079703d: Processing first storage report for DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3 from datanode 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d
2020-12-03 07:22:59,598 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc5215968e079703d: from storage DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3 node DatanodeRegistration(127.0.0.1:36727, datanodeUuid=1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d, infoPort=46091, infoSecurePort=0, ipcPort=35906, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3539934bfbea8864: Processing first storage report for DS-a56fb054-8f03-4051-8e81-893ebcf4e852 from datanode d291e966-f226-4f4d-8cf8-a56f618a3e23
2020-12-03 07:22:59,599 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3539934bfbea8864: from storage DS-a56fb054-8f03-4051-8e81-893ebcf4e852 node DatanodeRegistration(127.0.0.1:43065, datanodeUuid=d291e966-f226-4f4d-8cf8-a56f618a3e23, infoPort=38779, infoSecurePort=0, ipcPort=34336, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,599 [IPC Server handler 4 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc5215968e079703d
2020-12-03 07:22:59,599 [IPC Server handler 7 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x3539934bfbea8864
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbfb87e42c713545e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x56e5c9dee661edf9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 116 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc5215968e079703d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 93 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x101d381c806d26de,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 79 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,619 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb0278532e7abfaff,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3539934bfbea8864,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 95 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,620 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,618 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,620 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,619 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:22:59,670 [IPC Server handler 5 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,674 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:59,698 [IPC Server handler 0 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:59,732 [IPC Server handler 9 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:59,753 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(200)) - testReadWithBlockCorrupted: file = /corrupted_2_0, dataBlkDelNum = 2, parityBlkDelNum = 0, deleteBlockFile? false
2020-12-03 07:23:00,079 [IPC Server handler 6 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:00,099 [IPC Server handler 2 on default port 33556] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(774)) - *DIR* NameNode.create: file /corrupted_2_0 for DFSClient_NONMAPREDUCE_1970877875_1 at 127.0.0.1
2020-12-03 07:23:00,100 [IPC Server handler 2 on default port 33556] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2460)) - DIR* NameSystem.startFile: src=/corrupted_2_0, holder=DFSClient_NONMAPREDUCE_1970877875_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-12-03 07:23:00,112 [IPC Server handler 2 on default port 33556] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(579)) - DIR* addFile: corrupted_2_0 is added
2020-12-03 07:23:00,115 [IPC Server handler 2 on default port 33556] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(415)) - DIR* NameSystem.startFile: added /corrupted_2_0 inode 16386 DFSClient_NONMAPREDUCE_1970877875_1
2020-12-03 07:23:00,128 [IPC Server handler 2 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_2_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:00,236 [IPC Server handler 1 on default port 33556] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2767)) - BLOCK* getAdditionalBlock: /corrupted_2_0  inodeId 16386 for DFSClient_NONMAPREDUCE_1970877875_1
2020-12-03 07:23:00,249 [IPC Server handler 1 on default port 33556] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(524)) - DIR* FSDirectory.addBlock: /corrupted_2_0 with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-12-03 07:23:00,250 [IPC Server handler 1 on default port 33556] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:36413, 127.0.0.1:43188, 127.0.0.1:36727, 127.0.0.1:44129, 127.0.0.1:36365, 127.0.0.1:43065, 127.0.0.1:37459, 127.0.0.1:33535, 127.0.0.1:35006 for /corrupted_2_0
2020-12-03 07:23:00,251 [IPC Server handler 1 on default port 33556] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(758)) - persistNewBlock: /corrupted_2_0 with new block blk_-9223372036854775792_1001, current total block count is 1
2020-12-03 07:23:00,287 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,328 [Thread-352] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,357 [Thread-353] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,369 [Thread-354] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,382 [Thread-355] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,416 [Thread-356] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,452 [Thread-357] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,473 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:36100 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775792_1001 src: /127.0.0.1:36100 dest: /127.0.0.1:36413
2020-12-03 07:23:00,476 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:41368 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775786_1001 src: /127.0.0.1:41368 dest: /127.0.0.1:37459
2020-12-03 07:23:00,481 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:52646 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775788_1001 src: /127.0.0.1:52646 dest: /127.0.0.1:36365
2020-12-03 07:23:00,481 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:57762 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 src: /127.0.0.1:57762 dest: /127.0.0.1:44129
2020-12-03 07:23:00,500 [Thread-358] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,516 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:38458 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 src: /127.0.0.1:38458 dest: /127.0.0.1:43188
2020-12-03 07:23:00,517 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:33842 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775787_1001 src: /127.0.0.1:33842 dest: /127.0.0.1:43065
2020-12-03 07:23:00,517 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:46492 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775790_1001 src: /127.0.0.1:46492 dest: /127.0.0.1:36727
2020-12-03 07:23:00,537 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:37336 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775785_1001 src: /127.0.0.1:37336 dest: /127.0.0.1:33535
2020-12-03 07:23:00,538 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:00,543 [DataXceiver for client DFSClient_NONMAPREDUCE_1970877875_1 at /127.0.0.1:36670 [Receiving block BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775784_1001 src: /127.0.0.1:36670 dest: /127.0.0.1:35006
2020-12-03 07:23:00,935 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:23:00,938 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36100, dest: /127.0.0.1:36413, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 89059d77-c6e8-4d17-9e2e-f1c5202c92f6, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775792_1001, duration(ns): 281614646
2020-12-03 07:23:00,938 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,945 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38458, dest: /127.0.0.1:43188, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 87d2b441-cfb3-4464-a313-36d6eaa163f9, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001, duration(ns): 309020937
2020-12-03 07:23:00,947 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,952 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46492, dest: /127.0.0.1:36727, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775790_1001, duration(ns): 315060852
2020-12-03 07:23:00,952 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,957 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57762, dest: /127.0.0.1:44129, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 2cae3155-407a-4ada-b6de-3a4ce502c279, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001, duration(ns): 314535184
2020-12-03 07:23:00,957 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,962 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52646, dest: /127.0.0.1:36365, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775788_1001, duration(ns): 301706739
2020-12-03 07:23:00,962 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,968 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33842, dest: /127.0.0.1:43065, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: d291e966-f226-4f4d-8cf8-a56f618a3e23, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775787_1001, duration(ns): 333351553
2020-12-03 07:23:00,968 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,979 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36413, datanodeUuid=89059d77-c6e8-4d17-9e2e-f1c5202c92f6, infoPort=40272, infoSecurePort=0, ipcPort=42916, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,979 [IPC Server handler 8 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43065, datanodeUuid=d291e966-f226-4f4d-8cf8-a56f618a3e23, infoPort=38779, infoSecurePort=0, ipcPort=34336, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,983 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41368, dest: /127.0.0.1:37459, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 9caae05a-cc37-4f41-84a4-131bde04ea30, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775786_1001, duration(ns): 349270226
2020-12-03 07:23:00,983 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:00,979 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44129, datanodeUuid=2cae3155-407a-4ada-b6de-3a4ce502c279, infoPort=44095, infoSecurePort=0, ipcPort=34423, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,979 [IPC Server handler 7 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43188, datanodeUuid=87d2b441-cfb3-4464-a313-36d6eaa163f9, infoPort=44647, infoSecurePort=0, ipcPort=44206, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,988 [IPC Server handler 1 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36727, datanodeUuid=1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d, infoPort=46091, infoSecurePort=0, ipcPort=35906, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,987 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36365, datanodeUuid=7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998, infoPort=36217, infoSecurePort=0, ipcPort=43409, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,990 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37459, datanodeUuid=9caae05a-cc37-4f41-84a4-131bde04ea30, infoPort=36990, infoSecurePort=0, ipcPort=42624, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:00,992 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:44129 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:00,992 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:00,996 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:44129 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:00,999 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:44129
2020-12-03 07:23:00,999 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44129 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:00,999 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:43188 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:00,999 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,000 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:43188 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,000 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:43188
2020-12-03 07:23:01,000 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43188 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,000 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:36727 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:01,000 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37336, dest: /127.0.0.1:33535, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: 754beefe-30e4-4177-9a0e-0e6118511d00, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775785_1001, duration(ns): 336247234
2020-12-03 07:23:01,000 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,001 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:36727 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,001 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:01,001 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:36727
2020-12-03 07:23:01,001 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36727 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,001 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:43065 size 4194181 replicaState = FINALIZED
2020-12-03 07:23:01,001 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,001 [IPC Server handler 5 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33535, datanodeUuid=754beefe-30e4-4177-9a0e-0e6118511d00, infoPort=42952, infoSecurePort=0, ipcPort=34526, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:01,001 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:43065 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,005 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:43065
2020-12-03 07:23:01,005 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43065 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,006 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:36413 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:01,006 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,006 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:36413 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,006 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:36413
2020-12-03 07:23:01,006 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36413 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,007 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:36365 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:01,007 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,007 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36670, dest: /127.0.0.1:35006, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1970877875_1, offset: 0, srvID: f4cd2c65-00ba-436e-bc9e-747a1d3c4049, blockid: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775784_1001, duration(ns): 389968371
2020-12-03 07:23:01,007 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:36365 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,007 [PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:01,007 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:36365
2020-12-03 07:23:01,008 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36365 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,008 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:37459 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:01,008 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,008 [IPC Server handler 0 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35006, datanodeUuid=f4cd2c65-00ba-436e-bc9e-747a1d3c4049, infoPort=43477, infoSecurePort=0, ipcPort=42901, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338) 1 blocks.
2020-12-03 07:23:01,008 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:37459 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,008 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:37459
2020-12-03 07:23:01,009 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37459 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,009 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:33535 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:01,009 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,009 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:33535 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,010 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:33535
2020-12-03 07:23:01,010 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33535 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,010 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:35006 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:01,010 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:23:01,010 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35006 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:23:01,010 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:35006
2020-12-03 07:23:01,011 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35006 receiving: 0, received: 1, deleted: 0
2020-12-03 07:23:01,013 [IPC Server handler 9 on default port 33556] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /corrupted_2_0 for DFSClient_NONMAPREDUCE_1970877875_1
2020-12-03 07:23:01,017 [IPC Server handler 9 on default port 33556] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /corrupted_2_0 with 1 blocks is persisted to the file system
2020-12-03 07:23:01,018 [IPC Server handler 9 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /corrupted_2_0 is closed by DFSClient_NONMAPREDUCE_1970877875_1
2020-12-03 07:23:01,021 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(228)) - corruptBlocks on path /corrupted_2_0
2020-12-03 07:23:01,028 [IPC Server handler 6 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:01,031 [IPC Server handler 6 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,044 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(259)) - Corrupting block file BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
2020-12-03 07:23:01,049 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,052 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,053 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,054 [Thread-350] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-631318316-172.17.0.2-1606980172338/current/finalized/subdir0/subdir0/blk_-9223372036854775791
2020-12-03 07:23:01,055 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,055 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,056 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,056 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,057 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,057 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(259)) - Corrupting block file BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
2020-12-03 07:23:01,058 [Thread-350] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-631318316-172.17.0.2-1606980172338/current/finalized/subdir0/subdir0/blk_-9223372036854775789
2020-12-03 07:23:01,058 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,058 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,059 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,059 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,060 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,061 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,061 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,062 [Thread-350] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2223)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:260)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:217)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:23:01,062 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(134)) - verifyRead on path /corrupted_2_0
2020-12-03 07:23:01,070 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(136)) - verifyRead verifyLength on path /corrupted_2_0
2020-12-03 07:23:01,077 [IPC Server handler 7 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,078 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(138)) - verifyRead verifyPread on path /corrupted_2_0
2020-12-03 07:23:01,082 [IPC Server handler 1 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,089 [IPC Server handler 8 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:01,090 [IPC Server handler 8 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:01,138 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,169 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,177 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:43188,DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b,DISK] at 0
2020-12-03 07:23:01,220 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,225 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,256 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,260 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 from DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5,DISK] at 0
2020-12-03 07:23:01,312 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,372 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,378 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:01,475 [IPC Server handler 2 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:43188
2020-12-03 07:23:01,477 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775792_1001 added as corrupt on 127.0.0.1:43188 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:01,478 [IPC Server handler 2 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-12-03 07:23:01,478 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:23:01,479 [IPC Server handler 2 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 on datanode: 127.0.0.1:44129
2020-12-03 07:23:01,479 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775792_1001 added as corrupt on 127.0.0.1:44129 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:01,479 [IPC Server handler 2 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:01,479 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:23:01,480 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:02,424 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35006, datanodeUuid=f4cd2c65-00ba-436e-bc9e-747a1d3c4049, infoPort=43477, infoSecurePort=0, ipcPort=42901, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:23:02,425 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdcac148e142bbef8: Processing first storage report for DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229 from datanode f4cd2c65-00ba-436e-bc9e-747a1d3c4049
2020-12-03 07:23:02,425 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775784 on 127.0.0.1:35006 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,426 [IPC Server handler 2 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37459, datanodeUuid=9caae05a-cc37-4f41-84a4-131bde04ea30, infoPort=36990, infoSecurePort=0, ipcPort=42624, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:23:02,426 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:35006 size 25165701
2020-12-03 07:23:02,426 [IPC Server handler 9 on default port 33556] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44129, datanodeUuid=2cae3155-407a-4ada-b6de-3a4ce502c279, infoPort=44095, infoSecurePort=0, ipcPort=34423, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), reports.length=2
2020-12-03 07:23:02,426 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  1 oldPri  1
2020-12-03 07:23:02,426 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:02,426 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:02,427 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdcac148e142bbef8: from storage DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229 node DatanodeRegistration(127.0.0.1:35006, datanodeUuid=f4cd2c65-00ba-436e-bc9e-747a1d3c4049, infoPort=43477, infoSecurePort=0, ipcPort=42901, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 1, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,427 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f6738365ecac67b: Processing first storage report for DS-be96871d-4685-4cb2-b5a5-ab6d502ac360 from datanode 9caae05a-cc37-4f41-84a4-131bde04ea30
2020-12-03 07:23:02,427 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775786 on 127.0.0.1:37459 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,427 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:37459 size 25165701
2020-12-03 07:23:02,427 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  1 oldPri  1
2020-12-03 07:23:02,427 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:02,428 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:02,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f6738365ecac67b: from storage DS-be96871d-4685-4cb2-b5a5-ab6d502ac360 node DatanodeRegistration(127.0.0.1:37459, datanodeUuid=9caae05a-cc37-4f41-84a4-131bde04ea30, infoPort=36990, infoSecurePort=0, ipcPort=42624, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2544dece1d4f0db0: Processing first storage report for DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06 from datanode 2cae3155-407a-4ada-b6de-3a4ce502c279
2020-12-03 07:23:02,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2544dece1d4f0db0: from storage DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06 node DatanodeRegistration(127.0.0.1:44129, datanodeUuid=2cae3155-407a-4ada-b6de-3a4ce502c279, infoPort=44095, infoSecurePort=0, ipcPort=34423, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdcac148e142bbef8: Processing first storage report for DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2 from datanode f4cd2c65-00ba-436e-bc9e-747a1d3c4049
2020-12-03 07:23:02,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdcac148e142bbef8: from storage DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2 node DatanodeRegistration(127.0.0.1:35006, datanodeUuid=f4cd2c65-00ba-436e-bc9e-747a1d3c4049, infoPort=43477, infoSecurePort=0, ipcPort=42901, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,428 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f6738365ecac67b: Processing first storage report for DS-52f6da26-8467-4836-beaa-bc7025da3d08 from datanode 9caae05a-cc37-4f41-84a4-131bde04ea30
2020-12-03 07:23:02,429 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f6738365ecac67b: from storage DS-52f6da26-8467-4836-beaa-bc7025da3d08 node DatanodeRegistration(127.0.0.1:37459, datanodeUuid=9caae05a-cc37-4f41-84a4-131bde04ea30, infoPort=36990, infoSecurePort=0, ipcPort=42624, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,429 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2544dece1d4f0db0: Processing first storage report for DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5 from datanode 2cae3155-407a-4ada-b6de-3a4ce502c279
2020-12-03 07:23:02,429 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775789 on 127.0.0.1:44129 size 4194304 replicaState = FINALIZED
2020-12-03 07:23:02,429 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:44129 size 25165701
2020-12-03 07:23:02,430 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  1 oldPri  1
2020-12-03 07:23:02,430 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:02,430 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:02,430 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2544dece1d4f0db0: from storage DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5 node DatanodeRegistration(127.0.0.1:44129, datanodeUuid=2cae3155-407a-4ada-b6de-3a4ce502c279, infoPort=44095, infoSecurePort=0, ipcPort=34423, storageInfo=lv=-57;cid=testClusterID;nsid=1770548440;c=1606980172338), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,430 [IPC Server handler 3 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xdcac148e142bbef8
2020-12-03 07:23:02,431 [IPC Server handler 2 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x5f6738365ecac67b
2020-12-03 07:23:02,431 [IPC Server handler 9 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2544dece1d4f0db0
2020-12-03 07:23:02,432 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdcac148e142bbef8,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 2 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:02,432 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:02,432 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2544dece1d4f0db0,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:02,432 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:02,433 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f6738365ecac67b,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 3 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:02,433 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:03,940 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:03,940 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:04,546 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,554 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:43188,DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b,DISK] at 0
2020-12-03 07:23:04,554 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,564 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,568 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 from DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5,DISK] at 0
2020-12-03 07:23:04,568 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,574 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,582 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,590 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,596 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:04,667 [IPC Server handler 4 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:43188
2020-12-03 07:23:04,668 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:43188 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:04,668 [IPC Server handler 4 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:04,668 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:04,668 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:04,668 [IPC Server handler 4 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 on datanode: 127.0.0.1:44129
2020-12-03 07:23:04,669 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:44129 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:04,669 [IPC Server handler 4 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:04,669 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:04,669 [IPC Server handler 4 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:06,942 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:06,943 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:07,170 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:07,174 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:43188,DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b,DISK] at 0
2020-12-03 07:23:07,176 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:07,182 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 from DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5,DISK] at 0
2020-12-03 07:23:07,271 [IPC Server handler 6 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:43188
2020-12-03 07:23:07,272 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:43188 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:07,272 [IPC Server handler 6 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:07,272 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:07,272 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:07,273 [IPC Server handler 6 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 on datanode: 127.0.0.1:44129
2020-12-03 07:23:07,273 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:44129 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:07,273 [IPC Server handler 6 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:07,273 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:07,273 [IPC Server handler 6 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:09,943 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:09,943 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:09,961 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:09,976 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:43188,DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b,DISK] at 0
2020-12-03 07:23:09,979 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:09,992 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 from DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5,DISK] at 0
2020-12-03 07:23:10,093 [IPC Server handler 3 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:43188
2020-12-03 07:23:10,093 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:43188 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 on datanode: 127.0.0.1:44129
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:44129 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:10,094 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:10,095 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:13,416 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:13,417 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:13,491 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,495 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,496 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 from DatanodeInfoWithStorage[127.0.0.1:44129,DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5,DISK] at 0
2020-12-03 07:23:13,496 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,498 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,501 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,503 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,505 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(248)) - Found Checksum error for BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 from DatanodeInfoWithStorage[127.0.0.1:43188,DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b,DISK] at 0
2020-12-03 07:23:13,505 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,508 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:13,579 [IPC Server handler 3 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775791_1001 on datanode: 127.0.0.1:43188
2020-12-03 07:23:13,579 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:43188 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:13,580 [IPC Server handler 3 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:13,580 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:13,580 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:13,580 [IPC Server handler 3 on default port 33556] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5365)) - *DIR* reportBadBlocks for block: BP-631318316-172.17.0.2-1606980172338:blk_-9223372036854775789_1001 on datanode: 127.0.0.1:44129
2020-12-03 07:23:13,580 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:44129 by /127.0.0.1  because client machine reported it
2020-12-03 07:23:13,580 [IPC Server handler 3 on default port 33556] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-12-03 07:23:13,581 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-12-03 07:23:13,581 [IPC Server handler 3 on default port 33556] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-12-03 07:23:16,165 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:16,170 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:16,418 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:16,418 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:19,419 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:19,419 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:22,420 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:22,420 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:22,450 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(140)) - verifyRead verifyStatefulRead on path /corrupted_2_0
2020-12-03 07:23:22,453 [IPC Server handler 2 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:22,455 [IPC Server handler 2 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:22,476 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:22,480 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:25,421 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:25,422 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:27,244 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead2 on path /corrupted_2_0
2020-12-03 07:23:27,253 [IPC Server handler 7 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:27,254 [IPC Server handler 7 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,266 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:27,269 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:27,270 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:27,273 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:27,275 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:27,276 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:28,422 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:28,422 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:31,423 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:31,424 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:31,749 [Thread-350] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifySeek on path /corrupted_2_0
2020-12-03 07:23:31,753 [IPC Server handler 7 on default port 33556] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1433)) - blocks = [blk_-9223372036854775792_1001]
2020-12-03 07:23:31,754 [IPC Server handler 7 on default port 33556] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,763 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,766 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,768 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,770 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,774 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:31,777 [Thread-350] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,425 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:34,426 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:37,426 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(2037)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-12-03 07:23:37,427 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-12-03 07:23:38,741 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:38,743 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:23:38,744 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:38,744 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@126be319] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:38,746 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-5114e173-3b3c-4489-bece-91c8fe32cd03) exiting.
2020-12-03 07:23:38,746 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4622b5f2-52d3-4eef-bbfc-6d12e0d44a95) exiting.
2020-12-03 07:23:38,779 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27f0ad19{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:38,786 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@54e81b21{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:38,786 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75201592{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,786 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31198ceb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:38,790 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34526
2020-12-03 07:23:38,795 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,797 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,798 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:38,799 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 754beefe-30e4-4177-9a0e-0e6118511d00) service to localhost/127.0.0.1:33556
2020-12-03 07:23:38,799 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 754beefe-30e4-4177-9a0e-0e6118511d00)
2020-12-03 07:23:38,799 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:38,801 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,801 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,805 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:38,806 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:38,806 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:38,806 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:38,813 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:38,813 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:23:38,814 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:38,814 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@bae47a0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:38,815 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-a56fb054-8f03-4051-8e81-893ebcf4e852) exiting.
2020-12-03 07:23:38,815 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-0890bb71-321f-4cae-8aa2-540c52234ef2) exiting.
2020-12-03 07:23:38,845 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3add81c4{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:38,846 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@492f5b62{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:38,846 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c4ee95c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,847 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10567255{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:38,848 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34336
2020-12-03 07:23:38,860 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,862 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:38,864 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid d291e966-f226-4f4d-8cf8-a56f618a3e23) service to localhost/127.0.0.1:33556
2020-12-03 07:23:38,864 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid d291e966-f226-4f4d-8cf8-a56f618a3e23)
2020-12-03 07:23:38,864 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:38,865 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,865 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,870 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:38,871 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:38,872 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:38,872 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:38,874 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:38,874 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:23:38,875 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:38,875 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7bfc3126] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:38,884 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-04beb3d9-c6f0-49c7-b843-5383e5887ec2) exiting.
2020-12-03 07:23:38,885 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-22a7bcdf-6d4d-4b8e-94b2-e979b6940ad3) exiting.
2020-12-03 07:23:38,920 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@63a5e46c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:38,921 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e8e8651{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:38,921 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a1ebcff{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,922 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54a3ab8f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:38,923 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35906
2020-12-03 07:23:38,931 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,931 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:38,934 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d) service to localhost/127.0.0.1:33556
2020-12-03 07:23:38,934 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 1626d7c8-a3e6-4a6d-847d-a0b8fd636a7d)
2020-12-03 07:23:38,934 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:38,935 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,943 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:38,943 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:38,943 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:38,957 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:38,957 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:38,960 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:38,960 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:23:38,961 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:38,961 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@610db97e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:38,963 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be96871d-4685-4cb2-b5a5-ab6d502ac360) exiting.
2020-12-03 07:23:38,963 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-52f6da26-8467-4836-beaa-bc7025da3d08) exiting.
2020-12-03 07:23:38,995 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a7704c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:38,996 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6754ef00{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:38,996 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51b01960{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,996 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7bd69e82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:38,998 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42624
2020-12-03 07:23:39,006 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,006 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:39,008 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 9caae05a-cc37-4f41-84a4-131bde04ea30) service to localhost/127.0.0.1:33556
2020-12-03 07:23:39,008 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 9caae05a-cc37-4f41-84a4-131bde04ea30)
2020-12-03 07:23:39,008 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:39,009 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,011 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,027 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:39,027 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:39,029 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:39,029 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:39,032 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:39,032 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:23:39,033 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:39,033 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2024293c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:39,035 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-cd58b2c1-17cf-4665-b2dc-2938284dfc09) exiting.
2020-12-03 07:23:39,035 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-11d702bc-9bdd-47a1-a5f2-1a215015b377) exiting.
2020-12-03 07:23:39,063 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a7b503d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:39,064 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@512d92b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:39,064 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d0566ba{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:39,065 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a2bb0eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:39,066 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43409
2020-12-03 07:23:39,071 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,071 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,071 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:39,074 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998) service to localhost/127.0.0.1:33556
2020-12-03 07:23:39,078 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 7dfe47d1-e3cd-4bdf-b9ce-7ac5dde55998)
2020-12-03 07:23:39,078 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:39,079 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,087 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:39,088 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:39,088 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,090 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:39,091 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:39,096 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:39,096 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:39,096 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:39,097 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1edb61b1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:39,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-cec81ed8-1782-40c1-92bc-9a499dae0aa1) exiting.
2020-12-03 07:23:39,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-3c63f9d3-e4af-4d9b-8764-c259553ddd4b) exiting.
2020-12-03 07:23:39,122 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@ecf9fb3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:39,123 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2d35442b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:39,123 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51a06cbe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:39,123 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@669253b7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:39,125 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44206
2020-12-03 07:23:39,129 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,129 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,133 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:39,133 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 87d2b441-cfb3-4464-a313-36d6eaa163f9) service to localhost/127.0.0.1:33556
2020-12-03 07:23:39,133 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 87d2b441-cfb3-4464-a313-36d6eaa163f9)
2020-12-03 07:23:39,133 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:39,134 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,139 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,147 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:39,148 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:39,152 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:39,153 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:39,164 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:39,164 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:39,164 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:39,165 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@31500940] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:39,173 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a1ae05c3-1c16-4d42-ba81-82ab59057b39) exiting.
2020-12-03 07:23:39,173 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1efa175c-f495-434d-bae9-1f6dda15846c) exiting.
2020-12-03 07:23:39,304 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@133e019b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:39,305 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41382722{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:39,306 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e587920{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:39,306 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@750fe12e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:39,308 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42916
2020-12-03 07:23:39,344 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,344 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:39,344 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,344 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 89059d77-c6e8-4d17-9e2e-f1c5202c92f6) service to localhost/127.0.0.1:33556
2020-12-03 07:23:39,345 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 89059d77-c6e8-4d17-9e2e-f1c5202c92f6)
2020-12-03 07:23:39,345 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:39,346 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,346 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,365 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:39,366 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:39,371 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:39,371 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:39,388 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:39,388 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:39,388 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:39,389 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2970a5bc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:39,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f403b1a2-7bc0-429c-a7ba-8aa4e6559229) exiting.
2020-12-03 07:23:39,406 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-c0fbb80c-96b6-4e44-a2b6-c57f9d50a3e2) exiting.
2020-12-03 07:23:39,458 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e3cee7b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:39,459 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@71e9a896{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:39,460 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@324c64cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:39,461 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ad3a1bb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:39,472 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42901
2020-12-03 07:23:39,479 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,479 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,479 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:39,479 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid f4cd2c65-00ba-436e-bc9e-747a1d3c4049) service to localhost/127.0.0.1:33556
2020-12-03 07:23:39,484 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid f4cd2c65-00ba-436e-bc9e-747a1d3c4049)
2020-12-03 07:23:39,485 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:39,486 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,487 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,520 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:39,520 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:39,524 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:39,524 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:39,534 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:39,534 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:39,534 [Listener at localhost/34526] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:39,535 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@18518ccf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:39,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7608aab8-1980-4d8f-a91c-36b4aa70ee06) exiting.
2020-12-03 07:23:39,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2c99dbd7-010c-4277-8e6c-cd0733586fc5) exiting.
2020-12-03 07:23:39,560 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3faf2e7d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:39,561 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@35892295{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:39,561 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@267f474e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:39,562 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@acb0951{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:39,563 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34423
2020-12-03 07:23:39,569 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,570 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,575 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:39,575 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 2cae3155-407a-4ada-b6de-3a4ce502c279) service to localhost/127.0.0.1:33556
2020-12-03 07:23:39,676 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-631318316-172.17.0.2-1606980172338 (Datanode Uuid 2cae3155-407a-4ada-b6de-3a4ce502c279)
2020-12-03 07:23:39,676 [BP-631318316-172.17.0.2-1606980172338 heartbeating to localhost/127.0.0.1:33556] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-631318316-172.17.0.2-1606980172338
2020-12-03 07:23:39,677 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,678 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-631318316-172.17.0.2-1606980172338] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:39,716 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:39,717 [Listener at localhost/34526] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:39,722 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:39,722 [Listener at localhost/34526] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:39,735 [Listener at localhost/34526] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:39,736 [Listener at localhost/34526] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:39,736 [Listener at localhost/34526] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:39,737 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@207ea13] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:39,737 [Listener at localhost/34526] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:23:39,738 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@45cff11c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:39,738 [Listener at localhost/34526] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 1 Number of syncs: 9 SyncTimes(ms): 3 2 
2020-12-03 07:23:39,740 [Listener at localhost/34526] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:23:39,741 [Listener at localhost/34526] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:23:39,741 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:39,742 [CacheReplicationMonitor(2103819430)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:39,742 [Listener at localhost/34526] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33556
2020-12-03 07:23:39,749 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:39,749 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:39,760 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:39,760 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:39,761 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@1fdfafd2] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:39,806 [Listener at localhost/34526] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:39,806 [Listener at localhost/34526] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:39,808 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4dd6fd0a{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:39,810 [Listener at localhost/34526] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@295ace64{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:39,810 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb4f2a9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:39,811 [Listener at localhost/34526] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1807f5a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:39,813 [Listener at localhost/34526] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:39,839 [Listener at localhost/34526] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:39,840 [Listener at localhost/34526] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
