2020-12-03 07:23:43,922 [main] INFO  qjournal.MiniQJMHACluster (MiniQJMHACluster.java:<init>(113)) - Set MiniQJMHACluster basePort to 10852
2020-12-03 07:23:43,930 [main] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(101)) - Starting MiniJournalCluster with 3 journal nodes
2020-12-03 07:23:44,131 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:44,271 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:44,272 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:23:44,426 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:44,443 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:44,459 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1408ms
2020-12-03 07:23:44,598 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:44,641 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:44,642 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:44,661 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:44,664 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:44,664 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:44,665 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:44,697 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44191
2020-12-03 07:23:44,702 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:44,764 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@625732{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:44,766 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66498326{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:44,817 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3012646b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:44,831 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ebdc62c{HTTP/1.1,[http/1.1]}{localhost:44191}
2020-12-03 07:23:44,832 [main] INFO  server.Server (Server.java:doStart(419)) - Started @1781ms
2020-12-03 07:23:44,834 [main] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:44,888 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:44,904 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:45,317 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:45,317 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:45,321 [Listener at localhost/36810] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:45,325 [Listener at localhost/36810] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:45,325 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,328 [Listener at localhost/36810] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:45,329 [Listener at localhost/36810] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:45,330 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,334 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:45,335 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:45,335 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:45,336 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:45,337 [Listener at localhost/36810] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44075
2020-12-03 07:23:45,338 [Listener at localhost/36810] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:45,341 [Listener at localhost/36810] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68dc098b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:45,342 [Listener at localhost/36810] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d278d2b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:45,351 [Listener at localhost/36810] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@20c0a64d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:45,353 [Listener at localhost/36810] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@455b6df1{HTTP/1.1,[http/1.1]}{localhost:44075}
2020-12-03 07:23:45,353 [Listener at localhost/36810] INFO  server.Server (Server.java:doStart(419)) - Started @2303ms
2020-12-03 07:23:45,355 [Listener at localhost/36810] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:45,355 [Listener at localhost/36810] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:45,357 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:45,362 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:45,362 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:45,364 [Listener at localhost/42051] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:45,368 [Listener at localhost/42051] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:23:45,368 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,370 [Listener at localhost/42051] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:45,372 [Listener at localhost/42051] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:45,372 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:45,374 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:45,376 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:45,376 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:45,376 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:45,378 [Listener at localhost/42051] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41024
2020-12-03 07:23:45,378 [Listener at localhost/42051] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:45,382 [Listener at localhost/42051] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63611043{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:45,383 [Listener at localhost/42051] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d778add{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:45,391 [Listener at localhost/42051] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@51549490{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:45,392 [Listener at localhost/42051] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@71e9ebae{HTTP/1.1,[http/1.1]}{localhost:41024}
2020-12-03 07:23:45,393 [Listener at localhost/42051] INFO  server.Server (Server.java:doStart(419)) - Started @2342ms
2020-12-03 07:23:45,394 [Listener at localhost/42051] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:23:45,401 [Listener at localhost/42051] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:45,402 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:45,408 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:45,408 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:46,044 [IPC Server handler 0 on default port 42057] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive
2020-12-03 07:23:46,044 [IPC Server handler 0 on default port 42051] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive
2020-12-03 07:23:46,044 [IPC Server handler 0 on default port 36810] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive
2020-12-03 07:23:46,059 [IPC Server handler 0 on default port 42057] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive does not exist
2020-12-03 07:23:46,059 [IPC Server handler 0 on default port 36810] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive does not exist
2020-12-03 07:23:46,059 [IPC Server handler 0 on default port 42051] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive does not exist
2020-12-03 07:23:46,091 [IPC Server handler 0 on default port 36810] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:46,091 [IPC Server handler 0 on default port 36810] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:46,093 [IPC Server handler 0 on default port 42057] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:46,093 [IPC Server handler 0 on default port 42057] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:46,098 [IPC Server handler 0 on default port 42051] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:23:46,098 [IPC Server handler 0 on default port 42051] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:23:46,438 [Listener at localhost/42057] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=0
Formatting using clusterid: testClusterID
2020-12-03 07:23:46,723 [Listener at localhost/42057] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:46,736 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:46,738 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:46,738 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:46,739 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:46,739 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:46,740 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:46,741 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:46,741 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:46,781 [Listener at localhost/42057] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:46,787 [Listener at localhost/42057] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:46,787 [Listener at localhost/42057] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:46,787 [Listener at localhost/42057] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:46,792 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:46,792 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:46
2020-12-03 07:23:46,795 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:46,795 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:46,797 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:46,797 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:46,811 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:46,811 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:46,818 [Listener at localhost/42057] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:46,819 [Listener at localhost/42057] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:46,819 [Listener at localhost/42057] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:46,819 [Listener at localhost/42057] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:46,820 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:46,820 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:46,820 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:46,821 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:46,821 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:46,821 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:46,821 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:46,858 [Listener at localhost/42057] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:46,858 [Listener at localhost/42057] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:46,859 [Listener at localhost/42057] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:46,859 [Listener at localhost/42057] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:46,874 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:46,874 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:46,875 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:46,875 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:46,882 [Listener at localhost/42057] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:46,882 [Listener at localhost/42057] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:46,883 [Listener at localhost/42057] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:46,883 [Listener at localhost/42057] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:46,889 [Listener at localhost/42057] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:46,892 [Listener at localhost/42057] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:46,897 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:46,897 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:46,898 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:46,898 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:46,915 [Listener at localhost/42057] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:46,916 [Listener at localhost/42057] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:46,916 [Listener at localhost/42057] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:46,921 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:46,921 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:46,924 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:46,924 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:46,925 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:46,925 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:46,955 [IPC Server handler 1 on default port 36810] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:46,956 [IPC Server handler 0 on default port 42051] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1
2020-12-03 07:23:46,956 [IPC Server handler 0 on default port 42051] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1 does not exist
2020-12-03 07:23:46,955 [IPC Server handler 0 on default port 42057] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1
2020-12-03 07:23:46,956 [IPC Server handler 1 on default port 36810] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1 does not exist
2020-12-03 07:23:46,965 [IPC Server handler 0 on default port 42057] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1 does not exist
2020-12-03 07:23:46,969 [IPC Server handler 0 on default port 42051] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:23:46,972 [IPC Server handler 1 on default port 36810] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:23:46,977 [IPC Server handler 0 on default port 42057] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:23:46,990 [Listener at localhost/42057] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-185585796-172.17.0.4-1606980226990
2020-12-03 07:23:47,081 [Listener at localhost/42057] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:47,149 [Listener at localhost/42057] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:47,180 [IPC Server handler 3 on default port 36810] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1968455466;c=1606980226990;bpid=BP-185585796-172.17.0.4-1606980226990 and force: true
2020-12-03 07:23:47,181 [IPC Server handler 1 on default port 42057] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1968455466;c=1606980226990;bpid=BP-185585796-172.17.0.4-1606980226990 and force: true
2020-12-03 07:23:47,181 [IPC Server handler 3 on default port 36810] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1 does not exist. Creating ...
2020-12-03 07:23:47,181 [IPC Server handler 1 on default port 42057] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1 does not exist. Creating ...
2020-12-03 07:23:47,180 [IPC Server handler 1 on default port 42051] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1968455466;c=1606980226990;bpid=BP-185585796-172.17.0.4-1606980226990 and force: true
2020-12-03 07:23:47,182 [IPC Server handler 1 on default port 42051] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1 does not exist. Creating ...
2020-12-03 07:23:47,216 [IPC Server handler 1 on default port 42057] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:47,217 [IPC Server handler 1 on default port 42057] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null with nsid: 1968455466
2020-12-03 07:23:47,219 [IPC Server handler 1 on default port 42051] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:47,219 [IPC Server handler 3 on default port 36810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:47,219 [IPC Server handler 1 on default port 42051] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null with nsid: 1968455466
2020-12-03 07:23:47,219 [IPC Server handler 3 on default port 36810] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null with nsid: 1968455466
2020-12-03 07:23:47,273 [IPC Server handler 1 on default port 42051] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos
2020-12-03 07:23:47,274 [IPC Server handler 1 on default port 42057] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos
2020-12-03 07:23:47,306 [IPC Server handler 3 on default port 36810] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos
2020-12-03 07:23:47,344 [IPC Server handler 1 on default port 42057] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:47,344 [IPC Server handler 1 on default port 42051] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:47,377 [IPC Server handler 3 on default port 36810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:47,447 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:47,447 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:47,630 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:47,630 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:47,673 [Listener at localhost/42057] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:47,769 [Listener at localhost/42057] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3
2020-12-03 07:23:47,794 [Listener at localhost/42057] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4
2020-12-03 07:23:47,803 [Listener at localhost/42057] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:47,812 [Listener at localhost/42057] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:47,816 [Listener at localhost/42057] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:23:47,816 [Listener at localhost/42057] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:47,858 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f7b97da] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:47,859 [Listener at localhost/42057] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10853
2020-12-03 07:23:47,859 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:47,862 [Listener at localhost/42057] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:47,863 [Listener at localhost/42057] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:47,863 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:47,867 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:47,869 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:47,871 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:47,871 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:47,881 [Listener at localhost/42057] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:47,882 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:47,888 [Listener at localhost/42057] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10853
2020-12-03 07:23:47,888 [Listener at localhost/42057] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:47,892 [Listener at localhost/42057] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68044f4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:47,893 [Listener at localhost/42057] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@315f43d5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:47,907 [Listener at localhost/42057] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7ce97ee5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:47,909 [Listener at localhost/42057] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@32c8e539{HTTP/1.1,[http/1.1]}{localhost:10853}
2020-12-03 07:23:47,910 [Listener at localhost/42057] INFO  server.Server (Server.java:doStart(419)) - Started @4859ms
2020-12-03 07:23:47,975 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:47,978 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:36810 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:47,978 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:48,020 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:36810 has no edit logs
2020-12-03 07:23:48,020 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:36810 has no edit logs
2020-12-03 07:23:48,021 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42051 has no edit logs
2020-12-03 07:23:48,024 [Listener at localhost/42057] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:48,025 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:48,025 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:48,026 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:48,026 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:48,026 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:48,027 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:48,027 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:48,027 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:48,028 [Listener at localhost/42057] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:48,029 [Listener at localhost/42057] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:48,029 [Listener at localhost/42057] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:48,030 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:48,030 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:48
2020-12-03 07:23:48,030 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:48,031 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,031 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:48,032 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:48,047 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:48,048 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:48,048 [Listener at localhost/42057] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:48,049 [Listener at localhost/42057] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:48,049 [Listener at localhost/42057] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:48,049 [Listener at localhost/42057] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:48,050 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:48,050 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:48,050 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:48,050 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:48,051 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:48,051 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:48,051 [Listener at localhost/42057] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:48,052 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:48,052 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,053 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:48,053 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:48,061 [Listener at localhost/42057] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:48,061 [Listener at localhost/42057] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:48,061 [Listener at localhost/42057] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:48,062 [Listener at localhost/42057] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:48,062 [Listener at localhost/42057] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:48,062 [Listener at localhost/42057] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:48,063 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:48,063 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,063 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:48,064 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:48,066 [Listener at localhost/42057] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:48,067 [Listener at localhost/42057] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:48,067 [Listener at localhost/42057] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:48,067 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:48,068 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:48,068 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:48,068 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:48,069 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:48,070 [Listener at localhost/42057] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:48,106 [Listener at localhost/42057] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:48,140 [Listener at localhost/42057] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:48,163 [Listener at localhost/42057] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:48,164 [Listener at localhost/42057] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:48,194 [Listener at localhost/42057] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:48,203 [Listener at localhost/42057] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:48,203 [Listener at localhost/42057] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:48,209 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:48,210 [Listener at localhost/42057] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:48,210 [Listener at localhost/42057] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 139 msecs
2020-12-03 07:23:48,799 [Listener at localhost/42057] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10852
2020-12-03 07:23:48,836 [Listener at localhost/42057] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:48,846 [Socket Reader #1 for port 10852] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10852
2020-12-03 07:23:48,871 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:48,903 [Listener at localhost/10852] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:48,920 [Listener at localhost/10852] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:48,920 [Listener at localhost/10852] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:48,920 [Listener at localhost/10852] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:48,956 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:48,956 [IPC Server listener on 10852] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10852: starting
2020-12-03 07:23:48,960 [Listener at localhost/10852] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10852
2020-12-03 07:23:48,964 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:48,971 [Listener at localhost/10852] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:23:48,974 [Listener at localhost/10852] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:48,974 [Listener at localhost/10852] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:48,985 [Listener at localhost/10852] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://127.0.0.1:10855]
Serving checkpoints at http://localhost:10853
2020-12-03 07:23:48,989 [Listener at localhost/10852] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:48,996 [Listener at localhost/10852] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:48,997 [Listener at localhost/10852] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:23:48,997 [Listener at localhost/10852] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:49,020 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:42057, journal id: ns1
2020-12-03 07:23:49,021 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:49,029 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:36810 with /127.0.0.1:42057, journal id: ns1
2020-12-03 07:23:49,031 [Listener at localhost/10852] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10855
2020-12-03 07:23:49,031 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,033 [Listener at localhost/10852] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:49,034 [Listener at localhost/10852] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:49,037 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:49,034 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f4d427e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:49,040 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:49,048 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42051 has no edit logs
2020-12-03 07:23:49,050 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:49,052 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:49,052 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:49,063 [Listener at localhost/10852] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:49,065 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:49,066 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10855
2020-12-03 07:23:49,067 [Listener at localhost/10852] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:49,079 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42057 has no edit logs
2020-12-03 07:23:49,080 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42057 has no edit logs
2020-12-03 07:23:49,095 [Listener at localhost/10852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@362a019c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:49,097 [Listener at localhost/10852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c48c0c0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:49,109 [Listener at localhost/10852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5df417a7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:49,111 [Listener at localhost/10852] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7c041b41{HTTP/1.1,[http/1.1]}{localhost:10855}
2020-12-03 07:23:49,111 [Listener at localhost/10852] INFO  server.Server (Server.java:doStart(419)) - Started @6060ms
2020-12-03 07:23:49,116 [Listener at localhost/10852] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:49,117 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:49,117 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:49,117 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:49,118 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:49,118 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:49,118 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:49,119 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:49,119 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:49,120 [Listener at localhost/10852] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:49,120 [Listener at localhost/10852] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:49,120 [Listener at localhost/10852] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:49,121 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:49,121 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:49
2020-12-03 07:23:49,122 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:49,122 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,122 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:49,123 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:49,133 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:49,133 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:49,134 [Listener at localhost/10852] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:49,134 [Listener at localhost/10852] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:49,134 [Listener at localhost/10852] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:49,135 [Listener at localhost/10852] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:49,135 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:49,135 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:49,135 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:49,136 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:49,136 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:49,136 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:49,136 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:49,137 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:49,137 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,138 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:49,138 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:49,141 [Listener at localhost/10852] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:49,141 [Listener at localhost/10852] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:49,142 [Listener at localhost/10852] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:49,142 [Listener at localhost/10852] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:49,142 [Listener at localhost/10852] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:49,143 [Listener at localhost/10852] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:49,143 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:49,143 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,144 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:49,144 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:49,145 [Listener at localhost/10852] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:49,146 [Listener at localhost/10852] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:49,146 [Listener at localhost/10852] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:49,146 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:49,147 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:49,147 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:49,147 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:49,148 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:49,148 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:49,193 [Listener at localhost/10852] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:49,235 [Listener at localhost/10852] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:49,255 [Listener at localhost/10852] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:49,257 [Listener at localhost/10852] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:49,272 [Listener at localhost/10852] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:49,275 [Listener at localhost/10852] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:49,281 [Listener at localhost/10852] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:23:49,282 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:49,282 [Listener at localhost/10852] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:49,282 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 132 msecs
2020-12-03 07:23:49,283 [Listener at localhost/10852] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10854
2020-12-03 07:23:49,284 [Listener at localhost/10852] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:49,285 [Socket Reader #1 for port 10854] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10854
2020-12-03 07:23:49,298 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:49,321 [Listener at localhost/10854] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:49,323 [Listener at localhost/10854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:49,323 [Listener at localhost/10854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:49,323 [Listener at localhost/10854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:49,328 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:49,328 [IPC Server listener on 10854] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10854: starting
2020-12-03 07:23:49,336 [Listener at localhost/10854] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10854
2020-12-03 07:23:49,337 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:49,341 [Listener at localhost/10854] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:23:49,342 [Listener at localhost/10854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:49,342 [Listener at localhost/10854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:49,346 [Listener at localhost/10854] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10853]
Serving checkpoints at http://localhost:10855
2020-12-03 07:23:50,011 [IPC Server handler 0 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,042 [IPC Server handler 1 on default port 10854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,044 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:50,052 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:50,056 [IPC Server handler 2 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,061 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:36810 has no edit logs
2020-12-03 07:23:50,067 [IPC Server handler 2 on default port 10854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:50,071 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:50,072 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:50,072 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:50,076 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:50,080 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:36810 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:50,081 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10852
2020-12-03 07:23:50,096 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:50,096 [IPC Server listener on 10852] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10852
2020-12-03 07:23:50,097 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:50,098 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:50,100 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42051 has no edit logs
2020-12-03 07:23:50,100 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:50,102 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:36810 has no edit logs
2020-12-03 07:23:50,151 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:50,153 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:50,160 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7ce97ee5{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:50,170 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@32c8e539{HTTP/1.1,[http/1.1]}{localhost:10853}
2020-12-03 07:23:50,171 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@315f43d5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:50,172 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68044f4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:50,185 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:50,185 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:50,187 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:50,189 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10854
2020-12-03 07:23:50,193 [IPC Server listener on 10854] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10854
2020-12-03 07:23:50,193 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:50,197 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:50,201 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:50,215 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:50,215 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:50,221 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5df417a7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:50,233 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7c041b41{HTTP/1.1,[http/1.1]}{localhost:10855}
2020-12-03 07:23:50,234 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c48c0c0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:50,234 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@362a019c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:50,253 [Listener at localhost/10854] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:50,254 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:50,254 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:50,254 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:50,254 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:50,255 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:50,255 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:50,255 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:50,256 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:50,256 [Listener at localhost/10854] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,257 [Listener at localhost/10854] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:50,257 [Listener at localhost/10854] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:50,257 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:50,258 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:50
2020-12-03 07:23:50,258 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:50,258 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,259 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:50,259 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:50,266 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:50,267 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:50,267 [Listener at localhost/10854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:50,267 [Listener at localhost/10854] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:50,268 [Listener at localhost/10854] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:50,268 [Listener at localhost/10854] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:50,268 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:50,268 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:50,269 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:50,269 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:50,269 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:50,269 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:50,270 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:50,270 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:50,271 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,271 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:50,271 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:50,277 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:50,277 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:50,277 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:50,278 [Listener at localhost/10854] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:50,278 [Listener at localhost/10854] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:50,278 [Listener at localhost/10854] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:50,278 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:50,279 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,279 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:50,279 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:50,280 [Listener at localhost/10854] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:50,281 [Listener at localhost/10854] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:50,281 [Listener at localhost/10854] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:50,281 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:50,281 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:50,282 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:50,282 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,282 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:50,283 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:50,342 [Listener at localhost/10854] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,376 [Listener at localhost/10854] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,379 [Listener at localhost/10854] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:50,380 [Listener at localhost/10854] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:50,382 [Listener at localhost/10854] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:50,384 [Listener at localhost/10854] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:50,384 [Listener at localhost/10854] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:50,385 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:50,385 [Listener at localhost/10854] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:50,385 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 101 msecs
2020-12-03 07:23:50,386 [Listener at localhost/10854] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
Data exists in QJM to [127.0.0.1:36810, 127.0.0.1:42051, 127.0.0.1:42057]. Formatting anyway.
2020-12-03 07:23:50,424 [IPC Server handler 2 on default port 42051] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1968455466;c=1606980226990;bpid=BP-185585796-172.17.0.4-1606980226990 and force: true
2020-12-03 07:23:50,433 [IPC Server handler 2 on default port 36810] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1968455466;c=1606980226990;bpid=BP-185585796-172.17.0.4-1606980226990 and force: true
2020-12-03 07:23:50,433 [IPC Server handler 1 on default port 42057] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1968455466;c=1606980226990;bpid=BP-185585796-172.17.0.4-1606980226990 and force: true
2020-12-03 07:23:50,471 [IPC Server handler 2 on default port 42051] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,471 [IPC Server handler 2 on default port 42051] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null with nsid: 1968455466
2020-12-03 07:23:50,472 [IPC Server handler 2 on default port 42051] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/committed-txid]
2020-12-03 07:23:50,520 [IPC Server handler 2 on default port 36810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,520 [IPC Server handler 2 on default port 36810] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null with nsid: 1968455466
2020-12-03 07:23:50,521 [IPC Server handler 2 on default port 36810] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/committed-txid]
2020-12-03 07:23:50,520 [IPC Server handler 1 on default port 42057] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,522 [IPC Server handler 1 on default port 42057] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null with nsid: 1968455466
2020-12-03 07:23:50,522 [IPC Server handler 1 on default port 42057] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/committed-txid]
2020-12-03 07:23:50,555 [IPC Server handler 2 on default port 42051] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos
2020-12-03 07:23:50,596 [IPC Server handler 2 on default port 36810] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos
2020-12-03 07:23:50,596 [IPC Server handler 1 on default port 42057] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos
2020-12-03 07:23:50,636 [IPC Server handler 2 on default port 42051] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,665 [IPC Server handler 1 on default port 42057] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,665 [IPC Server handler 2 on default port 36810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,669 [Listener at localhost/10854] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:50,669 [Listener at localhost/10854] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:50,673 [Listener at localhost/10854] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:50,704 [IPC Server handler 3 on default port 36810] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:50,704 [IPC Server handler 4 on default port 42057] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:50,707 [IPC Server handler 4 on default port 42051] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:50,770 [IPC Server handler 4 on default port 42051] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:23:50,771 [IPC Server handler 4 on default port 42051] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:23:50,771 [IPC Server handler 4 on default port 42057] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:23:50,772 [IPC Server handler 3 on default port 36810] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:23:50,772 [IPC Server handler 4 on default port 42057] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:23:50,772 [IPC Server handler 3 on default port 36810] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:23:50,773 [Listener at localhost/10854] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 1
2020-12-03 07:23:50,779 [Listener at localhost/10854] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:50,780 [Listener at localhost/10854] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:50,781 [Listener at localhost/10854] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:10852
2020-12-03 07:23:50,782 [Listener at localhost/10854] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:50,797 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4925f4f5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:50,798 [Listener at localhost/10854] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10853
2020-12-03 07:23:50,798 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,801 [Listener at localhost/10854] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:50,803 [Listener at localhost/10854] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:50,803 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:50,806 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:50,807 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:50,807 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:50,807 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:50,810 [Listener at localhost/10854] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:50,810 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:50,811 [Listener at localhost/10854] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10853
2020-12-03 07:23:50,811 [Listener at localhost/10854] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:50,827 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28782602{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:50,828 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68105edc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:50,839 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@138a7441{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:50,841 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@81ff872{HTTP/1.1,[http/1.1]}{localhost:10853}
2020-12-03 07:23:50,841 [Listener at localhost/10854] INFO  server.Server (Server.java:doStart(419)) - Started @7790ms
2020-12-03 07:23:50,844 [Listener at localhost/10854] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:50,845 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:50,845 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:50,845 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:50,846 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:50,846 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:50,846 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:50,847 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:50,847 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:50,848 [Listener at localhost/10854] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:50,848 [Listener at localhost/10854] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:50,848 [Listener at localhost/10854] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:50,849 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:50,849 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:50
2020-12-03 07:23:50,850 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:50,850 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,850 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:50,851 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:50,867 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:50,868 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:50,868 [Listener at localhost/10854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:50,868 [Listener at localhost/10854] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:50,869 [Listener at localhost/10854] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:50,869 [Listener at localhost/10854] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:50,869 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:50,869 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:50,870 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:50,870 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:50,870 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:50,870 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:50,870 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:50,871 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:50,871 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,872 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:50,872 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:50,875 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:50,875 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:50,875 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:50,876 [Listener at localhost/10854] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:50,876 [Listener at localhost/10854] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:50,876 [Listener at localhost/10854] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:50,876 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:50,876 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,877 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:50,877 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:50,878 [Listener at localhost/10854] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:50,879 [Listener at localhost/10854] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:50,885 [Listener at localhost/10854] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:50,886 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:50,886 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:50,886 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:50,886 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:50,887 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:50,887 [Listener at localhost/10854] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:50,945 [Listener at localhost/10854] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,980 [Listener at localhost/10854] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:50,999 [Listener at localhost/10854] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:51,000 [Listener at localhost/10854] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:51,002 [Listener at localhost/10854] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:51,003 [Listener at localhost/10854] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:51,004 [Listener at localhost/10854] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:51,004 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:51,004 [Listener at localhost/10854] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:51,005 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 115 msecs
2020-12-03 07:23:51,005 [Listener at localhost/10854] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10852
2020-12-03 07:23:51,007 [Listener at localhost/10854] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:51,008 [Socket Reader #1 for port 10852] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10852
2020-12-03 07:23:51,032 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:51,051 [Listener at localhost/10852] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:51,053 [Listener at localhost/10852] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:51,054 [Listener at localhost/10852] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:51,054 [Listener at localhost/10852] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:51,061 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:51,063 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42051 has no edit logs
2020-12-03 07:23:51,072 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:51,072 [IPC Server listener on 10852] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10852: starting
2020-12-03 07:23:51,073 [Listener at localhost/10852] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10852
2020-12-03 07:23:51,074 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:51,077 [Listener at localhost/10852] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:23:51,077 [Listener at localhost/10852] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:51,078 [Listener at localhost/10852] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:51,080 [Listener at localhost/10852] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10855]
Serving checkpoints at http://localhost:10853
2020-12-03 07:23:51,081 [Listener at localhost/10852] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:51,081 [Listener at localhost/10852] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:51,082 [Listener at localhost/10852] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:10854
2020-12-03 07:23:51,082 [Listener at localhost/10852] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:51,092 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@241a0c3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:51,093 [Listener at localhost/10852] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10855
2020-12-03 07:23:51,100 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:51,100 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:36810 with /127.0.0.1:42057, journal id: ns1
2020-12-03 07:23:51,102 [Listener at localhost/10852] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:51,102 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:42057, journal id: ns1
2020-12-03 07:23:51,103 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42057 has no edit logs
2020-12-03 07:23:51,103 [Listener at localhost/10852] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:51,103 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:51,104 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getMissingLogSegments(328)) - Journal at /127.0.0.1:42057 has no edit logs
2020-12-03 07:23:51,106 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:51,107 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:51,108 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:51,108 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:51,110 [Listener at localhost/10852] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:51,110 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:51,111 [Listener at localhost/10852] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10855
2020-12-03 07:23:51,112 [Listener at localhost/10852] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:51,122 [Listener at localhost/10852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@46baf579{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:51,127 [Listener at localhost/10852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f7c0be3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:51,136 [Listener at localhost/10852] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3249a1ce{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:51,138 [Listener at localhost/10852] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4dd94a58{HTTP/1.1,[http/1.1]}{localhost:10855}
2020-12-03 07:23:51,138 [Listener at localhost/10852] INFO  server.Server (Server.java:doStart(419)) - Started @8087ms
2020-12-03 07:23:51,155 [Listener at localhost/10852] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:51,157 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:51,157 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:51,157 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:51,158 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:51,158 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:51,158 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:51,159 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:51,159 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:51,160 [Listener at localhost/10852] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:51,161 [Listener at localhost/10852] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:51,161 [Listener at localhost/10852] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:51,162 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:51,162 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:51
2020-12-03 07:23:51,162 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:51,163 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,164 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:51,164 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:51,179 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:51,179 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:51,180 [Listener at localhost/10852] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:51,180 [Listener at localhost/10852] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:51,180 [Listener at localhost/10852] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:51,181 [Listener at localhost/10852] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:51,181 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 0
2020-12-03 07:23:51,181 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:51,182 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:51,182 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:51,182 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:51,182 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:51,183 [Listener at localhost/10852] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:51,183 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:51,184 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,184 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:51,184 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:51,200 [Listener at localhost/10852] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:51,201 [Listener at localhost/10852] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:51,201 [Listener at localhost/10852] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:51,201 [Listener at localhost/10852] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:51,202 [Listener at localhost/10852] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:51,202 [Listener at localhost/10852] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:51,202 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:51,203 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,203 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:51,203 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:51,205 [Listener at localhost/10852] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:51,206 [Listener at localhost/10852] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:51,206 [Listener at localhost/10852] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:51,206 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:51,207 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:51,207 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:51,207 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:51,208 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:51,208 [Listener at localhost/10852] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:51,260 [Listener at localhost/10852] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:51,294 [Listener at localhost/10852] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:51,308 [Listener at localhost/10852] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:51,309 [Listener at localhost/10852] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:51,314 [Listener at localhost/10852] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:51,315 [Listener at localhost/10852] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:51,316 [Listener at localhost/10852] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:23:51,316 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:51,317 [Listener at localhost/10852] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:51,317 [Listener at localhost/10852] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 106 msecs
2020-12-03 07:23:51,317 [Listener at localhost/10852] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10854
2020-12-03 07:23:51,318 [Listener at localhost/10852] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:51,320 [Socket Reader #1 for port 10854] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10854
2020-12-03 07:23:51,338 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:51,368 [Listener at localhost/10854] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:51,371 [Listener at localhost/10854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:51,371 [Listener at localhost/10854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:51,372 [Listener at localhost/10854] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:51,381 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:51,383 [IPC Server listener on 10854] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10854: starting
2020-12-03 07:23:51,387 [Listener at localhost/10854] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10854
2020-12-03 07:23:51,388 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:51,389 [Listener at localhost/10854] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:23:51,389 [Listener at localhost/10854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:51,389 [Listener at localhost/10854] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:51,391 [Listener at localhost/10854] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10853]
Serving checkpoints at http://localhost:10855
2020-12-03 07:23:51,415 [IPC Server handler 0 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,429 [IPC Server handler 0 on default port 10854] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:51,431 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:51,434 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:51,439 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:51,440 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:51,443 [Listener at localhost/10854] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:23:51,448 [IPC Server handler 0 on default port 42051] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:51,448 [IPC Server handler 1 on default port 42057] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:51,452 [IPC Server handler 1 on default port 36810] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:51,532 [IPC Server handler 1 on default port 42057] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:23:51,532 [IPC Server handler 1 on default port 36810] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:23:51,532 [IPC Server handler 0 on default port 42051] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:23:51,534 [IPC Server handler 1 on default port 36810] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:23:51,534 [IPC Server handler 1 on default port 42057] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:23:51,534 [IPC Server handler 0 on default port 42051] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:23:51,537 [Listener at localhost/10854] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 2
2020-12-03 07:23:51,537 [Listener at localhost/10854] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:51,538 [Listener at localhost/10854] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:51,538 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:51,549 [Listener at localhost/10854] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:51,556 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:51,556 [Listener at localhost/10854] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:51,557 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:51,564 [Listener at localhost/10854] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:51,576 [IPC Server handler 4 on default port 42051] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:51,579 [IPC Server handler 0 on default port 36810] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:51,580 [IPC Server handler 3 on default port 42057] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:23:51,724 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:51,743 [Listener at localhost/10854] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 19 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:51,761 [CacheReplicationMonitor(1385821275)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:51,762 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:51,763 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:51,763 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:51,763 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:51,763 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:51,763 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 206 msec
2020-12-03 07:23:51,802 [IPC Server handler 1 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:51,862 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:51,862 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 3
2020-12-03 07:23:51,878 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 59 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 34 4 1 
2020-12-03 07:23:51,884 [IPC Server handler 4 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:51,885 [IPC Server handler 2 on default port 36810] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:51,886 [IPC Server handler 1 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:51,889 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:51,891 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2020-12-03 07:23:51,891 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 5
2020-12-03 07:23:52,022 [IPC Server handler 2 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,028 [IPC Server handler 5 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,034 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:52,034 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 5, 7
2020-12-03 07:23:52,037 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 20 3 4 
2020-12-03 07:23:52,039 [IPC Server handler 0 on default port 36810] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000005 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000005-0000000000000000008
2020-12-03 07:23:52,039 [IPC Server handler 4 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000005 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000005-0000000000000000008
2020-12-03 07:23:52,044 [IPC Server handler 3 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000005 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000005-0000000000000000008
2020-12-03 07:23:52,044 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000005 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000005-0000000000000000008
2020-12-03 07:23:52,045 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000005 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000005-0000000000000000008
2020-12-03 07:23:52,045 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 9
2020-12-03 07:23:52,064 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:52,103 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:36810 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:52,106 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:52,208 [Thread-231] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36810
2020-12-03 07:23:52,209 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@4c95a1b9] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(214)) - Stopping JournalNode Sync.
2020-12-03 07:23:52,210 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:52,210 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:52,211 [Thread-231] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3012646b{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:52,212 [Thread-231] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ebdc62c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:52,213 [Thread-231] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66498326{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:52,213 [Thread-231] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@625732{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:52,215 [Thread-231] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive; location= null
2020-12-03 07:23:52,215 [Thread-231] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null
2020-12-03 07:23:52,219 [IPC Server handler 0 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,226 [Logger channel (from single-thread executor) to /127.0.0.1:36810] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(400)) - Remote journal 127.0.0.1:36810 failed to write txns 10-10. Will try to write to this JN again after the next log roll.
java.io.EOFException: End of File Exception between local host is: "5cae4f03508f/172.17.0.4"; destination host is: "localhost":36810; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy17.journal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:191)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:397)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:390)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:57)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:23:52,237 [IPC Server handler 1 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/4	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,243 [IPC Server handler 2 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/5	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,244 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 72 bytes of edits!
2020-12-03 07:23:52,259 [IPC Server handler 5 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/6	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,259 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 72 bytes of edits!
2020-12-03 07:23:52,272 [IPC Server handler 4 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/7	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,273 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 72 bytes of edits!
2020-12-03 07:23:52,278 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:52,278 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 9, 14
2020-12-03 07:23:52,278 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:52,281 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 60 6 3 
2020-12-03 07:23:52,285 [IPC Server handler 4 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000009 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000009-0000000000000000015
2020-12-03 07:23:52,285 [IPC Server handler 4 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000009 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000009-0000000000000000015
2020-12-03 07:23:52,287 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000009 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000009-0000000000000000015
2020-12-03 07:23:52,289 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000009 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000009-0000000000000000015
2020-12-03 07:23:52,289 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 16
2020-12-03 07:23:52,308 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:52,449 [IPC Server handler 6 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/8	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,449 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 72 bytes of edits!
2020-12-03 07:23:52,458 [IPC Server handler 7 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/9	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,458 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 72 bytes of edits!
2020-12-03 07:23:52,464 [IPC Server handler 3 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,465 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:52,478 [IPC Server handler 8 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,479 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:52,484 [IPC Server handler 9 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:52,484 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:52,488 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:52,488 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 16, 21
2020-12-03 07:23:52,488 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:52,492 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 36 3 3 
2020-12-03 07:23:52,494 [IPC Server handler 0 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000016 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000016-0000000000000000022
2020-12-03 07:23:52,496 [IPC Server handler 1 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000016 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000016-0000000000000000022
2020-12-03 07:23:52,500 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000016 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000016-0000000000000000022
2020-12-03 07:23:52,501 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000016 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000016-0000000000000000022
2020-12-03 07:23:52,501 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 23
2020-12-03 07:23:52,512 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,079 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:53,108 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:42057, journal id: ns1
2020-12-03 07:23:53,242 [Logger channel (from single-thread executor) to /127.0.0.1:36810] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:36810. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:53,267 [IPC Server handler 4 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/13	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,267 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,272 [IPC Server handler 6 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/14	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,272 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,278 [IPC Server handler 7 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/15	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,279 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,287 [IPC Server handler 3 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/16	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,287 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,291 [IPC Server handler 8 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/17	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,292 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,294 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:53,294 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 23, 28
2020-12-03 07:23:53,295 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,298 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 24 2 1 
2020-12-03 07:23:53,302 [IPC Server handler 1 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000023 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000023-0000000000000000029
2020-12-03 07:23:53,305 [IPC Server handler 0 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000023 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000023-0000000000000000029
2020-12-03 07:23:53,306 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000023 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000023-0000000000000000029
2020-12-03 07:23:53,307 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000023 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000023-0000000000000000029
2020-12-03 07:23:53,307 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 30
2020-12-03 07:23:53,329 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,481 [IPC Server handler 9 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/18	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,481 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,490 [IPC Server handler 0 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/19	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,490 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,498 [IPC Server handler 1 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/20	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,499 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,512 [IPC Server handler 2 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/21	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,512 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,520 [IPC Server handler 5 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/22	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,521 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,525 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:53,525 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 30, 35
2020-12-03 07:23:53,525 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,528 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 35 2 2 
2020-12-03 07:23:53,531 [IPC Server handler 2 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000030 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000030-0000000000000000036
2020-12-03 07:23:53,532 [IPC Server handler 1 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000030 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000030-0000000000000000036
2020-12-03 07:23:53,533 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000030 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000030-0000000000000000036
2020-12-03 07:23:53,534 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000030 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000030-0000000000000000036
2020-12-03 07:23:53,534 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 37
2020-12-03 07:23:53,549 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,692 [IPC Server handler 4 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/23	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,692 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,702 [IPC Server handler 6 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/24	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,703 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,708 [IPC Server handler 7 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/25	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,708 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,712 [IPC Server handler 3 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/26	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,713 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,716 [IPC Server handler 8 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/27	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,716 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,718 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:53,718 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 37, 42
2020-12-03 07:23:53,718 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,720 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 21 13 3 
2020-12-03 07:23:53,724 [IPC Server handler 0 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000037 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000037-0000000000000000043
2020-12-03 07:23:53,726 [IPC Server handler 2 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000037 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000037-0000000000000000043
2020-12-03 07:23:53,728 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000037 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000037-0000000000000000043
2020-12-03 07:23:53,728 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000037 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000037-0000000000000000043
2020-12-03 07:23:53,728 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 44
2020-12-03 07:23:53,744 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:53,964 [IPC Server handler 9 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/28	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,965 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,973 [IPC Server handler 0 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/29	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,974 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:53,983 [IPC Server handler 1 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/30	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:53,983 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,002 [IPC Server handler 2 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/31	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,003 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,012 [IPC Server handler 5 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/32	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,012 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,015 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:54,015 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 44, 49
2020-12-03 07:23:54,019 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,022 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 47 3 2 
2020-12-03 07:23:54,024 [IPC Server handler 3 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000044 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000044-0000000000000000050
2020-12-03 07:23:54,032 [IPC Server handler 3 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000044 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000044-0000000000000000050
2020-12-03 07:23:54,034 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000044 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000050
2020-12-03 07:23:54,035 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000044 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000044-0000000000000000050
2020-12-03 07:23:54,036 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 51
2020-12-03 07:23:54,048 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,126 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:54,126 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:54,129 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(254)) - Could not sync with Journal at /127.0.0.1:36810
java.io.EOFException: End of File Exception between local host is: "5cae4f03508f/172.17.0.4"; destination host is: "localhost":36810; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy18.getEditLogManifestFromJournal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.InterQJournalProtocolTranslatorPB.getEditLogManifestFromJournal(InterQJournalProtocolTranslatorPB.java:75)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.syncWithJournalAtIndex(JournalNodeSyncer.java:251)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.syncJournals(JournalNodeSyncer.java:227)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:187)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:23:54,129 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(254)) - Could not sync with Journal at localhost/127.0.0.1:36810
java.io.EOFException: End of File Exception between local host is: "5cae4f03508f/172.17.0.4"; destination host is: "localhost":36810; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy18.getEditLogManifestFromJournal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.InterQJournalProtocolTranslatorPB.getEditLogManifestFromJournal(InterQJournalProtocolTranslatorPB.java:75)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.syncWithJournalAtIndex(JournalNodeSyncer.java:251)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.syncJournals(JournalNodeSyncer.java:227)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:187)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:23:54,153 [IPC Server handler 4 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/33	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,153 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,159 [IPC Server handler 6 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/34	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,159 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,167 [IPC Server handler 7 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/35	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,167 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,173 [IPC Server handler 3 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/36	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,173 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,177 [IPC Server handler 8 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/37	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,177 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,179 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:54,179 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 51, 56
2020-12-03 07:23:54,180 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,184 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 27 1 2 
2020-12-03 07:23:54,186 [IPC Server handler 4 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000051 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000051-0000000000000000057
2020-12-03 07:23:54,186 [IPC Server handler 4 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000051 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000051-0000000000000000057
2020-12-03 07:23:54,187 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000051 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000051-0000000000000000057
2020-12-03 07:23:54,188 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000051 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000051-0000000000000000057
2020-12-03 07:23:54,188 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 58
2020-12-03 07:23:54,199 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,243 [Logger channel (from single-thread executor) to /127.0.0.1:36810] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:36810. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:54,295 [IPC Server handler 9 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/38	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,295 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,299 [IPC Server handler 0 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/39	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,299 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,309 [IPC Server handler 1 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/40	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,309 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,313 [IPC Server handler 2 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/41	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,313 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,334 [IPC Server handler 5 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/42	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,334 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,343 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:54,344 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 58, 63
2020-12-03 07:23:54,344 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,351 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 34 2 0 
2020-12-03 07:23:54,354 [IPC Server handler 1 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000058 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000058-0000000000000000064
2020-12-03 07:23:54,356 [IPC Server handler 0 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000058 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000058-0000000000000000064
2020-12-03 07:23:54,358 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000058 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000058-0000000000000000064
2020-12-03 07:23:54,359 [Thread-231] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000058 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000058-0000000000000000064
2020-12-03 07:23:54,359 [Thread-231] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 65
2020-12-03 07:23:54,371 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,464 [Thread-231] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36810
2020-12-03 07:23:54,465 [Thread-231] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive; location= null
2020-12-03 07:23:54,465 [Thread-231] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null
2020-12-03 07:23:54,465 [Thread-231] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:23:54,468 [Thread-231] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:44191
2020-12-03 07:23:54,468 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:54,470 [Thread-231] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:54,471 [Thread-231] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:23:54,471 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:54,473 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:54,474 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:23:54,474 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:54,474 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:54,475 [Thread-231] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44191
2020-12-03 07:23:54,475 [Thread-231] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:54,478 [Thread-231] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f0785ac{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:54,478 [Thread-231] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d4707bf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:54,487 [Thread-231] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@431c51b8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:23:54,491 [Thread-231] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2ee039f1{HTTP/1.1,[http/1.1]}{localhost:44191}
2020-12-03 07:23:54,491 [Thread-231] INFO  server.Server (Server.java:doStart(419)) - Started @11440ms
2020-12-03 07:23:54,492 [Thread-231] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:36810
2020-12-03 07:23:54,492 [Thread-231] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:54,493 [Socket Reader #1 for port 36810] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 36810
2020-12-03 07:23:54,509 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:54,511 [IPC Server listener on 36810] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 36810: starting
2020-12-03 07:23:54,519 [IPC Server handler 4 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/43	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,519 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,524 [IPC Server handler 6 on default port 10852] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/44	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:23:54,525 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 73 bytes of edits!
2020-12-03 07:23:54,528 [Listener at localhost/36810] INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1318)) - Rolling edit logs
2020-12-03 07:23:54,529 [Listener at localhost/36810] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 65, 67
2020-12-03 07:23:54,529 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:54,544 [Listener at localhost/36810] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 24 2 1 
2020-12-03 07:23:54,546 [IPC Server handler 4 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000065 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000065-0000000000000000068
2020-12-03 07:23:54,549 [IPC Server handler 4 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000065 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000065-0000000000000000068
2020-12-03 07:23:54,550 [Listener at localhost/36810] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000065 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000065-0000000000000000068
2020-12-03 07:23:54,551 [Listener at localhost/36810] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000065 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000065-0000000000000000068
2020-12-03 07:23:54,551 [Listener at localhost/36810] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 69
2020-12-03 07:23:54,560 [FSEditLogAsync] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:reserveQueueSpace(495)) - Pending edits to 127.0.0.1:36810 is going to exceed limit size: 0, current queued edits size: 72, will silently drop 17 bytes of edits!
2020-12-03 07:23:55,130 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:55,131 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with /127.0.0.1:42057, journal id: ns1
2020-12-03 07:23:55,244 [Logger channel (from single-thread executor) to /127.0.0.1:36810] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:36810. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:55,250 [IPC Server handler 1 on default port 36810] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,314 [IPC Server handler 1 on default port 36810] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 6821@5cae4f03508f
2020-12-03 07:23:55,322 [IPC Server handler 1 on default port 36810] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:23:55,333 [IPC Server handler 1 on default port 36810] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000009,first=0000000000000000009,last=0000000000000000009,inProgress=true,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:23:55,336 [IPC Server handler 1 on default port 36810] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:23:55,338 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:36810 with /127.0.0.1:42051, journal id: ns1
2020-12-03 07:23:55,347 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=9&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,352 [Logger channel (from single-thread executor) to /127.0.0.1:36810] INFO  client.QuorumJournalManager (IPCLoggerChannel.java:call(531)) - Restarting previously-stopped writes to 127.0.0.1:36810 in segment starting at txid 16
2020-12-03 07:23:55,355 [IPC Server handler 2 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 2 on default port 36810, call Call#339 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 16 to end at txid 22 but only written up to txid 15 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,367 [IPC Server handler 4 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 4 on default port 36810, call Call#341 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 23 to end at txid 29 but only written up to txid 22 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,380 [IPC Server handler 0 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 0 on default port 36810, call Call#343 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 30 to end at txid 36 but only written up to txid 29 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,396 [IPC Server handler 3 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 3 on default port 36810, call Call#345 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 37 to end at txid 43 but only written up to txid 36 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,405 [IPC Server handler 1 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 1 on default port 36810, call Call#347 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 44 to end at txid 50 but only written up to txid 43 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,417 [IPC Server handler 2 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 2 on default port 36810, call Call#349 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 51 to end at txid 57 but only written up to txid 50 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,427 [IPC Server handler 4 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 4 on default port 36810, call Call#351 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 58 to end at txid 64 but only written up to txid 57 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,435 [IPC Server handler 0 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 0 on default port 36810, call Call#353 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.finalizeLogSegment from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Trying to finalize in-progress log segment 65 to end at txid 68 but only written up to txid 64 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.finalizeLogSegment(Journal.java:646)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.finalizeLogSegment(JournalNodeRpcServer.java:211)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.finalizeLogSegment(QJournalProtocolServerSideTranslatorPB.java:205)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28980)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:55,521 [qtp1201466784-63] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000009-0000000000000000015, fileSize: 402. Sent total: 402 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,583 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000009-0000000000000000015 took 0.00s.
2020-12-03 07:23:55,584 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000009-0000000000000000015 of size 402 bytes.
2020-12-03 07:23:55,586 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=16&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,590 [qtp1201466784-390] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000016-0000000000000000022, fileSize: 405. Sent total: 405 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,644 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000016-0000000000000000022 took 0.00s.
2020-12-03 07:23:55,644 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000016-0000000000000000022 of size 405 bytes.
2020-12-03 07:23:55,645 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=23&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,648 [qtp1201466784-51] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000023-0000000000000000029, fileSize: 407. Sent total: 407 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,695 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000023-0000000000000000029 took 0.00s.
2020-12-03 07:23:55,695 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000023-0000000000000000029 of size 407 bytes.
2020-12-03 07:23:55,696 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=30&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,699 [qtp1201466784-63] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000030-0000000000000000036, fileSize: 407. Sent total: 407 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,812 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000030-0000000000000000036 took 0.00s.
2020-12-03 07:23:55,813 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000030-0000000000000000036 of size 407 bytes.
2020-12-03 07:23:55,813 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=37&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,816 [qtp1201466784-390] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000037-0000000000000000043, fileSize: 407. Sent total: 407 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:55,950 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000037-0000000000000000043 took 0.00s.
2020-12-03 07:23:55,950 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000037-0000000000000000043 of size 407 bytes.
2020-12-03 07:23:55,951 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=44&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:55,954 [qtp1201466784-51] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000044-0000000000000000050, fileSize: 407. Sent total: 407 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:56,043 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000044-0000000000000000050 took 0.00s.
2020-12-03 07:23:56,043 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000044-0000000000000000050 of size 407 bytes.
2020-12-03 07:23:56,044 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=51&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:56,047 [qtp1201466784-63] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000051-0000000000000000057, fileSize: 407. Sent total: 407 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:56,133 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42051 with localhost/127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:56,133 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:syncWithJournalAtIndex(232)) - Syncing Journal /127.0.0.1:42057 with /127.0.0.1:36810, journal id: ns1
2020-12-03 07:23:56,144 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000051-0000000000000000057 took 0.00s.
2020-12-03 07:23:56,145 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000051-0000000000000000057 of size 407 bytes.
2020-12-03 07:23:56,145 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=58&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:56,148 [qtp1201466784-390] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000058-0000000000000000064, fileSize: 407. Sent total: 407 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:56,180 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000058-0000000000000000064 took 0.00s.
2020-12-03 07:23:56,180 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000058-0000000000000000064 of size 407 bytes.
2020-12-03 07:23:56,180 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(426)) - Downloading missing Edit Log from http://localhost:44075/getJournal?jid=ns1&segmentTxId=65&storageInfo=-65%3A1968455466%3A1606980226990%3AtestClusterID&inProgressOk=false to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:23:56,183 [qtp1201466784-51] INFO  namenode.TransferFsImage (TransferFsImage.java:copyFileToStream(397)) - Sending fileName: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000065-0000000000000000068, fileSize: 188. Sent total: 188 bytes. Size of last segment intended to send: -1 bytes.
2020-12-03 07:23:56,252 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:56,252 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:56,253 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,253 [Listener at localhost/10854] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 69, 69
2020-12-03 07:23:56,255 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1e6b9a95] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:56,256 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6f8d7714] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:56,257 [IPC Server handler 1 on default port 36810] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 1 on default port 36810, call Call#357 Retry#0 org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol.journal from 127.0.0.1:33246
org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException: Can't write txid 70 expecting nextTxId=69 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:23:56,258 [Listener at localhost/10854] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 5 1 1 
2020-12-03 07:23:56,259 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  common.Util (Util.java:receiveFile(314)) - Combined time for file download and fsync to all disks took 0.00s. The file download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/edits.sync/edits_0000000000000000065-0000000000000000068 took 0.00s.
2020-12-03 07:23:56,259 [Logger channel (from single-thread executor) to /127.0.0.1:36810] WARN  client.QuorumJournalManager (IPCLoggerChannel.java:call(400)) - Remote journal 127.0.0.1:36810 failed to write txns 70-70. Will try to write to this JN again after the next log roll.
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.qjournal.protocol.JournalOutOfSyncException): Can't write txid 70 expecting nextTxId=69 ; journal id: ns1
	at org.apache.hadoop.hdfs.qjournal.server.Journal.checkSync(Journal.java:545)
	at org.apache.hadoop.hdfs.qjournal.server.Journal.journal(Journal.java:424)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.journal(JournalNodeRpcServer.java:191)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.journal(QJournalProtocolServerSideTranslatorPB.java:164)
	at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:28974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy17.journal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:191)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:397)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:390)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:57)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:56,259 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:downloadMissingLogSegment(462)) - Downloaded file edits_0000000000000000065-0000000000000000068 of size 188 bytes.
2020-12-03 07:23:56,261 [IPC Server handler 4 on default port 42057] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000069 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000069-0000000000000000070
2020-12-03 07:23:56,261 [IPC Server handler 4 on default port 42051] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000069 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000069-0000000000000000070
2020-12-03 07:23:56,264 [Listener at localhost/10854] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000069 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000069-0000000000000000070
2020-12-03 07:23:56,265 [Listener at localhost/10854] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000069 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000069-0000000000000000070
2020-12-03 07:23:56,265 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:56,271 [CacheReplicationMonitor(1385821275)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:56,272 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10852
2020-12-03 07:23:56,293 [IPC Server listener on 10852] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10852
2020-12-03 07:23:56,295 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:56,295 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,411 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:56,435 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,436 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:56,444 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@138a7441{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:56,446 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@81ff872{HTTP/1.1,[http/1.1]}{localhost:10853}
2020-12-03 07:23:56,446 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68105edc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,447 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28782602{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,454 [Listener at localhost/10854] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:56,454 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:56,455 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:56,456 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10854
2020-12-03 07:23:56,459 [IPC Server listener on 10854] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10854
2020-12-03 07:23:56,460 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,460 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:56,461 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:56,473 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:56,474 [Listener at localhost/10854] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:56,475 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3249a1ce{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:56,478 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4dd94a58{HTTP/1.1,[http/1.1]}{localhost:10855}
2020-12-03 07:23:56,478 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f7c0be3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,479 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@46baf579{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,487 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36810
2020-12-03 07:23:56,487 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@7dc9d20e] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(214)) - Stopping JournalNode Sync.
2020-12-03 07:23:56,489 [IPC Server listener on 36810] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 36810
2020-12-03 07:23:56,489 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,492 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@431c51b8{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:56,493 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2ee039f1{HTTP/1.1,[http/1.1]}{localhost:44191}
2020-12-03 07:23:56,494 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3d4707bf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,495 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f0785ac{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,497 [Listener at localhost/10854] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null
2020-12-03 07:23:56,499 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@782f317c] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(214)) - Stopping JournalNode Sync.
2020-12-03 07:23:56,499 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42051
2020-12-03 07:23:56,501 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,501 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,501 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@20c0a64d{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:56,507 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@455b6df1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,507 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d278d2b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,508 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68dc098b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,512 [Listener at localhost/10854] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive; location= null
2020-12-03 07:23:56,512 [Listener at localhost/10854] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null
2020-12-03 07:23:56,514 [Listener at localhost/10854] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping JournalNode metrics system...
2020-12-03 07:23:56,519 [Listener at localhost/10854] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - JournalNode metrics system stopped.
2020-12-03 07:23:56,521 [Listener at localhost/10854] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - JournalNode metrics system shutdown complete.
2020-12-03 07:23:56,521 [Listener at localhost/10854] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42057
2020-12-03 07:23:56,521 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1147380457@661a3be1] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(214)) - Stopping JournalNode Sync.
2020-12-03 07:23:56,522 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:56,523 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:56,524 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@51549490{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:23:56,526 [Listener at localhost/10854] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@71e9ebae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:56,527 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d778add{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:56,527 [Listener at localhost/10854] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63611043{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:56,529 [Listener at localhost/10854] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive; location= null
2020-12-03 07:23:56,529 [Listener at localhost/10854] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null
msx-rc 0
