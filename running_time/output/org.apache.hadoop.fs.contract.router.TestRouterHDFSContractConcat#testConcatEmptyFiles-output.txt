2020-12-03 07:21:19,701 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-12-03 07:21:19,737 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:21:19,738 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:21:20,571 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:20,590 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:20,594 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:20,594 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:20,605 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:20,605 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:20,605 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:20,612 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:21:20,613 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:21:20,694 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:20,700 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:21:20,701 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:20,701 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:20,710 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:20,711 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:20
2020-12-03 07:21:20,714 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:20,714 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:20,717 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:21:20,718 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:20,746 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:20,746 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:20,756 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:20,757 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:20,757 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:20,758 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:20,759 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:20,759 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:20,759 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:20,760 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:20,760 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:20,761 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:20,761 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:20,801 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:21:20,802 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:20,802 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:20,802 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:20,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:20,824 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:20,824 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:21:20,825 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:20,833 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:20,833 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:20,834 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:20,834 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:20,844 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:20,849 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:20,857 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:20,857 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:20,858 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:21:20,858 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:20,872 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:20,873 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:20,873 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:20,880 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:20,881 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:20,883 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:20,884 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:20,885 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:21:20,885 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:20,937 [JUnit] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:21,017 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:21:21,085 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:21:21,180 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:21:21,222 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:21,222 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:21,399 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:21,399 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:21,481 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:21:21,579 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-12-03 07:21:21,609 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-12-03 07:21:21,631 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:21,718 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:21:22,204 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:21:22,204 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:22,215 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:21:22,216 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:21:22,271 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f20155b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:22,289 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:22,313 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3894ms
2020-12-03 07:21:22,454 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:22,461 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:22,474 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:22,477 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:22,477 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:22,478 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:22,513 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:22,514 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:22,525 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42463
2020-12-03 07:21:22,528 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:22,592 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c2375a9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:22,594 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d9c13b5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:22,939 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e19bb76{/,file:///tmp/jetty-localhost-42463-hdfs-_-any-2906662998731410509.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:21:22,948 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@142269f2{HTTP/1.1,[http/1.1]}{localhost:42463}
2020-12-03 07:21:22,949 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4529ms
2020-12-03 07:21:22,965 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:22,967 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:22,967 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:22,968 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:22,968 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:22,969 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:22,969 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:22,970 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:21:22,970 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:21:22,971 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:22,972 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:22,972 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:22,973 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:22,974 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:22
2020-12-03 07:21:22,974 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:22,974 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,975 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:22,975 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:22,983 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:22,984 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:22,984 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:22,985 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:22,985 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:22,985 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:22,985 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:22,986 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:22,986 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:22,986 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:22,986 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:22,987 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:22,987 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:22,988 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:22,988 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,988 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:22,988 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:22,990 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:22,991 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:22,991 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:22,991 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:22,991 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:22,992 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:22,992 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:22,992 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,993 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:22,993 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:22,996 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:22,996 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:22,997 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:22,997 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:22,997 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:22,998 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:22,998 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:22,999 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:22,999 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:23,039 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:23,082 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:23,083 [JUnit] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:21:23,090 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:23,091 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:23,145 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:23,158 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:23,158 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:23,166 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:21:23,167 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:23,168 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 165 msecs
2020-12-03 07:21:23,421 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:21:23,472 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:23,488 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:23,803 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:23,836 [Listener at 0.0.0.0/45920] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:23,856 [Listener at 0.0.0.0/45920] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:23,857 [Listener at 0.0.0.0/45920] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:23,857 [Listener at 0.0.0.0/45920] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:23,909 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:23,909 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:23,919 [Listener at 0.0.0.0/45920] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:45920
2020-12-03 07:21:23,933 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:21:23,936 [Listener at 0.0.0.0/45920] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:21:23,937 [Listener at 0.0.0.0/45920] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:21:23,937 [Listener at 0.0.0.0/45920] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:21:23,937 [Listener at 0.0.0.0/45920] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:21:23,948 [Listener at 0.0.0.0/45920] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:23,949 [Listener at 0.0.0.0/45920] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:21:23,950 [Listener at 0.0.0.0/45920] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:21:23,951 [Listener at 0.0.0.0/45920] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:21:23,963 [Listener at 0.0.0.0/45920] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:23,965 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29ad44e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:23,966 [Listener at 0.0.0.0/45920] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:23,967 [Listener at 0.0.0.0/45920] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:23,990 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:23,992 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:23,993 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:23,993 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:23,996 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:23,997 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:24,000 [Listener at 0.0.0.0/45920] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41242
2020-12-03 07:21:24,001 [Listener at 0.0.0.0/45920] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:24,005 [Listener at 0.0.0.0/45920] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@649f2009{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:24,007 [Listener at 0.0.0.0/45920] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69adf72c{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:24,263 [Listener at 0.0.0.0/45920] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e11bc55{/,file:///tmp/jetty-localhost-41242-hdfs-_-any-6906695807134201169.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:21:24,264 [Listener at 0.0.0.0/45920] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7544a1e4{HTTP/1.1,[http/1.1]}{localhost:41242}
2020-12-03 07:21:24,265 [Listener at 0.0.0.0/45920] INFO  server.Server (Server.java:doStart(419)) - Started @5845ms
2020-12-03 07:21:24,282 [Listener at 0.0.0.0/45920] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:24,283 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:24,283 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:24,284 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:24,284 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:24,285 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:24,285 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:24,286 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:21:24,286 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:21:24,292 [Listener at 0.0.0.0/45920] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:24,293 [Listener at 0.0.0.0/45920] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:24,293 [Listener at 0.0.0.0/45920] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:24,294 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:24,294 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:24
2020-12-03 07:21:24,294 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:24,295 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,295 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:24,295 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:24,312 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:24,312 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:24,313 [Listener at 0.0.0.0/45920] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:24,313 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:24,313 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:24,313 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:24,314 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:24,314 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:24,314 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:24,314 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:24,314 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:24,315 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:24,315 [Listener at 0.0.0.0/45920] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:24,315 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:24,316 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,316 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:24,316 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:24,326 [Listener at 0.0.0.0/45920] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:24,334 [Listener at 0.0.0.0/45920] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:24,334 [Listener at 0.0.0.0/45920] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:24,335 [Listener at 0.0.0.0/45920] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:24,335 [Listener at 0.0.0.0/45920] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:24,335 [Listener at 0.0.0.0/45920] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:24,336 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:24,336 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,337 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:24,337 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:24,339 [Listener at 0.0.0.0/45920] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:24,340 [Listener at 0.0.0.0/45920] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:24,340 [Listener at 0.0.0.0/45920] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:24,340 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:24,340 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:24,341 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:24,341 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,341 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:24,342 [Listener at 0.0.0.0/45920] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:24,379 [Listener at 0.0.0.0/45920] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:24,413 [Listener at 0.0.0.0/45920] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:24,414 [Listener at 0.0.0.0/45920] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:21:24,432 [Listener at 0.0.0.0/45920] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:24,438 [Listener at 0.0.0.0/45920] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:24,442 [Listener at 0.0.0.0/45920] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:24,445 [Listener at 0.0.0.0/45920] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:24,445 [Listener at 0.0.0.0/45920] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:21:24,446 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:21:24,446 [Listener at 0.0.0.0/45920] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:24,446 [Listener at 0.0.0.0/45920] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 103 msecs
2020-12-03 07:21:24,447 [Listener at 0.0.0.0/45920] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:21:24,449 [Listener at 0.0.0.0/45920] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:24,450 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:24,460 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:24,497 [Listener at 0.0.0.0/44977] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:24,538 [Listener at 0.0.0.0/44977] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:24,538 [Listener at 0.0.0.0/44977] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:24,539 [Listener at 0.0.0.0/44977] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:24,574 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:24,574 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:24,581 [Listener at 0.0.0.0/44977] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44977
2020-12-03 07:21:24,581 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:21:24,581 [Listener at 0.0.0.0/44977] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:21:24,582 [Listener at 0.0.0.0/44977] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:21:24,582 [Listener at 0.0.0.0/44977] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:21:24,582 [Listener at 0.0.0.0/44977] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
Formatting using clusterid: testClusterID
2020-12-03 07:21:24,590 [Listener at 0.0.0.0/44977] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:24,591 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:24,591 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:24,591 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:24,591 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:24,592 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:24,592 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:24,592 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:21:24,593 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:21:24,593 [Listener at 0.0.0.0/44977] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:24,594 [Listener at 0.0.0.0/44977] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:24,594 [Listener at 0.0.0.0/44977] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:24,595 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:24,596 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:24
2020-12-03 07:21:24,596 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:24,596 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,596 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:24,596 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:24,609 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:24,609 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:24,610 [Listener at 0.0.0.0/44977] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:24,610 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:24,611 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:24,611 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:24,611 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:24,611 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:24,611 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:24,611 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:24,612 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:24,612 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:24,612 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:24,612 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:24,613 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,613 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:24,613 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:24,619 [Listener at 0.0.0.0/44977] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:24,620 [Listener at 0.0.0.0/44977] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:24,620 [Listener at 0.0.0.0/44977] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:24,620 [Listener at 0.0.0.0/44977] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:24,620 [Listener at 0.0.0.0/44977] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:24,621 [Listener at 0.0.0.0/44977] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:24,621 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:24,621 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,622 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:24,622 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:24,624 [Listener at 0.0.0.0/44977] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:24,624 [Listener at 0.0.0.0/44977] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:24,624 [Listener at 0.0.0.0/44977] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:24,625 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:24,625 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:24,625 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:24,625 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:24,625 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:24,626 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:24,628 [Listener at 0.0.0.0/44977] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:24,779 [Listener at 0.0.0.0/44977] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-12-03 07:21:24,906 [Listener at 0.0.0.0/44977] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-12-03 07:21:25,028 [Listener at 0.0.0.0/44977] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-12-03 07:21:25,052 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:25,055 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:25,063 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:25,068 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:25,134 [Listener at 0.0.0.0/44977] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:21:25,138 [Listener at 0.0.0.0/44977] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-12-03 07:21:25,145 [Listener at 0.0.0.0/44977] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-12-03 07:21:25,152 [Listener at 0.0.0.0/44977] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:25,153 [Listener at 0.0.0.0/44977] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:21:25,154 [Listener at 0.0.0.0/44977] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:21:25,154 [Listener at 0.0.0.0/44977] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:21:25,164 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a551a63] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:25,164 [Listener at 0.0.0.0/44977] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:25,166 [Listener at 0.0.0.0/44977] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:25,168 [Listener at 0.0.0.0/44977] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:25,171 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:25,173 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:25,173 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:25,173 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:25,177 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:25,177 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:25,178 [Listener at 0.0.0.0/44977] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44628
2020-12-03 07:21:25,179 [Listener at 0.0.0.0/44977] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:25,183 [Listener at 0.0.0.0/44977] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29539e36{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:25,184 [Listener at 0.0.0.0/44977] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f5c79a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:25,418 [Listener at 0.0.0.0/44977] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30c0ccff{/,file:///tmp/jetty-localhost-44628-hdfs-_-any-4354568416203687786.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:21:25,421 [Listener at 0.0.0.0/44977] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@581d969c{HTTP/1.1,[http/1.1]}{localhost:44628}
2020-12-03 07:21:25,422 [Listener at 0.0.0.0/44977] INFO  server.Server (Server.java:doStart(419)) - Started @7002ms
2020-12-03 07:21:25,424 [Listener at 0.0.0.0/44977] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:25,425 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:25,425 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:25,425 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:25,425 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:25,425 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:25,426 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:25,426 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:21:25,426 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:21:25,427 [Listener at 0.0.0.0/44977] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:25,458 [Listener at 0.0.0.0/44977] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:25,459 [Listener at 0.0.0.0/44977] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:25,464 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:25,464 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:25
2020-12-03 07:21:25,465 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:25,465 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:25,465 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:25,466 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:25,490 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:25,491 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:25,491 [Listener at 0.0.0.0/44977] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:25,492 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:25,492 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:25,493 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:25,493 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:25,494 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:25,494 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:25,494 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:25,494 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:25,495 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:25,495 [Listener at 0.0.0.0/44977] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:25,496 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:25,496 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:25,497 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:25,497 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:25,504 [Listener at 0.0.0.0/44977] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:25,504 [Listener at 0.0.0.0/44977] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:25,504 [Listener at 0.0.0.0/44977] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:25,504 [Listener at 0.0.0.0/44977] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:25,505 [Listener at 0.0.0.0/44977] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:25,505 [Listener at 0.0.0.0/44977] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:25,505 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:25,505 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:25,505 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:25,506 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:25,508 [Listener at 0.0.0.0/44977] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:25,508 [Listener at 0.0.0.0/44977] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:25,508 [Listener at 0.0.0.0/44977] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:25,508 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:25,508 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:25,509 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:25,509 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:25,509 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:25,509 [Listener at 0.0.0.0/44977] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:25,544 [Listener at 0.0.0.0/44977] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:25,578 [Listener at 0.0.0.0/44977] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:25,579 [Listener at 0.0.0.0/44977] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:21:25,583 [Listener at 0.0.0.0/44977] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:25,583 [Listener at 0.0.0.0/44977] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:25,591 [Listener at 0.0.0.0/44977] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:25,592 [Listener at 0.0.0.0/44977] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:25,593 [Listener at 0.0.0.0/44977] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-12-03 07:21:25,593 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:21:25,593 [Listener at 0.0.0.0/44977] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:25,594 [Listener at 0.0.0.0/44977] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 83 msecs
2020-12-03 07:21:25,594 [Listener at 0.0.0.0/44977] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:21:25,595 [Listener at 0.0.0.0/44977] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:25,596 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:25,601 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:25,632 [Listener at 0.0.0.0/40407] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:25,634 [Listener at 0.0.0.0/40407] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:25,635 [Listener at 0.0.0.0/40407] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:25,635 [Listener at 0.0.0.0/40407] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:25,643 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:25,644 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:25,646 [Listener at 0.0.0.0/40407] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40407
2020-12-03 07:21:25,647 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:21:25,648 [Listener at 0.0.0.0/40407] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:21:25,648 [Listener at 0.0.0.0/40407] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:21:25,648 [Listener at 0.0.0.0/40407] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:21:25,648 [Listener at 0.0.0.0/40407] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:21:25,650 [Listener at 0.0.0.0/40407] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:25,651 [Listener at 0.0.0.0/40407] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:21:25,651 [Listener at 0.0.0.0/40407] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:21:25,664 [Listener at 0.0.0.0/40407] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:21:25,675 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cfd1875] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:25,675 [Listener at 0.0.0.0/40407] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:25,685 [Listener at 0.0.0.0/40407] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:25,687 [Listener at 0.0.0.0/40407] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:25,691 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:25,692 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:25,693 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:25,693 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:25,695 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:25,696 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:25,696 [Listener at 0.0.0.0/40407] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41585
2020-12-03 07:21:25,697 [Listener at 0.0.0.0/40407] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:25,700 [Listener at 0.0.0.0/40407] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68ed96ca{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:25,701 [Listener at 0.0.0.0/40407] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3228d990{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:25,944 [Listener at 0.0.0.0/40407] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33c2bd{/,file:///tmp/jetty-localhost-41585-hdfs-_-any-5410401004328628460.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:21:25,948 [Listener at 0.0.0.0/40407] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1dfd5f51{HTTP/1.1,[http/1.1]}{localhost:41585}
2020-12-03 07:21:25,948 [Listener at 0.0.0.0/40407] INFO  server.Server (Server.java:doStart(419)) - Started @7529ms
2020-12-03 07:21:25,952 [Listener at 0.0.0.0/40407] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:25,954 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:25,954 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:25,955 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:25,955 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:25,955 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:25,955 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:25,957 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:21:25,957 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:21:26,000 [Listener at 0.0.0.0/40407] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:26,001 [Listener at 0.0.0.0/40407] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:21:26,001 [Listener at 0.0.0.0/40407] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:26,002 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:26,003 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:26
2020-12-03 07:21:26,003 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:26,004 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:26,004 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:26,004 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:26,023 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:26,024 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:26,025 [Listener at 0.0.0.0/40407] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:26,025 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:26,025 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:26,025 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:26,026 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:26,026 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:26,026 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:26,026 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:26,026 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:26,027 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:26,027 [Listener at 0.0.0.0/40407] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:26,028 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:26,028 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:26,029 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:26,029 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:26,036 [Listener at 0.0.0.0/40407] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:26,037 [Listener at 0.0.0.0/40407] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:26,037 [Listener at 0.0.0.0/40407] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:26,037 [Listener at 0.0.0.0/40407] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:26,037 [Listener at 0.0.0.0/40407] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:26,038 [Listener at 0.0.0.0/40407] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:26,038 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:26,038 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:26,038 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:26,039 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:26,042 [Listener at 0.0.0.0/40407] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:26,042 [Listener at 0.0.0.0/40407] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:26,042 [Listener at 0.0.0.0/40407] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:26,042 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:26,043 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:26,043 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:26,043 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:26,043 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:26,044 [Listener at 0.0.0.0/40407] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:26,086 [Listener at 0.0.0.0/40407] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:26,123 [Listener at 0.0.0.0/40407] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:26,124 [Listener at 0.0.0.0/40407] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:21:26,128 [Listener at 0.0.0.0/40407] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:26,128 [Listener at 0.0.0.0/40407] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:26,139 [Listener at 0.0.0.0/40407] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:26,141 [Listener at 0.0.0.0/40407] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:26,141 [Listener at 0.0.0.0/40407] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-12-03 07:21:26,142 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:21:26,142 [Listener at 0.0.0.0/40407] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:26,142 [Listener at 0.0.0.0/40407] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 97 msecs
2020-12-03 07:21:26,143 [Listener at 0.0.0.0/40407] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:21:26,144 [Listener at 0.0.0.0/40407] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:26,151 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:26,173 [Listener at 0.0.0.0/40986] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:26,410 [Listener at 0.0.0.0/40986] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:26,413 [Listener at 0.0.0.0/40986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:26,413 [Listener at 0.0.0.0/40986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:26,413 [Listener at 0.0.0.0/40986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:26,421 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:26,422 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:26,428 [Listener at 0.0.0.0/40986] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40986
2020-12-03 07:21:26,429 [Listener at 0.0.0.0/40986] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:21:26,429 [Listener at 0.0.0.0/40986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:21:26,429 [Listener at 0.0.0.0/40986] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:21:26,429 [Listener at 0.0.0.0/40986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:21:26,430 [Listener at 0.0.0.0/40986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:21:26,450 [Listener at 0.0.0.0/40986] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:26,470 [Listener at 0.0.0.0/40986] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:26,483 [Listener at 0.0.0.0/40986] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:26,491 [Listener at 0.0.0.0/40986] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:26,496 [Listener at 0.0.0.0/40986] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:26,500 [Listener at 0.0.0.0/40986] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:26,505 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:26,507 [Listener at 0.0.0.0/40986] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:26,513 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:26,524 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38960
2020-12-03 07:21:26,527 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:26,528 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:26,569 [Listener at 0.0.0.0/40986] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:26,575 [Listener at 0.0.0.0/40986] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:26,579 [Listener at 0.0.0.0/40986] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:26,580 [Listener at 0.0.0.0/40986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:26,580 [Listener at 0.0.0.0/40986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:26,580 [Listener at 0.0.0.0/40986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:26,585 [Listener at 0.0.0.0/40986] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46471
2020-12-03 07:21:26,586 [Listener at 0.0.0.0/40986] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:26,588 [Listener at 0.0.0.0/40986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73e132e0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:26,589 [Listener at 0.0.0.0/40986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2472c7d8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:26,795 [Listener at 0.0.0.0/40986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6c2f1700{/,file:///tmp/jetty-localhost-46471-datanode-_-any-9018960704637683439.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:21:26,795 [Listener at 0.0.0.0/40986] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@350b3a17{HTTP/1.1,[http/1.1]}{localhost:46471}
2020-12-03 07:21:26,796 [Listener at 0.0.0.0/40986] INFO  server.Server (Server.java:doStart(419)) - Started @8376ms
2020-12-03 07:21:27,633 [Listener at 0.0.0.0/40986] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36945
2020-12-03 07:21:27,634 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@aed0151] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:27,635 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:27,635 [Listener at 0.0.0.0/40986] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:27,653 [Listener at 0.0.0.0/40986] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:27,654 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:27,666 [Listener at localhost/35435] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35435
2020-12-03 07:21:27,694 [Listener at localhost/35435] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:21:27,695 [Listener at localhost/35435] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:21:27,710 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45920 starting to offer service
2020-12-03 07:21:27,711 [Thread-158] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40407 starting to offer service
2020-12-03 07:21:27,710 [Thread-157] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44977 starting to offer service
2020-12-03 07:21:27,711 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40986 starting to offer service
2020-12-03 07:21:27,723 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:27,723 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:27,728 [Listener at localhost/35435] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:27,730 [Listener at localhost/35435] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:27,730 [Listener at localhost/35435] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:27,741 [Listener at localhost/35435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:27,742 [Listener at localhost/35435] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:27,742 [Listener at localhost/35435] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:27,745 [Listener at localhost/35435] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:27,745 [Listener at localhost/35435] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:27,746 [Listener at localhost/35435] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:27,747 [Listener at localhost/35435] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35299
2020-12-03 07:21:27,747 [Listener at localhost/35435] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:27,747 [Listener at localhost/35435] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:27,750 [Listener at localhost/35435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:27,751 [Listener at localhost/35435] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:27,754 [Listener at localhost/35435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:27,755 [Listener at localhost/35435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:27,755 [Listener at localhost/35435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:27,756 [Listener at localhost/35435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:27,757 [Listener at localhost/35435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37985
2020-12-03 07:21:27,757 [Listener at localhost/35435] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:27,759 [Listener at localhost/35435] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e134896{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:27,767 [Listener at localhost/35435] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e3a5237{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:28,004 [Listener at localhost/35435] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29182679{/,file:///tmp/jetty-localhost-37985-datanode-_-any-6788045343839186924.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:21:28,005 [Listener at localhost/35435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@57bd802b{HTTP/1.1,[http/1.1]}{localhost:37985}
2020-12-03 07:21:28,006 [Listener at localhost/35435] INFO  server.Server (Server.java:doStart(419)) - Started @9586ms
2020-12-03 07:21:28,094 [Thread-157] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:28,121 [Listener at localhost/35435] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37730
2020-12-03 07:21:28,122 [Listener at localhost/35435] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:28,122 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c779e5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:28,122 [Listener at localhost/35435] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:28,123 [Listener at localhost/35435] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:28,123 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:28,127 [Listener at localhost/37736] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37736
2020-12-03 07:21:28,131 [Listener at localhost/37736] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:21:28,132 [Listener at localhost/37736] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:21:28,144 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45920 starting to offer service
2020-12-03 07:21:28,144 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44977 starting to offer service
2020-12-03 07:21:28,144 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40407 starting to offer service
2020-12-03 07:21:28,144 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40986 starting to offer service
2020-12-03 07:21:28,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:28,150 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:28,156 [Listener at localhost/37736] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:28,158 [Listener at localhost/37736] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:28,158 [Listener at localhost/37736] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:28,162 [Listener at localhost/37736] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:28,170 [Listener at localhost/37736] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:28,171 [Thread-186] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:28,176 [Listener at localhost/37736] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:28,177 [Listener at localhost/37736] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:28,177 [Listener at localhost/37736] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:28,178 [Listener at localhost/37736] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:28,179 [Listener at localhost/37736] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40886
2020-12-03 07:21:28,179 [Listener at localhost/37736] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:28,179 [Listener at localhost/37736] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:28,183 [Listener at localhost/37736] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:28,184 [Listener at localhost/37736] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:28,187 [Listener at localhost/37736] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:28,188 [Listener at localhost/37736] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:28,189 [Listener at localhost/37736] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:28,189 [Listener at localhost/37736] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:28,190 [Listener at localhost/37736] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34008
2020-12-03 07:21:28,190 [Listener at localhost/37736] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:28,193 [Listener at localhost/37736] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d84cb86{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:28,194 [Listener at localhost/37736] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588ffeb{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:28,200 [Thread-157] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,202 [Thread-157] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,203 [Thread-157] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:21:28,235 [Thread-186] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,235 [Thread-186] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,236 [Thread-186] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f6ce1f79-94de-4804-b663-cf5653f7128d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:21:28,410 [Listener at localhost/37736] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@264c5d07{/,file:///tmp/jetty-localhost-34008-datanode-_-any-5094012787049052132.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:21:28,411 [Listener at localhost/37736] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@847f3e7{HTTP/1.1,[http/1.1]}{localhost:34008}
2020-12-03 07:21:28,412 [Listener at localhost/37736] INFO  server.Server (Server.java:doStart(419)) - Started @9993ms
2020-12-03 07:21:28,431 [Thread-157] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,432 [Thread-157] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,432 [Listener at localhost/37736] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35422
2020-12-03 07:21:28,433 [Thread-157] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8db0889b-9043-4481-b2de-164fa5e46a16 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:21:28,433 [Listener at localhost/37736] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:28,433 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19593091] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:28,433 [Listener at localhost/37736] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:28,434 [Listener at localhost/37736] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:28,435 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:28,438 [Listener at localhost/43179] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43179
2020-12-03 07:21:28,445 [Listener at localhost/43179] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:21:28,445 [Listener at localhost/43179] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:21:28,446 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45920 starting to offer service
2020-12-03 07:21:28,446 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44977 starting to offer service
2020-12-03 07:21:28,448 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40407 starting to offer service
2020-12-03 07:21:28,451 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40986 starting to offer service
2020-12-03 07:21:28,452 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:28,452 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:28,461 [Listener at localhost/43179] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:21:28,463 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:28,464 [Listener at localhost/43179] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:21:28,465 [Listener at localhost/43179] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:21:28,467 [Listener at localhost/43179] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:28,468 [Listener at localhost/43179] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:28,468 [Listener at localhost/43179] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:28,468 [Listener at localhost/43179] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:28,469 [Listener at localhost/43179] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:28,469 [Listener at localhost/43179] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:28,469 [Listener at localhost/43179] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42514
2020-12-03 07:21:28,470 [Listener at localhost/43179] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:28,470 [Listener at localhost/43179] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:28,473 [Listener at localhost/43179] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:28,473 [Listener at localhost/43179] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:28,475 [Listener at localhost/43179] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:28,476 [Listener at localhost/43179] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:28,476 [Listener at localhost/43179] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:28,476 [Listener at localhost/43179] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:28,477 [Listener at localhost/43179] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43787
2020-12-03 07:21:28,477 [Listener at localhost/43179] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:28,478 [Listener at localhost/43179] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6090f3ca{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:28,479 [Listener at localhost/43179] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25b865b5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:21:28,487 [Thread-186] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,488 [Thread-186] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,489 [Thread-186] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:21:28,524 [Thread-211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,524 [Thread-211] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,525 [Thread-211] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:21:28,660 [Listener at localhost/43179] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e6308a9{/,file:///tmp/jetty-localhost-43787-datanode-_-any-8864858140336229127.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:21:28,660 [Listener at localhost/43179] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30cecdca{HTTP/1.1,[http/1.1]}{localhost:43787}
2020-12-03 07:21:28,662 [Listener at localhost/43179] INFO  server.Server (Server.java:doStart(419)) - Started @10242ms
2020-12-03 07:21:28,672 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,672 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,673 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:28,673 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:28,749 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,750 [Thread-186] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,750 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:28,750 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:28,752 [Listener at localhost/43179] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33220
2020-12-03 07:21:28,753 [Listener at localhost/43179] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:28,753 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5486887b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:28,753 [Listener at localhost/43179] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:28,754 [Listener at localhost/43179] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:28,757 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:28,762 [Listener at localhost/41232] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41232
2020-12-03 07:21:28,769 [Listener at localhost/41232] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:21:28,770 [Listener at localhost/41232] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:21:28,771 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45920 starting to offer service
2020-12-03 07:21:28,771 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44977 starting to offer service
2020-12-03 07:21:28,772 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40407 starting to offer service
2020-12-03 07:21:28,776 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40986 starting to offer service
2020-12-03 07:21:28,779 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:28,779 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:28,795 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:28,854 [Thread-211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,855 [Thread-211] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,855 [Thread-211] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-77c02154-0af0-4716-b5e8-a4c39395524b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:21:28,871 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,876 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,876 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:28,876 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:28,889 [Thread-236] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:28,890 [Thread-236] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:28,890 [Thread-236] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3132759e-4b11-4f21-86e3-2804adb256bb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:21:28,956 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,957 [Thread-186] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:28,957 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:28,957 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:29,036 [Thread-158] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:29,036 [Thread-157] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=870181464;bpid=BP-1764627215-172.17.0.6-1606980080919;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=870181464;c=1606980080919;bpid=BP-1764627215-172.17.0.6-1606980080919;dnuuid=null
2020-12-03 07:21:29,037 [Thread-158] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:21:29,037 [Thread-158] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:21:29,049 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,049 [Thread-158] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,050 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,050 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,050 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,050 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,050 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:29,050 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:29,154 [Thread-186] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=870181464;bpid=BP-1764627215-172.17.0.6-1606980080919;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=870181464;c=1606980080919;bpid=BP-1764627215-172.17.0.6-1606980080919;dnuuid=null
2020-12-03 07:21:29,155 [Thread-188] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:29,156 [Thread-188] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:21:29,156 [Thread-188] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:21:29,188 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,188 [Thread-188] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,191 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,192 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,220 [Thread-236] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3431@288e5330cd10
2020-12-03 07:21:29,221 [Thread-236] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 870181464. Formatting...
2020-12-03 07:21:29,222 [Thread-236] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:21:29,336 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,336 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,337 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,337 [Thread-158] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,337 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:29,337 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,337 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:29,338 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,419 [IPC Server handler 2 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,429 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:29,430 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:29,444 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,445 [Thread-188] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,445 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,445 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,491 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,492 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,492 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:29,493 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:29,533 [IPC Server handler 3 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,534 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=870181464;bpid=BP-1764627215-172.17.0.6-1606980080919;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=870181464;c=1606980080919;bpid=BP-1764627215-172.17.0.6-1606980080919;dnuuid=null
2020-12-03 07:21:29,536 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:29,536 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:21:29,536 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:21:29,537 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:29,537 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:29,537 [Thread-158] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=660990299;bpid=BP-640137207-172.17.0.6-1606980084628;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=660990299;c=1606980084628;bpid=BP-640137207-172.17.0.6-1606980084628;dnuuid=null
2020-12-03 07:21:29,549 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,550 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,550 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,550 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,640 [IPC Server handler 4 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,641 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:29,642 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:29,656 [Thread-188] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=660990299;bpid=BP-640137207-172.17.0.6-1606980084628;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=660990299;c=1606980084628;bpid=BP-640137207-172.17.0.6-1606980084628;dnuuid=null
2020-12-03 07:21:29,697 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,698 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,698 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1764627215-172.17.0.6-1606980080919 is not formatted. Formatting ...
2020-12-03 07:21:29,698 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1764627215-172.17.0.6-1606980080919 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1764627215-172.17.0.6-1606980080919/current
2020-12-03 07:21:29,739 [Thread-157] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:29,752 [IPC Server handler 5 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,753 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:29,753 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:29,760 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,761 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,761 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,761 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,856 [IPC Server handler 7 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,856 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:29,857 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:29,867 [Thread-186] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:29,896 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f6ce1f79-94de-4804-b663-cf5653f7128d
2020-12-03 07:21:29,896 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86
2020-12-03 07:21:29,898 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:29,898 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:29,900 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e
2020-12-03 07:21:29,900 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:29,903 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=870181464;bpid=BP-1764627215-172.17.0.6-1606980080919;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=870181464;c=1606980080919;bpid=BP-1764627215-172.17.0.6-1606980080919;dnuuid=null
2020-12-03 07:21:29,903 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:29,904 [Thread-237] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:21:29,904 [Thread-237] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:21:29,905 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8db0889b-9043-4481-b2de-164fa5e46a16
2020-12-03 07:21:29,905 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:21:29,918 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:29,918 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:29,921 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,922 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,922 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:29,922 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:29,927 [Thread-158] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:29,929 [Thread-186] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:29,929 [Thread-188] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:29,927 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:29,943 [Thread-188] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:29,944 [Thread-186] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:29,944 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:29,943 [Thread-158] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:29,946 [Thread-188] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:29,946 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:29,946 [Thread-186] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:29,946 [Thread-158] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:29,947 [Thread-186] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:29,947 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:29,946 [Thread-188] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:29,947 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,947 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:29,947 [Thread-158] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:29,947 [Thread-188] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,948 [Thread-158] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:29,948 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:21:29,948 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:21:29,948 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:21:29,949 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:21:29,959 [IPC Server handler 0 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:29,960 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:29,960 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:29,963 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=660990299;bpid=BP-640137207-172.17.0.6-1606980084628;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=660990299;c=1606980084628;bpid=BP-640137207-172.17.0.6-1606980084628;dnuuid=null
2020-12-03 07:21:29,999 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 51ms
2020-12-03 07:21:30,001 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 52ms
2020-12-03 07:21:30,003 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 54ms
2020-12-03 07:21:30,003 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1764627215-172.17.0.6-1606980080919: 55ms
2020-12-03 07:21:30,004 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 55ms
2020-12-03 07:21:30,004 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1764627215-172.17.0.6-1606980080919: 57ms
2020-12-03 07:21:30,006 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:21:30,006 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:21:30,006 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:21:30,006 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:21:30,006 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:21:30,006 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:21:30,007 [Thread-269] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,007 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:21:30,008 [Thread-271] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,006 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:21:30,006 [Thread-266] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,008 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,010 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 4ms
2020-12-03 07:21:30,010 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:21:30,010 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 2ms
2020-12-03 07:21:30,010 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919: 5ms
2020-12-03 07:21:30,010 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:21:30,011 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919: 6ms
2020-12-03 07:21:30,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:30,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:30,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:30,015 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:30,023 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f6ce1f79-94de-4804-b663-cf5653f7128d): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,028 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,023 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-8db0889b-9043-4481-b2de-164fa5e46a16): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,023 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,039 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 32ms
2020-12-03 07:21:30,039 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 32ms
2020-12-03 07:21:30,040 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 34ms
2020-12-03 07:21:30,041 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 35ms
2020-12-03 07:21:30,041 [Thread-188] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-640137207-172.17.0.6-1606980084628: 36ms
2020-12-03 07:21:30,042 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:21:30,042 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:21:30,042 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,042 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,043 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:21:30,048 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-640137207-172.17.0.6-1606980084628: 43ms
2020-12-03 07:21:30,060 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 17ms
2020-12-03 07:21:30,060 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:21:30,060 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,061 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:21:30,061 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:21:30,061 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,062 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:21:30,072 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e): no suitable block pools found to scan.  Waiting 1814399942 ms.
2020-12-03 07:21:30,073 [Thread-188] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-640137207-172.17.0.6-1606980084628: 32ms
2020-12-03 07:21:30,079 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-8db0889b-9043-4481-b2de-164fa5e46a16): no suitable block pools found to scan.  Waiting 1814399935 ms.
2020-12-03 07:21:30,080 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86): no suitable block pools found to scan.  Waiting 1814399934 ms.
2020-12-03 07:21:30,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f6ce1f79-94de-4804-b663-cf5653f7128d): no suitable block pools found to scan.  Waiting 1814399933 ms.
2020-12-03 07:21:30,087 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:21:30,087 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,089 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e): no suitable block pools found to scan.  Waiting 1814399926 ms.
2020-12-03 07:21:30,087 [Thread-157] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:18 AM with interval of 21600000ms
2020-12-03 07:21:30,084 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-640137207-172.17.0.6-1606980084628: 24ms
2020-12-03 07:21:30,092 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:21:30,092 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f6ce1f79-94de-4804-b663-cf5653f7128d): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,092 [IPC Server handler 1 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,093 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f6ce1f79-94de-4804-b663-cf5653f7128d): no suitable block pools found to scan.  Waiting 1814399921 ms.
2020-12-03 07:21:30,094 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,094 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:21:30,101 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-8db0889b-9043-4481-b2de-164fa5e46a16): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,102 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-8db0889b-9043-4481-b2de-164fa5e46a16): no suitable block pools found to scan.  Waiting 1814399912 ms.
2020-12-03 07:21:30,102 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40986 beginning handshake with NN
2020-12-03 07:21:30,107 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:21:30,108 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,108 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-12-03 07:21:30,109 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40407 beginning handshake with NN
2020-12-03 07:21:30,090 [Thread-186] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:41 AM with interval of 21600000ms
2020-12-03 07:21:30,118 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:44977 beginning handshake with NN
2020-12-03 07:21:30,118 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:45920 beginning handshake with NN
2020-12-03 07:21:30,154 [IPC Server handler 3 on default port 44977] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,154 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40986 beginning handshake with NN
2020-12-03 07:21:30,154 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:44977 beginning handshake with NN
2020-12-03 07:21:30,154 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:45920 beginning handshake with NN
2020-12-03 07:21:30,155 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40407 beginning handshake with NN
2020-12-03 07:21:30,155 [IPC Server handler 4 on default port 40407] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,155 [IPC Server handler 2 on default port 45920] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,158 [IPC Server handler 7 on default port 40986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,160 [IPC Server handler 4 on default port 40407] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38960
2020-12-03 07:21:30,160 [IPC Server handler 7 on default port 40986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38960
2020-12-03 07:21:30,160 [IPC Server handler 2 on default port 45920] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38960
2020-12-03 07:21:30,160 [IPC Server handler 2 on default port 45920] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6313428-eb72-4ad8-be47-222c0bdbc519 (127.0.0.1:38960).
2020-12-03 07:21:30,160 [IPC Server handler 3 on default port 44977] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38960
2020-12-03 07:21:30,160 [IPC Server handler 7 on default port 40986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6313428-eb72-4ad8-be47-222c0bdbc519 (127.0.0.1:38960).
2020-12-03 07:21:30,160 [IPC Server handler 4 on default port 40407] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6313428-eb72-4ad8-be47-222c0bdbc519 (127.0.0.1:38960).
2020-12-03 07:21:30,162 [IPC Server handler 3 on default port 44977] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6313428-eb72-4ad8-be47-222c0bdbc519 (127.0.0.1:38960).
2020-12-03 07:21:30,167 [IPC Server handler 5 on default port 40407] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,167 [IPC Server handler 1 on default port 44977] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,167 [IPC Server handler 3 on default port 45920] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,168 [IPC Server handler 3 on default port 45920] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35299
2020-12-03 07:21:30,168 [IPC Server handler 1 on default port 44977] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35299
2020-12-03 07:21:30,168 [IPC Server handler 5 on default port 40407] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35299
2020-12-03 07:21:30,172 [IPC Server handler 1 on default port 44977] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dd383a72-5716-4d27-8d05-c0f1c806124c (127.0.0.1:35299).
2020-12-03 07:21:30,169 [IPC Server handler 4 on default port 40986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,169 [IPC Server handler 3 on default port 45920] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dd383a72-5716-4d27-8d05-c0f1c806124c (127.0.0.1:35299).
2020-12-03 07:21:30,173 [IPC Server handler 4 on default port 40986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35299
2020-12-03 07:21:30,173 [IPC Server handler 5 on default port 40407] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dd383a72-5716-4d27-8d05-c0f1c806124c (127.0.0.1:35299).
2020-12-03 07:21:30,174 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,174 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,175 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-640137207-172.17.0.6-1606980084628 is not formatted. Formatting ...
2020-12-03 07:21:30,175 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-640137207-172.17.0.6-1606980084628 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-640137207-172.17.0.6-1606980084628/current
2020-12-03 07:21:30,177 [IPC Server handler 4 on default port 40986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dd383a72-5716-4d27-8d05-c0f1c806124c (127.0.0.1:35299).
2020-12-03 07:21:30,180 [Thread-211] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,180 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40986 successfully registered with NN
2020-12-03 07:21:30,180 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40407 successfully registered with NN
2020-12-03 07:21:30,181 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,180 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:45920 successfully registered with NN
2020-12-03 07:21:30,181 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45920 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,181 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:44977 successfully registered with NN
2020-12-03 07:21:30,181 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40407 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,181 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44977 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,182 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40407 successfully registered with NN
2020-12-03 07:21:30,182 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40407 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,183 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:45920 successfully registered with NN
2020-12-03 07:21:30,184 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40986 successfully registered with NN
2020-12-03 07:21:30,185 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,186 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45920 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,190 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4
2020-12-03 07:21:30,191 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:30,193 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-77c02154-0af0-4716-b5e8-a4c39395524b
2020-12-03 07:21:30,196 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:21:30,190 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:44977 successfully registered with NN
2020-12-03 07:21:30,197 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44977 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,197 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:30,198 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:30,198 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:30,201 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:30,201 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:30,201 [IPC Server handler 4 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,205 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:30,204 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:30,208 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:30,208 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,208 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:30,209 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,209 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:21:30,209 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:21:30,213 [IPC Server handler 6 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f6ce1f79-94de-4804-b663-cf5653f7128d for DN 127.0.0.1:35299
2020-12-03 07:21:30,219 [IPC Server handler 6 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e for DN 127.0.0.1:35299
2020-12-03 07:21:30,220 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,220 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,221 [IPC Server handler 6 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 for DN 127.0.0.1:38960
2020-12-03 07:21:30,222 [IPC Server handler 7 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 for DN 127.0.0.1:38960
2020-12-03 07:21:30,226 [IPC Server handler 6 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8db0889b-9043-4481-b2de-164fa5e46a16 for DN 127.0.0.1:38960
2020-12-03 07:21:30,226 [IPC Server handler 7 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8db0889b-9043-4481-b2de-164fa5e46a16 for DN 127.0.0.1:38960
2020-12-03 07:21:30,228 [IPC Server handler 5 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f6ce1f79-94de-4804-b663-cf5653f7128d for DN 127.0.0.1:35299
2020-12-03 07:21:30,228 [IPC Server handler 5 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e for DN 127.0.0.1:35299
2020-12-03 07:21:30,228 [IPC Server handler 3 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 for DN 127.0.0.1:38960
2020-12-03 07:21:30,235 [IPC Server handler 5 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f6ce1f79-94de-4804-b663-cf5653f7128d for DN 127.0.0.1:35299
2020-12-03 07:21:30,235 [IPC Server handler 7 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 for DN 127.0.0.1:38960
2020-12-03 07:21:30,239 [IPC Server handler 2 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f6ce1f79-94de-4804-b663-cf5653f7128d for DN 127.0.0.1:35299
2020-12-03 07:21:30,240 [IPC Server handler 3 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8db0889b-9043-4481-b2de-164fa5e46a16 for DN 127.0.0.1:38960
2020-12-03 07:21:30,242 [IPC Server handler 5 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e for DN 127.0.0.1:35299
2020-12-03 07:21:30,242 [IPC Server handler 7 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8db0889b-9043-4481-b2de-164fa5e46a16 for DN 127.0.0.1:38960
2020-12-03 07:21:30,244 [IPC Server handler 2 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e for DN 127.0.0.1:35299
2020-12-03 07:21:30,245 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 36ms
2020-12-03 07:21:30,258 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 49ms
2020-12-03 07:21:30,258 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1764627215-172.17.0.6-1606980080919: 49ms
2020-12-03 07:21:30,259 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:21:30,259 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,259 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:21:30,259 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:21:30,260 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:21:30,262 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:21:30,262 [Thread-294] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,294 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x363db1f712852e0e: Processing first storage report for DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,294 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 33ms
2020-12-03 07:21:30,294 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6d4da06a5a47f177: Processing first storage report for DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,294 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919: 36ms
2020-12-03 07:21:30,295 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:30,295 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:30,295 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-77c02154-0af0-4716-b5e8-a4c39395524b): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,295 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,295 [Thread-211] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:36 AM with interval of 21600000ms
2020-12-03 07:21:30,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x54ee461ef713b1f: Processing first storage report for DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-77c02154-0af0-4716-b5e8-a4c39395524b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:21:30,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:21:30,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6d4da06a5a47f177: from storage DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9171f042d495ede6: Processing first storage report for DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9171f042d495ede6: from storage DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6d4da06a5a47f177: Processing first storage report for DS-f6ce1f79-94de-4804-b663-cf5653f7128d from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6d4da06a5a47f177: from storage DS-f6ce1f79-94de-4804-b663-cf5653f7128d node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9171f042d495ede6: Processing first storage report for DS-8db0889b-9043-4481-b2de-164fa5e46a16 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9171f042d495ede6: from storage DS-8db0889b-9043-4481-b2de-164fa5e46a16 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x363db1f712852e0e: from storage DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x54ee461ef713b1f: from storage DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfecc2d04adfee46f: Processing first storage report for DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,300 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:44977 beginning handshake with NN
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3b1d942b452ddeec: Processing first storage report for DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfecc2d04adfee46f: from storage DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,300 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x54ee461ef713b1f: Processing first storage report for DS-f6ce1f79-94de-4804-b663-cf5653f7128d from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,300 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:45920 beginning handshake with NN
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x54ee461ef713b1f: from storage DS-f6ce1f79-94de-4804-b663-cf5653f7128d node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x363db1f712852e0e: Processing first storage report for DS-f6ce1f79-94de-4804-b663-cf5653f7128d from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3b1d942b452ddeec: from storage DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x363db1f712852e0e: from storage DS-f6ce1f79-94de-4804-b663-cf5653f7128d node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3b1d942b452ddeec: Processing first storage report for DS-f6ce1f79-94de-4804-b663-cf5653f7128d from datanode dd383a72-5716-4d27-8d05-c0f1c806124c
2020-12-03 07:21:30,302 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3b1d942b452ddeec: from storage DS-f6ce1f79-94de-4804-b663-cf5653f7128d node DatanodeRegistration(127.0.0.1:35299, datanodeUuid=dd383a72-5716-4d27-8d05-c0f1c806124c, infoPort=37730, infoSecurePort=0, ipcPort=37736, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,301 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf1bb599644215e52: Processing first storage report for DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,302 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfecc2d04adfee46f: Processing first storage report for DS-8db0889b-9043-4481-b2de-164fa5e46a16 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,302 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf1bb599644215e52: from storage DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,302 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfecc2d04adfee46f: from storage DS-8db0889b-9043-4481-b2de-164fa5e46a16 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,302 [IPC Server handler 8 on default port 45920] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,303 [IPC Server handler 8 on default port 45920] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40886
2020-12-03 07:21:30,303 [IPC Server handler 8 on default port 45920] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN feca73c5-3268-488b-aa97-af2aa958132f (127.0.0.1:40886).
2020-12-03 07:21:30,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf1bb599644215e52: Processing first storage report for DS-8db0889b-9043-4481-b2de-164fa5e46a16 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,304 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf1bb599644215e52: from storage DS-8db0889b-9043-4481-b2de-164fa5e46a16 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,303 [IPC Server handler 2 on default port 44977] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,304 [IPC Server handler 2 on default port 44977] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40886
2020-12-03 07:21:30,304 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:45920 successfully registered with NN
2020-12-03 07:21:30,304 [IPC Server handler 2 on default port 44977] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN feca73c5-3268-488b-aa97-af2aa958132f (127.0.0.1:40886).
2020-12-03 07:21:30,304 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x825cc1e9ddc6ec1: Processing first storage report for DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,304 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45920 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,305 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x825cc1e9ddc6ec1: from storage DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,305 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x825cc1e9ddc6ec1: Processing first storage report for DS-8db0889b-9043-4481-b2de-164fa5e46a16 from datanode b6313428-eb72-4ad8-be47-222c0bdbc519
2020-12-03 07:21:30,306 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x825cc1e9ddc6ec1: from storage DS-8db0889b-9043-4481-b2de-164fa5e46a16 node DatanodeRegistration(127.0.0.1:38960, datanodeUuid=b6313428-eb72-4ad8-be47-222c0bdbc519, infoPort=36945, infoSecurePort=0, ipcPort=35435, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,307 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:44977 successfully registered with NN
2020-12-03 07:21:30,307 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44977 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,307 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 48ms
2020-12-03 07:21:30,308 [IPC Server handler 0 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 for DN 127.0.0.1:40886
2020-12-03 07:21:30,308 [IPC Server handler 0 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-77c02154-0af0-4716-b5e8-a4c39395524b for DN 127.0.0.1:40886
2020-12-03 07:21:30,309 [IPC Server handler 9 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 for DN 127.0.0.1:40886
2020-12-03 07:21:30,309 [IPC Server handler 9 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-77c02154-0af0-4716-b5e8-a4c39395524b for DN 127.0.0.1:40886
2020-12-03 07:21:30,312 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 52ms
2020-12-03 07:21:30,312 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-640137207-172.17.0.6-1606980084628: 53ms
2020-12-03 07:21:30,312 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:21:30,313 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:21:30,313 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,313 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,313 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:21:30,313 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:21:30,313 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7b2937967d60d1d0: Processing first storage report for DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,313 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x15ab515410c6ebb1: Processing first storage report for DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7b2937967d60d1d0: from storage DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,313 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-640137207-172.17.0.6-1606980084628: 2ms
2020-12-03 07:21:30,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7b2937967d60d1d0: Processing first storage report for DS-77c02154-0af0-4716-b5e8-a4c39395524b from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15ab515410c6ebb1: from storage DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7b2937967d60d1d0: from storage DS-77c02154-0af0-4716-b5e8-a4c39395524b node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x15ab515410c6ebb1: Processing first storage report for DS-77c02154-0af0-4716-b5e8-a4c39395524b from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,315 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40407 beginning handshake with NN
2020-12-03 07:21:30,315 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:21:30,315 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40986 beginning handshake with NN
2020-12-03 07:21:30,315 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15ab515410c6ebb1: from storage DS-77c02154-0af0-4716-b5e8-a4c39395524b node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,315 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:21:30,315 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-77c02154-0af0-4716-b5e8-a4c39395524b): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,316 [IPC Server handler 8 on default port 40407] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,316 [IPC Server handler 8 on default port 40407] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40886
2020-12-03 07:21:30,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-12-03 07:21:30,316 [IPC Server handler 1 on default port 40986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,316 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-77c02154-0af0-4716-b5e8-a4c39395524b): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-12-03 07:21:30,316 [IPC Server handler 8 on default port 40407] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN feca73c5-3268-488b-aa97-af2aa958132f (127.0.0.1:40886).
2020-12-03 07:21:30,316 [IPC Server handler 1 on default port 40986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40886
2020-12-03 07:21:30,317 [IPC Server handler 1 on default port 40986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN feca73c5-3268-488b-aa97-af2aa958132f (127.0.0.1:40886).
2020-12-03 07:21:30,317 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40986 successfully registered with NN
2020-12-03 07:21:30,318 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40407 successfully registered with NN
2020-12-03 07:21:30,318 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,318 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40407 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,319 [IPC Server handler 9 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 for DN 127.0.0.1:40886
2020-12-03 07:21:30,320 [IPC Server handler 0 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 for DN 127.0.0.1:40886
2020-12-03 07:21:30,320 [IPC Server handler 9 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-77c02154-0af0-4716-b5e8-a4c39395524b for DN 127.0.0.1:40886
2020-12-03 07:21:30,320 [IPC Server handler 0 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-77c02154-0af0-4716-b5e8-a4c39395524b for DN 127.0.0.1:40886
2020-12-03 07:21:30,323 [IPC Server handler 2 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,323 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=660990299;bpid=BP-640137207-172.17.0.6-1606980084628;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=660990299;c=1606980084628;bpid=BP-640137207-172.17.0.6-1606980084628;dnuuid=8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,324 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,324 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,324 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xafe55e769ee0913f: Processing first storage report for DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,324 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xafe55e769ee0913f: from storage DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,324 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xafe55e769ee0913f: Processing first storage report for DS-77c02154-0af0-4716-b5e8-a4c39395524b from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,325 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xafe55e769ee0913f: from storage DS-77c02154-0af0-4716-b5e8-a4c39395524b node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,327 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7b2937967d60d1d0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 14 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,327 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb6c4efca83abbdde: Processing first storage report for DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,329 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x825cc1e9ddc6ec1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 68 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,329 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6d4da06a5a47f177,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 69 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,329 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x54ee461ef713b1f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 67 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,331 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x15ab515410c6ebb1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 19 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,328 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf1bb599644215e52,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 65 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,329 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x363db1f712852e0e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 72 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,328 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9171f042d495ede6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 69 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,328 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfecc2d04adfee46f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 68 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,330 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xafe55e769ee0913f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 8 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,330 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3b1d942b452ddeec,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 69 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,330 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb6c4efca83abbdde: from storage DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4 node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,342 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb6c4efca83abbdde: Processing first storage report for DS-77c02154-0af0-4716-b5e8-a4c39395524b from datanode feca73c5-3268-488b-aa97-af2aa958132f
2020-12-03 07:21:30,342 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb6c4efca83abbdde: from storage DS-77c02154-0af0-4716-b5e8-a4c39395524b node DatanodeRegistration(127.0.0.1:40886, datanodeUuid=feca73c5-3268-488b-aa97-af2aa958132f, infoPort=35422, infoSecurePort=0, ipcPort=43179, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,343 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb6c4efca83abbdde,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 21 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,428 [IPC Server handler 3 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,429 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,430 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,515 [Thread-236] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,518 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3132759e-4b11-4f21-86e3-2804adb256bb
2020-12-03 07:21:30,518 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:30,521 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8
2020-12-03 07:21:30,521 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:21:30,522 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:30,529 [Thread-236] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:21:30,529 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,530 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:21:30,530 [Thread-236] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:21:30,531 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:21:30,531 [Thread-236] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:21:30,531 [Thread-236] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:21:30,531 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,532 [IPC Server handler 4 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,533 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:30,533 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:30,557 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 27ms
2020-12-03 07:21:30,560 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-640137207-172.17.0.6-1606980084628 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 29ms
2020-12-03 07:21:30,560 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-640137207-172.17.0.6-1606980084628: 30ms
2020-12-03 07:21:30,561 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:21:30,561 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,562 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:21:30,562 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:21:30,562 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:21:30,562 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:21:30,562 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-640137207-172.17.0.6-1606980084628/current/replicas doesn't exist 
2020-12-03 07:21:30,563 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:21:30,564 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-640137207-172.17.0.6-1606980084628: 3ms
2020-12-03 07:21:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:21:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-3132759e-4b11-4f21-86e3-2804adb256bb): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,565 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:19 PM with interval of 21600000ms
2020-12-03 07:21:30,566 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-640137207-172.17.0.6-1606980084628 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:21:30,566 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-3132759e-4b11-4f21-86e3-2804adb256bb): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:21:30,566 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8): finished scanning block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:30,568 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:21:30,568 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40986 beginning handshake with NN
2020-12-03 07:21:30,569 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40407 beginning handshake with NN
2020-12-03 07:21:30,570 [IPC Server handler 0 on default port 40407] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,571 [IPC Server handler 0 on default port 40407] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42514
2020-12-03 07:21:30,571 [IPC Server handler 0 on default port 40407] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8d448219-6453-4f13-be05-a4769c117172 (127.0.0.1:42514).
2020-12-03 07:21:30,573 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40407 successfully registered with NN
2020-12-03 07:21:30,573 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40407 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,575 [IPC Server handler 9 on default port 40986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628) storage 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,576 [IPC Server handler 9 on default port 40986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42514
2020-12-03 07:21:30,576 [IPC Server handler 5 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3132759e-4b11-4f21-86e3-2804adb256bb for DN 127.0.0.1:42514
2020-12-03 07:21:30,576 [IPC Server handler 9 on default port 40986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8d448219-6453-4f13-be05-a4769c117172 (127.0.0.1:42514).
2020-12-03 07:21:30,576 [IPC Server handler 5 on default port 40407] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 for DN 127.0.0.1:42514
2020-12-03 07:21:30,584 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40986 successfully registered with NN
2020-12-03 07:21:30,584 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,586 [IPC Server handler 4 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3132759e-4b11-4f21-86e3-2804adb256bb for DN 127.0.0.1:42514
2020-12-03 07:21:30,587 [IPC Server handler 4 on default port 40986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 for DN 127.0.0.1:42514
2020-12-03 07:21:30,592 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 29ms
2020-12-03 07:21:30,595 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1764627215-172.17.0.6-1606980080919 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 33ms
2020-12-03 07:21:30,596 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1764627215-172.17.0.6-1606980080919: 35ms
2020-12-03 07:21:30,596 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:21:30,596 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:21:30,596 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,596 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1764627215-172.17.0.6-1606980080919/current/replicas doesn't exist 
2020-12-03 07:21:30,597 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:21:30,597 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:21:30,599 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1764627215-172.17.0.6-1606980080919: 4ms
2020-12-03 07:21:30,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x80920d40c7c275e6: Processing first storage report for DS-3132759e-4b11-4f21-86e3-2804adb256bb from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,600 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:44977 beginning handshake with NN
2020-12-03 07:21:30,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x35e3cdea0a7266dc: Processing first storage report for DS-3132759e-4b11-4f21-86e3-2804adb256bb from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,600 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:21:30,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x35e3cdea0a7266dc: from storage DS-3132759e-4b11-4f21-86e3-2804adb256bb node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,600 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:45920 beginning handshake with NN
2020-12-03 07:21:30,601 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x35e3cdea0a7266dc: Processing first storage report for DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,600 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x80920d40c7c275e6: from storage DS-3132759e-4b11-4f21-86e3-2804adb256bb node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,601 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x35e3cdea0a7266dc: from storage DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,601 [IPC Server handler 0 on default port 44977] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,601 [IPC Server handler 5 on default port 45920] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919) storage 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,601 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,601 [IPC Server handler 0 on default port 44977] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42514
2020-12-03 07:21:30,601 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x80920d40c7c275e6: Processing first storage report for DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,603 [IPC Server handler 0 on default port 44977] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8d448219-6453-4f13-be05-a4769c117172 (127.0.0.1:42514).
2020-12-03 07:21:30,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1764627215-172.17.0.6-1606980080919 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:21:30,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:21:30,603 [IPC Server handler 5 on default port 45920] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42514
2020-12-03 07:21:30,604 [IPC Server handler 5 on default port 45920] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8d448219-6453-4f13-be05-a4769c117172 (127.0.0.1:42514).
2020-12-03 07:21:30,603 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x35e3cdea0a7266dc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-3132759e-4b11-4f21-86e3-2804adb256bb): finished scanning block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:30,604 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x80920d40c7c275e6: from storage DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=660990299;c=1606980084628), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,606 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:45920 successfully registered with NN
2020-12-03 07:21:30,606 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45920 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-3132759e-4b11-4f21-86e3-2804adb256bb): no suitable block pools found to scan.  Waiting 1814399959 ms.
2020-12-03 07:21:30,607 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:44977 successfully registered with NN
2020-12-03 07:21:30,607 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44977 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:21:30,610 [IPC Server handler 1 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3132759e-4b11-4f21-86e3-2804adb256bb for DN 127.0.0.1:42514
2020-12-03 07:21:30,610 [IPC Server handler 1 on default port 44977] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 for DN 127.0.0.1:42514
2020-12-03 07:21:30,611 [IPC Server handler 7 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3132759e-4b11-4f21-86e3-2804adb256bb for DN 127.0.0.1:42514
2020-12-03 07:21:30,612 [IPC Server handler 7 on default port 45920] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 for DN 127.0.0.1:42514
2020-12-03 07:21:30,615 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x80920d40c7c275e6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 20 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x797943f7e53d1d48: Processing first storage report for DS-3132759e-4b11-4f21-86e3-2804adb256bb from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x797943f7e53d1d48: from storage DS-3132759e-4b11-4f21-86e3-2804adb256bb node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x797943f7e53d1d48: Processing first storage report for DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,616 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x797943f7e53d1d48: from storage DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,617 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x797943f7e53d1d48,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x42606f496be7c498: Processing first storage report for DS-3132759e-4b11-4f21-86e3-2804adb256bb from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x42606f496be7c498: from storage DS-3132759e-4b11-4f21-86e3-2804adb256bb node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x42606f496be7c498: Processing first storage report for DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 from datanode 8d448219-6453-4f13-be05-a4769c117172
2020-12-03 07:21:30,618 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x42606f496be7c498: from storage DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8 node DatanodeRegistration(127.0.0.1:42514, datanodeUuid=8d448219-6453-4f13-be05-a4769c117172, infoPort=33220, infoSecurePort=0, ipcPort=41232, storageInfo=lv=-57;cid=testClusterID;nsid=870181464;c=1606980080919), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:30,619 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x42606f496be7c498,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:30,635 [IPC Server handler 0 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,644 [IPC Server handler 7 on default port 44977] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,654 [IPC Server handler 2 on default port 40407] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,662 [IPC Server handler 3 on default port 40986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,663 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:30,673 [IPC Server handler 2 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,678 [IPC Server handler 5 on default port 44977] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,686 [IPC Server handler 6 on default port 40407] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,692 [IPC Server handler 6 on default port 40986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:30,694 [Listener at localhost/41232] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:30,752 [Listener at localhost/41232] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:30,754 [Listener at localhost/41232] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,755 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,765 [Listener at 0.0.0.0/42735] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:30,765 [Listener at 0.0.0.0/42735] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:30,766 [Listener at 0.0.0.0/42735] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:30,784 [Listener at 0.0.0.0/42735] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:21:30,784 [Listener at 0.0.0.0/42735] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,785 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,791 [Listener at 0.0.0.0/36161] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:21:30,793 [Listener at 0.0.0.0/36161] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:21:30,793 [Listener at 0.0.0.0/36161] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:21:30,793 [Listener at 0.0.0.0/36161] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:21:30,793 [Listener at 0.0.0.0/36161] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:21:30,794 [Listener at 0.0.0.0/36161] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:30,807 [Listener at 0.0.0.0/36161] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:21:30,807 [Listener at 0.0.0.0/36161] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:21:30,811 [Listener at 0.0.0.0/36161] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:21:30,816 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,816 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,816 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,816 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:44628
2020-12-03 07:21:30,817 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,817 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,817 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,817 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42463
2020-12-03 07:21:30,818 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,818 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,818 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,818 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41585
2020-12-03 07:21:30,819 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,819 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,819 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,819 [Listener at 0.0.0.0/36161] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:41242
2020-12-03 07:21:30,834 [Listener at 0.0.0.0/36161] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:30,836 [Listener at 0.0.0.0/36161] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,837 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,843 [Listener at 0.0.0.0/34940] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:30,844 [Listener at 0.0.0.0/34940] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:30,849 [Listener at 0.0.0.0/34940] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:30,851 [Listener at 0.0.0.0/34940] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:21:30,851 [Listener at 0.0.0.0/34940] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,855 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,884 [Listener at 0.0.0.0/38961] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:21:30,884 [Listener at 0.0.0.0/38961] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:21:30,884 [Listener at 0.0.0.0/38961] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:21:30,885 [Listener at 0.0.0.0/38961] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:21:30,885 [Listener at 0.0.0.0/38961] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:21:30,885 [Listener at 0.0.0.0/38961] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:30,886 [Listener at 0.0.0.0/38961] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:21:30,887 [Listener at 0.0.0.0/38961] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:21:30,888 [Listener at 0.0.0.0/38961] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:21:30,889 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,889 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,889 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,889 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:44628
2020-12-03 07:21:30,890 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,890 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,890 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,890 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42463
2020-12-03 07:21:30,891 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,899 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,900 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,900 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41585
2020-12-03 07:21:30,901 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,901 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,901 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,901 [Listener at 0.0.0.0/38961] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:41242
2020-12-03 07:21:30,931 [Listener at 0.0.0.0/38961] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:30,933 [Listener at 0.0.0.0/38961] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,934 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,940 [Listener at 0.0.0.0/41974] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:30,940 [Listener at 0.0.0.0/41974] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:30,941 [Listener at 0.0.0.0/41974] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:30,942 [Listener at 0.0.0.0/41974] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:21:30,942 [Listener at 0.0.0.0/41974] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,943 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:30,951 [Listener at 0.0.0.0/37421] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:21:30,954 [Listener at 0.0.0.0/37421] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:21:30,954 [Listener at 0.0.0.0/37421] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:21:30,954 [Listener at 0.0.0.0/37421] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:21:30,955 [Listener at 0.0.0.0/37421] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:21:30,958 [Listener at 0.0.0.0/37421] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:30,970 [Listener at 0.0.0.0/37421] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-12-03 07:21:30,970 [Listener at 0.0.0.0/37421] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:21:30,971 [Listener at 0.0.0.0/37421] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-12-03 07:21:30,972 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,972 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,972 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40407
2020-12-03 07:21:30,973 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:44628
2020-12-03 07:21:30,973 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,973 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,973 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:45920
2020-12-03 07:21:30,974 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42463
2020-12-03 07:21:30,974 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,974 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,975 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40986
2020-12-03 07:21:30,975 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41585
2020-12-03 07:21:30,975 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,976 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,976 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44977
2020-12-03 07:21:30,976 [Listener at 0.0.0.0/37421] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:41242
2020-12-03 07:21:30,995 [Listener at 0.0.0.0/37421] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:21:30,996 [Listener at 0.0.0.0/37421] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:30,997 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:31,001 [Listener at 0.0.0.0/39770] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:21:31,001 [Listener at 0.0.0.0/39770] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:21:31,002 [Listener at 0.0.0.0/39770] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:21:31,003 [Listener at 0.0.0.0/39770] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:21:31,004 [Listener at 0.0.0.0/39770] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:31,005 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:31,010 [Listener at 0.0.0.0/46776] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:21:31,011 [Listener at 0.0.0.0/46776] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:21:31,011 [Listener at 0.0.0.0/46776] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:21:31,011 [Listener at 0.0.0.0/46776] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:21:31,011 [Listener at 0.0.0.0/46776] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:21:31,012 [Listener at 0.0.0.0/46776] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:21:31,013 [Listener at 0.0.0.0/46776] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-12-03 07:21:31,013 [Listener at 0.0.0.0/46776] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:21:31,014 [Listener at 0.0.0.0/46776] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-12-03 07:21:31,015 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40407
2020-12-03 07:21:31,015 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40407
2020-12-03 07:21:31,015 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40407
2020-12-03 07:21:31,015 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:44628
2020-12-03 07:21:31,016 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40986
2020-12-03 07:21:31,016 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40986
2020-12-03 07:21:31,016 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40986
2020-12-03 07:21:31,016 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41585
2020-12-03 07:21:31,018 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:45920
2020-12-03 07:21:31,018 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:45920
2020-12-03 07:21:31,019 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:45920
2020-12-03 07:21:31,019 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42463
2020-12-03 07:21:31,019 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:44977
2020-12-03 07:21:31,019 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:44977
2020-12-03 07:21:31,019 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:44977
2020-12-03 07:21:31,020 [Listener at 0.0.0.0/46776] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:41242
2020-12-03 07:21:31,025 [Listener at 0.0.0.0/46776] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,026 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:42735: State Store unavailable
2020-12-03 07:21:31,025 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77a2aa4a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:31,029 [Listener at 0.0.0.0/46776] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:21:31,034 [Listener at 0.0.0.0/46776] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,034 [Listener at 0.0.0.0/46776] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,035 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:31,039 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:21:31,039 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:21:31,041 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:31,067 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,067 [Listener at 0.0.0.0/46776] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:42735
2020-12-03 07:21:31,065 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,055 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,069 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,071 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:21:31,071 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,072 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,074 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,073 [Listener at 0.0.0.0/46776] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:21:31,074 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,076 [Listener at 0.0.0.0/46776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:31,077 [Listener at 0.0.0.0/46776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:21:31,078 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,080 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:31,080 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:21:31,080 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:31,080 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:31,084 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:31,085 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:31,085 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41107
2020-12-03 07:21:31,086 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:31,100 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@299270eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:31,101 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69fa8e76{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:31,110 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1046498a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:21:31,111 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@243f003c{HTTP/1.1,[http/1.1]}{0.0.0.0:41107}
2020-12-03 07:21:31,111 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(419)) - Started @12692ms
2020-12-03 07:21:31,111 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:31,115 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:31,115 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:31,116 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:31,119 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:21:31,129 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-12-03 07:21:31,142 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-12-03 07:21:31,144 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-12-03 07:21:31,144 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:42735: State Store unavailable
2020-12-03 07:21:31,156 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-12-03 07:21:31,162 [Listener at 0.0.0.0/46776] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:21:31,169 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:34940: State Store unavailable
2020-12-03 07:21:31,171 [Listener at 0.0.0.0/46776] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,171 [Listener at 0.0.0.0/46776] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:21:31,172 [Listener at 0.0.0.0/46776] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,172 [Listener at 0.0.0.0/46776] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,173 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:31,173 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:21:31,177 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f780a86] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:31,183 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:31,177 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:21:31,215 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,216 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,216 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,220 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:21:31,221 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,221 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,225 [Listener at 0.0.0.0/46776] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:34940
2020-12-03 07:21:31,226 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,226 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,231 [Listener at 0.0.0.0/46776] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:21:31,232 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,234 [Listener at 0.0.0.0/46776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:31,234 [Listener at 0.0.0.0/46776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:21:31,235 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,238 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:31,238 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:21:31,238 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:31,239 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:31,241 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:31,241 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:31,242 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37446
2020-12-03 07:21:31,242 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:31,245 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72d0f2b4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:31,246 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1da4b6b3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:31,253 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3402b4c9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:21:31,260 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@95bb2a2{HTTP/1.1,[http/1.1]}{0.0.0.0:37446}
2020-12-03 07:21:31,260 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(419)) - Started @12840ms
2020-12-03 07:21:31,260 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:31,260 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:31,261 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:31,261 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:31,261 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:21:31,263 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:34940: State Store unavailable
2020-12-03 07:21:31,263 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-12-03 07:21:31,263 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-12-03 07:21:31,264 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-12-03 07:21:31,264 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-12-03 07:21:31,264 [Listener at 0.0.0.0/46776] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:21:31,265 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:41974: State Store unavailable
2020-12-03 07:21:31,265 [Listener at 0.0.0.0/46776] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,265 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@499683c4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:31,265 [Listener at 0.0.0.0/46776] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:21:31,266 [Listener at 0.0.0.0/46776] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,266 [Listener at 0.0.0.0/46776] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,267 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:31,267 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:21:31,267 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:21:31,269 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,269 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,275 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:31,272 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,272 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:21:31,280 [Listener at 0.0.0.0/46776] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:41974
2020-12-03 07:21:31,289 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,289 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,291 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,293 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,296 [Listener at 0.0.0.0/46776] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:21:31,296 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,298 [Listener at 0.0.0.0/46776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:31,299 [Listener at 0.0.0.0/46776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:21:31,299 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,303 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:31,303 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:21:31,303 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:31,304 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:31,305 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:31,306 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:31,306 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38123
2020-12-03 07:21:31,306 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:31,321 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41bf79da{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:31,322 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5176d279{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:31,328 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@431f1eaf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:21:31,329 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@cb03411{HTTP/1.1,[http/1.1]}{0.0.0.0:38123}
2020-12-03 07:21:31,330 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(419)) - Started @12910ms
2020-12-03 07:21:31,330 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:31,330 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:31,331 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:31,331 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:31,333 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:21:31,339 [IPC Server handler 4 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,339 [IPC Server handler 5 on default port 40407] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,339 [IPC Server handler 9 on default port 40986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,339 [IPC Server handler 1 on default port 44977] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,342 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:41974: State Store unavailable
2020-12-03 07:21:31,342 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-12-03 07:21:31,342 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-12-03 07:21:31,346 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-12-03 07:21:31,347 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-12-03 07:21:31,347 [IPC Server handler 4 on default port 40986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,347 [Listener at 0.0.0.0/46776] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-12-03 07:21:31,347 [IPC Server handler 7 on default port 44977] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,347 [IPC Server handler 3 on default port 44977] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,348 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:39770: State Store unavailable
2020-12-03 07:21:31,348 [IPC Server handler 2 on default port 40407] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,347 [IPC Server handler 5 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,347 [IPC Server handler 7 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,347 [IPC Server handler 4 on default port 40407] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,348 [IPC Server handler 7 on default port 40986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,348 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56078cea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:31,348 [Listener at 0.0.0.0/46776] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,359 [Listener at 0.0.0.0/46776] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:21:31,360 [Listener at 0.0.0.0/46776] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,360 [Listener at 0.0.0.0/46776] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,360 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:31,361 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:21:31,361 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:21:31,362 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:21:31,363 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:31,363 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,363 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,364 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:21:31,371 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:21:31,372 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:21:31,374 [Listener at 0.0.0.0/46776] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:39770
2020-12-03 07:21:31,374 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:31,375 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:31,375 [Listener at 0.0.0.0/46776] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:21:31,383 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,389 [Listener at 0.0.0.0/46776] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:31,391 [Listener at 0.0.0.0/46776] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:21:31,391 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:31,453 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:31,458 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:21:31,459 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:31,459 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:31,460 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:31,463 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:31,464 [Listener at 0.0.0.0/46776] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40402
2020-12-03 07:21:31,464 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:31,475 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fad6218{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:21:31,476 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68217d41{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:31,482 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@11d4dbd6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:21:31,484 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6f4ade6e{HTTP/1.1,[http/1.1]}{0.0.0.0:40402}
2020-12-03 07:21:31,484 [Listener at 0.0.0.0/46776] INFO  server.Server (Server.java:doStart(419)) - Started @13065ms
2020-12-03 07:21:31,484 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:31,485 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:31,485 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:31,485 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:31,487 [Listener at 0.0.0.0/46776] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:21:31,488 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:39770: State Store unavailable
2020-12-03 07:21:31,489 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-12-03 07:21:31,489 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-12-03 07:21:31,489 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-12-03 07:21:31,490 [Listener at 0.0.0.0/46776] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-12-03 07:21:31,490 [IPC Server handler 6 on default port 40986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,490 [Listener at 0.0.0.0/46776] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-12-03 07:21:31,525 [IPC Server handler 8 on default port 40407] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,525 [IPC Server handler 2 on default port 44977] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,528 [IPC Server handler 0 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:31,564 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:31,565 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:21:31,577 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:31,579 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:21:31,579 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:31,580 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:31,580 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:21:31,583 [Listener at 0.0.0.0/46776] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:21:31,598 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:21:31,599 [Listener at 0.0.0.0/46776] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:31,600 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:21:31,601 [Listener at 0.0.0.0/46776] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:31,643 [Listener at 0.0.0.0/46776] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:31,653 [Listener at 0.0.0.0/46776] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:31,661 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:31,668 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:31,668 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:31,669 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:31,669 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:31,669 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 68 msec
2020-12-03 07:21:31,671 [CacheReplicationMonitor(1636760249)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:31,672 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:31,673 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:21:31,674 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:31,675 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-12-03 07:21:31,676 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-12-03 07:21:31,676 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-12-03 07:21:31,676 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:21:31,679 [Listener at 0.0.0.0/46776] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:21:31,695 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:21:31,695 [Listener at 0.0.0.0/46776] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:31,696 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:21:31,696 [Listener at 0.0.0.0/46776] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:31,730 [Listener at 0.0.0.0/46776] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:31,731 [Listener at 0.0.0.0/46776] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:31,734 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:31,734 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:31,735 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:31,735 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:31,735 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:31,735 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 39 msec
2020-12-03 07:21:31,738 [CacheReplicationMonitor(366650142)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:32,754 [Thread-480] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:39770 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-869489662_1, ugi=root (auth:SIMPLE)]]
2020-12-03 07:21:32,801 [IPC Server handler 3 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:32,890 [IPC Server handler 6 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/small.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:32,956 [IPC Server handler 4 on default port 45920] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38960, 127.0.0.1:35299, 127.0.0.1:42514 for /test/test/small.txt
2020-12-03 07:21:32,973 [Thread-483] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:33,070 [DataXceiver for client DFSClient_NONMAPREDUCE_-869489662_1 at /127.0.0.1:53230 [Receiving block BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001 src: /127.0.0.1:53230 dest: /127.0.0.1:38960
2020-12-03 07:21:33,096 [DataXceiver for client DFSClient_NONMAPREDUCE_-869489662_1 at /127.0.0.1:53230 [Receiving block BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:33,101 [DataXceiver for client DFSClient_NONMAPREDUCE_-869489662_1 at /127.0.0.1:51002 [Receiving block BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001 src: /127.0.0.1:51002 dest: /127.0.0.1:35299
2020-12-03 07:21:33,105 [DataXceiver for client DFSClient_NONMAPREDUCE_-869489662_1 at /127.0.0.1:51002 [Receiving block BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:33,108 [DataXceiver for client DFSClient_NONMAPREDUCE_-869489662_1 at /127.0.0.1:55232 [Receiving block BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001 src: /127.0.0.1:55232 dest: /127.0.0.1:42514
2020-12-03 07:21:33,163 [PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55232, dest: /127.0.0.1:42514, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-869489662_1, offset: 0, srvID: 8d448219-6453-4f13-be05-a4769c117172, blockid: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, duration(ns): 23679764
2020-12-03 07:21:33,163 [PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:33,170 [PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42514]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51002, dest: /127.0.0.1:35299, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-869489662_1, offset: 0, srvID: dd383a72-5716-4d27-8d05-c0f1c806124c, blockid: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, duration(ns): 39174337
2020-12-03 07:21:33,171 [PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42514]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42514] terminating
2020-12-03 07:21:33,175 [PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35299, 127.0.0.1:42514]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53230, dest: /127.0.0.1:38960, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-869489662_1, offset: 0, srvID: b6313428-eb72-4ad8-be47-222c0bdbc519, blockid: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, duration(ns): 42842034
2020-12-03 07:21:33,176 [PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35299, 127.0.0.1:42514]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1764627215-172.17.0.6-1606980080919:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35299, 127.0.0.1:42514] terminating
2020-12-03 07:21:33,193 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40407 trying to claim ACTIVE state with txid=1
2020-12-03 07:21:33,193 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40407 trying to claim ACTIVE state with txid=1
2020-12-03 07:21:33,200 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40407
2020-12-03 07:21:33,198 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40407
2020-12-03 07:21:33,205 [IPC Server handler 5 on default port 45920] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/test/small.txt
2020-12-03 07:21:33,217 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:45920 trying to claim ACTIVE state with txid=7
2020-12-03 07:21:33,217 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:45920
2020-12-03 07:21:33,217 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:45920 trying to claim ACTIVE state with txid=7
2020-12-03 07:21:33,217 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:45920
2020-12-03 07:21:33,309 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:45920 trying to claim ACTIVE state with txid=7
2020-12-03 07:21:33,309 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:45920
2020-12-03 07:21:33,324 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40407 trying to claim ACTIVE state with txid=1
2020-12-03 07:21:33,324 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40407
2020-12-03 07:21:33,578 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40407 trying to claim ACTIVE state with txid=1
2020-12-03 07:21:33,578 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40407
2020-12-03 07:21:33,612 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:45920 trying to claim ACTIVE state with txid=7
2020-12-03 07:21:33,612 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:45920
2020-12-03 07:21:33,619 [IPC Server handler 4 on default port 45920] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/test/small.txt is closed by DFSClient_NONMAPREDUCE_-869489662_1
2020-12-03 07:21:33,626 [IPC Server handler 1 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:33,631 [IPC Server handler 8 on default port 45920] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/test/zero.txt is closed by DFSClient_NONMAPREDUCE_-869489662_1
2020-12-03 07:21:33,638 [IPC Server handler 7 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:33,644 [IPC Server handler 9 on default port 45920] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-869489662_1
2020-12-03 07:21:33,669 [IPC Server handler 5 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-12-03 07:21:33,679 [IPC Server handler 9 on default port 39770] WARN  ipc.Server (Server.java:logException(2974)) - IPC Server handler 9 on default port 39770, call Call#173 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.concat from 172.17.0.6:53262
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol.concat(RouterClientProtocol.java:487)
	at org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.concat(RouterRpcServer.java:674)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:647)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:33,693 [IPC Server handler 0 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:21:33,719 [IPC Server handler 2 on default port 45920] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:21:33,728 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:33,728 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:21:33,729 [Listener at 0.0.0.0/46776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:33,729 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4690f583] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:33,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-3132759e-4b11-4f21-86e3-2804adb256bb) exiting.
2020-12-03 07:21:33,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d2701ca7-bca9-4111-a70d-a9ea58b977b8) exiting.
2020-12-03 07:21:34,362 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e6308a9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:34,365 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30cecdca{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,365 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25b865b5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,365 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6090f3ca{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,368 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41232
2020-12-03 07:21:34,375 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,375 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,376 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,377 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,377 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:45920
2020-12-03 07:21:34,377 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,378 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40407
2020-12-03 07:21:34,376 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,377 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:40986
2020-12-03 07:21:34,378 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172) service to localhost/127.0.0.1:44977
2020-12-03 07:21:34,378 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172)
2020-12-03 07:21:34,378 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid 8d448219-6453-4f13-be05-a4769c117172)
2020-12-03 07:21:34,378 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:34,380 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,382 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:34,380 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,384 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,384 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,389 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:34,390 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:34,391 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:34,391 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:34,397 [Listener at 0.0.0.0/46776] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:34,398 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:34,398 [Listener at 0.0.0.0/46776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:34,398 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4b1c0397] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:34,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-dba73fc0-0c17-41fa-b36f-fcea3f9a10c4) exiting.
2020-12-03 07:21:34,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-77c02154-0af0-4716-b5e8-a4c39395524b) exiting.
2020-12-03 07:21:34,436 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@264c5d07{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:34,437 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@847f3e7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,437 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588ffeb{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,438 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d84cb86{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,439 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43179
2020-12-03 07:21:34,452 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,460 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,460 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,460 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,460 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,460 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40407
2020-12-03 07:21:34,462 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,460 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:40986
2020-12-03 07:21:34,460 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:45920
2020-12-03 07:21:34,463 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f)
2020-12-03 07:21:34,462 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f) service to localhost/127.0.0.1:44977
2020-12-03 07:21:34,463 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:34,463 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid feca73c5-3268-488b-aa97-af2aa958132f)
2020-12-03 07:21:34,464 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,464 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,464 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:34,464 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,465 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,470 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:34,471 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:34,472 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:34,472 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:34,475 [Listener at 0.0.0.0/46776] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:34,475 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:34,476 [Listener at 0.0.0.0/46776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:34,476 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@301d8120] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:34,478 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-bd7baf9c-2ab4-4466-89b7-4c158346c29e) exiting.
2020-12-03 07:21:34,478 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f6ce1f79-94de-4804-b663-cf5653f7128d) exiting.
2020-12-03 07:21:34,505 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29182679{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:34,506 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@57bd802b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,506 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e3a5237{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,509 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e134896{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,511 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37736
2020-12-03 07:21:34,516 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,520 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,520 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,520 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,520 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:45920
2020-12-03 07:21:34,520 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,520 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,520 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40986
2020-12-03 07:21:34,520 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:40407
2020-12-03 07:21:34,521 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c)
2020-12-03 07:21:34,521 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:34,521 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c) service to localhost/127.0.0.1:44977
2020-12-03 07:21:34,522 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid dd383a72-5716-4d27-8d05-c0f1c806124c)
2020-12-03 07:21:34,522 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,522 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:34,522 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,524 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,530 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,537 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:34,541 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:34,548 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:34,548 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:34,556 [Listener at 0.0.0.0/46776] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:34,556 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:34,556 [Listener at 0.0.0.0/46776] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:34,557 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@50cf5a23] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:34,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-7391448f-2fe8-48ce-b9c7-4b31fda87a86) exiting.
2020-12-03 07:21:34,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-8db0889b-9043-4481-b2de-164fa5e46a16) exiting.
2020-12-03 07:21:34,603 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6c2f1700{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:34,604 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@350b3a17{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,604 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2472c7d8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,605 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73e132e0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,606 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35435
2020-12-03 07:21:34,609 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,609 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,609 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,609 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,610 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40986
2020-12-03 07:21:34,610 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,610 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:34,614 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:44977] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:44977
2020-12-03 07:21:34,610 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:45920
2020-12-03 07:21:34,614 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519) service to localhost/127.0.0.1:40407
2020-12-03 07:21:34,614 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1764627215-172.17.0.6-1606980080919 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519)
2020-12-03 07:21:34,614 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-640137207-172.17.0.6-1606980084628 (Datanode Uuid b6313428-eb72-4ad8-be47-222c0bdbc519)
2020-12-03 07:21:34,614 [BP-1764627215-172.17.0.6-1606980080919 heartbeating to localhost/127.0.0.1:45920] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1764627215-172.17.0.6-1606980080919
2020-12-03 07:21:34,615 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,615 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1764627215-172.17.0.6-1606980080919] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,616 [BP-640137207-172.17.0.6-1606980084628 heartbeating to localhost/127.0.0.1:40407] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-640137207-172.17.0.6-1606980084628
2020-12-03 07:21:34,616 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,616 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-640137207-172.17.0.6-1606980084628] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:34,632 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:34,633 [Listener at 0.0.0.0/46776] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:34,636 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:34,636 [Listener at 0.0.0.0/46776] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:34,647 [Listener at 0.0.0.0/46776] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:34,648 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:34,648 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:34,648 [Listener at 0.0.0.0/46776] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 13
2020-12-03 07:21:34,659 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@263bbfeb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:34,660 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7bebcd65] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:34,660 [Listener at 0.0.0.0/46776] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 14 Total time for transactions(ms): 35 Number of transactions batched in Syncs: 0 Number of syncs: 15 SyncTimes(ms): 8 3 2 
2020-12-03 07:21:34,662 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:21:34,663 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:21:34,664 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:21:34,664 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:34,664 [CacheReplicationMonitor(1636760249)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:34,668 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45920
2020-12-03 07:21:34,672 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,676 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:34,676 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:34,742 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:34,742 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:34,745 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e19bb76{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:34,750 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@142269f2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,750 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3d9c13b5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,751 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c2375a9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,779 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:34,780 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:34,780 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:21:34,781 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44977
2020-12-03 07:21:34,785 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,788 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,788 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:34,788 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:34,811 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:34,844 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:34,854 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e11bc55{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:34,856 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7544a1e4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,857 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69adf72c{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,857 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@649f2009{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,874 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:34,874 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:34,875 [Listener at 0.0.0.0/46776] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:21:34,875 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@45bb2aa1] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:34,875 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3e84111a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:34,888 [Listener at 0.0.0.0/46776] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 1 
2020-12-03 07:21:34,889 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:21:34,889 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:21:34,890 [Listener at 0.0.0.0/46776] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:21:34,890 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:34,891 [CacheReplicationMonitor(366650142)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:34,891 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40407
2020-12-03 07:21:34,896 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,896 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,904 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:34,901 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:34,923 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:34,924 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:34,926 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30c0ccff{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:34,957 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@581d969c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:34,958 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f5c79a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:34,958 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29539e36{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:34,976 [Listener at 0.0.0.0/46776] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:34,976 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:34,976 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:21:34,977 [Listener at 0.0.0.0/46776] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40986
2020-12-03 07:21:34,981 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:34,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:34,985 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:34,985 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:35,017 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:35,035 [Listener at 0.0.0.0/46776] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:35,040 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33c2bd{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:35,043 [Listener at 0.0.0.0/46776] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1dfd5f51{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:35,043 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3228d990{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:21:35,043 [Listener at 0.0.0.0/46776] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68ed96ca{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:35,083 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:42735: State Store unavailable
2020-12-03 07:21:35,093 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:21:35,093 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:21:35,101 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:21:35,102 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:35,110 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:21:35,110 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:35,119 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:21:35,120 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:35,125 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:21:35,126 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:35,138 [Thread-498] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1046498a{/,null,UNAVAILABLE}{/router}
2020-12-03 07:21:35,145 [Thread-498] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@243f003c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:21:35,149 [Thread-498] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69fa8e76{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:35,152 [Thread-498] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@299270eb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:35,158 [Thread-498] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36161
2020-12-03 07:21:35,168 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:35,170 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:35,183 [Thread-498] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42735
2020-12-03 07:21:35,191 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:35,197 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:35,212 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:21:35,212 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:21:35,220 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:21:35,220 [Thread-498] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:36,088 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:34940: State Store unavailable
2020-12-03 07:21:36,099 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:21:36,101 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:21:36,106 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:21:36,106 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:36,121 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:21:36,122 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:36,127 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:21:36,127 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:36,142 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:21:36,142 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:36,159 [Thread-499] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3402b4c9{/,null,UNAVAILABLE}{/router}
2020-12-03 07:21:36,165 [Thread-499] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@95bb2a2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:21:36,169 [Thread-499] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1da4b6b3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:36,179 [Thread-499] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72d0f2b4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:36,187 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:36,202 [Thread-499] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38961
2020-12-03 07:21:36,210 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:36,211 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:36,219 [Thread-499] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34940
2020-12-03 07:21:36,220 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:36,243 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:36,244 [Thread-499] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:21:36,246 [Thread-499] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:21:36,247 [Thread-499] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:21:36,253 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:21:36,254 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:21:36,256 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:21:36,256 [Thread-499] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:36,286 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:36,342 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:41974: State Store unavailable
2020-12-03 07:21:36,363 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:21:36,489 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:39770: State Store unavailable
2020-12-03 07:21:37,076 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:41974: State Store unavailable
2020-12-03 07:21:37,077 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:21:37,078 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:21:37,078 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:21:37,079 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:37,079 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:21:37,079 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:37,082 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:21:37,082 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:37,083 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:21:37,083 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:37,086 [Thread-500] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@431f1eaf{/,null,UNAVAILABLE}{/router}
2020-12-03 07:21:37,089 [Thread-500] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@cb03411{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:21:37,090 [Thread-500] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5176d279{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:37,091 [Thread-500] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41bf79da{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:37,092 [Thread-500] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37421
2020-12-03 07:21:37,093 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:37,093 [Thread-500] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41974
2020-12-03 07:21:37,093 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:37,094 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:37,096 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:21:37,096 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:37,096 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:21:37,096 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:21:37,097 [Thread-500] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:21:37,379 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:40407: End of File Exception between local host is: "288e5330cd10/172.17.0.6"; destination host is: "localhost":40407; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:21:37,379 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:40407
2020-12-03 07:21:37,387 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:45920: End of File Exception between local host is: "288e5330cd10/172.17.0.6"; destination host is: "localhost":45920; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:21:37,387 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:45920
2020-12-03 07:21:37,426 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:40986: End of File Exception between local host is: "288e5330cd10/172.17.0.6"; destination host is: "localhost":40986; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:21:37,426 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:44977: End of File Exception between local host is: "288e5330cd10/172.17.0.6"; destination host is: "localhost":44977; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-12-03 07:21:37,426 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:40986
2020-12-03 07:21:37,427 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:44977
2020-12-03 07:21:38,076 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 288e5330cd10:39770: State Store unavailable
2020-12-03 07:21:38,080 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:21:38,080 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:21:38,081 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:21:38,081 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:21:38,081 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:21:38,081 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:21:38,082 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:21:38,082 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:21:38,082 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:21:38,083 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:21:38,084 [Thread-501] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@11d4dbd6{/,null,UNAVAILABLE}{/router}
2020-12-03 07:21:38,086 [Thread-501] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6f4ade6e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:21:38,086 [Thread-501] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68217d41{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:38,087 [Thread-501] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fad6218{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:21:38,089 [Thread-501] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46776
2020-12-03 07:21:38,090 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:38,090 [Thread-501] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39770
2020-12-03 07:21:38,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:38,092 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:38,092 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:38,092 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:21:38,093 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:21:38,093 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:21:38,093 [Thread-501] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
