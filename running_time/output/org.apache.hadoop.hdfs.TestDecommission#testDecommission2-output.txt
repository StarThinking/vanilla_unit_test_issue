2020-12-03 07:22:00,624 [Thread-4] INFO  hdfs.TestDecommission (TestDecommission.java:testDecommission2(190)) - Starting test testDecommission
2020-12-03 07:22:00,643 [Thread-4] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=4
Formatting using clusterid: testClusterID
2020-12-03 07:22:01,314 [Thread-4] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:01,333 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:01,335 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:01,335 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:01,335 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:01,336 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:01,336 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:01,337 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:01,337 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:01,413 [Thread-4] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:01,422 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:01,423 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,424 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:01,425 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:01,427 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,427 [Thread-4] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:01,433 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:01,434 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:01
2020-12-03 07:22:01,437 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:01,437 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:01,439 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:01,439 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:01,458 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,459 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,462 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:01,463 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:01,466 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:01,466 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,471 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:01,471 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:01,472 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:01,472 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:01,473 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:01,473 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:01,473 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:01,474 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:01,474 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:01,474 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:01,474 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:01,512 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:01,513 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:01,514 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:01,514 [Thread-4] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:01,536 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:01,537 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:01,538 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:01,538 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:01,546 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:01,547 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:01,547 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:01,548 [Thread-4] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:01,557 [Thread-4] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:01,561 [Thread-4] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:01,569 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:01,569 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:01,570 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:01,570 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:01,584 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:01,584 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:01,585 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:01,589 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:01,590 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:01,592 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:01,593 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:01,593 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:01,594 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:01,631 [Thread-4] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:01,755 [Thread-4] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:01,877 [Thread-4] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:01,907 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:01,907 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:02,052 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:02,052 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:02,121 [Thread-4] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:02,128 [Thread-4] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:02,619 [Thread-4] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:02,705 [Thread-4] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:02,705 [Thread-4] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:02,713 [Thread-4] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:22:02,755 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@12dd910d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:02,777 [Thread-4] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:02,783 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:02,797 [Thread-4] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3553ms
2020-12-03 07:22:02,918 [Thread-4] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:02,922 [Thread-4] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:02,922 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:02,932 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:02,935 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:02,935 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:02,935 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:02,970 [Thread-4] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:02,970 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:02,982 [Thread-4] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39574
2020-12-03 07:22:02,984 [Thread-4] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:03,053 [Thread-4] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e3ed705{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:03,055 [Thread-4] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e024f92{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:03,117 [Thread-4] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f27a90b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:03,130 [Thread-4] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@505b68f2{HTTP/1.1,[http/1.1]}{localhost:39574}
2020-12-03 07:22:03,130 [Thread-4] INFO  server.Server (Server.java:doStart(419)) - Started @3886ms
2020-12-03 07:22:03,146 [Thread-4] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:03,147 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:03,147 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:03,148 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:03,148 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:03,148 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:03,148 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:03,149 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:03,149 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:03,150 [Thread-4] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:03,151 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:03,152 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:03,152 [Thread-4] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:03,152 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:03,152 [Thread-4] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:03,153 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:03,154 [Thread-4] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:03
2020-12-03 07:22:03,154 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:03,154 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:03,155 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:03,155 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:03,162 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:03,163 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:03,163 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:03,164 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:03,164 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:03,164 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:03,165 [Thread-4] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:03,165 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:03,166 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:03,166 [Thread-4] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:03,167 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:03,167 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:03,167 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:03,167 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:03,168 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:03,168 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:03,168 [Thread-4] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:03,169 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:03,169 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:03,170 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:03,170 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:03,173 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:03,174 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:03,174 [Thread-4] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:03,175 [Thread-4] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:03,175 [Thread-4] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:03,175 [Thread-4] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:03,176 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:03,176 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:03,177 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:03,177 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:03,179 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:03,179 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:03,179 [Thread-4] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:03,180 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:03,180 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:03,180 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:03,181 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:03,181 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:03,181 [Thread-4] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:03,255 [Thread-4] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:03,301 [Thread-4] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:03,305 [Thread-4] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:03,305 [Thread-4] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:03,306 [Thread-4] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:03,306 [Thread-4] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:03,349 [Thread-4] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:03,360 [Thread-4] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:03,361 [Thread-4] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:03,369 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:03,370 [Thread-4] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:03,449 [Thread-4] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:03,450 [Thread-4] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 266 msecs
2020-12-03 07:22:03,651 [Thread-4] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:03,699 [Thread-4] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:03,721 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:04,066 [Listener at localhost/38549] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38549 to access this namenode/service.
2020-12-03 07:22:04,076 [Listener at localhost/38549] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:04,099 [Listener at localhost/38549] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:04,116 [Listener at localhost/38549] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:04,117 [Listener at localhost/38549] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:04,118 [Listener at localhost/38549] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:04,118 [Listener at localhost/38549] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:04,123 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:04,123 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:04,124 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:04,124 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:04,124 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:04,124 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:22:04,164 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:04,169 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:04,172 [Listener at localhost/38549] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38549
2020-12-03 07:22:04,177 [Listener at localhost/38549] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:04,177 [Listener at localhost/38549] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:04,186 [Listener at localhost/38549] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:04,190 [CacheReplicationMonitor(1606716853)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:04,194 [Listener at localhost/38549] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:04,213 [Listener at localhost/38549] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:04,230 [Listener at localhost/38549] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:04,239 [Listener at localhost/38549] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:04,244 [Listener at localhost/38549] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:04,248 [Listener at localhost/38549] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:04,253 [Listener at localhost/38549] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:04,254 [Listener at localhost/38549] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:04,255 [Listener at localhost/38549] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:04,255 [Listener at localhost/38549] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:04,260 [Listener at localhost/38549] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:04,268 [Listener at localhost/38549] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34989
2020-12-03 07:22:04,271 [Listener at localhost/38549] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:04,271 [Listener at localhost/38549] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:04,297 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:04,300 [Listener at localhost/38549] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:04,302 [Listener at localhost/38549] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:04,302 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:04,306 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:04,307 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:04,308 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:04,308 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:04,313 [Listener at localhost/38549] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46699
2020-12-03 07:22:04,314 [Listener at localhost/38549] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:04,316 [Listener at localhost/38549] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52abf1e4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:04,317 [Listener at localhost/38549] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c85712{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:04,328 [Listener at localhost/38549] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@53f1664{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:04,330 [Listener at localhost/38549] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c1eec4{HTTP/1.1,[http/1.1]}{localhost:46699}
2020-12-03 07:22:04,331 [Listener at localhost/38549] INFO  server.Server (Server.java:doStart(419)) - Started @5087ms
2020-12-03 07:22:05,138 [Listener at localhost/38549] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36204
2020-12-03 07:22:05,139 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e810272] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:05,142 [Listener at localhost/38549] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:05,143 [Listener at localhost/38549] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:05,180 [Listener at localhost/38549] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:05,184 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:05,204 [Listener at localhost/46201] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46201
2020-12-03 07:22:05,224 [Listener at localhost/46201] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:05,226 [Listener at localhost/46201] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:05,238 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549 starting to offer service
2020-12-03 07:22:05,247 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:05,247 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:05,251 [Listener at localhost/46201] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:05,254 [Listener at localhost/46201] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:05,255 [Listener at localhost/46201] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:05,258 [Listener at localhost/46201] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:05,258 [Listener at localhost/46201] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,259 [Listener at localhost/46201] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:05,259 [Listener at localhost/46201] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:05,260 [Listener at localhost/46201] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,260 [Listener at localhost/46201] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,260 [Listener at localhost/46201] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,261 [Listener at localhost/46201] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:05,262 [Listener at localhost/46201] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34425
2020-12-03 07:22:05,262 [Listener at localhost/46201] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:05,263 [Listener at localhost/46201] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:05,265 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:05,271 [Listener at localhost/46201] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:05,272 [Listener at localhost/46201] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:05,272 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:05,275 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:05,276 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:05,276 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:05,276 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:05,278 [Listener at localhost/46201] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36584
2020-12-03 07:22:05,278 [Listener at localhost/46201] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:05,281 [Listener at localhost/46201] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a389651{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:05,282 [Listener at localhost/46201] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a196192{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:05,291 [Listener at localhost/46201] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@365d8d99{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:05,292 [Listener at localhost/46201] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2ebca257{HTTP/1.1,[http/1.1]}{localhost:36584}
2020-12-03 07:22:05,293 [Listener at localhost/46201] INFO  server.Server (Server.java:doStart(419)) - Started @6049ms
2020-12-03 07:22:05,377 [Listener at localhost/46201] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37012
2020-12-03 07:22:05,378 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1183b144] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:05,378 [Listener at localhost/46201] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:05,378 [Listener at localhost/46201] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:05,379 [Listener at localhost/46201] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:05,380 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:05,389 [Listener at localhost/36719] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36719
2020-12-03 07:22:05,397 [Listener at localhost/36719] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:05,397 [Listener at localhost/36719] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:05,398 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549 starting to offer service
2020-12-03 07:22:05,399 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:05,399 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:05,406 [Listener at localhost/36719] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:05,408 [Listener at localhost/36719] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:05,409 [Listener at localhost/36719] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:05,410 [Listener at localhost/36719] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:05,411 [Listener at localhost/36719] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,411 [Listener at localhost/36719] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:05,412 [Listener at localhost/36719] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:05,412 [Listener at localhost/36719] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,412 [Listener at localhost/36719] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,412 [Listener at localhost/36719] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,412 [Listener at localhost/36719] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:05,413 [Listener at localhost/36719] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46560
2020-12-03 07:22:05,413 [Listener at localhost/36719] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:05,414 [Listener at localhost/36719] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:05,415 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:05,417 [Listener at localhost/36719] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:05,418 [Listener at localhost/36719] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:05,418 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:05,421 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:05,422 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:05,422 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:05,422 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:05,423 [Listener at localhost/36719] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34573
2020-12-03 07:22:05,423 [Listener at localhost/36719] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:05,426 [Listener at localhost/36719] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@192d70ef{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:05,428 [Listener at localhost/36719] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31a5b8f4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:05,436 [Listener at localhost/36719] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56c11958{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:05,436 [Listener at localhost/36719] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30f828c6{HTTP/1.1,[http/1.1]}{localhost:34573}
2020-12-03 07:22:05,437 [Listener at localhost/36719] INFO  server.Server (Server.java:doStart(419)) - Started @6193ms
2020-12-03 07:22:05,459 [Listener at localhost/36719] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37155
2020-12-03 07:22:05,460 [Listener at localhost/36719] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:05,460 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@50a544d7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:05,460 [Listener at localhost/36719] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:05,460 [Listener at localhost/36719] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:05,461 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:05,466 [Listener at localhost/38562] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38562
2020-12-03 07:22:05,471 [Listener at localhost/38562] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:05,471 [Listener at localhost/38562] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:05,472 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549 starting to offer service
2020-12-03 07:22:05,474 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:05,474 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:05,477 [Listener at localhost/38562] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:05,478 [Listener at localhost/38562] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:05,479 [Listener at localhost/38562] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:05,480 [Listener at localhost/38562] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:05,480 [Listener at localhost/38562] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,480 [Listener at localhost/38562] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:05,481 [Listener at localhost/38562] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:05,481 [Listener at localhost/38562] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:05,481 [Listener at localhost/38562] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,481 [Listener at localhost/38562] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:05,482 [Listener at localhost/38562] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:05,482 [Listener at localhost/38562] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45344
2020-12-03 07:22:05,483 [Listener at localhost/38562] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:05,483 [Listener at localhost/38562] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:05,485 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:05,487 [Listener at localhost/38562] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:05,488 [Listener at localhost/38562] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:05,488 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:05,491 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:05,492 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:05,492 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:05,492 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:05,493 [Listener at localhost/38562] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34328
2020-12-03 07:22:05,493 [Listener at localhost/38562] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:05,496 [Listener at localhost/38562] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@380195e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:05,496 [Listener at localhost/38562] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1fa9b5fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:05,508 [Listener at localhost/38562] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1c5e2158{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:05,509 [Listener at localhost/38562] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b5666e9{HTTP/1.1,[http/1.1]}{localhost:34328}
2020-12-03 07:22:05,509 [Listener at localhost/38562] INFO  server.Server (Server.java:doStart(419)) - Started @6265ms
2020-12-03 07:22:05,557 [Listener at localhost/38562] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45116
2020-12-03 07:22:05,557 [Listener at localhost/38562] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:05,557 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@53d3bba6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:05,558 [Listener at localhost/38562] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:05,558 [Listener at localhost/38562] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:05,559 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:05,562 [Listener at localhost/40369] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40369
2020-12-03 07:22:05,566 [Listener at localhost/40369] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:05,567 [Listener at localhost/40369] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:05,567 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549 starting to offer service
2020-12-03 07:22:05,569 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:05,569 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:05,665 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549
2020-12-03 07:22:05,665 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549
2020-12-03 07:22:05,667 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549
2020-12-03 07:22:05,668 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38549
2020-12-03 07:22:05,668 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:05,672 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:05,670 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:05,669 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:05,733 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,734 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:05,733 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,736 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,746 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:05,746 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:05,747 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:05,746 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:05,750 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4cffc81e-6840-4c88-bc74-f40476d31388 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:05,753 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,754 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:05,755 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fe5d99d3-047f-414a-aaff-d03d6967e953 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:05,996 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,997 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:05,997 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:05,998 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,998 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:05,998 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e8494a0f-0911-4f19-be17-28d59929c27d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:05,999 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:05,999 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:06,000 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:06,028 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:06,029 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 437756292. Formatting...
2020-12-03 07:22:06,029 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:06,142 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,142 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,143 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,143 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,144 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,144 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,144 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,145 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,149 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,150 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,150 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,150 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,161 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,161 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,162 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,162 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,163 [IPC Server handler 3 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,186 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,186 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,290 [IPC Server handler 1 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,291 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,291 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,303 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,304 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,304 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,304 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,304 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,304 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,305 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,305 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,348 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,348 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,348 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,348 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,348 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,348 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,349 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-557387821-172.17.0.6-1606980121618 is not formatted. Formatting ...
2020-12-03 07:22:06,349 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-557387821-172.17.0.6-1606980121618 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-557387821-172.17.0.6-1606980121618/current
2020-12-03 07:22:06,394 [IPC Server handler 4 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,394 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,394 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,471 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=437756292;bpid=BP-557387821-172.17.0.6-1606980121618;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=437756292;c=1606980121618;bpid=BP-557387821-172.17.0.6-1606980121618;dnuuid=null
2020-12-03 07:22:06,471 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=437756292;bpid=BP-557387821-172.17.0.6-1606980121618;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=437756292;c=1606980121618;bpid=BP-557387821-172.17.0.6-1606980121618;dnuuid=null
2020-12-03 07:22:06,496 [IPC Server handler 5 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,497 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,497 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,506 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=437756292;bpid=BP-557387821-172.17.0.6-1606980121618;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=437756292;c=1606980121618;bpid=BP-557387821-172.17.0.6-1606980121618;dnuuid=null
2020-12-03 07:22:06,506 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=437756292;bpid=BP-557387821-172.17.0.6-1606980121618;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=437756292;c=1606980121618;bpid=BP-557387821-172.17.0.6-1606980121618;dnuuid=null
2020-12-03 07:22:06,600 [IPC Server handler 0 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,601 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,601 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,636 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6c2af899-8130-4c3e-a97e-4aaae6061cc6
2020-12-03 07:22:06,636 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3a41c7a1-821b-465e-b809-27442365964a
2020-12-03 07:22:06,671 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 59236ad1-435f-44fe-b05b-8ae7f3fc38ac
2020-12-03 07:22:06,671 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0
2020-12-03 07:22:06,703 [IPC Server handler 6 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,704 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,704 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,766 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8
2020-12-03 07:22:06,767 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:06,767 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fe5d99d3-047f-414a-aaff-d03d6967e953
2020-12-03 07:22:06,768 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:06,767 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0
2020-12-03 07:22:06,769 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:06,770 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e8494a0f-0911-4f19-be17-28d59929c27d
2020-12-03 07:22:06,772 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4cffc81e-6840-4c88-bc74-f40476d31388
2020-12-03 07:22:06,773 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:06,773 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:06,775 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8
2020-12-03 07:22:06,777 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:06,780 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:06,780 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:06,785 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92
2020-12-03 07:22:06,786 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:06,786 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:06,793 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:06,795 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:06,796 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c
2020-12-03 07:22:06,796 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:06,798 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:06,798 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:06,799 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:06,803 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:06,812 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:06,803 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:06,814 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:06,808 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:06,814 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:06,814 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:06,816 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,814 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:06,820 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,814 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:06,814 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:06,812 [IPC Server handler 8 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,823 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,823 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,825 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:06,825 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:06,828 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,831 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:06,833 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:06,833 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:06,833 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:06,840 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:06,840 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,840 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:06,845 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:06,846 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:06,892 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 59ms
2020-12-03 07:22:06,893 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 48ms
2020-12-03 07:22:06,911 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 70ms
2020-12-03 07:22:06,934 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 88ms
2020-12-03 07:22:06,935 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-557387821-172.17.0.6-1606980121618: 94ms
2020-12-03 07:22:06,940 [IPC Server handler 9 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,940 [Thread-167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:06,940 [Thread-166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:06,940 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 107ms
2020-12-03 07:22:06,940 [Thread-167] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,941 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:06,941 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:06,941 [Thread-152] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 110ms
2020-12-03 07:22:06,941 [Thread-166] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,942 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-557387821-172.17.0.6-1606980121618: 125ms
2020-12-03 07:22:06,942 [Thread-168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:06,943 [Thread-168] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,943 [Thread-167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 2ms
2020-12-03 07:22:06,943 [Thread-166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 2ms
2020-12-03 07:22:06,945 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:06,945 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 104ms
2020-12-03 07:22:06,944 [Thread-168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-12-03 07:22:06,945 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-557387821-172.17.0.6-1606980121618: 117ms
2020-12-03 07:22:06,945 [Thread-169] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,945 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-557387821-172.17.0.6-1606980121618: 5ms
2020-12-03 07:22:06,948 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:06,948 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-12-03 07:22:06,948 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:06,949 [Thread-170] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,949 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:22:06,949 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-fe5d99d3-047f-414a-aaff-d03d6967e953): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,948 [Thread-151] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-557387821-172.17.0.6-1606980121618 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 116ms
2020-12-03 07:22:06,953 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:06,949 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-557387821-172.17.0.6-1606980121618: 7ms
2020-12-03 07:22:06,953 [Thread-171] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,954 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-557387821-172.17.0.6-1606980121618: 133ms
2020-12-03 07:22:06,954 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:06,954 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:06,955 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4cffc81e-6840-4c88-bc74-f40476d31388): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,948 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:06,955 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,956 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:06,957 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:06,957 [Thread-177] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,957 [Thread-176] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-557387821-172.17.0.6-1606980121618/current/replicas doesn't exist 
2020-12-03 07:22:06,957 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:22:06,957 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:22:06,958 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-557387821-172.17.0.6-1606980121618: 5ms
2020-12-03 07:22:06,959 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:06,959 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:06,959 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,959 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e8494a0f-0911-4f19-be17-28d59929c27d): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,960 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,960 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 7ms
2020-12-03 07:22:06,960 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-557387821-172.17.0.6-1606980121618: 15ms
2020-12-03 07:22:06,961 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:06,961 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-557387821-172.17.0.6-1606980121618 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:06,961 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,962 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8): finished scanning block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:06,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-12-03 07:22:06,975 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:41 AM with interval of 21600000ms
2020-12-03 07:22:06,975 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:44 AM with interval of 21600000ms
2020-12-03 07:22:06,975 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:14 PM with interval of 21600000ms
2020-12-03 07:22:06,975 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:30 AM with interval of 21600000ms
2020-12-03 07:22:06,977 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4cffc81e-6840-4c88-bc74-f40476d31388): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:22:06,977 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e8494a0f-0911-4f19-be17-28d59929c27d): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:22:06,984 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:22:06,982 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:22:06,980 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:06,977 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:22:06,997 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-fe5d99d3-047f-414a-aaff-d03d6967e953): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:22:07,014 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 6c2af899-8130-4c3e-a97e-4aaae6061cc6) service to localhost/127.0.0.1:38549 beginning handshake with NN
2020-12-03 07:22:07,014 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 59236ad1-435f-44fe-b05b-8ae7f3fc38ac) service to localhost/127.0.0.1:38549 beginning handshake with NN
2020-12-03 07:22:07,018 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0) service to localhost/127.0.0.1:38549 beginning handshake with NN
2020-12-03 07:22:07,019 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 3a41c7a1-821b-465e-b809-27442365964a) service to localhost/127.0.0.1:38549 beginning handshake with NN
2020-12-03 07:22:07,029 [IPC Server handler 7 on default port 38549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618) storage 3a41c7a1-821b-465e-b809-27442365964a
2020-12-03 07:22:07,032 [IPC Server handler 7 on default port 38549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46560
2020-12-03 07:22:07,032 [IPC Server handler 7 on default port 38549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3a41c7a1-821b-465e-b809-27442365964a (127.0.0.1:46560).
2020-12-03 07:22:07,034 [IPC Server handler 2 on default port 38549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618) storage f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0
2020-12-03 07:22:07,034 [IPC Server handler 2 on default port 38549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45344
2020-12-03 07:22:07,035 [IPC Server handler 2 on default port 38549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0 (127.0.0.1:45344).
2020-12-03 07:22:07,035 [IPC Server handler 3 on default port 38549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618) storage 59236ad1-435f-44fe-b05b-8ae7f3fc38ac
2020-12-03 07:22:07,035 [IPC Server handler 3 on default port 38549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34989
2020-12-03 07:22:07,035 [IPC Server handler 3 on default port 38549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 59236ad1-435f-44fe-b05b-8ae7f3fc38ac (127.0.0.1:34989).
2020-12-03 07:22:07,036 [IPC Server handler 1 on default port 38549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618) storage 6c2af899-8130-4c3e-a97e-4aaae6061cc6
2020-12-03 07:22:07,036 [IPC Server handler 1 on default port 38549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34425
2020-12-03 07:22:07,036 [IPC Server handler 1 on default port 38549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6c2af899-8130-4c3e-a97e-4aaae6061cc6 (127.0.0.1:34425).
2020-12-03 07:22:07,037 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 3a41c7a1-821b-465e-b809-27442365964a) service to localhost/127.0.0.1:38549 successfully registered with NN
2020-12-03 07:22:07,037 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0) service to localhost/127.0.0.1:38549 successfully registered with NN
2020-12-03 07:22:07,038 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38549 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:07,038 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 59236ad1-435f-44fe-b05b-8ae7f3fc38ac) service to localhost/127.0.0.1:38549 successfully registered with NN
2020-12-03 07:22:07,038 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38549 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:07,038 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38549 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:07,038 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 6c2af899-8130-4c3e-a97e-4aaae6061cc6) service to localhost/127.0.0.1:38549 successfully registered with NN
2020-12-03 07:22:07,038 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38549 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:07,047 [IPC Server handler 4 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:07,054 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:34425
2020-12-03 07:22:07,054 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:07,067 [IPC Server handler 5 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fe5d99d3-047f-414a-aaff-d03d6967e953 for DN 127.0.0.1:45344
2020-12-03 07:22:07,069 [IPC Server handler 5 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 for DN 127.0.0.1:45344
2020-12-03 07:22:07,069 [IPC Server handler 8 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4cffc81e-6840-4c88-bc74-f40476d31388 for DN 127.0.0.1:34989
2020-12-03 07:22:07,070 [IPC Server handler 8 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c for DN 127.0.0.1:34989
2020-12-03 07:22:07,070 [IPC Server handler 6 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 for DN 127.0.0.1:34425
2020-12-03 07:22:07,071 [IPC Server handler 6 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 for DN 127.0.0.1:34425
2020-12-03 07:22:07,071 [IPC Server handler 0 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 for DN 127.0.0.1:46560
2020-12-03 07:22:07,071 [IPC Server handler 0 on default port 38549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e8494a0f-0911-4f19-be17-28d59929c27d for DN 127.0.0.1:46560
2020-12-03 07:22:07,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9adb8f950e43dee9: Processing first storage report for DS-4cffc81e-6840-4c88-bc74-f40476d31388 from datanode 59236ad1-435f-44fe-b05b-8ae7f3fc38ac
2020-12-03 07:22:07,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43dee9: from storage DS-4cffc81e-6840-4c88-bc74-f40476d31388 node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b49c3cd2566fcaa: Processing first storage report for DS-e8494a0f-0911-4f19-be17-28d59929c27d from datanode 3a41c7a1-821b-465e-b809-27442365964a
2020-12-03 07:22:07,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcaa: from storage DS-e8494a0f-0911-4f19-be17-28d59929c27d node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfd8cc18f3d2bdf8a: Processing first storage report for DS-fe5d99d3-047f-414a-aaff-d03d6967e953 from datanode f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0
2020-12-03 07:22:07,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8a: from storage DS-fe5d99d3-047f-414a-aaff-d03d6967e953 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9adb8f950e43dee9: Processing first storage report for DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c from datanode 59236ad1-435f-44fe-b05b-8ae7f3fc38ac
2020-12-03 07:22:07,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43dee9: from storage DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b49c3cd2566fcaa: Processing first storage report for DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 from datanode 3a41c7a1-821b-465e-b809-27442365964a
2020-12-03 07:22:07,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcaa: from storage DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfd8cc18f3d2bdf8a: Processing first storage report for DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 from datanode f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0
2020-12-03 07:22:07,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8a: from storage DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,120 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc1e8950daa419d30: Processing first storage report for DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 from datanode 6c2af899-8130-4c3e-a97e-4aaae6061cc6
2020-12-03 07:22:07,121 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d30: from storage DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,121 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc1e8950daa419d30: Processing first storage report for DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 from datanode 6c2af899-8130-4c3e-a97e-4aaae6061cc6
2020-12-03 07:22:07,121 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d30: from storage DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:07,134 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfd8cc18f3d2bdf8a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:07,134 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b49c3cd2566fcaa,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:07,135 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:07,135 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:07,135 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9adb8f950e43dee9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:07,135 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc1e8950daa419d30,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:07,135 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:07,135 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:07,157 [IPC Server handler 1 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:07,159 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:07,167 [IPC Server handler 4 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:07,168 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:07,170 [IPC Server handler 6 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:07,229 [IPC Server handler 5 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/testDecommission2.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:07,269 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:writeFile(143)) - Created file testDecommission2.dat with 4 replicas.
2020-12-03 07:22:07,288 [IPC Server handler 0 on default port 38549] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34989, 127.0.0.1:34425, 127.0.0.1:45344, 127.0.0.1:46560 for /user/root/testDecommission2.dat
2020-12-03 07:22:07,310 [Thread-186] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,376 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:33148 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001 src: /127.0.0.1:33148 dest: /127.0.0.1:34989
2020-12-03 07:22:07,406 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:33148 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,409 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:34358 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001 src: /127.0.0.1:34358 dest: /127.0.0.1:34425
2020-12-03 07:22:07,411 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:34358 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,413 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:59700 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001 src: /127.0.0.1:59700 dest: /127.0.0.1:45344
2020-12-03 07:22:07,414 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:59700 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,418 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:55598 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001 src: /127.0.0.1:55598 dest: /127.0.0.1:46560
2020-12-03 07:22:07,471 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55598, dest: /127.0.0.1:46560, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: 3a41c7a1-821b-465e-b809-27442365964a, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, duration(ns): 26864003
2020-12-03 07:22:07,471 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:07,475 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46560]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59700, dest: /127.0.0.1:45344, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, duration(ns): 36805932
2020-12-03 07:22:07,475 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46560]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46560] terminating
2020-12-03 07:22:07,487 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45344, 127.0.0.1:46560]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34358, dest: /127.0.0.1:34425, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: 6c2af899-8130-4c3e-a97e-4aaae6061cc6, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, duration(ns): 48567706
2020-12-03 07:22:07,487 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45344, 127.0.0.1:46560]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45344, 127.0.0.1:46560] terminating
2020-12-03 07:22:07,491 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:34425, 127.0.0.1:45344, 127.0.0.1:46560]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33148, dest: /127.0.0.1:34989, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: 59236ad1-435f-44fe-b05b-8ae7f3fc38ac, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, duration(ns): 50251732
2020-12-03 07:22:07,491 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:34425, 127.0.0.1:45344, 127.0.0.1:46560]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:34425, 127.0.0.1:45344, 127.0.0.1:46560] terminating
2020-12-03 07:22:07,506 [IPC Server handler 3 on default port 38549] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:34989, 127.0.0.1:45344, 127.0.0.1:46560, 127.0.0.1:34425 for /user/root/testDecommission2.dat
2020-12-03 07:22:07,521 [DataStreamer for file /user/root/testDecommission2.dat] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,524 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:33156 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002 src: /127.0.0.1:33156 dest: /127.0.0.1:34989
2020-12-03 07:22:07,526 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:33156 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,527 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:59706 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002 src: /127.0.0.1:59706 dest: /127.0.0.1:45344
2020-12-03 07:22:07,528 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:59706 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,538 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:55604 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002 src: /127.0.0.1:55604 dest: /127.0.0.1:46560
2020-12-03 07:22:07,539 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:55604 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:07,546 [DataXceiver for client DFSClient_NONMAPREDUCE_-595120700_28 at /127.0.0.1:34370 [Receiving block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002 src: /127.0.0.1:34370 dest: /127.0.0.1:34425
2020-12-03 07:22:07,568 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34370, dest: /127.0.0.1:34425, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: 6c2af899-8130-4c3e-a97e-4aaae6061cc6, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, duration(ns): 18993900
2020-12-03 07:22:07,569 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:07,574 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34425]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55604, dest: /127.0.0.1:46560, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: 3a41c7a1-821b-465e-b809-27442365964a, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, duration(ns): 22767228
2020-12-03 07:22:07,575 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34425]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34425] terminating
2020-12-03 07:22:07,578 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46560, 127.0.0.1:34425]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59706, dest: /127.0.0.1:45344, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, duration(ns): 26116016
2020-12-03 07:22:07,578 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46560, 127.0.0.1:34425]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46560, 127.0.0.1:34425] terminating
2020-12-03 07:22:07,582 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:45344, 127.0.0.1:46560, 127.0.0.1:34425]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33156, dest: /127.0.0.1:34989, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-595120700_28, offset: 0, srvID: 59236ad1-435f-44fe-b05b-8ae7f3fc38ac, blockid: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, duration(ns): 29610028
2020-12-03 07:22:07,583 [PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:45344, 127.0.0.1:46560, 127.0.0.1:34425]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:45344, 127.0.0.1:46560, 127.0.0.1:34425] terminating
2020-12-03 07:22:07,590 [IPC Server handler 8 on default port 38549] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/testDecommission2.dat is closed by DFSClient_NONMAPREDUCE_-595120700_28
2020-12-03 07:22:07,599 [IPC Server handler 7 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:07,600 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:takeNodeOutofService(259)) - Taking node: [127.0.0.1:46560] out of service
2020-12-03 07:22:07,603 [Listener at localhost/40369] INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(100)) - Adding a node "127.0.0.1:46560" to the list of excluded hosts from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/exclude
2020-12-03 07:22:07,604 [Listener at localhost/40369] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:46560 [DISK]DS-e8494a0f-0911-4f19-be17-28d59929c27d:NORMAL:127.0.0.1:46560 with 1 blocks
2020-12-03 07:22:07,604 [Listener at localhost/40369] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:46560 [DISK]DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8:NORMAL:127.0.0.1:46560 with 1 blocks
2020-12-03 07:22:07,604 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:46560 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:08,059 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8b: from storage DS-fe5d99d3-047f-414a-aaff-d03d6967e953 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,059 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8b: from storage DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,060 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfd8cc18f3d2bdf8b,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:08,060 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:08,060 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcab: from storage DS-e8494a0f-0911-4f19-be17-28d59929c27d node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,061 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcab: from storage DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,063 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b49c3cd2566fcab,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:08,064 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:08,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d31: from storage DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43deea: from storage DS-4cffc81e-6840-4c88-bc74-f40476d31388 node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d31: from storage DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,066 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43deea: from storage DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:08,066 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc1e8950daa419d31,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:08,066 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:08,067 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9adb8f950e43deea,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:08,067 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:08,105 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:46560 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:08,605 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:46560 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:09,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d32: from storage DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcac: from storage DS-e8494a0f-0911-4f19-be17-28d59929c27d node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d32: from storage DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43deeb: from storage DS-4cffc81e-6840-4c88-bc74-f40476d31388 node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcac: from storage DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43deeb: from storage DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,047 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc1e8950daa419d32,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:09,047 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b49c3cd2566fcac,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:09,047 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:09,047 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9adb8f950e43deeb,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:09,047 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:09,048 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:09,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8c: from storage DS-fe5d99d3-047f-414a-aaff-d03d6967e953 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8c: from storage DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:09,050 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfd8cc18f3d2bdf8c,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:09,050 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:09,106 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:46560 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:09,606 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:46560 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:10,043 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8d: from storage DS-fe5d99d3-047f-414a-aaff-d03d6967e953 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcad: from storage DS-e8494a0f-0911-4f19-be17-28d59929c27d node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfd8cc18f3d2bdf8d: from storage DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92 node DatanodeRegistration(127.0.0.1:45344, datanodeUuid=f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0, infoPort=45116, infoSecurePort=0, ipcPort=40369, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b49c3cd2566fcad: from storage DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8 node DatanodeRegistration(127.0.0.1:46560, datanodeUuid=3a41c7a1-821b-465e-b809-27442365964a, infoPort=37155, infoSecurePort=0, ipcPort=38562, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43deec: from storage DS-4cffc81e-6840-4c88-bc74-f40476d31388 node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d33: from storage DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9adb8f950e43deec: from storage DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c node DatanodeRegistration(127.0.0.1:34989, datanodeUuid=59236ad1-435f-44fe-b05b-8ae7f3fc38ac, infoPort=36204, infoSecurePort=0, ipcPort=46201, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1e8950daa419d33: from storage DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8 node DatanodeRegistration(127.0.0.1:34425, datanodeUuid=6c2af899-8130-4c3e-a97e-4aaae6061cc6, infoPort=37012, infoSecurePort=0, ipcPort=36719, storageInfo=lv=-57;cid=testClusterID;nsid=437756292;c=1606980121618), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfd8cc18f3d2bdf8d,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9adb8f950e43deec,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc1e8950daa419d33,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 2 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b49c3cd2566fcad,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,046 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,047 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,106 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(343)) - Waiting for node 127.0.0.1:46560 to change state to Decommissioned current state: Decommission In Progress
2020-12-03 07:22:10,117 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:46560
2020-12-03 07:22:10,117 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 2 blocks and 1 nodes this tick
2020-12-03 07:22:10,118 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(450)) - Failed to place enough replicas, still in need of 1 to reach 4 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-12-03 07:22:10,119 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(450)) - Failed to place enough replicas, still in need of 1 to reach 4 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-12-03 07:22:10,119 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=4, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-12-03 07:22:10,119 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(450)) - Failed to place enough replicas, still in need of 1 to reach 4 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-12-03 07:22:10,120 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(450)) - Failed to place enough replicas, still in need of 1 to reach 4 (unavailableStorages=[], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-12-03 07:22:10,120 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(450)) - Failed to place enough replicas, still in need of 1 to reach 4 (unavailableStorages=[DISK], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) For more information, please enable DEBUG log level on org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy and org.apache.hadoop.net.NetworkTopology
2020-12-03 07:22:10,120 [RedundancyMonitor] WARN  protocol.BlockStoragePolicy (BlockStoragePolicy.java:chooseStorageTypes(161)) - Failed to place enough replicas: expected size is 1 but only 0 storage types can be selected (replication=4, selected=[], unavailable=[DISK, ARCHIVE], removed=[DISK], policy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]})
2020-12-03 07:22:10,120 [RedundancyMonitor] WARN  blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(450)) - Failed to place enough replicas, still in need of 1 to reach 4 (unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}, newBlock=false) All required storage types are unavailable:  unavailableStorages=[DISK, ARCHIVE], storagePolicy=BlockStoragePolicy{HOT:7, storageTypes=[DISK], creationFallbacks=[], replicationFallbacks=[ARCHIVE]}
2020-12-03 07:22:10,607 [Listener at localhost/40369] INFO  hdfs.AdminStatesBaseTest (AdminStatesBaseTest.java:waitNodeState(352)) - node 127.0.0.1:46560 reached the state Decommissioned
2020-12-03 07:22:10,611 [IPC Server handler 9 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,622 [IPC Server handler 1 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/testDecommission2.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,639 [Listener at localhost/40369] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(129)) - Block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001 replica on DatanodeInfoWithStorage[127.0.0.1:46560,DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8,DISK] is decommissioned.
2020-12-03 07:22:10,639 [Listener at localhost/40369] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(140)) - Block BP-557387821-172.17.0.6-1606980121618:blk_1073741825_1001 has 1 decommissioned replica.
2020-12-03 07:22:10,639 [Listener at localhost/40369] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(129)) - Block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002 replica on DatanodeInfoWithStorage[127.0.0.1:46560,DS-e8494a0f-0911-4f19-be17-28d59929c27d,DISK] is decommissioned.
2020-12-03 07:22:10,639 [Listener at localhost/40369] INFO  hdfs.TestDecommission (TestDecommission.java:checkFile(140)) - Block BP-557387821-172.17.0.6-1606980121618:blk_1073741826_1002 has 1 decommissioned replica.
2020-12-03 07:22:10,643 [IPC Server handler 2 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/testDecommission2.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,659 [IPC Server handler 0 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/testDecommission2.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,664 [IPC Server handler 3 on default port 38549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/testDecommission2.dat	dst=null	perm=null	proto=rpc
2020-12-03 07:22:10,665 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:10,665 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:10,666 [Listener at localhost/40369] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:10,666 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@285d22a9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:10,668 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-fe5d99d3-047f-414a-aaff-d03d6967e953) exiting.
2020-12-03 07:22:10,668 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-7b90dc07-d2ea-4dfa-ae08-b43124680b92) exiting.
2020-12-03 07:22:10,696 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1c5e2158{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:10,702 [Listener at localhost/40369] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b5666e9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:10,702 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1fa9b5fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:10,703 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@380195e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:10,705 [Listener at localhost/40369] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40369
2020-12-03 07:22:10,708 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:10,709 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:10,710 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:10,710 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0) service to localhost/127.0.0.1:38549
2020-12-03 07:22:10,711 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid f4e7a328-cd28-4855-b3e9-d2dc8a0e13e0)
2020-12-03 07:22:10,711 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,713 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:10,713 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:10,715 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:10,716 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:10,716 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:10,716 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:10,722 [Listener at localhost/40369] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:10,723 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:10,723 [Listener at localhost/40369] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:10,723 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6c78eda0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:10,726 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-04c9f6f8-ca6a-4e0d-a551-bcf08ab729b8) exiting.
2020-12-03 07:22:10,726 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e8494a0f-0911-4f19-be17-28d59929c27d) exiting.
2020-12-03 07:22:10,839 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56c11958{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:10,862 [Listener at localhost/40369] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30f828c6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:10,863 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31a5b8f4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:10,863 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@192d70ef{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:10,865 [Listener at localhost/40369] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38562
2020-12-03 07:22:10,866 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:10,877 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:10,877 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:10,889 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 3a41c7a1-821b-465e-b809-27442365964a) service to localhost/127.0.0.1:38549
2020-12-03 07:22:10,889 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 3a41c7a1-821b-465e-b809-27442365964a)
2020-12-03 07:22:10,889 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,891 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:10,894 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:10,897 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:10,897 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:10,899 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:10,899 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:10,901 [Listener at localhost/40369] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:10,902 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:10,902 [Listener at localhost/40369] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:10,902 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7d6a7e7f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:10,903 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b8dcaf28-896a-4ae8-8e24-15268a48faf8) exiting.
2020-12-03 07:22:10,904 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d3cdd002-f147-4065-aaf1-32de7cbc82c0) exiting.
2020-12-03 07:22:10,939 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@365d8d99{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:10,940 [Listener at localhost/40369] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2ebca257{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:10,940 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a196192{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:10,941 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a389651{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:10,942 [Listener at localhost/40369] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36719
2020-12-03 07:22:10,945 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:10,946 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:10,947 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:10,947 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 6c2af899-8130-4c3e-a97e-4aaae6061cc6) service to localhost/127.0.0.1:38549
2020-12-03 07:22:10,947 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 6c2af899-8130-4c3e-a97e-4aaae6061cc6)
2020-12-03 07:22:10,947 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:10,949 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:10,951 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:10,954 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:10,954 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:10,955 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:10,955 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:10,981 [Listener at localhost/40369] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:10,981 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:10,982 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34cd6d30] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:10,982 [Listener at localhost/40369] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:10,985 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4cffc81e-6840-4c88-bc74-f40476d31388) exiting.
2020-12-03 07:22:10,985 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ed5a77cf-5af4-4572-bb2a-163d81bd7a5c) exiting.
2020-12-03 07:22:11,010 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@53f1664{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:11,011 [Listener at localhost/40369] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c1eec4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:11,012 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c85712{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:11,012 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52abf1e4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:11,014 [Listener at localhost/40369] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46201
2020-12-03 07:22:11,017 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:11,018 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:11,020 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:11,020 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 59236ad1-435f-44fe-b05b-8ae7f3fc38ac) service to localhost/127.0.0.1:38549
2020-12-03 07:22:11,020 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-557387821-172.17.0.6-1606980121618 (Datanode Uuid 59236ad1-435f-44fe-b05b-8ae7f3fc38ac)
2020-12-03 07:22:11,020 [BP-557387821-172.17.0.6-1606980121618 heartbeating to localhost/127.0.0.1:38549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-557387821-172.17.0.6-1606980121618
2020-12-03 07:22:11,021 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:11,022 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-557387821-172.17.0.6-1606980121618] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:11,033 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:11,033 [Listener at localhost/40369] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:11,036 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:11,036 [Listener at localhost/40369] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:11,040 [Listener at localhost/40369] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:11,040 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:11,040 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:11,041 [Listener at localhost/40369] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 12
2020-12-03 07:22:11,041 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@cc6c4e4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:11,042 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@453fe2ca] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:11,042 [Listener at localhost/40369] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 13 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 3 Number of syncs: 11 SyncTimes(ms): 1 2 
2020-12-03 07:22:11,044 [Listener at localhost/40369] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000013
2020-12-03 07:22:11,044 [Listener at localhost/40369] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000013
2020-12-03 07:22:11,045 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:11,045 [CacheReplicationMonitor(1606716853)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:11,046 [Listener at localhost/40369] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38549
2020-12-03 07:22:11,049 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:11,051 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:11,051 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:11,051 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:11,097 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:11,097 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:11,099 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f27a90b{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:11,101 [Listener at localhost/40369] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@505b68f2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:11,101 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e024f92{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:11,102 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e3ed705{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:11,106 [Listener at localhost/40369] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:11,117 [Listener at localhost/40369] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:11,118 [Listener at localhost/40369] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:22:11,137 [Listener at localhost/40369] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=4
Formatting using clusterid: testClusterID
2020-12-03 07:22:11,140 [Listener at localhost/40369] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:11,141 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:11,141 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:11,141 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:11,141 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:11,141 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:11,142 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:11,142 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:11,142 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:11,143 [Listener at localhost/40369] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:11,144 [Listener at localhost/40369] ERROR blockmanagement.DatanodeManager (DatanodeManager.java:<init>(264)) - error reading hosts files: 
java.io.FileNotFoundException: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/include (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:77)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:79)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:157)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:71)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:262)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:801)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:737)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1184)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:422)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1072)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommission2(TestDecommission.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:11,147 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,147 [Listener at localhost/40369] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:11,148 [Listener at localhost/40369] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:11,148 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,148 [Listener at localhost/40369] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:11,148 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:11,149 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:11
2020-12-03 07:22:11,149 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:11,149 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,150 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:11,150 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:11,153 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,154 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,154 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:11,154 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:11,154 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:11,154 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,155 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:11,155 [Listener at localhost/40369] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:11,155 [Listener at localhost/40369] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:11,155 [Listener at localhost/40369] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:11,155 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:11,155 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:11,156 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:11,156 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:11,156 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:11,156 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:11,156 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:11,157 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:11,157 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,157 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:11,157 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:11,159 [Listener at localhost/40369] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:11,159 [Listener at localhost/40369] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:11,160 [Listener at localhost/40369] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:11,160 [Listener at localhost/40369] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:11,160 [Listener at localhost/40369] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:11,160 [Listener at localhost/40369] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:11,160 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:11,160 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,161 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:11,161 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:11,163 [Listener at localhost/40369] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:11,163 [Listener at localhost/40369] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:11,163 [Listener at localhost/40369] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:11,163 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:11,164 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:11,164 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:11,164 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,164 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:11,164 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:11,166 [Listener at localhost/40369] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:11,228 [Listener at localhost/40369] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:11,296 [Listener at localhost/40369] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:11,316 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:11,316 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:11,323 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:22:11,327 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:22:11,390 [Listener at localhost/40369] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:11,393 [Listener at localhost/40369] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:11,398 [Listener at localhost/40369] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:11,400 [Listener at localhost/40369] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:11,400 [Listener at localhost/40369] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:11,402 [Listener at localhost/40369] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:22:11,424 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63e0ff97] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:11,424 [Listener at localhost/40369] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:11,424 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:11,426 [Listener at localhost/40369] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:11,426 [Listener at localhost/40369] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:11,426 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:11,429 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:11,429 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:11,429 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:11,430 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:11,431 [Listener at localhost/40369] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:11,431 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:11,432 [Listener at localhost/40369] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46507
2020-12-03 07:22:11,432 [Listener at localhost/40369] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:11,434 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a08fc01{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:11,436 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c44afb8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:11,450 [Listener at localhost/40369] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@15ec4127{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:11,460 [Listener at localhost/40369] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c0aab4c{HTTP/1.1,[http/1.1]}{localhost:46507}
2020-12-03 07:22:11,461 [Listener at localhost/40369] INFO  server.Server (Server.java:doStart(419)) - Started @12217ms
2020-12-03 07:22:11,464 [Listener at localhost/40369] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:11,464 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:11,464 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:11,464 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:11,464 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:11,465 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:11,465 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:11,465 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:11,465 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:11,465 [Listener at localhost/40369] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:11,466 [Listener at localhost/40369] ERROR blockmanagement.DatanodeManager (DatanodeManager.java:<init>(264)) - error reading hosts files: 
java.io.FileNotFoundException: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/temp/admin/include (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.util.HostsFileReader.readFileToSet(HostsFileReader.java:77)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.readFile(HostFileManager.java:79)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:157)
	at org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager.refresh(HostFileManager.java:71)
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:262)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:801)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:712)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:648)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:710)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:953)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:926)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1692)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1314)
	at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1083)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:958)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:890)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)
	at org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)
	at org.apache.hadoop.hdfs.TestDecommission.testDecommission2(TestDecommission.java:231)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-12-03 07:22:11,466 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,466 [Listener at localhost/40369] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:22:11,467 [Listener at localhost/40369] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:11,467 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,467 [Listener at localhost/40369] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(368)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 10400.
2020-12-03 07:22:11,467 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:11,468 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:11
2020-12-03 07:22:11,468 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:11,468 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,468 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:11,468 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:11,473 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,474 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,474 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:11,474 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:11,474 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:11,474 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,475 [Listener at localhost/40369] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:11,475 [Listener at localhost/40369] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:11,475 [Listener at localhost/40369] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:11,475 [Listener at localhost/40369] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:11,475 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:11,476 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:11,476 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:11,476 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:11,476 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:11,476 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:11,476 [Listener at localhost/40369] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:11,477 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:11,477 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,477 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:11,477 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:11,480 [Listener at localhost/40369] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:11,480 [Listener at localhost/40369] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:11,480 [Listener at localhost/40369] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:11,481 [Listener at localhost/40369] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:11,481 [Listener at localhost/40369] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:11,481 [Listener at localhost/40369] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:11,481 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:11,481 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,482 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:11,482 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:11,483 [Listener at localhost/40369] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:11,483 [Listener at localhost/40369] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:11,484 [Listener at localhost/40369] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:11,484 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:11,484 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:11,484 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:11,484 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:11,485 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:11,485 [Listener at localhost/40369] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:11,523 [Listener at localhost/40369] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:11,549 [Listener at localhost/40369] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:11,551 [Listener at localhost/40369] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:11,552 [Listener at localhost/40369] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:11,552 [Listener at localhost/40369] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:11,552 [Listener at localhost/40369] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:11,554 [Listener at localhost/40369] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:11,564 [Listener at localhost/40369] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:11,565 [Listener at localhost/40369] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:11,565 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:11,566 [Listener at localhost/40369] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:11,675 [Listener at localhost/40369] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:11,676 [Listener at localhost/40369] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 190 msecs
2020-12-03 07:22:11,678 [Listener at localhost/40369] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:11,680 [Listener at localhost/40369] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:11,683 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:11,692 [Listener at localhost/32769] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:32769 to access this namenode/service.
2020-12-03 07:22:11,694 [Listener at localhost/32769] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:11,772 [Listener at localhost/32769] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:11,779 [Listener at localhost/32769] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:11,780 [Listener at localhost/32769] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:11,780 [Listener at localhost/32769] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:11,780 [Listener at localhost/32769] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:11,789 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:11,789 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:11,789 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:11,789 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:11,789 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:11,789 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-12-03 07:22:11,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:11,794 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:11,805 [Listener at localhost/32769] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:32769
2020-12-03 07:22:11,806 [Listener at localhost/32769] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:11,807 [Listener at localhost/32769] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:11,812 [Listener at localhost/32769] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:11,817 [CacheReplicationMonitor(1940445598)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:11,821 [Listener at localhost/32769] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:11,822 [Listener at localhost/32769] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:11,823 [Listener at localhost/32769] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:11,824 [Listener at localhost/32769] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:11,826 [Listener at localhost/32769] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:11,827 [Listener at localhost/32769] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:11,827 [Listener at localhost/32769] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:11,827 [Listener at localhost/32769] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:11,828 [Listener at localhost/32769] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,828 [Listener at localhost/32769] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,828 [Listener at localhost/32769] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:11,829 [Listener at localhost/32769] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39544
2020-12-03 07:22:11,833 [Listener at localhost/32769] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:11,834 [Listener at localhost/32769] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:11,835 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:11,837 [Listener at localhost/32769] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:11,838 [Listener at localhost/32769] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:11,838 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:11,841 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:11,842 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:11,842 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:11,843 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:11,844 [Listener at localhost/32769] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37433
2020-12-03 07:22:11,844 [Listener at localhost/32769] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:11,854 [Listener at localhost/32769] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e895f4d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:11,856 [Listener at localhost/32769] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@578f42b7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:11,867 [Listener at localhost/32769] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@513ceb19{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:11,870 [Listener at localhost/32769] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b838fde{HTTP/1.1,[http/1.1]}{localhost:37433}
2020-12-03 07:22:11,871 [Listener at localhost/32769] INFO  server.Server (Server.java:doStart(419)) - Started @12627ms
2020-12-03 07:22:11,899 [Listener at localhost/32769] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44696
2020-12-03 07:22:11,899 [Listener at localhost/32769] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:11,900 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@639bf3cc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:11,900 [Listener at localhost/32769] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:11,900 [Listener at localhost/32769] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:11,901 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:11,918 [Listener at localhost/36163] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36163
2020-12-03 07:22:11,937 [Listener at localhost/36163] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:11,938 [Listener at localhost/36163] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:11,938 [Thread-260] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769 starting to offer service
2020-12-03 07:22:11,971 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:11,971 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:11,981 [Thread-260] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769
2020-12-03 07:22:11,985 [Thread-260] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:11,985 [Listener at localhost/36163] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:11,987 [Listener at localhost/36163] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:11,989 [Listener at localhost/36163] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:11,997 [Listener at localhost/36163] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:11,997 [Listener at localhost/36163] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:11,997 [Listener at localhost/36163] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:11,998 [Listener at localhost/36163] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:11,998 [Listener at localhost/36163] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:11,998 [Listener at localhost/36163] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,999 [Listener at localhost/36163] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:11,999 [Listener at localhost/36163] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:12,002 [Listener at localhost/36163] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39580
2020-12-03 07:22:12,002 [Listener at localhost/36163] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:12,002 [Listener at localhost/36163] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:12,006 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:12,008 [Listener at localhost/36163] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:12,009 [Listener at localhost/36163] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:12,010 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:12,011 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:12,012 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:12,012 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:12,012 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:12,013 [Listener at localhost/36163] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45072
2020-12-03 07:22:12,013 [Listener at localhost/36163] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:12,015 [Listener at localhost/36163] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77013cd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:12,015 [Listener at localhost/36163] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34f77daf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:12,019 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,020 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,020 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-99a86e9a-e753-4d49-b03e-798de2a8e737 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:12,026 [Listener at localhost/36163] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6920966c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:12,033 [Listener at localhost/36163] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1167b60f{HTTP/1.1,[http/1.1]}{localhost:45072}
2020-12-03 07:22:12,033 [Listener at localhost/36163] INFO  server.Server (Server.java:doStart(419)) - Started @12789ms
2020-12-03 07:22:12,068 [Listener at localhost/36163] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35067
2020-12-03 07:22:12,069 [Listener at localhost/36163] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:12,069 [Listener at localhost/36163] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:12,070 [Listener at localhost/36163] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:12,071 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e5532c9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:12,076 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:12,078 [Listener at localhost/36032] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36032
2020-12-03 07:22:12,110 [Listener at localhost/36032] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:12,111 [Listener at localhost/36032] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:12,112 [Thread-283] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769 starting to offer service
2020-12-03 07:22:12,113 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:12,114 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:12,116 [Listener at localhost/36032] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:12,124 [Listener at localhost/36032] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:12,126 [Listener at localhost/36032] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:12,126 [Thread-283] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769
2020-12-03 07:22:12,129 [Thread-283] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:12,130 [Listener at localhost/36032] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:12,141 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,146 [Listener at localhost/36032] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:12,146 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,146 [Listener at localhost/36032] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:12,146 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:12,147 [Listener at localhost/36032] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:12,147 [Listener at localhost/36032] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:12,148 [Listener at localhost/36032] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:12,148 [Listener at localhost/36032] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:12,149 [Listener at localhost/36032] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:12,150 [Listener at localhost/36032] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41082
2020-12-03 07:22:12,150 [Listener at localhost/36032] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:12,150 [Listener at localhost/36032] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:12,151 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:12,154 [Listener at localhost/36032] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:12,154 [Listener at localhost/36032] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:12,155 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:12,157 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:12,157 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:12,157 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:12,158 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:12,158 [Listener at localhost/36032] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43418
2020-12-03 07:22:12,159 [Listener at localhost/36032] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:12,160 [Listener at localhost/36032] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6dcc11e8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:12,161 [Listener at localhost/36032] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78b85f00{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:12,168 [Listener at localhost/36032] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6ee78535{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:12,176 [Listener at localhost/36032] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@47b5d0f0{HTTP/1.1,[http/1.1]}{localhost:43418}
2020-12-03 07:22:12,177 [Listener at localhost/36032] INFO  server.Server (Server.java:doStart(419)) - Started @12933ms
2020-12-03 07:22:12,180 [Thread-283] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,180 [Thread-283] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,180 [Thread-283] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:12,202 [Listener at localhost/36032] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44060
2020-12-03 07:22:12,203 [Listener at localhost/36032] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:12,203 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d6c804b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:12,203 [Listener at localhost/36032] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:12,204 [Listener at localhost/36032] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:12,205 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:12,212 [Listener at localhost/45411] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45411
2020-12-03 07:22:12,234 [Listener at localhost/45411] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:12,235 [Listener at localhost/45411] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:12,237 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:12,237 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:12,237 [Thread-305] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769 starting to offer service
2020-12-03 07:22:12,279 [Listener at localhost/45411] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:12,294 [Listener at localhost/45411] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:12,300 [Listener at localhost/45411] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:12,310 [Thread-305] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769
2020-12-03 07:22:12,315 [Thread-305] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:12,327 [Listener at localhost/45411] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:12,328 [Listener at localhost/45411] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:12,328 [Listener at localhost/45411] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:12,329 [Listener at localhost/45411] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:12,329 [Listener at localhost/45411] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:12,329 [Listener at localhost/45411] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:12,329 [Listener at localhost/45411] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:12,330 [Listener at localhost/45411] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:12,338 [Listener at localhost/45411] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34232
2020-12-03 07:22:12,338 [Listener at localhost/45411] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:12,338 [Listener at localhost/45411] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:12,339 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,339 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,339 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:12,340 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:12,340 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:12,341 [Listener at localhost/45411] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:12,342 [Listener at localhost/45411] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:12,342 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:12,345 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:12,345 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:12,346 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:12,346 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:12,347 [Listener at localhost/45411] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37312
2020-12-03 07:22:12,347 [Listener at localhost/45411] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:12,349 [Listener at localhost/45411] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24298a38{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:12,349 [Listener at localhost/45411] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@88267c4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:12,363 [Listener at localhost/45411] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@fec53b0{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:12,368 [Listener at localhost/45411] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70bf9792{HTTP/1.1,[http/1.1]}{localhost:37312}
2020-12-03 07:22:12,369 [Listener at localhost/45411] INFO  server.Server (Server.java:doStart(419)) - Started @13125ms
2020-12-03 07:22:12,408 [Thread-305] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,408 [Thread-305] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,409 [Thread-305] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9adabb52-d865-46d4-93fc-afaabc6f9654 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:12,434 [Thread-283] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,434 [Thread-283] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,434 [Thread-283] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:12,447 [Listener at localhost/45411] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44705
2020-12-03 07:22:12,448 [Listener at localhost/45411] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:12,448 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63d84d20] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:12,448 [Listener at localhost/45411] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:12,449 [Listener at localhost/45411] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:12,450 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:12,458 [Listener at localhost/44246] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44246
2020-12-03 07:22:12,485 [Listener at localhost/44246] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:22:12,485 [Listener at localhost/44246] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:22:12,486 [Thread-327] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769 starting to offer service
2020-12-03 07:22:12,491 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:12,491 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:12,557 [Thread-327] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32769
2020-12-03 07:22:12,560 [Thread-327] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:12,565 [IPC Server handler 5 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,566 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:12,566 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:12,593 [Thread-283] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,594 [Thread-283] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,594 [Thread-283] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:12,595 [Thread-283] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:12,595 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,595 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,595 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:12,596 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:12,632 [Thread-327] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,632 [Thread-327] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,633 [Thread-327] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:12,671 [Thread-305] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,674 [IPC Server handler 6 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,674 [Thread-305] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,677 [Thread-305] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:12,677 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:12,677 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:12,748 [Thread-260] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1083088715;bpid=BP-11750243-172.17.0.6-1606980131166;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1083088715;c=1606980131166;bpid=BP-11750243-172.17.0.6-1606980131166;dnuuid=null
2020-12-03 07:22:12,760 [Thread-283] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,760 [Thread-283] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,760 [Thread-283] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:12,760 [Thread-283] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:12,802 [IPC Server handler 8 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,803 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:12,803 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:12,842 [Thread-305] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,843 [Thread-305] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:12,843 [Thread-305] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:12,843 [Thread-305] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:12,879 [Thread-327] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 10828@796e7be4bc1c
2020-12-03 07:22:12,880 [Thread-327] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1083088715. Formatting...
2020-12-03 07:22:12,880 [Thread-327] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1d152755-81c8-4f79-9d4f-33bedef5896a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:12,911 [IPC Server handler 0 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:12,912 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:12,912 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:12,965 [Thread-260] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0ce8c028-cb77-4ad0-a523-42ee6ee563cc
2020-12-03 07:22:12,965 [Thread-283] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1083088715;bpid=BP-11750243-172.17.0.6-1606980131166;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1083088715;c=1606980131166;bpid=BP-11750243-172.17.0.6-1606980131166;dnuuid=null
2020-12-03 07:22:12,972 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-99a86e9a-e753-4d49-b03e-798de2a8e737
2020-12-03 07:22:12,972 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:12,976 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0
2020-12-03 07:22:13,007 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:13,014 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:13,018 [IPC Server handler 2 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,019 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,021 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,023 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:13,072 [Thread-327] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,072 [Thread-327] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,073 [Thread-327] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:13,073 [Thread-327] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:13,074 [Thread-305] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,074 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:13,074 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:13,074 [Thread-305] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,074 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:13,076 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,076 [Thread-305] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:13,077 [Thread-305] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:13,080 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:13,081 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:13,125 [IPC Server handler 3 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,126 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,126 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,134 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 54ms
2020-12-03 07:22:13,136 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 56ms
2020-12-03 07:22:13,136 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-11750243-172.17.0.6-1606980131166: 60ms
2020-12-03 07:22:13,137 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:13,137 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:13,137 [Thread-345] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,137 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,137 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:22:13,138 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:22:13,138 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-11750243-172.17.0.6-1606980131166: 1ms
2020-12-03 07:22:13,138 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:13,138 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:13,139 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-99a86e9a-e753-4d49-b03e-798de2a8e737): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,139 [Thread-260] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:12 AM with interval of 21600000ms
2020-12-03 07:22:13,139 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,141 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 0ce8c028-cb77-4ad0-a523-42ee6ee563cc) service to localhost/127.0.0.1:32769 beginning handshake with NN
2020-12-03 07:22:13,141 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-99a86e9a-e753-4d49-b03e-798de2a8e737): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:13,143 [IPC Server handler 4 on default port 32769] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39544, datanodeUuid=0ce8c028-cb77-4ad0-a523-42ee6ee563cc, infoPort=44696, infoSecurePort=0, ipcPort=36163, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166) storage 0ce8c028-cb77-4ad0-a523-42ee6ee563cc
2020-12-03 07:22:13,143 [IPC Server handler 4 on default port 32769] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39544
2020-12-03 07:22:13,143 [IPC Server handler 4 on default port 32769] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0ce8c028-cb77-4ad0-a523-42ee6ee563cc (127.0.0.1:39544).
2020-12-03 07:22:13,153 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0): no suitable block pools found to scan.  Waiting 1814399985 ms.
2020-12-03 07:22:13,153 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 0ce8c028-cb77-4ad0-a523-42ee6ee563cc) service to localhost/127.0.0.1:32769 successfully registered with NN
2020-12-03 07:22:13,154 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32769 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:13,160 [IPC Server handler 5 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-99a86e9a-e753-4d49-b03e-798de2a8e737 for DN 127.0.0.1:39544
2020-12-03 07:22:13,160 [IPC Server handler 5 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0 for DN 127.0.0.1:39544
2020-12-03 07:22:13,164 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb27fbed8d635d2c5: Processing first storage report for DS-99a86e9a-e753-4d49-b03e-798de2a8e737 from datanode 0ce8c028-cb77-4ad0-a523-42ee6ee563cc
2020-12-03 07:22:13,164 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb27fbed8d635d2c5: from storage DS-99a86e9a-e753-4d49-b03e-798de2a8e737 node DatanodeRegistration(127.0.0.1:39544, datanodeUuid=0ce8c028-cb77-4ad0-a523-42ee6ee563cc, infoPort=44696, infoSecurePort=0, ipcPort=36163, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,165 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb27fbed8d635d2c5: Processing first storage report for DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0 from datanode 0ce8c028-cb77-4ad0-a523-42ee6ee563cc
2020-12-03 07:22:13,165 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb27fbed8d635d2c5: from storage DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0 node DatanodeRegistration(127.0.0.1:39544, datanodeUuid=0ce8c028-cb77-4ad0-a523-42ee6ee563cc, infoPort=44696, infoSecurePort=0, ipcPort=36163, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,166 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb27fbed8d635d2c5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,166 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,181 [Thread-283] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID bc72f8cb-93b8-4b2e-993a-c8bbdee9375e
2020-12-03 07:22:13,196 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918
2020-12-03 07:22:13,197 [Thread-283] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:13,226 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8
2020-12-03 07:22:13,226 [Thread-283] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:13,228 [Thread-283] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:13,229 [IPC Server handler 8 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,229 [Thread-283] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:13,230 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,230 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,230 [Thread-283] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:13,230 [Thread-283] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:13,230 [Thread-283] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:13,232 [Thread-283] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,232 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:13,232 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:13,247 [Thread-305] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1083088715;bpid=BP-11750243-172.17.0.6-1606980131166;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1083088715;c=1606980131166;bpid=BP-11750243-172.17.0.6-1606980131166;dnuuid=null
2020-12-03 07:22:13,256 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 24ms
2020-12-03 07:22:13,262 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 30ms
2020-12-03 07:22:13,262 [Thread-327] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,262 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-11750243-172.17.0.6-1606980131166: 31ms
2020-12-03 07:22:13,263 [Thread-327] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,263 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:13,263 [Thread-327] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-11750243-172.17.0.6-1606980131166 is not formatted. Formatting ...
2020-12-03 07:22:13,263 [Thread-356] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,263 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:13,263 [Thread-327] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-11750243-172.17.0.6-1606980131166 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-11750243-172.17.0.6-1606980131166/current
2020-12-03 07:22:13,263 [Thread-357] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,264 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:22:13,264 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:22:13,264 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-11750243-172.17.0.6-1606980131166: 1ms
2020-12-03 07:22:13,264 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:13,264 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:13,265 [Thread-283] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:45 AM with interval of 21600000ms
2020-12-03 07:22:13,265 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,265 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,266 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid bc72f8cb-93b8-4b2e-993a-c8bbdee9375e) service to localhost/127.0.0.1:32769 beginning handshake with NN
2020-12-03 07:22:13,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:13,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:13,267 [IPC Server handler 7 on default port 32769] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39580, datanodeUuid=bc72f8cb-93b8-4b2e-993a-c8bbdee9375e, infoPort=35067, infoSecurePort=0, ipcPort=36032, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166) storage bc72f8cb-93b8-4b2e-993a-c8bbdee9375e
2020-12-03 07:22:13,268 [IPC Server handler 7 on default port 32769] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39580
2020-12-03 07:22:13,268 [IPC Server handler 7 on default port 32769] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bc72f8cb-93b8-4b2e-993a-c8bbdee9375e (127.0.0.1:39580).
2020-12-03 07:22:13,269 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid bc72f8cb-93b8-4b2e-993a-c8bbdee9375e) service to localhost/127.0.0.1:32769 successfully registered with NN
2020-12-03 07:22:13,269 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32769 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:13,272 [IPC Server handler 9 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918 for DN 127.0.0.1:39580
2020-12-03 07:22:13,273 [IPC Server handler 9 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8 for DN 127.0.0.1:39580
2020-12-03 07:22:13,276 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4e08329a5979b204: Processing first storage report for DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918 from datanode bc72f8cb-93b8-4b2e-993a-c8bbdee9375e
2020-12-03 07:22:13,276 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4e08329a5979b204: from storage DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918 node DatanodeRegistration(127.0.0.1:39580, datanodeUuid=bc72f8cb-93b8-4b2e-993a-c8bbdee9375e, infoPort=35067, infoSecurePort=0, ipcPort=36032, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,276 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4e08329a5979b204: Processing first storage report for DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8 from datanode bc72f8cb-93b8-4b2e-993a-c8bbdee9375e
2020-12-03 07:22:13,276 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4e08329a5979b204: from storage DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8 node DatanodeRegistration(127.0.0.1:39580, datanodeUuid=bc72f8cb-93b8-4b2e-993a-c8bbdee9375e, infoPort=35067, infoSecurePort=0, ipcPort=36032, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,278 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4e08329a5979b204,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,278 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,331 [IPC Server handler 0 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,333 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,333 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,435 [IPC Server handler 2 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,436 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,436 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,443 [Thread-305] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d67a3d92-c8df-4084-a251-fc76a5f50806
2020-12-03 07:22:13,443 [Thread-327] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1083088715;bpid=BP-11750243-172.17.0.6-1606980131166;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1083088715;c=1606980131166;bpid=BP-11750243-172.17.0.6-1606980131166;dnuuid=null
2020-12-03 07:22:13,446 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9adabb52-d865-46d4-93fc-afaabc6f9654
2020-12-03 07:22:13,447 [Thread-305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:13,449 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba
2020-12-03 07:22:13,449 [Thread-305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:13,450 [Thread-305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:13,451 [Thread-305] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:13,452 [Thread-305] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:13,452 [Thread-305] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:13,453 [Thread-305] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:13,453 [Thread-305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,454 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:13,454 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:13,480 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 26ms
2020-12-03 07:22:13,481 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 27ms
2020-12-03 07:22:13,485 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-11750243-172.17.0.6-1606980131166: 31ms
2020-12-03 07:22:13,485 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:13,485 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:13,485 [Thread-367] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,485 [Thread-368] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,486 [Thread-367] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:22:13,486 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:22:13,486 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-11750243-172.17.0.6-1606980131166: 1ms
2020-12-03 07:22:13,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:13,486 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:13,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-9adabb52-d865-46d4-93fc-afaabc6f9654): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,487 [Thread-305] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:42 AM with interval of 21600000ms
2020-12-03 07:22:13,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-9adabb52-d865-46d4-93fc-afaabc6f9654): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:13,488 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:13,488 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid d67a3d92-c8df-4084-a251-fc76a5f50806) service to localhost/127.0.0.1:32769 beginning handshake with NN
2020-12-03 07:22:13,493 [IPC Server handler 3 on default port 32769] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41082, datanodeUuid=d67a3d92-c8df-4084-a251-fc76a5f50806, infoPort=44060, infoSecurePort=0, ipcPort=45411, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166) storage d67a3d92-c8df-4084-a251-fc76a5f50806
2020-12-03 07:22:13,494 [IPC Server handler 3 on default port 32769] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41082
2020-12-03 07:22:13,494 [IPC Server handler 3 on default port 32769] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d67a3d92-c8df-4084-a251-fc76a5f50806 (127.0.0.1:41082).
2020-12-03 07:22:13,495 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid d67a3d92-c8df-4084-a251-fc76a5f50806) service to localhost/127.0.0.1:32769 successfully registered with NN
2020-12-03 07:22:13,495 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32769 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:13,498 [IPC Server handler 4 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9adabb52-d865-46d4-93fc-afaabc6f9654 for DN 127.0.0.1:41082
2020-12-03 07:22:13,498 [IPC Server handler 4 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba for DN 127.0.0.1:41082
2020-12-03 07:22:13,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe74a382a06365a1: Processing first storage report for DS-9adabb52-d865-46d4-93fc-afaabc6f9654 from datanode d67a3d92-c8df-4084-a251-fc76a5f50806
2020-12-03 07:22:13,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe74a382a06365a1: from storage DS-9adabb52-d865-46d4-93fc-afaabc6f9654 node DatanodeRegistration(127.0.0.1:41082, datanodeUuid=d67a3d92-c8df-4084-a251-fc76a5f50806, infoPort=44060, infoSecurePort=0, ipcPort=45411, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe74a382a06365a1: Processing first storage report for DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba from datanode d67a3d92-c8df-4084-a251-fc76a5f50806
2020-12-03 07:22:13,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe74a382a06365a1: from storage DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba node DatanodeRegistration(127.0.0.1:41082, datanodeUuid=d67a3d92-c8df-4084-a251-fc76a5f50806, infoPort=44060, infoSecurePort=0, ipcPort=45411, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,501 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe74a382a06365a1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,502 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,539 [IPC Server handler 6 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,541 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,541 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,616 [Thread-327] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7102202a-cfaa-4337-9dc7-34f4538f3281
2020-12-03 07:22:13,619 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92
2020-12-03 07:22:13,619 [Thread-327] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:13,623 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1d152755-81c8-4f79-9d4f-33bedef5896a
2020-12-03 07:22:13,623 [Thread-327] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:13,623 [Thread-327] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:13,641 [Thread-327] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:13,642 [Thread-327] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:13,642 [Thread-327] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:13,642 [Thread-327] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:13,644 [Thread-327] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,644 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:13,644 [Thread-375] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:13,649 [IPC Server handler 8 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,650 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:13,650 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:13,669 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 25ms
2020-12-03 07:22:13,670 [Thread-375] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-11750243-172.17.0.6-1606980131166 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 26ms
2020-12-03 07:22:13,671 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-11750243-172.17.0.6-1606980131166: 27ms
2020-12-03 07:22:13,671 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:13,671 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:13,671 [Thread-378] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,672 [Thread-379] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-11750243-172.17.0.6-1606980131166/current/replicas doesn't exist 
2020-12-03 07:22:13,672 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:22:13,672 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:22:13,672 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-11750243-172.17.0.6-1606980131166: 2ms
2020-12-03 07:22:13,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:13,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-11750243-172.17.0.6-1606980131166 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:13,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1d152755-81c8-4f79-9d4f-33bedef5896a): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,673 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92): finished scanning block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,674 [Thread-327] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:08 AM with interval of 21600000ms
2020-12-03 07:22:13,674 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:13,674 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1d152755-81c8-4f79-9d4f-33bedef5896a): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:13,675 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 7102202a-cfaa-4337-9dc7-34f4538f3281) service to localhost/127.0.0.1:32769 beginning handshake with NN
2020-12-03 07:22:13,676 [IPC Server handler 7 on default port 32769] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34232, datanodeUuid=7102202a-cfaa-4337-9dc7-34f4538f3281, infoPort=44705, infoSecurePort=0, ipcPort=44246, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166) storage 7102202a-cfaa-4337-9dc7-34f4538f3281
2020-12-03 07:22:13,677 [IPC Server handler 7 on default port 32769] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34232
2020-12-03 07:22:13,677 [IPC Server handler 7 on default port 32769] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7102202a-cfaa-4337-9dc7-34f4538f3281 (127.0.0.1:34232).
2020-12-03 07:22:13,678 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 7102202a-cfaa-4337-9dc7-34f4538f3281) service to localhost/127.0.0.1:32769 successfully registered with NN
2020-12-03 07:22:13,678 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32769 using BLOCKREPORT_INTERVAL of 1000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:22:13,681 [IPC Server handler 9 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92 for DN 127.0.0.1:34232
2020-12-03 07:22:13,681 [IPC Server handler 9 on default port 32769] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1d152755-81c8-4f79-9d4f-33bedef5896a for DN 127.0.0.1:34232
2020-12-03 07:22:13,685 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1d0b49c148d01698: Processing first storage report for DS-1d152755-81c8-4f79-9d4f-33bedef5896a from datanode 7102202a-cfaa-4337-9dc7-34f4538f3281
2020-12-03 07:22:13,685 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1d0b49c148d01698: from storage DS-1d152755-81c8-4f79-9d4f-33bedef5896a node DatanodeRegistration(127.0.0.1:34232, datanodeUuid=7102202a-cfaa-4337-9dc7-34f4538f3281, infoPort=44705, infoSecurePort=0, ipcPort=44246, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,685 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1d0b49c148d01698: Processing first storage report for DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92 from datanode 7102202a-cfaa-4337-9dc7-34f4538f3281
2020-12-03 07:22:13,686 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1d0b49c148d01698: from storage DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92 node DatanodeRegistration(127.0.0.1:34232, datanodeUuid=7102202a-cfaa-4337-9dc7-34f4538f3281, infoPort=44705, infoSecurePort=0, ipcPort=44246, storageInfo=lv=-57;cid=testClusterID;nsid=1083088715;c=1606980131166), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,686 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1d0b49c148d01698,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,686 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,752 [IPC Server handler 0 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,754 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:13,764 [IPC Server handler 2 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,766 [Listener at localhost/44246] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:13,767 [IPC Server handler 3 on default port 32769] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,769 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:13,770 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:13,772 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:13,772 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b3ecd72] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:13,774 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1d152755-81c8-4f79-9d4f-33bedef5896a) exiting.
2020-12-03 07:22:13,774 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-92dd0555-3536-4bfd-a48c-1ba4e418ba92) exiting.
2020-12-03 07:22:13,801 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@fec53b0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:13,802 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70bf9792{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:13,802 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@88267c4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:13,803 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24298a38{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:13,817 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44246
2020-12-03 07:22:13,822 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:13,823 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:13,824 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:13,824 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 7102202a-cfaa-4337-9dc7-34f4538f3281) service to localhost/127.0.0.1:32769
2020-12-03 07:22:13,824 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 7102202a-cfaa-4337-9dc7-34f4538f3281)
2020-12-03 07:22:13,825 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,825 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:13,825 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:13,828 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:13,829 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:13,830 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:13,830 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:13,832 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:13,833 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:13,833 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:13,833 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@36c0b07c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:13,835 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-b9a38f1f-87d4-41fe-a2c6-bbb997f8afba) exiting.
2020-12-03 07:22:13,835 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-9adabb52-d865-46d4-93fc-afaabc6f9654) exiting.
2020-12-03 07:22:13,868 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6ee78535{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:13,868 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@47b5d0f0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:13,870 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78b85f00{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:13,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6dcc11e8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:13,882 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45411
2020-12-03 07:22:13,893 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:13,893 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:13,902 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:13,902 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid d67a3d92-c8df-4084-a251-fc76a5f50806) service to localhost/127.0.0.1:32769
2020-12-03 07:22:13,902 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid d67a3d92-c8df-4084-a251-fc76a5f50806)
2020-12-03 07:22:13,902 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,903 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:13,903 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:13,909 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:13,909 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:13,910 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:13,910 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:13,917 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:13,918 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:13,918 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:13,918 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4bda6012] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:13,920 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-4d2d8171-8511-4b1b-95a3-f32fe528eeb8) exiting.
2020-12-03 07:22:13,920 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c2472ba8-8815-4c0d-933f-b91c8cb1c918) exiting.
2020-12-03 07:22:13,972 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6920966c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:13,973 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1167b60f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:13,976 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@34f77daf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:13,978 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77013cd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:13,985 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36032
2020-12-03 07:22:13,986 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:13,989 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:13,990 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:13,990 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid bc72f8cb-93b8-4b2e-993a-c8bbdee9375e) service to localhost/127.0.0.1:32769
2020-12-03 07:22:13,990 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid bc72f8cb-93b8-4b2e-993a-c8bbdee9375e)
2020-12-03 07:22:13,990 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:13,991 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:13,993 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:14,000 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:14,000 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:14,002 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:14,002 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:14,003 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:14,003 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:14,003 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:14,003 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1edd9b7e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:14,006 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-99a86e9a-e753-4d49-b03e-798de2a8e737) exiting.
2020-12-03 07:22:14,010 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a968b7de-b78d-4fc3-aa5c-08fa178dace0) exiting.
2020-12-03 07:22:14,061 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@513ceb19{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:14,062 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b838fde{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:14,064 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@578f42b7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:14,066 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e895f4d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:14,073 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36163
2020-12-03 07:22:14,074 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:14,074 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:14,075 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:14,075 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 0ce8c028-cb77-4ad0-a523-42ee6ee563cc) service to localhost/127.0.0.1:32769
2020-12-03 07:22:14,075 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-11750243-172.17.0.6-1606980131166 (Datanode Uuid 0ce8c028-cb77-4ad0-a523-42ee6ee563cc)
2020-12-03 07:22:14,075 [BP-11750243-172.17.0.6-1606980131166 heartbeating to localhost/127.0.0.1:32769] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-11750243-172.17.0.6-1606980131166
2020-12-03 07:22:14,081 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:14,081 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-11750243-172.17.0.6-1606980131166] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:14,114 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:14,115 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:14,116 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:14,116 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:14,117 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:14,117 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:14,117 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:14,125 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:22:14,125 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4faa3b89] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:14,125 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5a4ca169] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:14,128 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 18 4 
2020-12-03 07:22:14,130 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:14,132 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:14,133 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:14,133 [CacheReplicationMonitor(1940445598)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:14,154 [main] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32769
2020-12-03 07:22:14,157 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:14,158 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:14,159 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:14,159 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:14,170 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:14,170 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:14,187 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@15ec4127{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:14,189 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c0aab4c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:14,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c44afb8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:14,195 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a08fc01{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:14,196 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:14,199 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:14,199 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
